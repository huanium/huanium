{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc1b05b4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color = 'black'> Notes </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eef196db",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Author: Huan Q. Bui\n",
    "\n",
    "Affiliation: BEC1 experiment at Zlabs, MIT\n",
    "             \n",
    "PI: Professor Martin Zwierlein\n",
    "\n",
    "First updated: Feb 07, 2023\n",
    "\n",
    "Last updated: April 06, 2023\n",
    "\n",
    "To do:\n",
    "- Implement returning Fermi energy from Box Exp shots\n",
    "- Compressibility!\n",
    "- Implement bootstrapping\n",
    "- Intelligent Box Exp cutting\n",
    "- Try thermometry on Box Exp shots\n",
    "- Rapid ramp analysis (condensate fraction fit)\n",
    "- Na BEC fitting (condensate fraction fit)\n",
    "- Li MT LF thermometry. This is a good starting point for hybrid trap thermometry.\n",
    "- Simulate compressible fluid in a box with a perturbing side wall?\n",
    "- Breit Rabi calculator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28ef2da4",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'> Setting up </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05e01da4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  <font size=3, color=#399FD5>Collapsible Headings and Initialization Cells</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1422a2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Run the following commands in anaconda prompt to install a graphical interface for configuring collapsible headings and other extentions/plugins from within the notebooks:\n",
    "\n",
    "pip install jupyter_contrib_nbextensions\n",
    "jupyter contrib nbextension install --user\n",
    "jupyter nbextensions_configurator enable --user\n",
    "\n",
    "Once done, go to Jupyter notebook --> Nbextensions --> check the \"Collapsible Headings\" box\n",
    "\n",
    "Can also turn on \"Initialization cell\" in Jupyter Notebook extension settings. \n",
    "Then go to View/Cell Toolbar/Initialization Cell and check cells that will be run on startup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54c4e9be",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Imports and Parallel Computing Setup</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2253dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.178800Z",
     "start_time": "2023-03-08T02:54:44.172006Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from tkinter import Tk\n",
    "from tkinter import filedialog # for prompting user to set analysis folder\n",
    "import glob\n",
    "import json\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import os\n",
    "import scipy\n",
    "from scipy.optimize import fsolve\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.integrate import trapezoid\n",
    "from scipy.signal import savgol_filter\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "import numba\n",
    "import shutil\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae714af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.186070Z",
     "start_time": "2023-03-08T02:54:44.181162Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# for parallel processing\n",
    "import contextlib\n",
    "import joblib\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c5e9bc9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Suppress Warnings</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65376db9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.190501Z",
     "start_time": "2023-03-08T02:54:44.187837Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b43d457",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size = 3, color=#399FD5>Constants</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83028873",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.196542Z",
     "start_time": "2023-03-08T02:54:44.193306Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "ABSORPTION_LIMIT = 5.0\n",
    "SPECIAL_CHARACTERS = \"!@#$%^&*()-+?_=,<>/\"\n",
    "\n",
    "# physics constants\n",
    "hbar = 1.05457182*10**(-34) # Js\n",
    "\n",
    "# Lithium constants\n",
    "mLi6 = 9.9883414*10**(-27) # kg\n",
    "Li6D2Gamma = 5.8724 # MHz. Note that this is NOT angular freq\n",
    "Li6D2lambda0 = 670.977338*10**(-9) # meters\n",
    "Li6D2sigma0 = 3*(Li6D2lambda0)**2/(2*np.pi)\n",
    "\n",
    "# Sodium constants\n",
    "mNa23 = 0.381754035*10**(-25) # kg "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef33df1f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'>Utility functions </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b787925",
   "metadata": {},
   "source": [
    "## <font size=3, color=#399FD5>Mathematical functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea891495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _absorption_coefficient(omega, amp, omega0, gamma_prime, offset):\n",
    "    return amp * gamma_prime**2/ ( 4*(omega-omega0)**2 + gamma_prime**2) + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef727e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _P2_Rabi(omega_and_tau, omegaR, omega0, offset):\n",
    "    omega = omega_and_tau[0]\n",
    "    tau = omega_and_tau[1]    \n",
    "    OmegaR = np.sqrt( omegaR**2 + (omega - omega0)**2 )\n",
    "    return ( omegaR**2 / OmegaR**2) * np.sin( 2*np.pi*OmegaR * tau * 10**(6-3)/ 2)**2 + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c330e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cosine(t, amp, omega0, phi, offset):\n",
    "    return amp * np.cos(2*np.pi*(t*omega0 + phi)) + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996bc313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parabola(x, curvature, gradient, bias):\n",
    "    return curvature*x**2 + gradient*x + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ca012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gaussian(x, center, amp, sigma, offset):\n",
    "    return amp * np.exp(-(x-center)**2/(2*sigma**2)) + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe65eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lorentzian(omega, amp, omega0, gamma_prime, offset):\n",
    "    return amp * gamma_prime**2/ ( 4*(omega-omega0)**2 + gamma_prime**2) + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lorentzian_no_offset(omega, amp, omega0, gamma_prime):\n",
    "    return amp * gamma_prime**2/ ( 4*(omega-omega0)**2 + gamma_prime**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a33119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(z, amplitude, center, sharpness, width, offset):\n",
    "    return (-1/(1 + np.exp((-(z - center) + width/2)/sharpness)) + 1/(1 + np.exp((-(z - center) - width/2)/sharpness)) )*amplitude + offset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60f0c90e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get run parameters</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcdcedd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.200933Z",
     "start_time": "2023-03-08T02:54:44.197672Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_run_param_from_filename(folder_path, current_file_fullpath, metadata_dict = dict(), param = ''):\n",
    "    '''\n",
    "    get a single parameter value from a file, if metadata)dict exists:\n",
    "    '''\n",
    "    param_for_filename = 0\n",
    "    name = str(current_file_fullpath.split(folder_path)[1]).replace('\\\\',\"\")\n",
    "    run_id = name.split('_')[0]\n",
    "    run_id = \"\".join(ch for ch in run_id if ch.isalnum() ) # extract run_id out of folder name\n",
    "    # get params for this run_id\n",
    "    if bool(metadata_dict):\n",
    "        params_for_run_id = metadata_dict[run_id]\n",
    "        param_for_filename = params_for_run_id[param]\n",
    "    return param_for_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c0e8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.206384Z",
     "start_time": "2023-03-08T02:54:44.202167Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_run_params_for_data_frame(folder_path, metadata_dict = dict(), params = []):\n",
    "    '''\n",
    "    params: list of param names [p1,p2,...]\n",
    "    returns a dictionary of the form {p1: [], p2: [],...}\n",
    "    '''\n",
    "    params_for_folder = dict() # this is a dict() of lists\n",
    "    # initial params_for_folder:\n",
    "    if params != []:\n",
    "        for p in params:\n",
    "            params_for_folder[p] = []\n",
    "    if bool(metadata_dict): \n",
    "        for f in sorted(glob.glob(folder_path + '/*.fits')): # for every fits file in folder\n",
    "            name = str(f.split(folder_path)[1]).replace('\\\\',\"\")\n",
    "            run_id = name.split('_')[0] \n",
    "            run_id = \"\".join(ch for ch in run_id if ch.isalnum() )\n",
    "\n",
    "            if run_id in metadata_dict.keys():\n",
    "                # get params for this run_id\n",
    "                params_for_run_id = metadata_dict[run_id]\n",
    "                for k in params_for_folder.keys():\n",
    "                    params_for_folder[k].append(params_for_run_id[k])\n",
    "                \n",
    "    return params_for_folder\n",
    "\n",
    "### EXAMPLE CODE: ####\n",
    "# params = get_run_params(folder_path, params = ['LFImgFreq', 'SideGreenEvap', 'IREvap'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ae6e0fe",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Initialize data frame</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced32705",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.216815Z",
     "start_time": "2023-03-08T02:54:44.207660Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def init_dataframe_metadata_and_exp_params(optional_parameter_list = []):\n",
    "\n",
    "    folder_path = filedialog.askdirectory()\n",
    "    metadata_dict = dict()\n",
    "    experiment_parameters_dict = dict()\n",
    "    \n",
    "    # load metadata if avalable:\n",
    "    metadata_fullpath_load_status = False\n",
    "    metadata_fullpath = folder_path + \"/run_params_dump.json\"\n",
    "    if os.path.isfile(metadata_fullpath):\n",
    "        metadata_fullpath_load_status = True\n",
    "        with open(metadata_fullpath, 'r') as json_file:\n",
    "            metadata_dict = json.load(json_file)  \n",
    "\n",
    "    # load experiment_parameters if avaiable:\n",
    "    experiment_parameters_fullpath_load_status = False\n",
    "    experiment_parameters_fullpath = folder_path + \"/experiment_parameters.json\"\n",
    "    if os.path.isfile(experiment_parameters_fullpath):\n",
    "        experiment_parameters_fullpath_load_status = True\n",
    "        with open(experiment_parameters_fullpath, 'r') as json_file:\n",
    "            experiment_parameters_dict = json.load(json_file)  \n",
    "            \n",
    "    # construct data frame with full paths:\n",
    "    image_list = sorted(glob.glob(folder_path + '/*.fits'))\n",
    "    data_frame = pd.DataFrame()\n",
    "    \n",
    "    # get file names for readability and attach to data frame:\n",
    "    # also get image type: TopA, TopB, Side\n",
    "    run_ids = []\n",
    "    image_type = []\n",
    "    ImagFreq1 = []\n",
    "    ImagFreq2 = []\n",
    "    LFImgFreq = []\n",
    "    image_list_df = []\n",
    "    for f in image_list:\n",
    "        \n",
    "        # add run_id\n",
    "        name = str(f.split(folder_path)[1]).replace('\\\\',\"\")\n",
    "        run_id = name.split('_')[0] \n",
    "        run_id = \"\".join(ch for ch in run_id if ch.isalnum() )\n",
    "        \n",
    "        if run_id in metadata_dict.keys():\n",
    "            run_ids.append(run_id)\n",
    "            # add path to image_list_df:\n",
    "            image_list_df.append(f)\n",
    "            # add image type\n",
    "            if 'TopA' in name:\n",
    "                image_type.append('TopA')\n",
    "            elif 'TopB' in name:\n",
    "                image_type.append('TopB')\n",
    "            elif 'Side' in name:\n",
    "                image_type.append('Side')\n",
    "\n",
    "            # add ImagFreq, only if metadata_dict is available:\n",
    "            if bool(metadata_dict):\n",
    "                ImagFreq1.append(get_run_param_from_filename(folder_path, f, metadata_dict, 'ImagFreq1'))\n",
    "                ImagFreq2.append(get_run_param_from_filename(folder_path, f, metadata_dict, 'ImagFreq2'))\n",
    "                LFImgFreq.append(get_run_param_from_filename(folder_path, f, metadata_dict, 'LFImgFreq'))\n",
    "                    \n",
    "    data_frame['fullpaths'] = image_list_df\n",
    "    data_frame['good_shot'] = [True for i in range(len(image_list_df))]\n",
    "    data_frame['run_id'] = run_ids\n",
    "    data_frame['image_type'] = image_type\n",
    "    if bool(metadata_dict):\n",
    "        data_frame['ImagFreq1'] = ImagFreq1\n",
    "        data_frame['ImagFreq2'] = ImagFreq2\n",
    "        data_frame['LFImgFreq'] = LFImgFreq\n",
    "    \n",
    "    # add relevant parameters to dataframe... can always add more later:\n",
    "    run_params = get_run_params_for_data_frame(folder_path, metadata_dict, optional_parameter_list)\n",
    "    # add data to dataframe:\n",
    "    if bool(run_params):\n",
    "        for param in run_params.keys():\n",
    "            data_frame[param] = run_params[param]\n",
    "    \n",
    "    ##################################################\n",
    "    ############## PRINT OUT STATUS ##################\n",
    "    ##################################################\n",
    "\n",
    "    print('Current folder: ' + folder_path)\n",
    "    if metadata_fullpath_load_status:\n",
    "        print('Metadata loaded')\n",
    "    else:\n",
    "        print('No metadata to load') \n",
    "    if experiment_parameters_fullpath_load_status:\n",
    "        print('Experiment parameters loaded')\n",
    "    else:\n",
    "        print('No experiment parameters to load')\n",
    "    print('Data frame initialized!')\n",
    "\n",
    "    return (data_frame, metadata_dict, experiment_parameters_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db70e83a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Display image</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd89fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.220149Z",
     "start_time": "2023-03-08T02:54:44.217909Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# function for safely handling subtractions...\n",
    "# Credit: Eric A. Wolf, BEC1@MIT, 2022. \n",
    "\n",
    "def safe_subtract(x, y, minimum_cast = np.byte):\n",
    "    newtype = np.result_type(x, y, minimum_cast)\n",
    "    return x.astype(newtype) - y.astype(newtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148967aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.233229Z",
     "start_time": "2023-03-08T02:54:44.221318Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# display an image given folder_path, run_id, ROI, and frame_type:\n",
    "def display_image(current_file_fullpath, ROI, norm_box, \n",
    "                  frame_type = 'FakeOD', min_scale=0, max_scale=1.3, brightness=12):\n",
    "    # set up figure\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # read image\n",
    "    fits_image = fits.open(current_file_fullpath)\n",
    "    # fits_image.info() # display fits image info\n",
    "    img = fits_image[0].data\n",
    "    fits_image.close()\n",
    "\n",
    "    # get dims of image\n",
    "    dims = img[0,:,:].shape \n",
    "    x_limit = dims[1]\n",
    "    y_limit = dims[0]\n",
    "\n",
    "    # then show image:\n",
    "    if frame_type == 'OD':\n",
    "        frame = (-np.log(safe_subtract(img[0,:,:], img[2,:,:])/safe_subtract(img[1,:,:], img[2,:,:])))\n",
    "        # clean image: using nan_to_num\n",
    "        frame = np.nan_to_num(frame, nan=ABSORPTION_LIMIT)\n",
    "        # fix clipping\n",
    "        frame = np.clip(frame, 0, ABSORPTION_LIMIT)\n",
    "        ax.imshow(frame, cmap='gray', vmin=0, vmax=2**15).set_clim(min_scale, max_scale)\n",
    "        ax.invert_yaxis()\n",
    "\n",
    "    else:\n",
    "        if frame_type == 'FakeOD':\n",
    "            frame = (safe_subtract(img[0,:,:], img[2,:,:])/safe_subtract(img[1,:,:], img[2,:,:]))\n",
    "            # clean image: using nan_to_num\n",
    "            frame = np.nan_to_num(frame)\n",
    "            # fix clipping\n",
    "            frame = np.clip(frame, 0, ABSORPTION_LIMIT)\n",
    "            ax.imshow(frame, cmap='gray', vmin=0, vmax=2**15).set_clim(min_scale, max_scale)\n",
    "            ax.invert_yaxis()\n",
    "        else:\n",
    "            if frame_type == 'With atoms':\n",
    "                frame = img[0,:,:]\n",
    "                # clean image: using nan_to_num\n",
    "                frame = np.nan_to_num(frame)\n",
    "                ax.imshow(frame, cmap='gray', vmin=0, vmax=2**brightness)  # need to adjust gray scale/colormap here with BRIGHTNESS variable\n",
    "                ax.invert_yaxis()\n",
    "            elif frame_type == 'Without atoms':\n",
    "                frame = img[1,:,:]\n",
    "                # clean image: using nan_to_num\n",
    "                frame = np.nan_to_num(frame)\n",
    "                ax.imshow(frame, cmap='gray', vmin=0, vmax=2**brightness)  # need to adjust gray scale/colormap here with BRIGHTNESS variable\n",
    "                ax.invert_yaxis()\n",
    "            elif frame_type == 'Dark':\n",
    "                frame = img[2,:,:]\n",
    "                # clean image: using nan_to_num\n",
    "                frame = np.nan_to_num(frame)\n",
    "                ax.imshow(frame, cmap='gray', vmin=0, vmax=2**brightness)  # need to adjust gray scale/colormap here with BRIGHTNESS variable\n",
    "                ax.invert_yaxis()\n",
    "            else:\n",
    "                frame = (-np.log(safe_subtract(img[0,:,:], img[2,:,:])/safe_subtract(img[1,:,:], img[2,:,:])))\n",
    "                # clean image: using nan_to_num\n",
    "                frame = np.nan_to_num(frame)\n",
    "                ax.imshow(frame, cmap='gray', vmin=0, vmax=2**15).set_clim(min_scale, max_scale)\n",
    "                ax.invert_yaxis()\n",
    "                \n",
    "    # Create a roi patch\n",
    "    width = abs(int(ROI[1]) - int(ROI[0]))\n",
    "    height = abs(int(ROI[3]) - int(ROI[2]))\n",
    "    xmin = min(int(ROI[0]), int(ROI[1]))\n",
    "    ymin = min(int(ROI[2]), int(ROI[3]))\n",
    "    roi = patches.Rectangle((xmin, ymin), \n",
    "                             width, \n",
    "                             height, \n",
    "                             linewidth=1, \n",
    "                             edgecolor='r', \n",
    "                             facecolor='none')\n",
    "    # Add the ROI to the Axes\n",
    "    ax.add_patch(roi)\n",
    "    \n",
    "    # Create a norm_box patch\n",
    "    width_norm = abs(int(norm_box[1]) - int(norm_box[0]))\n",
    "    height_norm = abs(int(norm_box[3]) - int(norm_box[2]))\n",
    "    xmin_norm = min(int(norm_box[0]), int(norm_box[1]))\n",
    "    ymin_norm = min(int(norm_box[2]), int(norm_box[3]))\n",
    "    \n",
    "    norm_roi = patches.Rectangle((xmin_norm, ymin_norm), \n",
    "                             width_norm, \n",
    "                             height_norm, \n",
    "                             linewidth=1, \n",
    "                             edgecolor='g', \n",
    "                             facecolor='none')\n",
    "    # Add the ROI to the Axes\n",
    "    ax.add_patch(roi)\n",
    "    ax.add_patch(norm_roi)   \n",
    "    \n",
    "    # add center of ROI box to image:\n",
    "    ROI_center = [(ROI[2] + ROI[3])//2, (ROI[0] + ROI[1])//2]\n",
    "    ax.scatter([ROI_center[1]],[ROI_center[0]], marker='.', color = 'red', s=1)\n",
    "    \n",
    "    # show everything\n",
    "    plt.show()\n",
    "                \n",
    "    return (fig, ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c56e0f5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Add normalized FakeOD to dataframe</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b00dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.240749Z",
     "start_time": "2023-03-08T02:54:44.236107Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_fakeOD_cropped(current_file_fullpath, ROI, norm_box):\n",
    "    \n",
    "    # memmapping:\n",
    "    with fits.open(current_file_fullpath, memmap = True, do_not_scale_image_data = True) as fits_image:\n",
    "        img = fits_image[0].data\n",
    "    \n",
    "    # get fakeOD image and crop it\n",
    "    wa_roi   = img[0, ROI[2]:ROI[3], ROI[0]:ROI[1]]\n",
    "    woa_roi  = img[1, ROI[2]:ROI[3], ROI[0]:ROI[1]]\n",
    "    dark_roi = img[2, ROI[2]:ROI[3], ROI[0]:ROI[1]]\n",
    "    wa_roi   = wa_roi.astype(float)\n",
    "    woa_roi  = woa_roi.astype(float)\n",
    "    dark_roi = dark_roi.astype(float)\n",
    "    \n",
    "    wa_nb   = img[0, norm_box[2]:norm_box[3], norm_box[0]:norm_box[1]]\n",
    "    woa_nb  = img[1, norm_box[2]:norm_box[3], norm_box[0]:norm_box[1]]\n",
    "    dark_nb = img[2, norm_box[2]:norm_box[3], norm_box[0]:norm_box[1]]\n",
    "    wa_nb   = wa_nb.astype(float)\n",
    "    woa_nb  = woa_nb.astype(float)\n",
    "    dark_nb = dark_nb.astype(float)\n",
    "    \n",
    "    wa_over_woa_factor = sum(sum(wa_nb))/sum(sum(woa_nb))\n",
    "    adjusted_woa_roi = woa_roi*wa_over_woa_factor\n",
    "        \n",
    "    fakeOD = safe_subtract(wa_roi, dark_roi)/safe_subtract(adjusted_woa_roi,dark_roi)\n",
    "    \n",
    "    return fakeOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145d81a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.245160Z",
     "start_time": "2023-03-08T02:54:44.241815Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_background_subtracted_ROI_to_dataframe_fast(df, ROI, norm_box): \n",
    "\n",
    "    # now add fakeOD with background subtraction to dataframe:\n",
    "    fake_od_background_subtracted_roi = []        \n",
    "    with tqdm_joblib(tqdm(desc=\"Loading ROIs\", total = len(df['fullpaths']))) as progress_bar:\n",
    "        fake_od_background_subtracted_roi = Parallel(n_jobs=-2)(delayed(get_fakeOD_cropped)(df['fullpaths'][i],\n",
    "                                                                                            ROI, \n",
    "                                                                                            norm_box) \n",
    "                                                 for i in range(len(df['fullpaths'])))    \n",
    "    # update dataframe:\n",
    "    df['fakeOD_roi'] = fake_od_background_subtracted_roi\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd38da8c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Pixel summing</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddf83bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.249547Z",
     "start_time": "2023-03-08T02:54:44.246484Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_pixel_sums_to_data_frame_from_FakeOD_ROI(df):\n",
    "    if 'fakeOD_roi' in df.columns:\n",
    "        pixel_sums = []\n",
    "        for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "            # first compute od from cleaned fakeOD:\n",
    "            od = -np.log(row['fakeOD_roi'])\n",
    "            # now clean od:\n",
    "            od = np.nan_to_num(od)\n",
    "            # fix clipping\n",
    "            od = np.clip(od, 0, ABSORPTION_LIMIT)\n",
    "            od = od.astype(np.float)\n",
    "\n",
    "            pixel_sums.append(sum(sum(od)))\n",
    "\n",
    "        # update dataframe:\n",
    "        df['pixel_sum'] = pixel_sums\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffe3864f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get atom densities from absorption images</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faaa569",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some theory for atom counting. The 2D atom density, including the effect of saturation, is given by \n",
    "\n",
    "$n_{2d}(x,y) = \\int n_{3d}(x,y,z)\\,dz = -\\frac{1+I/I_\\text{sat}(\\omega)}{\\sigma(\\omega)} \\ln \\frac{I_f}{I_0} = \\frac{1+s\\sigma(\\omega)/\\sigma_0}{\\sigma(\\omega)} \\times \\text{OD}, $ \n",
    "\n",
    "where $\\kappa(\\omega, I) = \\frac{n_{2d} \\sigma(\\omega)}{1 + I / I_\\text{sat}(\\omega)}$ is the absorption coefficient, \n",
    "$\\sigma(\\omega) = \\sigma_0 \\frac{\\Gamma^2/4}{(\\omega-\\omega_0)^2 + \\Gamma^2/4}$, and $\\sigma_0 = \\frac{3\\lambda_0^2}{2\\pi}$.\n",
    "\n",
    "So, after the fit has been done, we know $\\omega_0$ and $s$. Since $\\sigma_0$ is known, we can calculate $(1+s \\sigma(\\omega)/\\sigma_0)/\\sigma(\\omega)$ for every shot. From here, we can obtain $n_{2d}$ from knowing the OD (which comes from the image). Finally, to obtain the atom number, we just multiply the atom density $n_{2d}$ by the pixel size and integrate over the entire image to get $N$. \n",
    "\n",
    "Notice that we have not considered the fact that for (nearly) blacked out clouds the saturation parameter changes as a function of the line of integration. How might we take this into account? Consider the Beer-Lambert law, which says \n",
    "\n",
    "$ \\frac{dI}{I} = -\\kappa(I, \\omega) \\,dz = -n\\sigma_0 \\frac{\\Gamma^2/4}{\\delta^2 + (1+s)\\Gamma^2/4} \\,dz \\implies \\int_{s_0}^{s_f} \\frac{1}{s} \\frac{\\Gamma^2/4}{\\delta^2 + (1+s)\\Gamma^2/4} \\,ds =  -n_{2d}\\sigma_0 $.\n",
    "\n",
    "where we have made the substitution $I \\to s I_\\text{sat},  I_0 \\to s_0 I_\\text{sat}, I_f \\to s_f I_\\text{sat}$ and integrated both sides, simplifying the integrand, we find that\n",
    "\n",
    "$-n_{2d} \\sigma_0 =  \\int_{s_0}^{s_f} 1 + \\frac{1 + 4\\delta^2/\\Gamma^2}{s}\\,ds = (s_f - s_0) + \\left( 1 + \\frac{4\\delta^2}{\\Gamma^2} \\right)\\ln \\frac{s_f}{s_0}.$\n",
    "\n",
    "From here, the atom density is readily found:\n",
    "\n",
    "$\\boxed{n_{2d} = -\\frac{1}{\\sigma_0} \\left[ \\left( 1 + \\frac{4\\delta^2}{\\Gamma^2} \\right) \\ln \\frac{I_f}{I_0} +  \\frac{I_f - I_0}{I_\\text{sat}}\\right] =  \\frac{1}{\\sigma_0} \\left( 1 + \\frac{4\\delta^2}{\\Gamma^2} \\right) \\times od  -\\frac{1}{\\sigma_0} \\frac{I_f - I_0}{I_\\text{sat}} = \\frac{od}{\\sigma(\\omega)}  -\\frac{1}{\\sigma_0} \\frac{I_f - I_0}{I_\\text{sat}} } $\n",
    "\n",
    "One final thing: how do we obtain $I_\\text{sat}$? There are several ways to do this, but one way is to obtain the saturation parameter $s$ from the imaging resonance curve fit, and then take the without atom shot and divide it by $s$ to get an approximation for $I_\\text{sat}$. \n",
    "\n",
    "Since the second term is typically much smaller than the first, in the interest of simplifying and making the analysis code faster we will drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f0a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.254303Z",
     "start_time": "2023-03-08T02:54:44.250638Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_atom_densities_abs_to_data_frame_Side_LF_fast(df, \n",
    "                                                      sigma0 = Li6D2sigma0,\n",
    "                                                      Gamma = Li6D2Gamma, \n",
    "                                                      s = 0, \n",
    "                                                      omega0 = 0,\n",
    "                                                      AOM_factor = -2):\n",
    "    # for now handle saturation parameter separately from data frame\n",
    "    '''\n",
    "    s: saturation parameters, default to 0\n",
    "    Assumes that df already has 'LFImgFreq'\n",
    "    '''\n",
    "    n2d = []\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        sigma = sigma0 * (Gamma**2/4) / ( (AOM_factor*(omega0 - row['LFImgFreq']))**2 + Gamma**2/4 )\n",
    "        # first compute od from cleaned fakeOD:\n",
    "        od = -np.log(row['fakeOD_roi'])\n",
    "        # now clean od:\n",
    "        od = np.nan_to_num(od)\n",
    "        # fix clipping\n",
    "        od = np.clip(od, 0, ABSORPTION_LIMIT)\n",
    "        od = od.astype(np.float)\n",
    "        # n2d = od/sigma(omega)\n",
    "        n2d.append(od/sigma)\n",
    "        \n",
    "    df['column_density'] = n2d\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417cf06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.259902Z",
     "start_time": "2023-03-08T02:54:44.255342Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_atom_densities_abs_to_data_frame_TopAB_fast(df, \n",
    "                                                    sigma0 = Li6D2sigma0,\n",
    "                                                    Gamma = Li6D2Gamma, \n",
    "                                                    s_A = 0, s_B = 0,\n",
    "                                                    omega0_A = 0, omega0_B = 0,\n",
    "                                                    AOM_factor = -2):\n",
    "    \n",
    "    # for now handle saturation parameter separately from data frame\n",
    "    '''\n",
    "    s_A, s_B: saturation parameters, default to 0\n",
    "    For now, the saturation parameters are not used\n",
    "    Assumes that df already has 'ImagFreq1' and 'ImagFreq2'\n",
    "    '''\n",
    "    # since imaging from top is not along quantization axis, cross section is reduced by 2\n",
    "    top_imaging_factor = 0.5\n",
    "    sigma0 = sigma0 * top_imaging_factor\n",
    "    \n",
    "    n2d = []\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        if row['image_type'] == 'TopA':\n",
    "            sigma = sigma0 * (Gamma**2/4) / ((AOM_factor*(omega0_A - row['ImagFreq1']))**2 + Gamma**2/4 )        \n",
    "        elif row['image_type'] == 'TopB':\n",
    "            sigma = sigma0 * (Gamma**2/4) / ((AOM_factor*(omega0_B - row['ImagFreq2']))**2 + Gamma**2/4 )\n",
    "        else:\n",
    "            print('NOT YET SUPPORTED!')\n",
    "        # first compute od from cleaned fakeOD:\n",
    "        od = -np.log(row['fakeOD_roi'])\n",
    "        # now clean od:\n",
    "        od = np.nan_to_num(od)\n",
    "        # fix clipping\n",
    "        od = np.clip(od, 0, ABSORPTION_LIMIT)\n",
    "        od = od.astype(np.float)\n",
    "        \n",
    "        # n2d = od/sigma(omega)\n",
    "        n2d.append(od/sigma)\n",
    "\n",
    "    # update dataframe\n",
    "    df['column_density'] = n2d   \n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c36162c5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Polarization Rotation Imaging Functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f96c82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.267121Z",
     "start_time": "2023-03-08T02:54:44.260991Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True, cache=True)\n",
    "def polrot_equations(actual_ods, *params):\n",
    "        \n",
    "    od0_1, od0_2 = actual_ods\n",
    "    \n",
    "    observed_fakeOD_A, observed_fakeOD_B, detuning_A_1, detuning_A_2, detuning_B_1, detuning_B_2, phase_sign, Li6D2Gamma = params\n",
    "    \n",
    "    odA_1 = od0_1 / (1 + pow(2*detuning_A_1/Li6D2Gamma,2))\n",
    "    odA_2 = od0_2 / (1 + pow(2*detuning_A_2/Li6D2Gamma,2))\n",
    "    odB_1 = od0_1 / (1 + pow(2*detuning_B_1/Li6D2Gamma,2))\n",
    "    odB_2 = od0_2 / (1 + pow(2*detuning_B_2/Li6D2Gamma,2))\n",
    "    \n",
    "    aA = math.exp( -(odA_1 + odA_2)/2.0)\n",
    "    aB = math.exp( -(odB_1 + odB_2)/2.0)\n",
    "    phiA = phase_sign*(-detuning_A_1*odA_1 - detuning_A_2*odA_2)/Li6D2Gamma\n",
    "    phiB = phase_sign*(-detuning_B_1*odB_1 - detuning_B_2*odB_2)/Li6D2Gamma\n",
    "    \n",
    "    return ( (1/2 + aA**2/2) - aA*math.sin(phiA) - observed_fakeOD_A, \n",
    "             (1/2 + aB**2/2) - aB*math.sin(phiB) - observed_fakeOD_B )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f60cf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.271458Z",
     "start_time": "2023-03-08T02:54:44.268005Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def polrot_solve(fake_OD_roi_A, fake_OD_roi_B, detuning_A_1, detuning_A_2, detuning_B_1, detuning_B_2, polrot_phase_sign, height, width):   \n",
    "    \n",
    "    # prepare od0_1 and od0_2:\n",
    "    od0_1 = np.empty([height, width])\n",
    "    od0_2 = np.empty([height, width])\n",
    "    \n",
    "    # now process:\n",
    "    for h in range(height):\n",
    "        for w in range(width):\n",
    "            od0_1[h][w], od0_2[h][w] =  fsolve(polrot_equations, \n",
    "                                               (0,0), # this is a fakeOD guess \n",
    "                                               args = (fake_OD_roi_A[h][w], \n",
    "                                                       fake_OD_roi_B[h][w], \n",
    "                                                       detuning_A_1, \n",
    "                                                       detuning_A_2, \n",
    "                                                       detuning_B_1, \n",
    "                                                       detuning_B_2,\n",
    "                                                       polrot_phase_sign,\n",
    "                                                       Li6D2Gamma),\n",
    "                                               xtol=1e-10, \n",
    "                                               maxfev=2000)\n",
    "    return od0_1, od0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd063e24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.280380Z",
     "start_time": "2023-03-08T02:54:44.272497Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_polrot_column_densities_to_dataframe(df_PR, exp_params_dict_PR, ROI_PR):\n",
    "\n",
    "    # get imaging parameters:\n",
    "    state_1_unitarity_res_freq_MHz = exp_params_dict_PR[\"Values\"]['state_1_unitarity_res_freq_MHz']\n",
    "    state_3_unitarity_res_freq_MHz = exp_params_dict_PR[\"Values\"]['state_3_unitarity_res_freq_MHz']\n",
    "    li_hf_freq_multiplier = exp_params_dict_PR[\"Values\"][\"li_hf_freq_multiplier\"]\n",
    "    polrot_phase_sign = exp_params_dict_PR[\"Values\"][\"polrot_phase_sign\"]\n",
    "    \n",
    "    # these variables are added recently:\n",
    "    hf_lock_setpoint = 0\n",
    "    hf_lock_unitarity_resonance_value = 0\n",
    "    if \"hf_lock_setpoint\" in exp_params_dict_PR[\"Values\"] and \"hf_lock_unitarity_resonance_value\" in exp_params_dict_PR[\"Values\"]:\n",
    "        hf_lock_setpoint = exp_params_dict_PR[\"Values\"][\"hf_lock_setpoint\"]\n",
    "        hf_lock_unitarity_resonance_value = exp_params_dict_PR[\"Values\"][\"hf_lock_unitarity_resonance_value\"]\n",
    "\n",
    "    # calculate imaging parameters to \n",
    "    omega0_1 = state_1_unitarity_res_freq_MHz # resonance freq for state 1\n",
    "    omega0_2 = state_3_unitarity_res_freq_MHz # resonance freq for state 3\n",
    "    omega_A  = df_PR['ImagFreq1'][0] - (hf_lock_setpoint-hf_lock_unitarity_resonance_value)/li_hf_freq_multiplier \n",
    "    omega_B  = df_PR['ImagFreq2'][0] - (hf_lock_setpoint-hf_lock_unitarity_resonance_value)/li_hf_freq_multiplier \n",
    "\n",
    "    detuning_A_1 = (-omega0_1 + omega_A)*li_hf_freq_multiplier\n",
    "    detuning_A_2 = (-omega0_2 + omega_A)*li_hf_freq_multiplier\n",
    "    detuning_B_1 = (-omega0_1 + omega_B)*li_hf_freq_multiplier\n",
    "    detuning_B_2 = (-omega0_2 + omega_B)*li_hf_freq_multiplier\n",
    "\n",
    "    # get size of ROI:\n",
    "    height = ROI_PR[3] - ROI_PR[2]\n",
    "    width  = ROI_PR[1] - ROI_PR[0] \n",
    "\n",
    "    # shouldn't pass the entire data frame to processes... since there's a lot of extra info that we won't need:\n",
    "    # instead make list of images:\n",
    "    fake_OD_roi_A = []\n",
    "    fake_OD_roi_B = []\n",
    "    \n",
    "    # implement clever...\n",
    "    for i in range(0, len(df_PR), 2):\n",
    "        if df_PR['image_type'][i] == 'TopA' and df_PR['image_type'][i+1] == 'TopB':\n",
    "            fake_OD_roi_A.append(df_PR['fakeOD_roi'][i])\n",
    "            fake_OD_roi_B.append(df_PR['fakeOD_roi'][i+1])\n",
    "        elif df_PR['image_type'][i] == 'TopB' and df_PR['image_type'][i+1] == 'TopA':\n",
    "            fake_OD_roi_A.append(df_PR['fakeOD_roi'][i+1])\n",
    "            fake_OD_roi_B.append(df_PR['fakeOD_roi'][i])\n",
    "                    \n",
    "    with tqdm_joblib(tqdm(desc=\"Solving images\", total= len(df_PR)//2)) as progress_bar:\n",
    "        results = Parallel(n_jobs=-2)(delayed(polrot_solve)(fake_OD_roi_A = fake_OD_roi_A[i], \n",
    "                                                            fake_OD_roi_B = fake_OD_roi_B[i],\n",
    "                                                            detuning_A_1 = detuning_A_1, \n",
    "                                                            detuning_A_2 = detuning_A_2, \n",
    "                                                            detuning_B_1 = detuning_B_1, \n",
    "                                                            detuning_B_2 = detuning_B_2, \n",
    "                                                            polrot_phase_sign = polrot_phase_sign,\n",
    "                                                            height = height, \n",
    "                                                            width = width) \n",
    "                                      for i in range(len(df_PR)//2))\n",
    "    # remember that factor of 2 reduction in the cross section when imaging from Top:\n",
    "    PR_densities = []\n",
    "    for r in results:\n",
    "        PR_densities.append(r[0]/(Li6D2sigma0/2))\n",
    "        PR_densities.append(r[1]/(Li6D2sigma0/2))\n",
    "    df_PR['column_density'] = PR_densities\n",
    "    \n",
    "    return df_PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5024d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.283947Z",
     "start_time": "2023-03-08T02:54:44.281493Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_counts_from_PR_column_densities_to_dataframe(df_PR, exp_params_dict):\n",
    "    um_per_pixel = exp_params_dict['Values']['top_um_per_pixel'] # in um\n",
    "    counts = []\n",
    "    for idx, row in df_PR.iterrows():\n",
    "        counts.append( sum(sum(row['column_density']))* (um_per_pixel**2) * 10**(-12) )\n",
    "    df_PR['atom_count'] = counts\n",
    "    return df_PR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0859dec",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get atom counts from densities</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be446c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.287659Z",
     "start_time": "2023-03-08T02:54:44.285104Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_atom_counts_from_densities_to_data_frame(df, um_per_pixel):\n",
    "    '''\n",
    "    um_per_pixel is, obviously, in um\n",
    "    we have to convert this to m, since sigma0 is in m^2\n",
    "    '''\n",
    "    counts = []\n",
    "    for index, row in df.iterrows():\n",
    "        counts.append(sum(sum(row['column_density'])) * (um_per_pixel**2) * 10**(-12))\n",
    "    df['atom_count'] = counts\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a485cdc5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Hybrid Top analysis functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0f4c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.291951Z",
     "start_time": "2023-03-08T02:54:44.288729Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_justified_column_density_to_dataframe(df, exp_params_dict):\n",
    "    tilt_angle = exp_params_dict[\"Values\"][\"axicon_tilt_deg\"]\n",
    "    df['justified_column_density'] = [None]*df.shape[0]\n",
    "    print('Tilt angle: ' + str(tilt_angle) + ' degrees')\n",
    "    if 'column_density' in df.columns:\n",
    "        for idx, row in df.iterrows():\n",
    "            if tilt_angle != 0:\n",
    "                df.at[idx, 'justified_column_density'] = scipy.ndimage.rotate(input = row['column_density'],\n",
    "                                                                              angle = tilt_angle, \n",
    "                                                                              reshape = False)\n",
    "            else:\n",
    "                df.at[idx, 'justified_column_density'] = row['column_density']\n",
    "    print('Column density justified')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e91aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.296173Z",
     "start_time": "2023-03-08T02:54:44.292987Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_n3d_along_harmonic_axis_to_dataframe(df, exp_params_dict):\n",
    "    # box dimensions:\n",
    "    axicon_diameter_pix = exp_params_dict[\"Values\"][\"axicon_diameter_pix\"]\n",
    "    um_per_pixel = exp_params_dict[\"Values\"][\"top_um_per_pixel\"]\n",
    "\n",
    "    hybrid_trap_radius_um = um_per_pixel * axicon_diameter_pix / 2.0\n",
    "    hybrid_trap_cross_sectional_area_um2 = np.pi * hybrid_trap_radius_um**2\n",
    "\n",
    "    # get radial_integrated_density:\n",
    "    hybrid_3D_densities_along_harmonic_axis = []\n",
    "    for hybrid_column_density in df['justified_column_density']:\n",
    "        # computes sum n(x,z).dx --> n(z) with units = per length. Then divide this by cross section to get n_3D(z)\n",
    "        # column densities are in 1/m^2... so need to multiply by 1e-12 to get 1/um^2\n",
    "        n3d = um_per_pixel*np.sum(hybrid_column_density, axis = 1)*(1e-12)/hybrid_trap_cross_sectional_area_um2\n",
    "        hybrid_3D_densities_along_harmonic_axis.append(n3d)\n",
    "    # add hybrid_3D_densities_along_harmonic_axis to dataframe:\n",
    "    df['n3D_along_harmonic_ax'] = hybrid_3D_densities_along_harmonic_axis\n",
    "    \n",
    "    print('n3D along harmonic axis added.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3eac4",
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_hybrid_harmonic_trap_centers_to_dataframe(df):\n",
    "    centers = []\n",
    "    if 'n3D_along_harmonic_ax' in df.columns:\n",
    "        for idx, row in df.iterrows():\n",
    "            # fit n3D_along_harmonic_ax with parabola:\n",
    "            n = row['n3D_along_harmonic_ax']\n",
    "            positions = np.linspace(1, n.shape[0], n.shape[0])\n",
    "\n",
    "            # guesses for the fit\n",
    "            center_guess =  np.argmax(n)\n",
    "            amp_guess = max(n) - min(n)\n",
    "            sigma_guess = len(positions)//5\n",
    "            offset_guess = min(n)\n",
    "\n",
    "            # fit now\n",
    "            params_gauss, covariance_gauss = scipy.optimize.curve_fit(_gaussian, positions, n, \n",
    "                                                      p0=[center_guess, amp_guess, \n",
    "                                                          sigma_guess, offset_guess], \n",
    "                                                                      maxfev = 10000)\n",
    "\n",
    "            # get center and append\n",
    "            # if center_fit is something weird, then just use the guess\n",
    "            if (params_gauss[0] >= len(n)) or (params_gauss[0] <= 0): \n",
    "                center = center_guess\n",
    "            else:\n",
    "                center = int(params_gauss[0])\n",
    "            centers.append(center)   \n",
    "    df['hybrid_harmonic_trap_center'] = centers\n",
    "    print('Harmonic trap centers added.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14258a9",
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_energy_from_hybrid_expansion_to_dataframe(df, exp_params_dict):\n",
    "    axial_trap_frequency_hz = exp_params_dict[\"Values\"]['axial_trap_frequency_hz']\n",
    "    axial_trap_frequency = 2.0 * np.pi * axial_trap_frequency_hz\n",
    "    top_um_per_pixel = exp_params_dict[\"Values\"]['top_um_per_pixel']\n",
    "    \n",
    "    axicon_diameter_pix = exp_params_dict[\"Values\"][\"axicon_diameter_pix\"]\n",
    "    hybrid_trap_radius_um = top_um_per_pixel * axicon_diameter_pix / 2.0\n",
    "    Acyl = (np.pi * hybrid_trap_radius_um**2) # in um^2\n",
    "    \n",
    "    energy_hz_from_ax_trap = []\n",
    "    boundary = []\n",
    "    if ('n3D_along_harmonic_ax' in df.columns) and ('hybrid_harmonic_trap_center' in df.columns):\n",
    "        for idx, row in df.iterrows():\n",
    "            n3d_along_harmonic_axis = row['n3D_along_harmonic_ax']\n",
    "            smooth_n3d = savgol_filter(n3d_along_harmonic_axis, len(n3d_along_harmonic_axis)//5,3)\n",
    "            hyb_trap_center = int(row['hybrid_harmonic_trap_center'])\n",
    "            max_n3d = max(smooth_n3d)\n",
    "\n",
    "            upper_z = len(n3d_along_harmonic_axis)-1\n",
    "            for i in range(hyb_trap_center, len(smooth_n3d)):\n",
    "                if smooth_n3d[i] <= 0.05*(max_n3d):\n",
    "                    upper_z = i\n",
    "                    break\n",
    "            lower_z = 0\n",
    "            for i in np.arange(hyb_trap_center, 0,-1, dtype='int'):\n",
    "                if smooth_n3d[i] <= 0.05*(max_n3d):\n",
    "                    lower_z = i\n",
    "                    break\n",
    "                    \n",
    "            z = np.linspace(lower_z, upper_z, upper_z - lower_z)  \n",
    "            z = z - hyb_trap_center # this is the displacement\n",
    "            z_um = z*top_um_per_pixel\n",
    "            z_m = z*top_um_per_pixel*1e-6 \n",
    "\n",
    "            U_hz_z = (0.5 * mLi6 * axial_trap_frequency**2 * z_m**2) / (2*np.pi*hbar)  \n",
    "            \n",
    "            # from Zhenjie's Boiling UFG paper\n",
    "            energy_hz = 4*Acyl*trapezoid(n3d_along_harmonic_axis[lower_z:upper_z]*U_hz_z, x=z_um)\n",
    "            # now find energy per particle:\n",
    "            energy_hz_per_particle = energy_hz / row['atom_count']\n",
    "            \n",
    "            energy_hz_from_ax_trap.append(energy_hz_per_particle)\n",
    "            boundary.append([lower_z, upper_z])\n",
    "            \n",
    "    # energy in Hz per particle\n",
    "    df['E_hz_pp_from_ax_trap'] = energy_hz_from_ax_trap \n",
    "    df['ax_trap_boundary'] = boundary\n",
    "    \n",
    "    print('Energy added.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5ce38e",
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def get_counts_energies_and_vars_from_hybrid_top_PR(df, exp_params_dict, extra_var = ''):\n",
    "    # get counts\n",
    "    df = add_counts_from_PR_column_densities_to_dataframe(df, exp_params_dict)\n",
    "    # tilt, add n3d along harmonic axis, find trap center and add boundary of cloud to get Energy\n",
    "    df = add_justified_column_density_to_dataframe(df, exp_params_dict) \n",
    "    df = add_n3d_along_harmonic_axis_to_dataframe(df, exp_params_dict)\n",
    "    df = add_hybrid_harmonic_trap_centers_to_dataframe(df)\n",
    "\n",
    "    # add energies (from expansion into harmonic axial trap)\n",
    "    df = add_energy_from_hybrid_expansion_to_dataframe(df, exp_params_dict)\n",
    "    \n",
    "    # get counts:\n",
    "    counts_A = np.array(df[(df['image_type'] == 'TopA')]['atom_count'])\n",
    "    counts_B = np.array(df[(df['image_type'] == 'TopB')]['atom_count'])\n",
    "    \n",
    "    # get energies:\n",
    "    energies_A = np.array(df[(df['image_type'] == 'TopA')]['E_hz_pp_from_ax_trap'])\n",
    "    energies_B = np.array(df[(df['image_type'] == 'TopB')]['E_hz_pp_from_ax_trap'])\n",
    "    \n",
    "    # get run_ids:\n",
    "    run_ids = df[(df['image_type'] == 'TopA')]['run_id']\n",
    "    \n",
    "    # get RF12 Time:\n",
    "    RF12_Times = df[(df['image_type'] == 'TopA')]['RF12_Time']\n",
    "    \n",
    "    # get extra var:\n",
    "    if extra_var == '':\n",
    "        extra_variable = 0\n",
    "        x_data = run_ids\n",
    "        x_data_name = 'Run Id'\n",
    "    else:\n",
    "        extra_variable = df[(df['image_type'] == 'TopA')][extra_var]\n",
    "        x_data = extra_variable\n",
    "        x_data_name = extra_var\n",
    "    \n",
    "    # now get ready for plotting:\n",
    "    fig = plt.figure(figsize=(7,3))\n",
    "    ax_counts = fig.add_subplot(121)\n",
    "    \n",
    "    # plot counts vs whatever\n",
    "    pr1 = ax_counts.scatter(x_data, counts_A, color = 'red' , s = 10)\n",
    "    pr2 = ax_counts.scatter(x_data, counts_B, color = 'blue', s = 10)\n",
    "    ax_counts.legend([pr1, pr2],['State 1', 'State 3'])\n",
    "    fig.autofmt_xdate()\n",
    "    ax_counts.set_xticks([])\n",
    "    ax_counts.set_ylim(ymin=0)\n",
    "    plt.xlabel(x_data_name)\n",
    "    plt.ylabel('Counts')\n",
    "    \n",
    "    # plot energies vs whatever\n",
    "    ax_energies = fig.add_subplot(122)\n",
    "    e1 = ax_energies.scatter(x_data, energies_A, color = 'red', s = 10)\n",
    "    e2 = ax_energies.scatter(x_data, energies_B, color = 'blue', s = 10)\n",
    "    ax_energies.legend([e1, e2],['State 1', 'State 3'])\n",
    "    fig.autofmt_xdate()\n",
    "    ax_energies.set_xticks([])\n",
    "    ax_energies.set_ylim(ymin=0)\n",
    "    plt.xlabel(x_data_name)\n",
    "    plt.ylabel('Energies per particle (Hz)')\n",
    "    \n",
    "    # add title to figure:\n",
    "    folder_name = os.path.basename(os.path.dirname(df['fullpaths'][0]))\n",
    "    fig.suptitle(folder_name)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # calculate imbalance\n",
    "    imbalance = (counts_B - counts_A)/(counts_A + counts_B)\n",
    "    \n",
    "    # calculate (weighted) average energy per particle:\n",
    "    weighted_avg_energy = (energies_A*counts_A + energies_B*counts_B)/(counts_A + counts_B)\n",
    "    \n",
    "    #### statistics report ####\n",
    "    print('--- Counts and Energies per particle ---')\n",
    "    print('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A))))\n",
    "    print('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A))))\n",
    "    print('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B))))\n",
    "    print('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B))))\n",
    "    print('Mean State 1 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_A))))\n",
    "    print('Stdev state 1 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_A))))\n",
    "    print('Mean State 3 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_B))))\n",
    "    print('Stdev state 3 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_B))))\n",
    "    print('Mean weighted energy (Hz): ' + str(\"{:.2f}\".format(np.mean(weighted_avg_energy))))\n",
    "    print('Std weighted energy (Hz):  ' + str(\"{:.2f}\".format(np.std(weighted_avg_energy))))\n",
    "    print('Average imbalance:         ' + str(\"{:.2f}\".format(np.mean(imbalance))))\n",
    "    print('Stdev imbalance:           ' + str(\"{:.2f}\".format(np.std(imbalance))))\n",
    "\n",
    "    result_dict = {'df':df,\n",
    "                   'counts_A': counts_A, \n",
    "                   'counts_B': counts_B, \n",
    "                   'energies_A': energies_A, \n",
    "                   'energies_B': energies_B, \n",
    "                   'run_ids': run_ids, \n",
    "                   'RF12_Times': RF12_Times,\n",
    "                   extra_var: extra_variable, \n",
    "                   'figure': fig, \n",
    "                   'imbalance': imbalance,\n",
    "                   'weighted_average_energy': weighted_avg_energy}\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc50e75b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Box Top analysis functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0e04f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.300399Z",
     "start_time": "2023-03-08T02:54:44.297208Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_delta_n3d_with_no_shake_subtracted_to_dataframe(df, exp_params_dict):\n",
    "    # box dimensions:\n",
    "    axicon_diameter_pix = exp_params_dict[\"Values\"][\"axicon_diameter_pix\"]\n",
    "    axicon_length_pix = exp_params_dict[\"Values\"][\"hybrid_trap_typical_length_pix\"]\n",
    "    um_per_pixel = exp_params_dict[\"Values\"][\"top_um_per_pixel\"]\n",
    "\n",
    "    hybrid_trap_radius_um = um_per_pixel * axicon_diameter_pix / 2.0\n",
    "    hybrid_trap_cross_sectional_area_um2 = np.pi * hybrid_trap_radius_um**2\n",
    "\n",
    "    # get delta_n3d along z:\n",
    "    delta_3D_densities_along_harmonic_axis = []\n",
    "    for hybrid_column_density in df['no_shake_subtracted']:\n",
    "        # computes sum n(x,z).dx --> n(z) with units = per length. Then divide this by cross section to get n_3D(z)\n",
    "        # column densities are in 1/m^2... so need to multiply by 1e-12 to get 1/um^2\n",
    "        n3d = um_per_pixel*np.sum(hybrid_column_density, axis = 1)*(1e-12)/hybrid_trap_cross_sectional_area_um2\n",
    "        delta_3D_densities_along_harmonic_axis.append(n3d)\n",
    "    \n",
    "    # # get n3d along z:\n",
    "    # n3D_densities_along_harmonic_axis = []\n",
    "    # for justified_column_density in df['justified_column_density']:\n",
    "    #     # computes sum n(x,z).dx --> n(z) with units = per length. Then divide this by cross section to get n_3D(z)\n",
    "    #     # column densities are in 1/m^2... so need to multiply by 1e-12 to get 1/um^2\n",
    "    #     n3d = um_per_pixel*np.sum(justified_column_density, axis = 1)*(1e-12)/hybrid_trap_cross_sectional_area_um2\n",
    "    #     n3D_densities_along_harmonic_axis.append(n3d)\n",
    "    \n",
    "    # add hybrid_3D_densities_along_harmonic_axis to dataframe:\n",
    "    # df['n3D_along_harmonic_ax'] = n3D_densities_along_harmonic_axis\n",
    "    df['no_shake_subtracted_integrated'] = delta_3D_densities_along_harmonic_axis\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062da0b",
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def plot_box_counts_and_imbalance(df, filter = False, title_extra=''):\n",
    "    \n",
    "    # get folder name:\n",
    "    folder_name = os.path.basename(os.path.dirname(df['fullpaths'].iloc[0]))\n",
    "\n",
    "    # setup axes for plotting\n",
    "    fig_Sound_Scan_counts_and_imbalance = plt.figure(figsize=(8,3))\n",
    "    ax_Sound_Scan_PR_counts = fig_Sound_Scan_counts_and_imbalance.add_subplot(121)\n",
    "\n",
    "    # get counts and run_ids\n",
    "    if filter:\n",
    "        counts_A_Sound_Scan_PR = np.array(df[(df['image_type']=='TopA') & (df['good_shot']==True)]['atom_count'])\n",
    "        counts_B_Sound_Scan_PR = np.array(df[(df['image_type']=='TopB') & (df['good_shot']==True)]['atom_count'])\n",
    "        run_ids_Sound_Scan_PR  = df[(df['image_type']=='TopA') & (df['good_shot']==True)]['run_id']\n",
    "        plot_title = 'Filtered data'\n",
    "    else:\n",
    "        counts_A_Sound_Scan_PR = np.array(df[df['image_type']=='TopA']['atom_count'])\n",
    "        counts_B_Sound_Scan_PR = np.array(df[df['image_type']=='TopB']['atom_count'])\n",
    "        run_ids_Sound_Scan_PR  = df[df['image_type']=='TopA']['run_id']\n",
    "        plot_title = 'Unfiltered data'\n",
    "\n",
    "    # get statistics for counts:\n",
    "    mean_counts_A = np.mean(counts_A_Sound_Scan_PR)\n",
    "    std_counts_A = np.std(counts_A_Sound_Scan_PR)\n",
    "    mean_counts_B = np.mean(counts_B_Sound_Scan_PR)\n",
    "    std_counts_B = np.std(counts_B_Sound_Scan_PR)\n",
    "\n",
    "    # plot counts, mean, and stds vs Run Id\n",
    "    pr1_Sound_Scan = ax_Sound_Scan_PR_counts.scatter(run_ids_Sound_Scan_PR, \n",
    "                                                       counts_A_Sound_Scan_PR, \n",
    "                                                       color = 'red' , \n",
    "                                                       s = 10)\n",
    "    ax_Sound_Scan_PR_counts.axhline(y = mean_counts_A, color='r', linestyle='-')\n",
    "    ax_Sound_Scan_PR_counts.axhline(y = mean_counts_A+std_counts_A, color='r', linestyle='--')\n",
    "    ax_Sound_Scan_PR_counts.axhline(y = mean_counts_A-std_counts_A, color='r', linestyle='--')\n",
    "\n",
    "    pr2_Sound_Scan = ax_Sound_Scan_PR_counts.scatter(run_ids_Sound_Scan_PR, \n",
    "                                                       counts_B_Sound_Scan_PR, \n",
    "                                                       color = 'blue', \n",
    "                                                       s = 10)\n",
    "    ax_Sound_Scan_PR_counts.axhline(y = mean_counts_B, color='blue', linestyle='-')\n",
    "    ax_Sound_Scan_PR_counts.axhline(y = mean_counts_B+std_counts_B, color='blue', linestyle='--')\n",
    "    ax_Sound_Scan_PR_counts.axhline(y = mean_counts_B-std_counts_B, color='blue', linestyle='--')\n",
    "\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel('Run Id')\n",
    "    plt.ylabel('Counts')\n",
    "    ax_Sound_Scan_PR_counts.legend([pr1_Sound_Scan, pr2_Sound_Scan],['State 1', 'State 3'])\n",
    "    ax_Sound_Scan_PR_counts.set_xticks([])\n",
    "    ax_Sound_Scan_PR_counts.set_ylim(ymin=0)\n",
    "    fig_Sound_Scan_counts_and_imbalance.autofmt_xdate()\n",
    "\n",
    "    # plot imbalance versus run id:\n",
    "    imbalance_Sound_Scan = (counts_B_Sound_Scan_PR - counts_A_Sound_Scan_PR)/(counts_B_Sound_Scan_PR + counts_A_Sound_Scan_PR)\n",
    "    ax_Sound_Scan_PR_imbalance = fig_Sound_Scan_counts_and_imbalance.add_subplot(122)\n",
    "    imb_Sound_Scan_plot = ax_Sound_Scan_PR_imbalance.scatter(run_ids_Sound_Scan_PR,\n",
    "                                                            imbalance_Sound_Scan,\n",
    "                                                            color = 'black',\n",
    "                                                            s=10)\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel('Run Id')\n",
    "    plt.ylabel('$(N_A-N_B)/(N_A+N_B)$')\n",
    "    ax_Sound_Scan_PR_imbalance.set_xticks([])\n",
    "    ax_Sound_Scan_PR_imbalance.set_ylim(ymin=-1, ymax=1)\n",
    "\n",
    "    fig_Sound_Scan_counts_and_imbalance.suptitle(folder_name + ', ' + title_extra)\n",
    "    fig_Sound_Scan_counts_and_imbalance.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print('Average imbalance: ' + str(\"{:.2f}\".format(np.mean(imbalance_Sound_Scan))))\n",
    "    print('Standard deviation in imbalance: ' + str(\"{:.2f}\".format(np.std(imbalance_Sound_Scan))))\n",
    "    print('')\n",
    "    \n",
    "    return fig_Sound_Scan_counts_and_imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ba2b40",
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_delta_n3d_over_n3d_along_z_to_dataframe(df, exp_params_dict, avg_no_shake_A, avg_no_shake_B):\n",
    "       \n",
    "    # box dimensions:\n",
    "    axicon_diameter_pix = exp_params_dict[\"Values\"][\"axicon_diameter_pix\"]\n",
    "    axicon_length_pix = exp_params_dict[\"Values\"][\"hybrid_trap_typical_length_pix\"]\n",
    "    um_per_pixel = exp_params_dict[\"Values\"][\"top_um_per_pixel\"]\n",
    "    \n",
    "    hybrid_trap_radius_um = um_per_pixel * axicon_diameter_pix / 2.0\n",
    "    hybrid_trap_cross_sectional_area_um2 = np.pi * hybrid_trap_radius_um**2\n",
    "    \n",
    "    # column densities are in 1/m^2... so need to multiply by 1e-12 to get 1/um^2\n",
    "    no_shake_A_int = um_per_pixel*np.sum(avg_no_shake_A, axis = 1)*(1e-12)/hybrid_trap_cross_sectional_area_um2\n",
    "    no_shake_B_int = um_per_pixel*np.sum(avg_no_shake_B, axis = 1)*(1e-12)/hybrid_trap_cross_sectional_area_um2\n",
    "    \n",
    "    delta_n3dz_over_n3dz = []\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['image_type'] == 'TopA':\n",
    "            delta_n3dz_over_n3dz.append(row['no_shake_subtracted_integrated']/no_shake_A_int)\n",
    "            #delta_n3dz_over_n3dz.append(row['no_shake_subtracted_integrated']/row['n3D_along_harmonic_ax'])\n",
    "        if row['image_type'] == 'TopB':\n",
    "            delta_n3dz_over_n3dz.append(row['no_shake_subtracted_integrated']/no_shake_B_int)\n",
    "            #delta_n3dz_over_n3dz.append(row['no_shake_subtracted_integrated']/row['n3D_along_harmonic_ax'])\n",
    "    \n",
    "    df['delta_n3dz_over_n3dz'] = delta_n3dz_over_n3dz\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649240ce",
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def add_box_boundary_along_z_to_dataframe(df, cut_depth):\n",
    "    # average over all no shake shots\n",
    "    n3d = np.mean(df[df['ShakingCycles']==0]['n3D_along_harmonic_ax'], axis = 0) \n",
    "    smoothened_n3d = savgol_filter(n3d, len(n3d)//5, 3)    \n",
    "    max_n3d_smoothened = max(smoothened_n3d)\n",
    "\n",
    "    upper_z = len(smoothened_n3d)-1\n",
    "    lower_z = 0\n",
    "    center = (upper_z + lower_z)//2\n",
    "        \n",
    "    if (cut_depth <= 1) and (cut_depth >= 0):\n",
    "        for i in range(center, len(smoothened_n3d)):\n",
    "            if smoothened_n3d[i] <= cut_depth*(max_n3d_smoothened):\n",
    "                upper_z = i\n",
    "                break\n",
    "        for i in np.arange(center, 0,-1, dtype='int'):\n",
    "            if smoothened_n3d[i] <= cut_depth*(max_n3d_smoothened):\n",
    "                lower_z = i\n",
    "                break   \n",
    "\n",
    "        plt.figure(figsize=(4.5,1))\n",
    "        plt.plot(smoothened_n3d)\n",
    "        plt.axhline(max_n3d_smoothened*cut_depth, color='black')\n",
    "        plt.axvline(upper_z, color = 'red')\n",
    "        plt.axvline(lower_z, color = 'red')\n",
    "        plt.title('Box cut along z, depth = ' + str(cut_depth))\n",
    "        plt.show()\n",
    "        \n",
    "    df['box_boundary_along_z'] = [[lower_z, upper_z]]*len(df)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb814e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_box_boundary_with_sigmoid_along_z_to_dataframe(df, cut_depth):\n",
    "    n3d = np.mean(df[df['ShakingCycles']==0]['n3D_along_harmonic_ax'], axis=0)\n",
    "    smoothened_n3d = savgol_filter(n3d, len(n3d)//5, 3)   \n",
    "\n",
    "    z = np.arange(len(n3d))\n",
    "    amp_guess = max(smoothened_n3d) - min(smoothened_n3d)\n",
    "    center_guess = z[len(z)//2]\n",
    "    sharpness_guess = 3\n",
    "    width_guess = len(z)*0.8 # just a guess\n",
    "    offset_guess = min(smoothened_n3d)\n",
    "    \n",
    "    params_sig, covariance_sig = scipy.optimize.curve_fit(_sigmoid, z, n3d, \n",
    "                                                              p0=[amp_guess, center_guess, sharpness_guess, width_guess, offset_guess],\n",
    "                                                              bounds = ([0, 0, 0, 0, -np.inf], [np.inf, len(z), len(z), len(z), max(smoothened_n3d)]))\n",
    "    errors_sig = np.sqrt(np.diag(covariance_sig))\n",
    "    \n",
    "    # get fit parameters:\n",
    "    amplitude = params_sig[0]\n",
    "    center    = params_sig[1]\n",
    "    sharpness = params_sig[2]\n",
    "    width     = params_sig[3]\n",
    "    offset    = params_sig[4]\n",
    "\n",
    "    # get fit parameter errors\n",
    "    amplitude_error = errors_sig[0]\n",
    "    center_error    = errors_sig[1]\n",
    "    sharpness_error = errors_sig[2]\n",
    "    width_error     = errors_sig[3]\n",
    "    offset_error    = errors_sig[4]\n",
    "\n",
    "    # make fitted curve\n",
    "    n3d_fit_plot = _sigmoid(z, amplitude, center, sharpness, width, offset)\n",
    "\n",
    "    # get boundaries now:\n",
    "    upper_z = len(smoothened_n3d)-1\n",
    "    lower_z = 0\n",
    "    center = (upper_z + lower_z)//2\n",
    "        \n",
    "    for i in range(center, len(smoothened_n3d)):\n",
    "            if smoothened_n3d[i] <= amplitude*cut_depth + offset:\n",
    "                upper_z = i\n",
    "                break\n",
    "    for i in np.arange(center, 0,-1, dtype='int'):\n",
    "        if smoothened_n3d[i] <= amplitude*cut_depth + offset:\n",
    "            lower_z = i\n",
    "            break  \n",
    "\n",
    "    # plotting \n",
    "    plt.figure(figsize=(4.5,1))\n",
    "    plt.plot(z, n3d)\n",
    "    plt.plot(z, n3d_fit_plot, color='red', linewidth=1)\n",
    "    plt.xlabel('z')\n",
    "    plt.ylabel('n3d(z)')\n",
    "    plt.title('Box sigmoid fit')\n",
    "    plt.axhline(amplitude*cut_depth + offset, color='green')\n",
    "    plt.axvline(lower_z, color='black')\n",
    "    plt.axvline(upper_z, color='black')\n",
    "    plt.show()\n",
    "\n",
    "    # print box stats:\n",
    "    print('Box width along z (px):      ' + \"{:.2f}\".format(width))\n",
    "    print('Box sharpness along z (px):  ' + \"{:.2f}\".format(sharpness))\n",
    "    print('')\n",
    "\n",
    "    df['box_boundary_along_z'] = [[lower_z, upper_z]]*len(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_box_Fermi_energy_to_dataframe(df, print_result = True, filter = False):\n",
    "    # first part looks like finding box_boundary, except that the cut_depth is 0.8\n",
    "    # to only get the top/center of the box\n",
    "    n3d = df[df['ShakingCycles']==0]['n3D_along_harmonic_ax'].iloc[0]\n",
    "    smoothened_n3d = savgol_filter(n3d, len(n3d)//5, 3)    \n",
    "    max_n3d_smoothened = max(smoothened_n3d)\n",
    "\n",
    "    upper_z = len(smoothened_n3d)-1\n",
    "    lower_z = 0\n",
    "    center = (upper_z + lower_z)//2\n",
    "    cut_depth = 0.85\n",
    "        \n",
    "    if (cut_depth <= 1) and (cut_depth >= 0):\n",
    "        for i in range(center, len(smoothened_n3d)):\n",
    "            if smoothened_n3d[i] <= cut_depth*(max_n3d_smoothened):\n",
    "                upper_z = i\n",
    "                break\n",
    "        for i in np.arange(center, 0,-1, dtype='int'):\n",
    "            if smoothened_n3d[i] <= cut_depth*(max_n3d_smoothened):\n",
    "                lower_z = i\n",
    "                break   \n",
    "\n",
    "    # second part is finding <n3D(z)> over this range:\n",
    "    Fermi_energy = []\n",
    "    for idx, row in df.iterrows():\n",
    "        avg_n3Dz = np.mean(row['n3D_along_harmonic_ax'][lower_z : upper_z]) * 1e18 # convert to 1/m^3\n",
    "        EF_hz = ((hbar**2)/(2*mLi6)) * (6 * np.pi**2 * avg_n3Dz)**(2.0/3.0) / (2*np.pi*hbar) # in Hz\n",
    "        Fermi_energy.append(EF_hz)\n",
    "    df['Fermi_energy'] = Fermi_energy\n",
    "\n",
    "    avg_EF_A = np.mean(np.array( df[(df['good_shot'] == filter) & (df['image_type']=='TopA')]['Fermi_energy'] ))\n",
    "    avg_EF_B = np.mean(np.array( df[(df['good_shot'] == filter) & (df['image_type']=='TopB')]['Fermi_energy'] ))\n",
    "\n",
    "    if print_result:\n",
    "        print('Average Fermi energy (A) in Hz:   ' + str(\"{:.2f}\".format(avg_EF_A)))\n",
    "        print('Average Fermi energy (B) in Hz:   ' + str(\"{:.2f}\".format(avg_EF_B)))\n",
    "\n",
    "    return df, avg_EF_A, avg_EF_B"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ec160c9",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Fit functions</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1040dfbc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font size=2, color='6C828D'>Li resonance imaging curve fit</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feceb513",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.329417Z",
     "start_time": "2023-03-08T02:54:44.321917Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def Li_resonance_imaging_curve_fit(freqs, \n",
    "                                   pixel_sums, \n",
    "                                   AOM_factor,\n",
    "                                   center_guess, \n",
    "                                   plot_xlabel = 'ImagFreq1 x AOM_Factor',\n",
    "                                   plot_title = 'Resonance Curve'):\n",
    "    \n",
    "    # get guesses from experiment_parameters_dict and known constants\n",
    "    center_guess = center_guess*AOM_factor \n",
    "    gamma_prime_guess = Li6D2Gamma # from table of constants\n",
    "    amplitude_guess = max(pixel_sums)\n",
    "    offset_guess = min(pixel_sums)/10\n",
    "\n",
    "    # fit\n",
    "    freqs_fit = freqs*AOM_factor\n",
    "    params_lorzt, covariance_lorzt = scipy.optimize.curve_fit(_absorption_coefficient, freqs_fit, pixel_sums, \n",
    "                                                              p0=[amplitude_guess, center_guess, \n",
    "                                                                  gamma_prime_guess, offset_guess],\n",
    "                                                              bounds = ([0, -np.inf, 0, 0],\n",
    "                                                                       [np.inf, np.inf, np.inf, np.inf]))\n",
    "    errors_lorzt = np.sqrt(np.diag(covariance_lorzt))\n",
    "\n",
    "    # get fit parameters\n",
    "    amplitude = params_lorzt[0]\n",
    "    center = params_lorzt[1]\n",
    "    gamma_prime = params_lorzt[2]\n",
    "    offset = params_lorzt[3]\n",
    "\n",
    "    # get fit parameter errors\n",
    "    amplitude_error = errors_lorzt[0]\n",
    "    center_error = errors_lorzt[1]\n",
    "    gamma_prime_error = errors_lorzt[2]\n",
    "    offset_error = errors_lorzt[3]\n",
    "\n",
    "    # make fitted curve\n",
    "    freqs_fit_plot = np.linspace(min(freqs)*AOM_factor, max(freqs)*AOM_factor, len(freqs)*10)\n",
    "    pixel_sums_fit = amplitude*gamma_prime**2/ ( 4*(freqs_fit_plot-center)**2 + gamma_prime**2) + offset\n",
    "\n",
    "    # print out fit results\n",
    "    print('----------Fit result----------------')\n",
    "    print('Amplitude: ' + str('{:.2f}'.format(amplitude)) + ' +/- ' + str('{:.2f}'.format(amplitude_error)))\n",
    "    print('Center: ' + str('{:.2f}'.format(center)) + ' +/- ' + str('{:.2f}'.format(center_error)))\n",
    "    print('Gamma prime: ' + str('{:.2f}'.format(gamma_prime)) + ' +/- ' + str('{:.2f}'.format(gamma_prime_error)))\n",
    "    print('Offset: ' + str('{:.2f}'.format(offset)) + ' +/- ' + str('{:.2f}'.format(offset_error)))\n",
    "    print('Calculated saturation parameter: ' + str('{:.2f}'.format((gamma_prime/Li6D2Gamma)**2 - 1)))\n",
    "\n",
    "    # print resonance value in Cicero space:\n",
    "    print('------------------------------------')\n",
    "    print('Set value in Cicero to: ' + str('{:.2f}'.format(-center/2)))\n",
    "\n",
    "    # plotting \n",
    "    plt.scatter(freqs_fit, pixel_sums, color = 'black', s=10)\n",
    "    plt.plot(freqs_fit_plot, pixel_sums_fit, color='red', linewidth=1)\n",
    "    plt.xlabel(plot_xlabel)\n",
    "    plt.ylabel('Pixel sum')\n",
    "    plt.title(plot_title)\n",
    "    plt.show()\n",
    "    \n",
    "    # return results\n",
    "    fit_result = dict()\n",
    "    fit_result['amplitude'] = amplitude\n",
    "    fit_result['center'] = center\n",
    "    fit_result['gamma prime'] = gamma_prime\n",
    "    fit_result['offset'] = offset\n",
    "    fit_result['calculated saturation parameter'] = (gamma_prime/Li6D2Gamma)**2 - 1\n",
    "    \n",
    "    return fit_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2dc6572",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font size=2, color='6C828D'>RF resonance curve fit</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece2b2c1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How do we find the best guess for the resonant RF frequency from the RF transfer curve? While there are certainly more sophisticated solutions, here we implement a rather simple one. \n",
    "\n",
    "We can quite safely assuem that in most cases, our RF transfer curve will either be unimodal or bimodal. So first we have to be able to classify various any curve into one of these types. To do this, we will use the scipy peak-finding method to extract peaks. If the data is unimodal, then the guess for $\\omega_0$ is simply the RF frequency at which the RF transfer maximizes. If the data is bimodal, then we take the two peaks, and the guess for $\\omega_0$ is simply the average of the RF frequencies associated with those two peaks. \n",
    "\n",
    "Before we proceed, remember that because data is often taken in randomized order, we will have to sort the RF transfer values by the RF frequency value (low-to-high). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b270f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.336870Z",
     "start_time": "2023-03-08T02:54:44.330480Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def RF_spec_generate_guesses(RF_freqs_and_taus, RF_transfers, peaks_ratio_threshold = 0.8):\n",
    "    '''\n",
    "    peaks_ratio_threshold should be in range [0,1]\n",
    "    '''\n",
    "    offset_guess = min(RF_transfers)\n",
    "    omegaR_guess = 0.001 # these are typically on the order of 0.001 MHz \n",
    "    \n",
    "    # the guess for omega0_guess is the best symmetry point...\n",
    "    peaks = scipy.signal.find_peaks(RF_transfers)\n",
    "    \n",
    "    # sort first so that things work nicely\n",
    "    sorted_RF_transfers = np.array([x for _,x in sorted(zip(RF_freqs_and_taus[0], RF_transfers))])\n",
    "    sorted_RF_freqs = np.array(sorted(RF_freqs_and_taus[0]))\n",
    "    RF_transfers_no_dup = np.array([sorted_RF_transfers[0]])\n",
    "    RF_freqs_no_dup = np.array([sorted_RF_freqs[0]])\n",
    "        \n",
    "    # now take average to remove duplicates in X:\n",
    "    x_old = -np.inf\n",
    "    x_count = 0\n",
    "    for i in range(len(sorted_RF_transfers)):\n",
    "        if sorted_RF_freqs[i] == x_old:\n",
    "            # if RF freq already exists, then update previous one in RF transfers\n",
    "            x_count += 1\n",
    "            RF_transfers_no_dup[-1] = ((RF_transfers_no_dup[-1]*x_count)+sorted_RF_transfers[i])/(x_count+1)\n",
    "        else:\n",
    "            # if RF freq is new, then just append\n",
    "            RF_transfers_no_dup = np.append(RF_transfers_no_dup, sorted_RF_transfers[i])\n",
    "            RF_freqs_no_dup = np.append(RF_freqs_no_dup, sorted_RF_freqs[i])\n",
    "            x_count = 0\n",
    "            x_old = sorted_RF_freqs[i]\n",
    "\n",
    "    # now find peaks on this modified dataset:\n",
    "    peak_indices = scipy.signal.find_peaks(RF_transfers_no_dup)[0]\n",
    "    plt.scatter(RF_freqs_no_dup[peak_indices], RF_transfers_no_dup[peak_indices], color = 'blue', marker='o')\n",
    "    sorted_RF_transfers_peaks = sorted(RF_transfers_no_dup[peak_indices])\n",
    "    sorted_RF_freqs_peaks = np.array([x for _,x in sorted(zip(RF_transfers_no_dup[peak_indices], RF_freqs_no_dup[peak_indices]))])\n",
    "        \n",
    "    # compare the two tallest peaks in the data:\n",
    "    if len(sorted_RF_transfers_peaks) == 1:\n",
    "        # in this case, omega0_guess is just the RF_freq associated with this peak!\n",
    "        omega0_guess = sorted_RF_freqs_peaks[-1]\n",
    "    else:\n",
    "        if sorted_RF_transfers_peaks[-2]/sorted_RF_transfers_peaks[-1] < peaks_ratio_threshold:\n",
    "            # in this case, omega0_guess is just the RF_freq associated with this peak!\n",
    "            omega0_guess = sorted_RF_freqs_peaks[-1]\n",
    "        else:\n",
    "            # in this case, take the average \n",
    "            omega0_guess = (sorted_RF_freqs_peaks[-1] + sorted_RF_freqs_peaks[-2])/2      \n",
    "    plt.scatter([sorted_RF_freqs_peaks[-1]], [sorted_RF_transfers_peaks[-1]], color='red', marker='x')\n",
    "    \n",
    "    return omegaR_guess, omega0_guess, offset_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe3e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.344889Z",
     "start_time": "2023-03-08T02:54:44.337951Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# fitting function:\n",
    "def Li_P2_Rabi_RF_curve_fit(RF_freqs_and_taus, \n",
    "                            RF_transfers, \n",
    "                            omega0_guess = 75,\n",
    "                            omegaR_guess = 1, \n",
    "                            offset_guess = 0,\n",
    "                            smart_guesses = False,\n",
    "                            peaks_ratio_threshold = 0.8,\n",
    "                            plot_xlabel = 'RF frequency',\n",
    "                            plot_title = 'RF Resonance Curve'):\n",
    "    \n",
    "    if smart_guesses:\n",
    "        omegaR_guess, omega0_guess, offset_guess = RF_spec_generate_guesses(RF_freqs_and_taus, \n",
    "                                                                            RF_transfers,\n",
    "                                                                           peaks_ratio_threshold = peaks_ratio_threshold)\n",
    "        \n",
    "    # fit\n",
    "    params_Rabi, covariance_Rabi = scipy.optimize.curve_fit(_P2_Rabi, \n",
    "                                                              xdata = RF_freqs_and_taus, \n",
    "                                                              ydata = RF_transfers, \n",
    "                                                              p0 = [omegaR_guess, omega0_guess, offset_guess])\n",
    "    errors_Rabi = np.sqrt(np.diag(covariance_Rabi))\n",
    "    \n",
    "    # get fit parameters\n",
    "    omegaR = params_Rabi[0]\n",
    "    omega0 = params_Rabi[1]\n",
    "    offset = params_Rabi[2]\n",
    "    \n",
    "    # get fit parameter errors\n",
    "    omegaR_error = errors_Rabi[0]\n",
    "    omega0_error = errors_Rabi[1]\n",
    "    offset_error = errors_Rabi[2]\n",
    "    \n",
    "    # make fitted curve\n",
    "    RF_freqs_fit_plot = np.linspace(min(RF_freqs_and_taus[0]), max(RF_freqs_and_taus[0]), len(RF_freqs_and_taus[0])*10)\n",
    "    taus_fit_plot = np.linspace(min(RF_freqs_and_taus[1]), max(RF_freqs_and_taus[1]), len(RF_freqs_and_taus[1])*10)\n",
    "    OmegaR = np.sqrt(omegaR**2 + (RF_freqs_fit_plot - omega0)**2)\n",
    "    RF_transfer_fit = (omegaR**2 / OmegaR**2) * np.sin(2*np.pi*OmegaR * taus_fit_plot * 10**(6-3) / 2)**2 + offset\n",
    "        \n",
    "    # plotting \n",
    "    plt.scatter(RF_freqs_and_taus[0], RF_transfers, color = 'black', s=10)\n",
    "    plt.plot(RF_freqs_fit_plot, RF_transfer_fit, color='red', linewidth=1)\n",
    "    plt.xlabel(plot_xlabel)\n",
    "    plt.ylabel('RF Transfer B/(A+B)')\n",
    "    plt.title(plot_title)\n",
    "    plt.show()\n",
    "    \n",
    "    fit_result = dict()\n",
    "    fit_result['omegaR'] = omegaR\n",
    "    fit_result['center'] = omega0\n",
    "    fit_result['offset'] = offset\n",
    "    \n",
    "    ######## PRINT OUT RESULTS ############\n",
    "    print('----------Fit result----------------')\n",
    "    print('Rabi frequency: ' + str('{:.6f}'.format(omegaR)) + ' +/- ' + str('{:.6f}'.format(omegaR_error)))\n",
    "    print('Center: ' + str('{:.5f}'.format(omega0)) + ' +/- ' + str('{:.5f}'.format(omega0_error)))\n",
    "    print('Offset: ' + str('{:.5f}'.format(offset)) + ' +/- ' + str('{:.5f}'.format(offset_error)))\n",
    "    \n",
    "    return fit_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e2ac85e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font size=2, color='6C828D'>Hybrid sloshing fit</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9e248",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.353294Z",
     "start_time": "2023-03-08T02:54:44.346160Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def hybrid_sloshing_fit(times, positions, \n",
    "                        plot_xlabel = 'Times', \n",
    "                        plot_ylabel = 'Positions',\n",
    "                        plot_title = 'Fit to cos'):\n",
    "    amp_guess = (max(positions) - min(positions))/2.0\n",
    "    omega0_guess = 23\n",
    "    phi_guess = 0.5\n",
    "    offset_guess = (max(positions) + min(positions))/2.0\n",
    "       \n",
    "    times = np.array(times)/1000.0 # convert ms to s\n",
    "    \n",
    "    params_cos, covariance_cos = scipy.optimize.curve_fit(_cosine, times, positions, \n",
    "                                                              p0=[amp_guess, omega0_guess, \n",
    "                                                                  phi_guess, offset_guess],\n",
    "                                                              bounds = ([0, 0, 0, 0],\n",
    "                                                                       [np.inf, np.inf, 2*np.pi, np.inf]))\n",
    "    errors_cos = np.sqrt(np.diag(covariance_cos))\n",
    "    \n",
    "    # get fit parameters\n",
    "    amp = params_cos[0]\n",
    "    omega0 = params_cos[1]\n",
    "    phi = params_cos[2]\n",
    "    offset = params_cos[3]\n",
    "    \n",
    "    # get fit parameter errors\n",
    "    amp_error = errors_cos[0]\n",
    "    omega0_error = errors_cos[1]\n",
    "    phi_error = errors_cos[2]\n",
    "    offset_error = errors_cos[3]\n",
    "    \n",
    "    # make fitted curve\n",
    "    times_fit_plot = np.linspace(min(times), max(times), len(times)*10)\n",
    "    positions_fit_plot = amp*np.cos(2*np.pi*(times_fit_plot*omega0 + phi)) + offset\n",
    "\n",
    "    # print out fit results\n",
    "    print('----------Fit result----------------')\n",
    "    print('Amplitude: ' + str('{:.2f}'.format(amp)) + ' +/- ' + str('{:.2f}'.format(amp_error)))\n",
    "    print('Center: ' + str('{:.2f}'.format(omega0)) + ' +/- ' + str('{:.2f}'.format(omega0_error)))\n",
    "    print('Phase: ' + str('{:.2f}'.format(phi)) + ' +/- ' + str('{:.2f}'.format(phi_error)))\n",
    "    print('Offset: ' + str('{:.2f}'.format(offset)) + ' +/- ' + str('{:.2f}'.format(offset_error)))\n",
    "\n",
    "    # plotting \n",
    "    plt.scatter(times, positions, color = 'black', s=10)\n",
    "    plt.plot(times_fit_plot, positions_fit_plot, color='red', linewidth=1)\n",
    "    plt.xlabel(plot_xlabel)\n",
    "    plt.ylabel(plot_ylabel)\n",
    "    plt.title(plot_title)\n",
    "    plt.show()\n",
    "    \n",
    "    # return results\n",
    "    fit_result = dict()\n",
    "    fit_result['amplitude'] = amp\n",
    "    fit_result['center'] = omega0\n",
    "    fit_result['phase'] = phi\n",
    "    fit_result['offset'] = offset\n",
    "    \n",
    "    return fit_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2675eb55",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font size=2, color='6C828D'>First sound resonance curve fit</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4b9855",
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def first_sound_resonance_curve_fit(df, \n",
    "                                    symmetric_mode = 1, \n",
    "                                    fit = False, \n",
    "                                    real = False, \n",
    "                                    normalize = False,\n",
    "                                    with_offset = False):\n",
    "    # loop through no_shake_subtracted_density and get amplitude for 1st symmetric mode:\n",
    "    fourier_amplitudes_AB = []\n",
    "    for idx, row in df.iterrows():\n",
    "        # to be implemented: \n",
    "        # for every shot, obtain box boundaries to get nice Fourier amplitudes\n",
    "        \n",
    "        lower_z = row['box_boundary_along_z'][0]\n",
    "        upper_z = row['box_boundary_along_z'][1]\n",
    "        \n",
    "        if normalize:\n",
    "            # divide by the average no shake integrated density\n",
    "            density_FT = fft(row['delta_n3dz_over_n3dz'][lower_z:upper_z])\n",
    "        else:\n",
    "            density_FT = fft(row['no_shake_subtracted_integrated'][lower_z:upper_z])\n",
    "        \n",
    "        if real:\n",
    "            density_FT = np.real(density_FT)\n",
    "            \n",
    "        fourier_amplitudes = np.abs(density_FT)\n",
    "        if row['image_type'] == 'TopA':\n",
    "            fourier_amplitudes_AB.append(fourier_amplitudes[symmetric_mode])\n",
    "        if row['image_type'] == 'TopB':\n",
    "            fourier_amplitudes_AB.append(fourier_amplitudes[symmetric_mode])\n",
    "            \n",
    "    df['fourier_amplitudes'] = fourier_amplitudes_AB\n",
    "\n",
    "    # get fourier amplitudes for each image type:\n",
    "    fourier_amplitudes_A = np.array(df[(df['image_type']=='TopA') &\n",
    "                                                    (df['good_shot'] == True) & \n",
    "                                                    (df['ShakingCycles'] != 0)]['fourier_amplitudes'])\n",
    "    fourier_amplitudes_B = np.array(df[(df['image_type']=='TopB') &\n",
    "                                                    (df['good_shot'] == True) & \n",
    "                                                    (df['ShakingCycles'] != 0)]['fourier_amplitudes'])\n",
    "    BoxShakeFreqs = np.array(df[(df['image_type']=='TopA') &\n",
    "                                             (df['good_shot'] == True) & \n",
    "                                             (df['ShakingCycles'] != 0)]['BoxShakeFreq'])   \n",
    "          \n",
    "    # now plot fourier amplitudes against BoxShakeFreqs\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    fA = ax.scatter(BoxShakeFreqs, fourier_amplitudes_A, color='red', s=10)\n",
    "    fB = ax.scatter(BoxShakeFreqs, fourier_amplitudes_B, color='blue', s=10)\n",
    "    \n",
    "    # now fit:\n",
    "    if fit:\n",
    "        # first make frequencies to plot model:\n",
    "        BoxShakeFreqs_for_fit = np.linspace(min(BoxShakeFreqs), max(BoxShakeFreqs), len(BoxShakeFreqs)*10)\n",
    "\n",
    "        ##################################\n",
    "        # Sound resonance curve fit for A:\n",
    "        center_guess = BoxShakeFreqs[np.argmax(fourier_amplitudes_A)]\n",
    "        gamma_prime_guess = (max(BoxShakeFreqs) - min(BoxShakeFreqs))/3.0 # typically, width is roughly a third of the scanning range\n",
    "        amplitude_guess = max(fourier_amplitudes_A)\n",
    "\n",
    "        if with_offset:\n",
    "            offset_guess = min(fourier_amplitudes_A)       \n",
    "            params_lorzt, covariance_lorzt = scipy.optimize.curve_fit(_lorentzian, BoxShakeFreqs, fourier_amplitudes_A, \n",
    "                                                                p0=[amplitude_guess, center_guess, \n",
    "                                                                    gamma_prime_guess, offset_guess],\n",
    "                                                                bounds = ([0, -np.inf, 0, 0],\n",
    "                                                                        [np.inf, np.inf, np.inf, np.inf]))\n",
    "            errors_lorzt = np.sqrt(np.diag(covariance_lorzt))\n",
    "\n",
    "            # get fit parameters:\n",
    "            amplitude_A = params_lorzt[0]\n",
    "            center_A = params_lorzt[1]\n",
    "            gamma_prime_A = params_lorzt[2]\n",
    "            offset_A = params_lorzt[3]\n",
    "\n",
    "            # get fit parameter errors\n",
    "            center_A_error = errors_lorzt[1]\n",
    "            gamma_A_prime_error = errors_lorzt[2]\n",
    "            \n",
    "            # make fitted curve:\n",
    "            fitted_fourier_amplitudes_A = _lorentzian(BoxShakeFreqs_for_fit, amplitude_A, center_A, gamma_prime_A, offset_A)\n",
    "\n",
    "        else:\n",
    "            params_lorzt, covariance_lorzt = scipy.optimize.curve_fit(_lorentzian_no_offset, BoxShakeFreqs, fourier_amplitudes_A, \n",
    "                                                                p0=[amplitude_guess, center_guess, \n",
    "                                                                    gamma_prime_guess],\n",
    "                                                                bounds = ([0, -np.inf, 0],\n",
    "                                                                        [np.inf, np.inf, np.inf]))\n",
    "            errors_lorzt = np.sqrt(np.diag(covariance_lorzt))\n",
    "\n",
    "            # get fit parameters:\n",
    "            amplitude_A = params_lorzt[0]\n",
    "            center_A = params_lorzt[1]\n",
    "            gamma_prime_A = params_lorzt[2]\n",
    "\n",
    "            # get fit parameter errors\n",
    "            center_A_error = errors_lorzt[1]\n",
    "            gamma_A_prime_error = errors_lorzt[2]\n",
    "            \n",
    "            # make fitted curve:\n",
    "            fitted_fourier_amplitudes_A = _lorentzian_no_offset(BoxShakeFreqs_for_fit, amplitude_A, center_A, gamma_prime_A)\n",
    "        \n",
    "        # print out fit results\n",
    "        print('-------- Fit result State 1 ---------')\n",
    "        #print('Amplitude: ' + str('{:.2f}'.format(amplitude_A)) + ' +/- ' + str('{:.2f}'.format(amplitude_A_error)))\n",
    "        print('Center (Hz): ' + str('{:.2f}'.format(center_A)) + ' +/- ' + str('{:.2f}'.format(center_A_error)))\n",
    "        print('Gamma (Hz): ' + str('{:.2f}'.format(gamma_prime_A)) + ' +/- ' + str('{:.2f}'.format(gamma_A_prime_error)))\n",
    "        #print('Offset: ' + str('{:.2f}'.format(offset_A)) + ' +/- ' + str('{:.2f}'.format(offset_A_error)))\n",
    "    \n",
    "        ##################################\n",
    "        print('')\n",
    "        # Sound resonance curve fit for B:\n",
    "        center_guess = BoxShakeFreqs[np.argmax(fourier_amplitudes_B)]\n",
    "        gamma_prime_guess = (max(BoxShakeFreqs) - min(BoxShakeFreqs))/3.0 # typically, width is roughly a third of the scanning range\n",
    "        amplitude_guess = max(fourier_amplitudes_B)\n",
    "\n",
    "        if with_offset:\n",
    "            offset_guess = min(fourier_amplitudes_B)\n",
    "            \n",
    "            params_lorzt, covariance_lorzt = scipy.optimize.curve_fit(_lorentzian, BoxShakeFreqs, fourier_amplitudes_B, \n",
    "                                                                p0=[amplitude_guess, center_guess, \n",
    "                                                                    gamma_prime_guess, offset_guess],\n",
    "                                                                bounds = ([0, -np.inf, 0, 0],\n",
    "                                                                        [np.inf, np.inf, np.inf, np.inf]))\n",
    "            errors_lorzt = np.sqrt(np.diag(covariance_lorzt))\n",
    "            \n",
    "            # get fit parameters:\n",
    "            amplitude_B = params_lorzt[0]\n",
    "            center_B = params_lorzt[1]\n",
    "            gamma_prime_B = params_lorzt[2]\n",
    "            offset_B = params_lorzt[3]\n",
    "\n",
    "            # get fit parameter errors\n",
    "            center_B_error = errors_lorzt[1]\n",
    "            gamma_B_prime_error = errors_lorzt[2]\n",
    "            \n",
    "            # make fitted curve:\n",
    "            fitted_fourier_amplitudes_B = _lorentzian(BoxShakeFreqs_for_fit, amplitude_B, center_B, gamma_prime_B, offset_B)\n",
    "        else:\n",
    "            params_lorzt, covariance_lorzt = scipy.optimize.curve_fit(_lorentzian_no_offset, BoxShakeFreqs, fourier_amplitudes_B, \n",
    "                                                                p0=[amplitude_guess, center_guess, \n",
    "                                                                    gamma_prime_guess],\n",
    "                                                                bounds = ([0, -np.inf, 0],\n",
    "                                                                        [np.inf, np.inf, np.inf]))\n",
    "            errors_lorzt = np.sqrt(np.diag(covariance_lorzt))\n",
    "            \n",
    "            # get fit parameters:\n",
    "            amplitude_B = params_lorzt[0]\n",
    "            center_B = params_lorzt[1]\n",
    "            gamma_prime_B = params_lorzt[2]\n",
    "\n",
    "            # get fit parameter errors\n",
    "            center_B_error = errors_lorzt[1]\n",
    "            gamma_B_prime_error = errors_lorzt[2]\n",
    "            \n",
    "            # make fitted curve:\n",
    "            fitted_fourier_amplitudes_B = _lorentzian_no_offset(BoxShakeFreqs_for_fit, amplitude_B, center_B, gamma_prime_B)\n",
    "\n",
    "        \n",
    "        # print out fit results\n",
    "        print('-------- Fit result State 3 ---------')\n",
    "        #print('Amplitude: ' + str('{:.2f}'.format(amplitude_B)) + ' +/- ' + str('{:.2f}'.format(amplitude_B_error)))\n",
    "        print('Center (Hz): ' + str('{:.2f}'.format(center_B)) + ' +/- ' + str('{:.2f}'.format(center_B_error)))\n",
    "        print('Gamma (Hz): ' + str('{:.2f}'.format(gamma_prime_B)) + ' +/- ' + str('{:.2f}'.format(gamma_B_prime_error)))\n",
    "        #print('Offset: ' + str('{:.2f}'.format(offset_B)) + ' +/- ' + str('{:.2f}'.format(offset_B_error)))\n",
    "        \n",
    "        ##################################\n",
    "        # now plot fit:\n",
    "        fA_fit = ax.plot(BoxShakeFreqs_for_fit, fitted_fourier_amplitudes_A, color='red')\n",
    "        fB_fit = ax.plot(BoxShakeFreqs_for_fit, fitted_fourier_amplitudes_B, color='blue')\n",
    "        ax.legend([fA, fB, fA_fit, fB_fit],['State 1', 'State 3', 'State 1 fit', 'State 3 fit'])\n",
    "\n",
    "    else:\n",
    "        center_A = 0\n",
    "        gamma_prime_A = 0\n",
    "        center_B = 0 \n",
    "        gamma_prime_B = 0  \n",
    "        center_A_error = 0\n",
    "        gamma_A_prime_error = 0\n",
    "        center_B_error = 0\n",
    "        gamma_B_prime_error = 0\n",
    "        ax.legend([fA, fB],['State 1', 'State 3'])\n",
    "    \n",
    "    plt.ylabel('Fourier amplitude (arb. units)')\n",
    "    plt.xlabel('Box Shake Frequency (Hz)')    \n",
    "    \n",
    "    folder_name = os.path.basename(os.path.dirname(df['fullpaths'].iloc[0]))\n",
    "    if normalize:\n",
    "        plt.title('Sound resonance curve, $\\delta n/n$' + \"\\n\" + folder_name)\n",
    "    else:\n",
    "        plt.title('Sound resonance curve, $\\delta n$' + \"\\n\" + folder_name)\n",
    "    \n",
    "    fig.autofmt_xdate()\n",
    "    plt.show()\n",
    "\n",
    "    results_dict = dict()\n",
    "    results_dict['figure'] = fig\n",
    "    results_dict['center_A'] = center_A \n",
    "    results_dict['center_B'] = center_B\n",
    "    results_dict['gamma_A'] = gamma_prime_A\n",
    "    results_dict['gamma_B'] = gamma_prime_B\n",
    "    results_dict['center_A_error'] = center_A_error\n",
    "    results_dict['center_B_error'] = center_B_error\n",
    "    results_dict['gamma_A_error'] = gamma_A_prime_error\n",
    "    results_dict['gamma_B_error'] = gamma_B_prime_error\n",
    "        \n",
    "    return results_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9209a1b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Data filter</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11314e46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.358175Z",
     "start_time": "2023-03-08T02:54:44.354387Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def reset_data_filter(df):\n",
    "    good_shot = [True]*(df.shape[0])\n",
    "    df['good_shot'] = good_shot\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42994495",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:54:44.362097Z",
     "start_time": "2023-03-08T02:54:44.359266Z"
    },
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def data_filter(df, variable_to_filter, tolerance, condition_var_and_value = ['','']):    \n",
    "    # condition_var_and_value = [var_name, value] \n",
    "    if condition_var_and_value[0] != '' and condition_var_and_value[1] != '':\n",
    "        mean_var = np.mean(np.array(df[df[condition_var_and_value[0]]==condition_var_and_value[1]][variable_to_filter]))\n",
    "        std_var  = np.std(np.array(df[df[condition_var_and_value[0]]==condition_var_and_value[1]][variable_to_filter]))\n",
    "    else:\n",
    "        mean_var = df[variable_to_filter].mean()\n",
    "        std_var  = df[variable_to_filter].std() \n",
    "            \n",
    "    # next change good_shot to False if row[variable_to_filter_by] is outside of acceptance region\n",
    "    for index, row in df.iterrows():\n",
    "        if condition_var_and_value[0] != '' and condition_var_and_value[1] != '':\n",
    "            if row[condition_var_and_value[0]] == condition_var_and_value[1]:\n",
    "                if row[variable_to_filter] > mean_var + tolerance*std_var or row[variable_to_filter] < mean_var - tolerance*std_var:\n",
    "                    # classify all images with same run id as bad:\n",
    "                    for idx, r in df.iterrows():\n",
    "                        if r['run_id'] == row['run_id']:\n",
    "                            df.at[idx, 'good_shot'] = False\n",
    "                else:\n",
    "                    # classify all images with same run id as good:\n",
    "                    for idx, r in df.iterrows():\n",
    "                        if r['run_id'] == row['run_id']:\n",
    "                            df.at[idx, 'good_shot'] = True\n",
    "                    \n",
    "        else:\n",
    "            if row[variable_to_filter] > mean_var + tolerance*std_var or row[variable_to_filter] < mean_var - tolerance*std_var:\n",
    "                # classify all images with same run id as bad:\n",
    "                for idx, r in df.iterrows():\n",
    "                    if r['run_id'] == row['run_id']:\n",
    "                        df.at[idx, 'good_shot'] = False\n",
    "            else:\n",
    "                # classify all images with same run id as good:\n",
    "                for idx, r in df.iterrows():\n",
    "                    if r['run_id'] == row['run_id']:\n",
    "                        df.at[idx, 'good_shot'] = True\n",
    "                        \n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e76068f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'> Atomic Physics Tools </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ddccbd49",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  <font size=3, color=#399FD5>Breit-Rabi Diagram</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a7f5a74",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  <font size=3, color=#399FD5>Numerical Zeeman Effect Calculator</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5171dc3c",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  <font size=3, color=#399FD5>Simulations</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a7035e1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  <font size=3, color=#399FD5>BEC Counts Calculator</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6f3a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def BEC_counts_calculator(BEC_diameter, TOF, ax_freq, rad_freq, umpx):\n",
    "    r = BEC_diameter/2.0\n",
    "    tof = TOF/1000.0 # units in seconds\n",
    "    a = 85*(0.529e-10) # scattering length\n",
    "    omega = (2*np.pi*rad_freq*2*np.pi*rad_freq*2*np.pi*ax_freq)**(1/3)\n",
    "    m = mNa23\n",
    "    \n",
    "    BEC_counts = ((m/2*(2*np.pi*rad_freq)**2/(1 + (2*np.pi*rad_freq*tof)**2))*(umpx*10**(-6)*r)**2)**(5/2)/(15*hbar**2*m**(1/2)*omega**3*a/2**(5/2))\n",
    "    \n",
    "    return BEC_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef6cc349",
   "metadata": {},
   "source": [
    "# <font size=5, color='blue'> Initialize notebook</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all code cells above this to activate the notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f80d6a5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'> Na Catch </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ed2ed315",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black' >Na BEC </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c44c043a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6bfd8b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "data_frame_BEC, metadata_dict_BEC, experiment_parameters_dict_BEC = init_dataframe_metadata_and_exp_params()\n",
    "\n",
    "# ROI Box and norm_box for BEC\n",
    "ROI_BEC = [260, # x min\n",
    "           480, # x max\n",
    "           5,   # y min\n",
    "           220] # y max\n",
    "\n",
    "# BEC Norm Box:\n",
    "norm_box_BEC = [290, # x min\n",
    "                450, # x max \n",
    "                300, # y min\n",
    "                400] # y max\n",
    "\n",
    "# display BEC image:\n",
    "frame_type_BEC = 'FakeOD'\n",
    "current_file_fullpath_BEC = data_frame_BEC['fullpaths'][0]\n",
    "fig, ax = display_image(current_file_fullpath_BEC, ROI_BEC, norm_box_BEC, frame_type_BEC)\n",
    "\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_BEC)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_BEC)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4924970a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>BEC counts from radius</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af717c76",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "BEC_diameter = 70 # px\n",
    "BEC_TOF = 18 # ms\n",
    "BEC_ax_freq = 12 # Hz\n",
    "BEC_rad_freq = 95 # Hz\n",
    "BEC_um_per_px = 5\n",
    "\n",
    "BEC_counts = BEC_counts_calculator(BEC_diameter, BEC_TOF, BEC_ax_freq, BEC_rad_freq, BEC_um_per_px)\n",
    "print('BEC counts from radius: ' + str(BEC_counts))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "978971a1",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'>Li ODT LF Resonance Curve (Abs)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dc503b5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879a57b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "data_frame_ODT_LF, metadata_dict_ODT_LF, experiment_parameters_dict_ODT_LF = init_dataframe_metadata_and_exp_params()\n",
    "\n",
    "# ROI Box and norm_box for ODT LF\n",
    "ROI_ODT_LF = [250, 509, 120, 460] # y max\n",
    "\n",
    "# Li LF Norm Box (ODT):\n",
    "norm_box_ODT_LF = [250, 509, 50, 100] # y max\n",
    "\n",
    "# add background-subtracted FakeOD ROI to dataframe:\n",
    "data_frame_ODT_LF = add_background_subtracted_ROI_to_dataframe_fast(data_frame_ODT_LF, ROI_ODT_LF, norm_box_ODT_LF)\n",
    "\n",
    "\n",
    "# display Li LF image:\n",
    "frame_type_ODT_LF = 'FakeOD'\n",
    "current_file_fullpath_ODT_LF = data_frame_ODT_LF['fullpaths'][0]\n",
    "fig, ax = display_image(current_file_fullpath_ODT_LF, ROI_ODT_LF, norm_box_ODT_LF, frame_type_ODT_LF)\n",
    "\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_ODT_LF)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_ODT_LF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8e3ed08a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Li ODT LF pixel sums and resonance curve fitting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a977c5d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compute, for each shot, a pixel sum\n",
    "data_frame_ODT_LF = add_pixel_sums_to_data_frame_from_FakeOD_ROI(data_frame_ODT_LF)\n",
    "\n",
    "# get pixel sums and RF freqs from dataframe:\n",
    "pixel_sums_ODT_LF = data_frame_ODT_LF['pixel_sum']\n",
    "img_freqs_ODT_LF = data_frame_ODT_LF['LFImgFreq']\n",
    "\n",
    "# ODT LF: \n",
    "center_guess_ODT_LF = experiment_parameters_dict_ODT_LF[\"Values\"]['li_lf_res_freq']\n",
    "AOM_factor_ODT_LF = experiment_parameters_dict_ODT_LF[\"Values\"]['li_lf_freq_multiplier']\n",
    "\n",
    "fit_result_ODT_LF = Li_resonance_imaging_curve_fit(img_freqs_ODT_LF, \n",
    "                               pixel_sums_ODT_LF, \n",
    "                               AOM_factor_ODT_LF,\n",
    "                               center_guess_ODT_LF,\n",
    "                               plot_xlabel = 'LFImgFreq x AOM_Factor',\n",
    "                               plot_title = 'Li ODT LF res curve')\n",
    "\n",
    "print(fit_result_ODT_LF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "866aa044",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Li ODT LF atom counting</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "946605d0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font size=2, color=#6C828D>Get densities and atom counts</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d596cce6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get imaging parameters here:\n",
    "AOM_factor_ODT_LF = experiment_parameters_dict_ODT_LF[\"Values\"]['li_lf_freq_multiplier']\n",
    "omega0_ODT_LF = fit_result_ODT_LF['center']/AOM_factor_ODT_LF\n",
    "saturation_parameter_ODT_LF = fit_result_ODT_LF['calculated saturation parameter']\n",
    "um_per_pixel_ODT_LF = experiment_parameters_dict_ODT_LF['Values']['side_low_mag_um_per_pixel'] # in um\n",
    "\n",
    "# get densities:\n",
    "data_frame_ODT_LF = add_atom_densities_abs_to_data_frame_Side_LF_fast(data_frame_ODT_LF, \n",
    "                                                                      sigma0 = Li6D2sigma0,\n",
    "                                                                      Gamma = Li6D2Gamma, \n",
    "                                                                      s = saturation_parameter_ODT_LF, \n",
    "                                                                      omega0 = omega0_ODT_LF,\n",
    "                                                                      AOM_factor = AOM_factor_ODT_LF)\n",
    "\n",
    "# now get counts from this:\n",
    "data_frame_ODT_LF = add_atom_counts_from_densities_to_data_frame(data_frame_ODT_LF, \n",
    "                                                                 um_per_pixel_ODT_LF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99518a27",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font size=2, color=#6C828D>Plot counts</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a3a31",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "atom_counts_ODT_LF = data_frame_ODT_LF['atom_count']\n",
    "        \n",
    "plt.scatter(img_freqs_ODT_LF, atom_counts_ODT_LF, color = 'black', s=10)\n",
    "plt.ylim([0, max(atom_counts_ODT_LF)])\n",
    "plt.xlabel('LFImgFreq')\n",
    "plt.ylabel('Counts ODT LF')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "025ef7ee",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'>Li ODT Top HF Resonance Curve (Abs)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1d7bbae",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd606c61",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "data_frame_ODT_HF, metadata_dict_ODT_HF, experiment_parameters_dict_ODT_HF = init_dataframe_metadata_and_exp_params()\n",
    "\n",
    "# ROI Box and norm_box for ODT HF\n",
    "ROI_ODT_HF = [650, 1450, 1100, 1500] # y max\n",
    "\n",
    "# Li HF Norm Box (ODT):\n",
    "norm_box_ODT_HF = [900, 1500, 900, 1000] # y max\n",
    "\n",
    "# add background-subtracted FakeOD ROI to dataframe:\n",
    "data_frame_ODT_HF = add_background_subtracted_ROI_to_dataframe_fast(data_frame_ODT_HF, ROI_ODT_HF, norm_box_ODT_HF)\n",
    "\n",
    "# display Li LF image:\n",
    "frame_type_ODT_HF = 'FakeOD'\n",
    "current_file_fullpath_ODT_HF = data_frame_ODT_HF['fullpaths'][0]\n",
    "fig, ax = display_image(current_file_fullpath_ODT_HF, ROI_ODT_HF, norm_box_ODT_HF, frame_type_ODT_HF)\n",
    "\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_ODT_HF)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_ODT_HF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dcc4cc65",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Li ODT HF pixel sums and resonance curve fitting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75fcc2c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# HF pixel sums and resonance curve fitting \n",
    "# compute, for each shot, a pixel sum\n",
    "data_frame_ODT_HF = add_pixel_sums_to_data_frame_from_FakeOD_ROI(data_frame_ODT_HF)\n",
    "\n",
    "# get pixel sums and RF freqs from dataframe:\n",
    "pixel_sums_A_ODT_HF = data_frame_ODT_HF[data_frame_ODT_HF['image_type']=='TopA']['pixel_sum']\n",
    "img_freqs_A_ODT_HF = data_frame_ODT_HF[data_frame_ODT_HF['image_type']=='TopA']['ImagFreq1']\n",
    "pixel_sums_B_ODT_HF = data_frame_ODT_HF[data_frame_ODT_HF['image_type']=='TopB']['pixel_sum']\n",
    "img_freqs_B_ODT_HF = data_frame_ODT_HF[data_frame_ODT_HF['image_type']=='TopB']['ImagFreq2']\n",
    "\n",
    "# ODT Top: \n",
    "center_guess_A = experiment_parameters_dict_ODT_HF['Values']['state_1_unitarity_res_freq_MHz']\n",
    "center_guess_B = experiment_parameters_dict_ODT_HF['Values']['state_3_unitarity_res_freq_MHz']\n",
    "AOM_factor = experiment_parameters_dict_ODT_HF['Values']['li_hf_freq_multiplier']\n",
    "\n",
    "# Top A\n",
    "fit_result_TopA = Li_resonance_imaging_curve_fit(img_freqs_A_ODT_HF, \n",
    "                               pixel_sums_A_ODT_HF, \n",
    "                               AOM_factor,\n",
    "                               center_guess_A,       \n",
    "                               plot_xlabel = 'ImagFreq1 x AOM_Factor',\n",
    "                               plot_title = 'Li ODT Top A res curve')\n",
    "\n",
    "# Top B\n",
    "fit_result_TopB = Li_resonance_imaging_curve_fit(img_freqs_B_ODT_HF, \n",
    "                               pixel_sums_B_ODT_HF, \n",
    "                               AOM_factor,\n",
    "                               center_guess_B,\n",
    "                               plot_xlabel = 'ImagFreq2 x AOM_Factor',\n",
    "                               plot_title = 'Li ODT Top B res curve')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23dcacf7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Li ODT HF atom counting</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38306aa6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get densities from counts\n",
    "# get imaging parameters here:\n",
    "AOM_factor_ODT_HF = experiment_parameters_dict_ODT_HF[\"Values\"]['li_hf_freq_multiplier']\n",
    "omega0_ODT_HF_A = fit_result_TopA['center']/AOM_factor_ODT_HF # from fit\n",
    "omega0_ODT_HF_B = fit_result_TopB['center']/AOM_factor_ODT_HF # from fit\n",
    "saturation_parameter_ODT_HF_A = fit_result_TopA['calculated saturation parameter'] # from fit\n",
    "saturation_parameter_ODT_HF_B = fit_result_TopB['calculated saturation parameter'] # from fit\n",
    "um_per_pixel_ODT_HF = experiment_parameters_dict_ODT_HF['Values']['top_um_per_pixel'] # in um\n",
    "\n",
    "# get densities:\n",
    "data_frame_ODT_HF = add_atom_densities_abs_to_data_frame_TopAB_fast(data_frame_ODT_HF, \n",
    "                                                                    sigma0 = Li6D2sigma0,\n",
    "                                                                    Gamma = Li6D2Gamma, \n",
    "                                                                    s_A = saturation_parameter_ODT_HF_A, \n",
    "                                                                    s_B = saturation_parameter_ODT_HF_B,\n",
    "                                                                    omega0_A = omega0_ODT_HF_A,\n",
    "                                                                    omega0_B = omega0_ODT_HF_B,\n",
    "                                                                    AOM_factor = AOM_factor_ODT_HF)\n",
    "\n",
    "# now get counts from this:\n",
    "data_frame_ODT_HF = add_atom_counts_from_densities_to_data_frame(data_frame_ODT_HF, \n",
    "                                                                 um_per_pixel_ODT_HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6062d8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot counts\n",
    "atom_counts_ODT_HF_A = data_frame_ODT_HF[data_frame_ODT_HF['image_type']=='TopA']['atom_count']\n",
    "atom_counts_ODT_HF_B = data_frame_ODT_HF[data_frame_ODT_HF['image_type']=='TopB']['atom_count']\n",
    "\n",
    "# plot results now        \n",
    "plt.scatter(img_freqs_A_ODT_HF, atom_counts_ODT_HF_A, color = 'black',s=10)\n",
    "plt.ylim([0, max(atom_counts_ODT_HF_A)*1.1])\n",
    "plt.xlabel('ImagFreq1')\n",
    "plt.ylabel('Counts Top A')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(img_freqs_B_ODT_HF, atom_counts_ODT_HF_B, color = 'black',s=10)\n",
    "plt.ylim([0, max(atom_counts_ODT_HF_B)*1.1])\n",
    "plt.xlabel('ImagFreq2')\n",
    "plt.ylabel('Counts Top B')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6041d267",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'>Li Hybrid Top: Box Exp - with imbalance curve (PR)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "587a9c11",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Load existing dataframe</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bc51c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load existing df\n",
    "df_file_name = filedialog.askopenfilename()\n",
    "data_frame_Box_Exp_Imb_PR = pd.read_pickle(df_file_name)\n",
    "\n",
    "folder_path = os.path.dirname(df_file_name)\n",
    "metadata_fullpath = folder_path + \"/run_params_dump.json\"\n",
    "experiment_parameters_fullpath = folder_path + \"/experiment_parameters.json\"\n",
    "\n",
    "with open(metadata_fullpath, 'r') as json_file:\n",
    "    metadata_dict_Box_Exp_Imb_PR = json.load(json_file)  \n",
    "with open(experiment_parameters_fullpath, 'r') as json_file:\n",
    "    experiment_parameters_dict_Box_Exp_Imb_PR = json.load(json_file)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4b20952",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d08b4e",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "data_frame_Box_Exp_Imb_PR, metadata_dict_Box_Exp_Imb_PR, experiment_parameters_dict_Box_Exp_Imb_PR = init_dataframe_metadata_and_exp_params(['RF12_Time'])\n",
    "\n",
    "ROI_Box_Exp_Imb_PR = [1150, 1350, 1000, 1700] # xmin, xmax, ymin, ymax\n",
    "norm_box_Box_Exp_Imb_PR = [1150, 1350, 600, 700] # xmin, xmax, ymin, ymax\n",
    "\n",
    "# display image:\n",
    "frame_type_Box_Exp_Imb_PR = 'FakeOD'\n",
    "current_file_fullpath_Box_Exp_Imb_PR = data_frame_Box_Exp_Imb_PR['fullpaths'][1]\n",
    "fig, ax = display_image(current_file_fullpath_Box_Exp_Imb_PR, \n",
    "                        ROI_Box_Exp_Imb_PR, \n",
    "                        norm_box_Box_Exp_Imb_PR, \n",
    "                        frame_type_Box_Exp_Imb_PR)\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_Box_Exp_Imb_PR)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_Box_Exp_Imb_PR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "586d3cc4",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get column densities, counts, and energies</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ad91e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add od_roi and od_norm_box to dataframe, then column densities\n",
    "data_frame_Box_Exp_Imb_PR = add_background_subtracted_ROI_to_dataframe_fast(data_frame_Box_Exp_Imb_PR, \n",
    "                                                                           ROI_Box_Exp_Imb_PR, \n",
    "                                                                           norm_box_Box_Exp_Imb_PR)\n",
    "# get column densities\n",
    "data_frame_Box_Exp_Imb_PR = add_polrot_column_densities_to_dataframe(data_frame_Box_Exp_Imb_PR, \n",
    "                                                                     experiment_parameters_dict_Box_Exp_Imb_PR, \n",
    "                                                                     ROI_Box_Exp_Imb_PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b001a46",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get counts, energies, etc.\n",
    "Box_Exp_Imb_PR_result_dict = get_counts_energies_and_vars_from_hybrid_top_PR(data_frame_Box_Exp_Imb_PR, \n",
    "                                                                             experiment_parameters_dict_Box_Exp_Imb_PR, \n",
    "                                                                             extra_var = '')\n",
    "\n",
    "data_frame_Box_Exp_Imb_PR = Box_Exp_Imb_PR_result_dict['df']\n",
    "counts_A_Box_Exp_Imb_PR   = Box_Exp_Imb_PR_result_dict['counts_A']\n",
    "counts_B_Box_Exp_Imb_PR   = Box_Exp_Imb_PR_result_dict['counts_B']\n",
    "energies_A_Box_Exp_Imb_PR = Box_Exp_Imb_PR_result_dict['energies_A']\n",
    "energies_B_Box_Exp_Imb_PR = Box_Exp_Imb_PR_result_dict['energies_B']\n",
    "RF12_Times_Box_Exp_Imb    = Box_Exp_Imb_PR_result_dict['RF12_Times']\n",
    "run_ids_Box_Exp_Imb_PR    = Box_Exp_Imb_PR_result_dict['run_ids']\n",
    "fig_Box_Exp_Imb_PR        = Box_Exp_Imb_PR_result_dict['figure']\n",
    "imbalance_PR              = Box_Exp_Imb_PR_result_dict['imbalance']\n",
    "weighted_avg_energy_PR    = Box_Exp_Imb_PR_result_dict['weighted_average_energy']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffd7000f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get imbalance from counts</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f736490",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot imbalance vs RF12_Time and run_id\n",
    "fig_PR_imbalance_vs_RF12_Time = plt.figure(figsize=(7,4))\n",
    "ax_PR_imbalance_vs_RF12_Time = fig_PR_imbalance_vs_RF12_Time.add_subplot(121)\n",
    "ax_PR_imbalance_vs_RF12_Time.scatter(RF12_Times_Box_Exp_Imb, imbalance_PR, color = 'black', s = 10)\n",
    "fig_PR_imbalance_vs_RF12_Time.autofmt_xdate()\n",
    "plt.xlabel('RF12_Time (ms)')\n",
    "plt.ylabel('$(N_B-N_A)/(N_A+N_B)$')\n",
    "\n",
    "ax_PR_imbalance_vs_run_id = fig_PR_imbalance_vs_RF12_Time.add_subplot(122)\n",
    "ax_PR_imbalance_vs_run_id.scatter(run_ids_Box_Exp_Imb_PR, imbalance_PR, color = 'black', s=10)\n",
    "ax_PR_imbalance_vs_run_id.set_ylim(ymin=-1, ymax=1)\n",
    "ax_PR_imbalance_vs_run_id.set_xticks([])\n",
    "fig_PR_imbalance_vs_RF12_Time.autofmt_xdate()\n",
    "plt.xlabel('Run id')\n",
    "plt.ylabel('$(N_B-N_A)/(N_A+N_B)$')\n",
    "\n",
    "# add title to figure:\n",
    "folder_name = os.path.basename(os.path.dirname(data_frame_Box_Exp_Imb_PR['fullpaths'][0]))\n",
    "fig_PR_imbalance_vs_RF12_Time.suptitle(folder_name)\n",
    "fig_PR_imbalance_vs_RF12_Time.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print average imbalance:\n",
    "print('Average imbalance: ' + str(\"{:.2f}\".format(np.mean(imbalance_PR))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d507d71b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Save dataframe and results associated with data folder</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748ec501",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save df and results\n",
    "folder_name = os.path.basename(os.path.dirname(data_frame_Box_Exp_Imb_PR['fullpaths'][0]))\n",
    "today = str(datetime.date.today())\n",
    "path = \"/Users/huanbui/Desktop/BEC1_dataframes/\"\n",
    "# make directory if it's not there yet\n",
    "path_name = path+today+'/'+folder_name+'/'\n",
    "if os.path.isdir(path+today) == False:\n",
    "    os.mkdir(path+today)\n",
    "if os.path.isdir(path_name) == False:\n",
    "    os.mkdir(path_name)\n",
    "file_name = path_name + folder_name + \".pkl\"\n",
    "metadata_name = path_name + 'run_params_dump.json'\n",
    "run_params_name = path_name + 'experiment_parameters.json'\n",
    " \n",
    "# save dataframe as file_name:\n",
    "data_frame_Box_Exp_Imb_PR.to_pickle(file_name)\n",
    "\n",
    "# also save metadata and exp params:\n",
    "with open(metadata_name, 'w') as fp:\n",
    "    json.dump(metadata_dict_Box_Exp_Imb_PR, fp)\n",
    "with open(run_params_name, 'w') as fp:\n",
    "    json.dump(experiment_parameters_dict_Box_Exp_Imb_PR, fp)\n",
    "    \n",
    "# save images:\n",
    "fig_Box_Exp_Imb_PR.savefig(path_name+'Counts_and_Energies.png')\n",
    "#fig_PR_imbalance_vs_RF12_Time.savefig(path_name+'Imbalance_vs_RF12_and_Run_Id.png')\n",
    "\n",
    "# save numerical results as txt file:\n",
    "with open(path_name+folder_name+ '_results.txt', 'w') as f:\n",
    "    f.write('--- Counts and Energies per particle ---' + \"\\n\")\n",
    "    f.write('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_Box_Exp_Imb_PR))) + \"\\n\")\n",
    "    f.write('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_Box_Exp_Imb_PR))) + \"\\n\")\n",
    "    f.write('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_Box_Exp_Imb_PR))) + \"\\n\")\n",
    "    f.write('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_Box_Exp_Imb_PR)))+ \"\\n\")\n",
    "    f.write('Mean State 1 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_A_Box_Exp_Imb_PR)))+ \"\\n\")\n",
    "    f.write('Stdev state 1 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_A_Box_Exp_Imb_PR)))+ \"\\n\")\n",
    "    f.write('Mean State 3 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_B_Box_Exp_Imb_PR)))+ \"\\n\")\n",
    "    f.write('Stdev state 3 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_B_Box_Exp_Imb_PR)))+ \"\\n\")\n",
    "    f.write('Mean weighted energy (Hz): ' + str(\"{:.2f}\".format(np.mean(weighted_avg_energy_PR)))+ \"\\n\")\n",
    "    f.write('Std weighted energy (Hz):  ' + str(\"{:.2f}\".format(np.std(weighted_avg_energy_PR)))+ \"\\n\")\n",
    "    f.write('Average imbalance:         ' + str(\"{:.2f}\".format(np.mean(imbalance_PR)))+ \"\\n\")\n",
    "    f.write('Stdev imbalance:           ' + str(\"{:.2f}\".format(np.std(imbalance_PR)))+ \"\\n\")\n",
    "\n",
    "print('Results and images saved!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd199d71",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'>Li Hybrid Top: Box Exp - scanning Axicon Heating (PR)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b59ee57",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ca97e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "data_frame_Box_Exp_AxHeat, metadata_dict_Box_Exp_AxHeat, experiment_parameters_dict_Box_Exp_AxHeat = init_dataframe_metadata_and_exp_params(['RF12_Time','HeatCycles'])\n",
    "\n",
    "# ROI Box\n",
    "ROI_Box_Exp_AxHeat = [1150,  # x min\n",
    "          1350, # x max\n",
    "          800, # y min\n",
    "          1900] # y max\n",
    "# Norm box\n",
    "norm_box_Box_Exp_AxHeat = [1150,  # x min\n",
    "               1350, # x max\n",
    "               700,  # y min\n",
    "               800] # y max\n",
    "# display image:\n",
    "frame_type_Box_Exp_AxHeat = 'FakeOD'\n",
    "current_file_fullpath_Box_Exp_AxHeat = data_frame_Box_Exp_AxHeat['fullpaths'][1]\n",
    "fig, ax = display_image(current_file_fullpath_Box_Exp_AxHeat, \n",
    "                        ROI_Box_Exp_AxHeat, \n",
    "                        norm_box_Box_Exp_AxHeat, \n",
    "                        frame_type_Box_Exp_AxHeat)\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_Box_Exp_AxHeat)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_Box_Exp_AxHeat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d418b274",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get counts and energies (per particle) vs HeatCycles</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9813e05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add od_roi and od_norm_box to dataframe, then get column densities\n",
    "data_frame_Box_Exp_AxHeat = add_background_subtracted_ROI_to_dataframe_fast(data_frame_Box_Exp_AxHeat, \n",
    "                                                                           ROI_Box_Exp_AxHeat, \n",
    "                                                                           norm_box_Box_Exp_AxHeat)\n",
    "# get column densities\n",
    "data_frame_Box_Exp_AxHeat = add_polrot_column_densities_to_dataframe(data_frame_Box_Exp_AxHeat, \n",
    "                                                                     experiment_parameters_dict_Box_Exp_AxHeat, \n",
    "                                                                     ROI_Box_Exp_AxHeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a208a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get counts and energies, etc.\n",
    "Box_Exp_AxHeat_result_dict = get_counts_energies_and_vars_from_hybrid_top_PR(data_frame_Box_Exp_AxHeat, \n",
    "                                                                             experiment_parameters_dict_Box_Exp_AxHeat, \n",
    "                                                                             extra_var = 'HeatCycles')\n",
    "data_frame_Box_Exp_AxHeat = Box_Exp_AxHeat_result_dict['df']\n",
    "counts_A_Box_Exp_AxHeat = Box_Exp_AxHeat_result_dict['counts_A']\n",
    "counts_B_Box_Exp_AxHeat = Box_Exp_AxHeat_result_dict['counts_B']\n",
    "energies_A_Box_Exp_AxHeat = Box_Exp_AxHeat_result_dict['energies_A']\n",
    "energies_B_Box_Exp_AxHeat = Box_Exp_AxHeat_result_dict['energies_B']\n",
    "RF12_Times_Box_Exp_AxHeat = Box_Exp_AxHeat_result_dict['RF12_Times']\n",
    "run_ids_Box_Exp_AxHeat = Box_Exp_AxHeat_result_dict['run_ids']\n",
    "HeatCycles_Box_Exp_AxHeat = Box_Exp_AxHeat_result_dict['HeatCycles']\n",
    "fig_Box_Exp_AxHeat = Box_Exp_AxHeat_result_dict['figure']\n",
    "imbalance_AxHeat = Box_Exp_AxHeat_result_dict['imbalance'] \n",
    "weighted_avg_energy_AxHeat = Box_Exp_AxHeat_result_dict['weighted_average_energy']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c60d5e29",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Save dataframe and results associated with data folder</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf63cc8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save df and results\n",
    "folder_name = os.path.basename(os.path.dirname(data_frame_Box_Exp_AxHeat['fullpaths'][0]))\n",
    "today = str(datetime.date.today())\n",
    "path = \"/Users/huanbui/Desktop/BEC1_dataframes/\"\n",
    "# make directory if it's not there yet\n",
    "path_name = path+today+'/'+folder_name+'/'\n",
    "if os.path.isdir(path+today) == False:\n",
    "    os.mkdir(path+today)\n",
    "if os.path.isdir(path_name) == False:\n",
    "    os.mkdir(path_name)\n",
    "file_name = path_name + folder_name + \".pkl\"\n",
    "metadata_name = path_name + 'run_params_dump.json'\n",
    "run_params_name = path_name + 'experiment_parameters.json'\n",
    " \n",
    "# save dataframe as file_name:\n",
    "data_frame_Box_Exp_AxHeat.to_pickle(file_name)\n",
    "\n",
    "# also save metadata and exp params:\n",
    "with open(metadata_name, 'w') as fp:\n",
    "    json.dump(metadata_dict_Box_Exp_AxHeat, fp)\n",
    "with open(run_params_name, 'w') as fp:\n",
    "    json.dump(experiment_parameters_dict_Box_Exp_AxHeat, fp)\n",
    "    \n",
    "# save images:\n",
    "fig_Box_Exp_AxHeat.savefig(path_name+'Counts_and_Energies_vs_HeatCycles.png')\n",
    "#fig_PR_imbalance_vs_RF12_Time.savefig(path_name+'Imbalance_vs_RF12_and_Run_Id.png')\n",
    "\n",
    "# save numerical results as txt file:\n",
    "with open(path_name+folder_name+ '_results.txt', 'w') as f:\n",
    "    f.write('--- Counts and Energies per particle ---' + \"\\n\")\n",
    "    f.write('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_Box_Exp_AxHeat))) + \"\\n\")\n",
    "    f.write('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_Box_Exp_AxHeat))) + \"\\n\")\n",
    "    f.write('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_Box_Exp_AxHeat))) + \"\\n\")\n",
    "    f.write('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_Box_Exp_AxHeat)))+ \"\\n\")\n",
    "    f.write('Mean State 1 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_A_Box_Exp_AxHeat)))+ \"\\n\")\n",
    "    f.write('Stdev state 1 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_A_Box_Exp_AxHeat)))+ \"\\n\")\n",
    "    f.write('Mean State 3 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_B_Box_Exp_AxHeat)))+ \"\\n\")\n",
    "    f.write('Stdev state 3 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_B_Box_Exp_AxHeat)))+ \"\\n\")\n",
    "    f.write('Mean weighted energy (Hz): ' + str(\"{:.2f}\".format(np.mean(weighted_avg_energy_AxHeat)))+ \"\\n\")\n",
    "    f.write('Std weighted energy (Hz):  ' + str(\"{:.2f}\".format(np.std(weighted_avg_energy_AxHeat)))+ \"\\n\")\n",
    "    f.write('Average imbalance:         ' + str(\"{:.2f}\".format(np.mean(imbalance_AxHeat)))+ \"\\n\")\n",
    "    f.write('Std imbalance:             ' + str(\"{:.2f}\".format(np.std(imbalance_AxHeat)))+ \"\\n\")\n",
    "\n",
    "print('Results and images saved!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cbbf5367",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'>Li Hybrid Top: Box Exp - Mixed Heating (PR)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b71504f",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Load existing dataframe</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3623166",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load existing df\n",
    "df_file_name = filedialog.askopenfilename()\n",
    "data_frame_Box_Exp_mixedheat = pd.read_pickle(df_file_name)\n",
    "\n",
    "folder_path = os.path.dirname(df_file_name)\n",
    "metadata_fullpath = folder_path + \"/run_params_dump.json\"\n",
    "experiment_parameters_fullpath = folder_path + \"/experiment_parameters.json\"\n",
    "\n",
    "with open(metadata_fullpath, 'r') as json_file:\n",
    "    metadata_dict_Box_Exp_mixedheat = json.load(json_file)  \n",
    "with open(experiment_parameters_fullpath, 'r') as json_file:\n",
    "    experiment_parameters_dict_Box_Exp_mixedheat = json.load(json_file) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15ae02f3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f164cd4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "data_frame_Box_Exp_mixedheat, metadata_dict_Box_Exp_mixedheat, experiment_parameters_dict_Box_Exp_mixedheat = init_dataframe_metadata_and_exp_params(['RF12_Time', 'HeatCycles'])\n",
    "\n",
    "# ROI Box\n",
    "ROI_Box_Exp_mixedheat = [1150, 1350, 900, 1800] # y max\n",
    "# Norm box\n",
    "norm_box_Box_Exp_mixedheat = [1150, 1350, 700, 800] # y max\n",
    "# display image:\n",
    "frame_type_Box_Exp_mixedheat = 'FakeOD'\n",
    "current_file_fullpath_Box_Exp_mixedheat = data_frame_Box_Exp_mixedheat['fullpaths'][1]\n",
    "fig, ax = display_image(current_file_fullpath_Box_Exp_mixedheat, \n",
    "                        ROI_Box_Exp_mixedheat, \n",
    "                        norm_box_Box_Exp_mixedheat, \n",
    "                        frame_type_Box_Exp_mixedheat)\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_Box_Exp_mixedheat)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_Box_Exp_mixedheat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a17546ef",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get column densities, counts, and energies</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027b6db",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add od_roi and od_norm_box to dataframe, then get column densities\n",
    "data_frame_Box_Exp_mixedheat = add_background_subtracted_ROI_to_dataframe_fast(data_frame_Box_Exp_mixedheat, \n",
    "                                                                           ROI_Box_Exp_mixedheat, \n",
    "                                                                           norm_box_Box_Exp_mixedheat)\n",
    "# get column densities\n",
    "data_frame_Box_Exp_mixedheat = add_polrot_column_densities_to_dataframe(data_frame_Box_Exp_mixedheat, \n",
    "                                                                     experiment_parameters_dict_Box_Exp_mixedheat, \n",
    "                                                                     ROI_Box_Exp_mixedheat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8541b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get counts, tilt, and energies, etc.\n",
    "data_frame_Box_Exp_mixedheat = add_counts_from_PR_column_densities_to_dataframe(data_frame_Box_Exp_mixedheat, \n",
    "                                                                             experiment_parameters_dict_Box_Exp_mixedheat)\n",
    "# tilt, add n3d along harmonic axis, find trap center and add boundary of cloud to get Energy\n",
    "data_frame_Box_Exp_mixedheat = add_justified_column_density_to_dataframe(data_frame_Box_Exp_mixedheat, \n",
    "                                                                         experiment_parameters_dict_Box_Exp_mixedheat)\n",
    "data_frame_Box_Exp_mixedheat = add_n3d_along_harmonic_axis_to_dataframe(data_frame_Box_Exp_mixedheat, \n",
    "                                                                     experiment_parameters_dict_Box_Exp_mixedheat)\n",
    "data_frame_Box_Exp_mixedheat = add_hybrid_harmonic_trap_centers_to_dataframe(data_frame_Box_Exp_mixedheat)\n",
    "# add energies (from expansion into harmonic axial trap)\n",
    "data_frame_Box_Exp_mixedheat = add_energy_from_hybrid_expansion_to_dataframe(data_frame_Box_Exp_mixedheat, \n",
    "                                                                          experiment_parameters_dict_Box_Exp_mixedheat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42e102bc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Report counts, energies, and imbalance (no heat)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0159c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# report results for unheated\n",
    "# now get counts, energies versus run_id for HeatCycles = 0\n",
    "counts_A_noheat = data_frame_Box_Exp_mixedheat[(data_frame_Box_Exp_mixedheat['image_type'] == 'TopA') & (data_frame_Box_Exp_mixedheat['HeatCycles'] == 0)]['atom_count']\n",
    "counts_B_noheat = data_frame_Box_Exp_mixedheat[(data_frame_Box_Exp_mixedheat['image_type'] == 'TopB') & (data_frame_Box_Exp_mixedheat['HeatCycles'] == 0)]['atom_count']\n",
    "energies_A_noheat = data_frame_Box_Exp_mixedheat[(data_frame_Box_Exp_mixedheat['image_type'] == 'TopA') & (data_frame_Box_Exp_mixedheat['HeatCycles'] == 0)]['E_hz_pp_from_ax_trap']\n",
    "energies_B_noheat = data_frame_Box_Exp_mixedheat[(data_frame_Box_Exp_mixedheat['image_type'] == 'TopB') & (data_frame_Box_Exp_mixedheat['HeatCycles'] == 0)]['E_hz_pp_from_ax_trap']\n",
    "run_ids_noheat = data_frame_Box_Exp_mixedheat[(data_frame_Box_Exp_mixedheat['image_type'] == 'TopA') & (data_frame_Box_Exp_mixedheat['HeatCycles'] == 0)]['run_id']\n",
    "\n",
    "fig_Box_Exp_noheat = plt.figure(figsize=(7,3))\n",
    "ax_Box_Exp_noheat_counts = fig_Box_Exp_noheat.add_subplot(121)\n",
    "\n",
    "# plot counts vs Run Id\n",
    "pr1_Box_Exp_noheat = ax_Box_Exp_noheat_counts.scatter(run_ids_noheat, counts_A_noheat, color = 'red' , s = 10)\n",
    "pr2_Box_Exp_noheat = ax_Box_Exp_noheat_counts.scatter(run_ids_noheat, counts_B_noheat, color = 'blue', s = 10)\n",
    "\n",
    "ax_Box_Exp_noheat_counts.legend([pr1_Box_Exp_noheat, pr2_Box_Exp_noheat],['State 1', 'State 3'])\n",
    "fig_Box_Exp_noheat.autofmt_xdate()\n",
    "ax_Box_Exp_noheat_counts.set_xticks([])\n",
    "ax_Box_Exp_noheat_counts.set_ylim(ymin=0)\n",
    "plt.xlabel('Run Id')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "# plot energies vs run id\n",
    "ax_Box_Exp_noheat_energies = fig_Box_Exp_noheat.add_subplot(122)\n",
    "e1_Box_Exp_noheat = ax_Box_Exp_noheat_energies.scatter(run_ids_noheat, energies_A_noheat, color = 'red', s = 10)\n",
    "e2_Box_Exp_noheat = ax_Box_Exp_noheat_energies.scatter(run_ids_noheat, energies_B_noheat, color = 'blue', s = 10)\n",
    "ax_Box_Exp_noheat_energies.legend([e1_Box_Exp_noheat, e2_Box_Exp_noheat],['State 1', 'State 3'])\n",
    "fig_Box_Exp_noheat.autofmt_xdate()\n",
    "ax_Box_Exp_noheat_energies.set_xticks([])\n",
    "ax_Box_Exp_noheat_energies.set_ylim(ymin=0)\n",
    "plt.xlabel('Run Id')\n",
    "plt.ylabel('Energies per particle (Hz)')\n",
    "\n",
    "# add title to figure:\n",
    "folder_name = os.path.basename(os.path.dirname(data_frame_Box_Exp_mixedheat['fullpaths'][0]))\n",
    "fig_Box_Exp_noheat.suptitle(folder_name + \"\\n\" + 'no heat')\n",
    "fig_Box_Exp_noheat.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# calculate imbalance vs Run Id\n",
    "counts_A_noheat = np.array(counts_A_noheat)\n",
    "counts_B_noheat = np.array(counts_B_noheat)\n",
    "energies_A_noheat = np.array(energies_A_noheat)\n",
    "energies_B_noheat = np.array(energies_B_noheat)\n",
    "imbalance_noheat = (counts_B_noheat - counts_A_noheat)/(counts_B_noheat + counts_A_noheat)\n",
    "weighted_avg_energy_noheat = (energies_A_noheat*counts_A_noheat + energies_B_noheat*counts_B_noheat)/(counts_A_noheat + counts_B_noheat)\n",
    "\n",
    "#### statistics report ####\n",
    "print('--- Counts and Energies per particle (NO HEAT) ---')\n",
    "print('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_noheat))))\n",
    "print('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_noheat))))\n",
    "print('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_noheat))))\n",
    "print('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_noheat))))\n",
    "print('Mean State 1 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_A_noheat))))\n",
    "print('Stdev state 1 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_A_noheat))))\n",
    "print('Mean State 3 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_B_noheat))))\n",
    "print('Stdev state 3 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_B_noheat))))\n",
    "print('Mean weighted energy (Hz): ' + str(\"{:.2f}\".format(np.mean(weighted_avg_energy_noheat))))\n",
    "print('Std weighted energy (Hz):  ' + str(\"{:.2f}\".format(np.std(weighted_avg_energy_noheat))))\n",
    "# print average imbalance:\n",
    "print('Average imbalance:         ' + str(\"{:.2f}\".format(np.mean(imbalance_noheat))))\n",
    "print('Std imbalance:             ' + str(\"{:.2f}\".format(np.std(imbalance_noheat))))\n",
    "# print RF12 Time:\n",
    "RF12_Time_noheat = data_frame_Box_Exp_mixedheat[data_frame_Box_Exp_mixedheat['HeatCycles']==0]['RF12_Time'].iloc[0]\n",
    "print('RF12 Time (ms):            ' + str(\"{:.2f}\".format(RF12_Time_noheat)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f3cbc16",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Report counts, energies, and imbalance (with heat)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7b4ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# report statistics for heated:\n",
    "# now get counts, energies versus run_id for HeatCycles = 0\n",
    "counts_A_heat = data_frame_Box_Exp_mixedheat[(data_frame_Box_Exp_mixedheat['image_type'] == 'TopA') & (data_frame_Box_Exp_mixedheat['HeatCycles'] != 0)]['atom_count']\n",
    "counts_B_heat = data_frame_Box_Exp_mixedheat[(data_frame_Box_Exp_mixedheat['image_type'] == 'TopB') & (data_frame_Box_Exp_mixedheat['HeatCycles'] != 0)]['atom_count']\n",
    "energies_A_heat = data_frame_Box_Exp_mixedheat[(data_frame_Box_Exp_mixedheat['image_type'] == 'TopA') & (data_frame_Box_Exp_mixedheat['HeatCycles'] != 0)]['E_hz_pp_from_ax_trap']\n",
    "energies_B_heat = data_frame_Box_Exp_mixedheat[(data_frame_Box_Exp_mixedheat['image_type'] == 'TopB') & (data_frame_Box_Exp_mixedheat['HeatCycles'] != 0)]['E_hz_pp_from_ax_trap']\n",
    "run_ids_heat = data_frame_Box_Exp_mixedheat[(data_frame_Box_Exp_mixedheat['image_type'] == 'TopA') & (data_frame_Box_Exp_mixedheat['HeatCycles'] != 0)]['run_id']\n",
    "\n",
    "fig_Box_Exp_heat = plt.figure(figsize=(7,3))\n",
    "ax_Box_Exp_heat_counts = fig_Box_Exp_heat.add_subplot(121)\n",
    "\n",
    "# plot counts vs Run Id\n",
    "pr1_Box_Exp_heat = ax_Box_Exp_heat_counts.scatter(run_ids_heat, counts_A_heat, color = 'red', s = 10)\n",
    "pr2_Box_Exp_heat = ax_Box_Exp_heat_counts.scatter(run_ids_heat, counts_B_heat, color = 'blue', s = 10)\n",
    "\n",
    "ax_Box_Exp_heat_counts.legend([pr1_Box_Exp_heat, pr2_Box_Exp_heat],['State 1', 'State 3'])\n",
    "fig_Box_Exp_heat.autofmt_xdate()\n",
    "ax_Box_Exp_heat_counts.set_xticks([])\n",
    "ax_Box_Exp_heat_counts.set_ylim(ymin=0)\n",
    "plt.xlabel('Run Id')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "# plot energies vs run id\n",
    "ax_Box_Exp_heat_energies = fig_Box_Exp_heat.add_subplot(122)\n",
    "e1_Box_Exp_heat = ax_Box_Exp_heat_energies.scatter(run_ids_heat, energies_A_heat, color = 'red', s = 10)\n",
    "e2_Box_Exp_heat = ax_Box_Exp_heat_energies.scatter(run_ids_heat, energies_B_heat, color = 'blue', s = 10)\n",
    "\n",
    "ax_Box_Exp_heat_energies.legend([e1_Box_Exp_heat, e2_Box_Exp_heat],['State 1', 'State 3'])\n",
    "fig_Box_Exp_heat.autofmt_xdate()\n",
    "ax_Box_Exp_heat_energies.set_xticks([])\n",
    "ax_Box_Exp_heat_energies.set_ylim(ymin=0)\n",
    "plt.xlabel('Run Id')\n",
    "plt.ylabel('Energies per particle (Hz)')\n",
    "\n",
    "# add title to figure:\n",
    "folder_name = os.path.basename(os.path.dirname(data_frame_Box_Exp_mixedheat['fullpaths'][0]))\n",
    "fig_Box_Exp_heat.suptitle(folder_name + \"\\n\" + 'with heat')\n",
    "fig_Box_Exp_heat.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# calculate imbalance vs Run Id\n",
    "counts_A_heat = np.array(counts_A_heat)\n",
    "counts_B_heat = np.array(counts_B_heat)\n",
    "energies_A_heat = np.array(energies_A_heat)\n",
    "energies_B_heat = np.array(energies_B_heat)\n",
    "imbalance_heat = (counts_B_heat - counts_A_heat)/(counts_B_heat + counts_A_heat)\n",
    "weighted_avg_energy_heat = (energies_A_heat*counts_A_heat + energies_B_heat*counts_B_heat)/(counts_A_heat + counts_B_heat)\n",
    "\n",
    "#### statistics report ####\n",
    "print('--- Counts and Energies per particle (WITH HEAT) ---')\n",
    "print('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_heat))))\n",
    "print('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_heat))))\n",
    "print('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_heat))))\n",
    "print('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_heat))))\n",
    "print('Mean State 1 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_A_heat))))\n",
    "print('Stdev state 1 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_A_heat))))\n",
    "print('Mean State 3 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_B_heat))))\n",
    "print('Stdev state 3 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_B_heat))))\n",
    "print('Mean weighted energy (Hz): ' + str(\"{:.2f}\".format(np.mean(weighted_avg_energy_heat))))\n",
    "print('Std weighted energy (Hz):  ' + str(\"{:.2f}\".format(np.std(weighted_avg_energy_heat))))\n",
    "# print average imbalance:\n",
    "print('Average imbalance:         ' + str(\"{:.2f}\".format(np.mean(imbalance_heat))))\n",
    "print('Std imbalance:             ' + str(\"{:.2f}\".format(np.std(imbalance_heat))))\n",
    "# print RF12 Time:\n",
    "RF12_Time_heat = data_frame_Box_Exp_mixedheat[data_frame_Box_Exp_mixedheat['HeatCycles']!=0]['RF12_Time'].iloc[0]\n",
    "print('RF12 Time (ms):            ' + str(\"{:.2f}\".format(RF12_Time_heat)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00b7839a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Save dataframe, figures, and results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33ef08",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save df and results\n",
    "folder_name = os.path.basename(os.path.dirname(data_frame_Box_Exp_mixedheat['fullpaths'][0]))\n",
    "today = str(datetime.date.today())\n",
    "path = \"/Users/huanbui/Desktop/BEC1_dataframes/\"\n",
    "# make directory if it's not there yet\n",
    "path_name = path+today+'/'+folder_name+'/'\n",
    "\n",
    "if os.path.isdir(path+today) == False:\n",
    "    os.mkdir(path+today)\n",
    "if os.path.isdir(path_name) == False:\n",
    "    os.mkdir(path_name)\n",
    "    \n",
    "file_name = path_name + folder_name + \".pkl\"\n",
    "metadata_name = path_name + 'run_params_dump.json'\n",
    "run_params_name = path_name + 'experiment_parameters.json'\n",
    " \n",
    "# save dataframe as file_name:\n",
    "data_frame_Box_Exp_mixedheat.to_pickle(file_name)\n",
    "\n",
    "# also save metadata and exp params:\n",
    "with open(metadata_name, 'w') as fp:\n",
    "    json.dump(metadata_dict_Box_Exp_mixedheat, fp)\n",
    "with open(run_params_name, 'w') as fp:\n",
    "    json.dump(experiment_parameters_dict_Box_Exp_mixedheat, fp)\n",
    "    \n",
    "# save images:\n",
    "fig_Box_Exp_noheat.savefig(path_name+'Counts_and_Energies_noheat.png')\n",
    "fig_Box_Exp_heat.savefig(path_name+'Counts_and_Energies_heat.png')\n",
    "\n",
    "# save numerical results as txt file:\n",
    "with open(path_name+folder_name+ '_results.txt', 'w') as f:\n",
    "    # no heat\n",
    "    f.write('--- Counts and Energies per particle NO HEAT ---' + \"\\n\")\n",
    "    f.write('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_noheat))) + \"\\n\")\n",
    "    f.write('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_noheat))) + \"\\n\")\n",
    "    f.write('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_noheat))) + \"\\n\")\n",
    "    f.write('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_noheat)))+ \"\\n\")\n",
    "    f.write('Mean State 1 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_A_noheat)))+ \"\\n\")\n",
    "    f.write('Stdev state 1 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_A_noheat)))+ \"\\n\")\n",
    "    f.write('Mean State 3 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_B_noheat)))+ \"\\n\")\n",
    "    f.write('Stdev state 3 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_B_noheat)))+ \"\\n\")\n",
    "    f.write('Mean weighted energy (Hz): ' + str(\"{:.2f}\".format(np.mean(weighted_avg_energy_noheat)))+ \"\\n\")\n",
    "    f.write('Std weighted energy (Hz):  ' + str(\"{:.2f}\".format(np.std(weighted_avg_energy_noheat)))+ \"\\n\")\n",
    "    f.write('Average imbalance:         ' + str(\"{:.2f}\".format(np.mean(imbalance_noheat)))+ \"\\n\")\n",
    "    f.write('Std imbalance:             ' + str(\"{:.2f}\".format(np.std(imbalance_noheat)))+ \"\\n\")\n",
    "    f.write('RF12 Time (ms):            ' + str(\"{:.2f}\".format(RF12_Time_noheat)) + \"\\n\")\n",
    "    # with heat\n",
    "    f.write('--- Counts and Energies per particle WITH HEAT ---' + \"\\n\")\n",
    "    f.write('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_heat))) + \"\\n\")\n",
    "    f.write('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_heat))) + \"\\n\")\n",
    "    f.write('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_heat))) + \"\\n\")\n",
    "    f.write('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_heat)))+ \"\\n\")\n",
    "    f.write('Mean State 1 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_A_heat)))+ \"\\n\")\n",
    "    f.write('Stdev state 1 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_A_heat)))+ \"\\n\")\n",
    "    f.write('Mean State 3 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_B_heat)))+ \"\\n\")\n",
    "    f.write('Stdev state 3 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_B_heat)))+ \"\\n\")\n",
    "    f.write('Mean weighted energy (Hz): ' + str(\"{:.2f}\".format(np.mean(weighted_avg_energy_heat)))+ \"\\n\")\n",
    "    f.write('Std weighted energy (Hz):  ' + str(\"{:.2f}\".format(np.std(weighted_avg_energy_heat)))+ \"\\n\")\n",
    "    f.write('Average imbalance:         ' + str(\"{:.2f}\".format(np.mean(imbalance_heat)))+ \"\\n\")\n",
    "    f.write('Std imbalance:             ' + str(\"{:.2f}\".format(np.std(imbalance_heat)))+ \"\\n\")\n",
    "    f.write('RF12 Time (ms):            ' + str(\"{:.2f}\".format(RF12_Time_heat)) + \"\\n\")\n",
    "    \n",
    "print('Results and images saved!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a1219ba",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'>Li Hybrid Top: Compressibility (PR)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0742cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "df_compressibility, metadata_dict_compressibility, experiment_parameters_dict_compressibility = init_dataframe_metadata_and_exp_params(['RF12_Time'])\n",
    "\n",
    "ROI_compressibility = [1150, 1350, 800, 1900] # xmin, xmax, ymin, ymax\n",
    "norm_box_compressibility = [1150, 1350, 600, 700] # xmin, xmax, ymin, ymax\n",
    "\n",
    "# display image:\n",
    "frame_type_compressibility = 'FakeOD'\n",
    "current_file_fullpath_compressibility = df_compressibility['fullpaths'][1]\n",
    "fig, ax = display_image(current_file_fullpath_compressibility, \n",
    "                        ROI_compressibility, \n",
    "                        norm_box_compressibility, \n",
    "                        frame_type_compressibility)\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_compressibility)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_compressibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add od_roi and od_norm_box to dataframe, then column densities\n",
    "df_compressibility = add_background_subtracted_ROI_to_dataframe_fast(df_compressibility, \n",
    "                                                                           ROI_compressibility, \n",
    "                                                                           norm_box_compressibility)\n",
    "# get column densities\n",
    "df_compressibility = add_polrot_column_densities_to_dataframe(df_compressibility, \n",
    "                                                                     experiment_parameters_dict_compressibility, \n",
    "                                                                     ROI_compressibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb2b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts, energies, etc.\n",
    "compressibility_result_dict = get_counts_energies_and_vars_from_hybrid_top_PR(df_compressibility, \n",
    "                                                                             experiment_parameters_dict_compressibility, \n",
    "                                                                             extra_var = '')\n",
    "\n",
    "df_compressibility                     = compressibility_result_dict['df']\n",
    "counts_A_compressibility               = compressibility_result_dict['counts_A']\n",
    "counts_B_compressibility               = compressibility_result_dict['counts_B']\n",
    "energies_A_compressibility             = compressibility_result_dict['energies_A']\n",
    "energies_B_compressibility             = compressibility_result_dict['energies_B']\n",
    "RF12_Times_compressibility             = compressibility_result_dict['RF12_Times']\n",
    "run_ids_compressibility                = compressibility_result_dict['run_ids']\n",
    "fig_compressibility                    = compressibility_result_dict['figure']\n",
    "imbalance_compressibility              = compressibility_result_dict['imbalance']\n",
    "weighted_avg_energy_compressibility    = compressibility_result_dict['weighted_average_energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compressibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.arange(abs(ROI_compressibility[2] - ROI_compressibility[3]))\n",
    "z = z - df_compressibility['hybrid_harmonic_trap_center'].iloc[0]\n",
    "axial_trap_frequency_hz = experiment_parameters_dict_compressibility['Values']['axial_trap_frequency_hz']\n",
    "top_um_per_pixel =  experiment_parameters_dict_compressibility['Values']['top_um_per_pixel']\n",
    "Uz_hz = ((mLi6 * (2*np.pi*axial_trap_frequency_hz)**2 * (z*top_um_per_pixel*1e-6)**2)/2 ) / (2*np.pi*hbar)\n",
    "\n",
    "print(Uz_hz)\n",
    "\n",
    "plt.plot(z, df_compressibility[df_compressibility['image_type']=='TopA']['n3D_along_harmonic_ax'].mean())\n",
    "plt.plot(z, df_compressibility[df_compressibility['image_type']=='TopB']['n3D_along_harmonic_ax'].mean())\n",
    "plt.xticks(z, Uz_hz)\n",
    "plt.locator_params(axis='x', nbins=4)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "554a730f",
   "metadata": {},
   "source": [
    "# <font size=5, color='black'>Li Hybrid Top: Box Exp - Mixed RF (PR)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63d20d",
   "metadata": {},
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f50a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "data_frame_Box_Exp_mixedRF, metadata_dict_Box_Exp_mixedRF, experiment_parameters_dict_Box_Exp_mixedRF = init_dataframe_metadata_and_exp_params(['RF12_Time'])\n",
    "\n",
    "# ROI Box\n",
    "ROI_Box_Exp_mixedRF = [1150, 1350, 900, 1800] # y max\n",
    "# Norm box\n",
    "norm_box_Box_Exp_mixedRF = [1150, 1350, 700, 800] # y max\n",
    "# display image:\n",
    "frame_type_Box_Exp_mixedRF = 'FakeOD'\n",
    "current_file_fullpath_Box_Exp_mixedRF = data_frame_Box_Exp_mixedRF['fullpaths'][1]\n",
    "fig, ax = display_image(current_file_fullpath_Box_Exp_mixedRF, \n",
    "                        ROI_Box_Exp_mixedRF, \n",
    "                        norm_box_Box_Exp_mixedRF, \n",
    "                        frame_type_Box_Exp_mixedRF)\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_Box_Exp_mixedRF)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_Box_Exp_mixedRF)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b24ac74",
   "metadata": {},
   "source": [
    "## <font size=3, color=#399FD5>Analyze</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383e1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add od_roi and od_norm_box to dataframe, then get column densities\n",
    "data_frame_Box_Exp_mixedRF = add_background_subtracted_ROI_to_dataframe_fast(data_frame_Box_Exp_mixedRF, \n",
    "                                                                           ROI_Box_Exp_mixedRF, \n",
    "                                                                           norm_box_Box_Exp_mixedRF)\n",
    "# get column densities\n",
    "data_frame_Box_Exp_mixedRF = add_polrot_column_densities_to_dataframe(data_frame_Box_Exp_mixedRF, \n",
    "                                                                     experiment_parameters_dict_Box_Exp_mixedRF, \n",
    "                                                                     ROI_Box_Exp_mixedRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8681356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts, tilt, and energies, etc.\n",
    "data_frame_Box_Exp_mixedRF = add_counts_from_PR_column_densities_to_dataframe(data_frame_Box_Exp_mixedRF, \n",
    "                                                                             experiment_parameters_dict_Box_Exp_mixedRF)\n",
    "# tilt, add n3d along harmonic axis, find trap center and add boundary of cloud to get Energy\n",
    "data_frame_Box_Exp_mixedRF = add_justified_column_density_to_dataframe(data_frame_Box_Exp_mixedRF, \n",
    "                                                                         experiment_parameters_dict_Box_Exp_mixedRF)\n",
    "data_frame_Box_Exp_mixedRF = add_n3d_along_harmonic_axis_to_dataframe(data_frame_Box_Exp_mixedRF, \n",
    "                                                                     experiment_parameters_dict_Box_Exp_mixedRF)\n",
    "data_frame_Box_Exp_mixedRF = add_hybrid_harmonic_trap_centers_to_dataframe(data_frame_Box_Exp_mixedRF)\n",
    "# add energies (from expansion into harmonic axial trap)\n",
    "data_frame_Box_Exp_mixedRF = add_energy_from_hybrid_expansion_to_dataframe(data_frame_Box_Exp_mixedRF, \n",
    "                                                                          experiment_parameters_dict_Box_Exp_mixedRF)\n",
    "\n",
    "# FILTER DATA\n",
    "data_frame_Box_Exp_mixedRF = data_filter(data_frame_Box_Exp_mixedRF, 'atom_count', 1.5, ['image_type','TopA'])\n",
    "data_frame_Box_Exp_mixedRF = data_filter(data_frame_Box_Exp_mixedRF, 'atom_count', 1.5, ['image_type','TopB'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report results for RF12_1\n",
    "# now get counts, energies versus run_id for HeatCycles = 0\n",
    "counts_A_RF12_1 = data_frame_Box_Exp_mixedRF[(data_frame_Box_Exp_mixedRF['image_type'] == 'TopA') & \n",
    "                                             (data_frame_Box_Exp_mixedRF['RF12_Time'] == 11) & \n",
    "                                             (data_frame_Box_Exp_mixedRF['good_shot'] == True)]['atom_count']\n",
    "counts_B_RF12_1 = data_frame_Box_Exp_mixedRF[(data_frame_Box_Exp_mixedRF['image_type'] == 'TopB') & \n",
    "                                             (data_frame_Box_Exp_mixedRF['RF12_Time'] == 11) & \n",
    "                                             (data_frame_Box_Exp_mixedRF['good_shot'] == True)]['atom_count']\n",
    "energies_A_RF12_1 = data_frame_Box_Exp_mixedRF[(data_frame_Box_Exp_mixedRF['image_type'] == 'TopA') & \n",
    "                                               (data_frame_Box_Exp_mixedRF['RF12_Time'] == 11) & \n",
    "                                               (data_frame_Box_Exp_mixedRF['good_shot'] == True)]['E_hz_pp_from_ax_trap']\n",
    "energies_B_RF12_1 = data_frame_Box_Exp_mixedRF[(data_frame_Box_Exp_mixedRF['image_type'] == 'TopB') & \n",
    "                                               (data_frame_Box_Exp_mixedRF['RF12_Time'] == 11) & \n",
    "                                               (data_frame_Box_Exp_mixedRF['good_shot'] == True)]['E_hz_pp_from_ax_trap']\n",
    "run_ids_RF12_1 = data_frame_Box_Exp_mixedRF[(data_frame_Box_Exp_mixedRF['image_type'] == 'TopA') & \n",
    "                                            (data_frame_Box_Exp_mixedRF['RF12_Time'] == 11) & \n",
    "                                            (data_frame_Box_Exp_mixedRF['good_shot'] == True)]['run_id']\n",
    "\n",
    "fig_Box_Exp_RF12_1 = plt.figure(figsize=(7,3))\n",
    "ax_Box_Exp_RF12_1_counts = fig_Box_Exp_RF12_1.add_subplot(121)\n",
    "\n",
    "# plot counts vs Run Id\n",
    "pr1_Box_Exp_RF12_1 = ax_Box_Exp_RF12_1_counts.scatter(run_ids_RF12_1, counts_A_RF12_1, color = 'red' , s = 10)\n",
    "pr2_Box_Exp_RF12_1 = ax_Box_Exp_RF12_1_counts.scatter(run_ids_RF12_1, counts_B_RF12_1, color = 'blue', s = 10)\n",
    "\n",
    "ax_Box_Exp_RF12_1_counts.legend([pr1_Box_Exp_RF12_1, pr2_Box_Exp_RF12_1],['State 1', 'State 3'])\n",
    "fig_Box_Exp_RF12_1.autofmt_xdate()\n",
    "ax_Box_Exp_RF12_1_counts.set_xticks([])\n",
    "ax_Box_Exp_RF12_1_counts.set_ylim(ymin=0)\n",
    "plt.xlabel('Run Id')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "# plot energies vs run id\n",
    "ax_Box_Exp_RF12_1_energies = fig_Box_Exp_RF12_1.add_subplot(122)\n",
    "e1_Box_Exp_RF12_1 = ax_Box_Exp_RF12_1_energies.scatter(run_ids_RF12_1, energies_A_RF12_1, color = 'red', s = 10)\n",
    "e2_Box_Exp_RF12_1 = ax_Box_Exp_RF12_1_energies.scatter(run_ids_RF12_1, energies_B_RF12_1, color = 'blue', s = 10)\n",
    "ax_Box_Exp_RF12_1_energies.legend([e1_Box_Exp_RF12_1, e2_Box_Exp_RF12_1],['State 1', 'State 3'])\n",
    "fig_Box_Exp_RF12_1.autofmt_xdate()\n",
    "ax_Box_Exp_RF12_1_energies.set_xticks([])\n",
    "ax_Box_Exp_RF12_1_energies.set_ylim(ymin=0)\n",
    "plt.xlabel('Run Id')\n",
    "plt.ylabel('Energies per particle (Hz)')\n",
    "\n",
    "# add title to figure:\n",
    "folder_name = os.path.basename(os.path.dirname(data_frame_Box_Exp_mixedRF['fullpaths'][0]))\n",
    "fig_Box_Exp_RF12_1.suptitle(folder_name)\n",
    "fig_Box_Exp_RF12_1.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# calculate imbalance vs Run Id\n",
    "counts_A_RF12_1 = np.array(counts_A_RF12_1)\n",
    "counts_B_RF12_1 = np.array(counts_B_RF12_1)\n",
    "energies_A_RF12_1 = np.array(energies_A_RF12_1)\n",
    "energies_B_RF12_1 = np.array(energies_B_RF12_1)\n",
    "imbalance_RF12_1 = (counts_B_RF12_1 - counts_A_RF12_1)/(counts_B_RF12_1 + counts_A_RF12_1)\n",
    "weighted_avg_energy_RF12_1 = (energies_A_RF12_1*counts_A_RF12_1 + energies_B_RF12_1*counts_B_RF12_1)/(counts_A_RF12_1 + counts_B_RF12_1)\n",
    "\n",
    "#### statistics report ####\n",
    "print('--- Counts and Energies per particle (RF12_1) ---')\n",
    "print('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_RF12_1))))\n",
    "print('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_RF12_1))))\n",
    "print('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_RF12_1))))\n",
    "print('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_RF12_1))))\n",
    "print('Mean State 1 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_A_RF12_1))))\n",
    "print('Stdev state 1 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_A_RF12_1))))\n",
    "print('Mean State 3 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_B_RF12_1))))\n",
    "print('Stdev state 3 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_B_RF12_1))))\n",
    "print('Mean weighted energy (Hz): ' + str(\"{:.2f}\".format(np.mean(weighted_avg_energy_RF12_1))))\n",
    "print('Std weighted energy (Hz):  ' + str(\"{:.2f}\".format(np.std(weighted_avg_energy_RF12_1))))\n",
    "# print average imbalance:\n",
    "print('Average imbalance:         ' + str(\"{:.2f}\".format(np.mean(imbalance_RF12_1))))\n",
    "print('Std imbalance:             ' + str(\"{:.2f}\".format(np.std(imbalance_RF12_1))))\n",
    "# print RF12 Time:\n",
    "RF12_Time_RF12_1 = 11\n",
    "print('RF12 Time (ms):            ' + str(\"{:.2f}\".format(RF12_Time_RF12_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6920cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report results for RF12_2\n",
    "# now get counts, energies versus run_id for HeatCycles = 0\n",
    "counts_A_RF12_2 = data_frame_Box_Exp_mixedRF[(data_frame_Box_Exp_mixedRF['image_type'] == 'TopA') & \n",
    "                                             (data_frame_Box_Exp_mixedRF['RF12_Time'] == 32) & \n",
    "                                             (data_frame_Box_Exp_mixedRF['good_shot'] == True)]['atom_count']\n",
    "counts_B_RF12_2 = data_frame_Box_Exp_mixedRF[(data_frame_Box_Exp_mixedRF['image_type'] == 'TopB') & \n",
    "                                             (data_frame_Box_Exp_mixedRF['RF12_Time'] == 32) & \n",
    "                                             (data_frame_Box_Exp_mixedRF['good_shot'] == True)]['atom_count']\n",
    "energies_A_RF12_2 = data_frame_Box_Exp_mixedRF[(data_frame_Box_Exp_mixedRF['image_type'] == 'TopA') & \n",
    "                                               (data_frame_Box_Exp_mixedRF['RF12_Time'] == 32) & \n",
    "                                               (data_frame_Box_Exp_mixedRF['good_shot'] == True)]['E_hz_pp_from_ax_trap']\n",
    "energies_B_RF12_2 = data_frame_Box_Exp_mixedRF[(data_frame_Box_Exp_mixedRF['image_type'] == 'TopB') & \n",
    "                                               (data_frame_Box_Exp_mixedRF['RF12_Time'] == 32) & \n",
    "                                               (data_frame_Box_Exp_mixedRF['good_shot'] == True)]['E_hz_pp_from_ax_trap']\n",
    "run_ids_RF12_2 = data_frame_Box_Exp_mixedRF[(data_frame_Box_Exp_mixedRF['image_type'] == 'TopA') & \n",
    "                                            (data_frame_Box_Exp_mixedRF['RF12_Time'] == 32) & \n",
    "                                            (data_frame_Box_Exp_mixedRF['good_shot'] == True)]['run_id']\n",
    "\n",
    "fig_Box_Exp_RF12_2 = plt.figure(figsize=(7,3))\n",
    "ax_Box_Exp_RF12_2_counts = fig_Box_Exp_RF12_2.add_subplot(121)\n",
    "\n",
    "# plot counts vs Run Id\n",
    "pr1_Box_Exp_RF12_2 = ax_Box_Exp_RF12_2_counts.scatter(run_ids_RF12_2, counts_A_RF12_2, color = 'red' , s = 10)\n",
    "pr2_Box_Exp_RF12_2 = ax_Box_Exp_RF12_2_counts.scatter(run_ids_RF12_2, counts_B_RF12_2, color = 'blue', s = 10)\n",
    "\n",
    "ax_Box_Exp_RF12_2_counts.legend([pr1_Box_Exp_RF12_2, pr2_Box_Exp_RF12_2],['State 1', 'State 3'])\n",
    "fig_Box_Exp_RF12_2.autofmt_xdate()\n",
    "ax_Box_Exp_RF12_2_counts.set_xticks([])\n",
    "ax_Box_Exp_RF12_2_counts.set_ylim(ymin=0)\n",
    "plt.xlabel('Run Id')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "# plot energies vs run id\n",
    "ax_Box_Exp_RF12_2_energies = fig_Box_Exp_RF12_2.add_subplot(122)\n",
    "e1_Box_Exp_RF12_2 = ax_Box_Exp_RF12_2_energies.scatter(run_ids_RF12_2, energies_A_RF12_2, color = 'red', s = 10)\n",
    "e2_Box_Exp_RF12_2 = ax_Box_Exp_RF12_2_energies.scatter(run_ids_RF12_2, energies_B_RF12_2, color = 'blue', s = 10)\n",
    "ax_Box_Exp_RF12_2_energies.legend([e1_Box_Exp_RF12_2, e2_Box_Exp_RF12_2],['State 1', 'State 3'])\n",
    "fig_Box_Exp_RF12_2.autofmt_xdate()\n",
    "ax_Box_Exp_RF12_2_energies.set_xticks([])\n",
    "ax_Box_Exp_RF12_2_energies.set_ylim(ymin=0)\n",
    "plt.xlabel('Run Id')\n",
    "plt.ylabel('Energies per particle (Hz)')\n",
    "\n",
    "# add title to figure:\n",
    "folder_name = os.path.basename(os.path.dirname(data_frame_Box_Exp_mixedRF['fullpaths'][0]))\n",
    "fig_Box_Exp_RF12_2.suptitle(folder_name)\n",
    "fig_Box_Exp_RF12_2.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# calculate imbalance vs Run Id\n",
    "counts_A_RF12_2 = np.array(counts_A_RF12_2)\n",
    "counts_B_RF12_2 = np.array(counts_B_RF12_2)\n",
    "energies_A_RF12_2 = np.array(energies_A_RF12_2)\n",
    "energies_B_RF12_2 = np.array(energies_B_RF12_2)\n",
    "imbalance_RF12_2 = (counts_B_RF12_2 - counts_A_RF12_2)/(counts_B_RF12_2 + counts_A_RF12_2)\n",
    "weighted_avg_energy_RF12_2 = (energies_A_RF12_2*counts_A_RF12_2 + energies_B_RF12_2*counts_B_RF12_2)/(counts_A_RF12_2 + counts_B_RF12_2)\n",
    "\n",
    "#### statistics report ####\n",
    "print('--- Counts and Energies per particle (RF12_2) ---')\n",
    "print('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_RF12_2))))\n",
    "print('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_RF12_2))))\n",
    "print('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_RF12_2))))\n",
    "print('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_RF12_2))))\n",
    "print('Mean State 1 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_A_RF12_2))))\n",
    "print('Stdev state 1 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_A_RF12_2))))\n",
    "print('Mean State 3 energy (Hz):  ' + str(\"{:.2f}\".format(np.mean(energies_B_RF12_2))))\n",
    "print('Stdev state 3 energy (Hz): ' + str(\"{:.2f}\".format(np.std(energies_B_RF12_2))))\n",
    "print('Mean weighted energy (Hz): ' + str(\"{:.2f}\".format(np.mean(weighted_avg_energy_RF12_2))))\n",
    "print('Std weighted energy (Hz):  ' + str(\"{:.2f}\".format(np.std(weighted_avg_energy_RF12_2))))\n",
    "# print average imbalance:\n",
    "print('Average imbalance:         ' + str(\"{:.2f}\".format(np.mean(imbalance_RF12_2))))\n",
    "print('Std imbalance:             ' + str(\"{:.2f}\".format(np.std(imbalance_RF12_2))))\n",
    "# print RF12 Time:\n",
    "RF12_Time_RF12_2 = 32\n",
    "print('RF12 Time (ms):            ' + str(\"{:.2f}\".format(RF12_Time_RF12_2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fb05972",
   "metadata": {},
   "source": [
    "# <font size=5, color='black'>Li Box Top: Sound Scan (PR) </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d6e5392",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Load existing dataframe</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe035a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load existing df\n",
    "df_file_name = filedialog.askopenfilename()\n",
    "data_frame_Sound_Scan_PR = pd.read_pickle(df_file_name)\n",
    "\n",
    "folder_path = os.path.dirname(df_file_name)\n",
    "metadata_fullpath = folder_path + \"/run_params_dump.json\"\n",
    "experiment_parameters_fullpath = folder_path + \"/experiment_parameters.json\"\n",
    "\n",
    "with open(metadata_fullpath, 'r') as json_file:\n",
    "    metadata_dict_Sound_Scan_PR = json.load(json_file)  \n",
    "with open(experiment_parameters_fullpath, 'r') as json_file:\n",
    "    experiment_parameters_dict_Sound_Scan_PR = json.load(json_file) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79eaf280",
   "metadata": {},
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc2b3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-08T02:57:15.048888Z",
     "start_time": "2023-03-08T02:56:19.198915Z"
    }
   },
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "data_frame_Sound_Scan_PR, metadata_dict_Sound_Scan_PR, experiment_parameters_dict_Sound_Scan_PR = init_dataframe_metadata_and_exp_params(['RF12_Time', \n",
    "                                                                                                                                          'ShakingCycles', \n",
    "                                                                                                                                          'BoxShakeFreq'])\n",
    "# xmin, xmax, ymin, ymax\n",
    "ROI_Sound_Scan_PR = [1150, 1350, 1245, 1455] # to get counts right...\n",
    "norm_box_Sound_Scan_PR = [1150, 1300, 1000, 1100]\n",
    "\n",
    "# display image:\n",
    "frame_type_Sound_Scan_PR = 'FakeOD'\n",
    "current_file_fullpath_Sound_Scan_PR = data_frame_Sound_Scan_PR['fullpaths'][0]\n",
    "fig, ax = display_image(current_file_fullpath_Sound_Scan_PR, \n",
    "                        ROI_Sound_Scan_PR, \n",
    "                        norm_box_Sound_Scan_PR, \n",
    "                        frame_type_Sound_Scan_PR)\n",
    "\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_Sound_Scan_PR)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_Sound_Scan_PR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e03c6409",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get column densities, counts, imbalance, filter data, justify, get n3D(z), get Fermi energies </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "56a2b268",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading ROIs: 100%|| 202/202 [04:07<00:00,  1.22s/it]\n",
      "Solving images:   0%|          | 0/101 [00:00<?, ?it/s]/Users/huanbui/anaconda3/envs/BEC1_Calculator/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Users/huanbui/anaconda3/envs/BEC1_Calculator/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Users/huanbui/anaconda3/envs/BEC1_Calculator/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Solving images:  10%|         | 10/101 [00:05<00:44,  2.04it/s]/Users/huanbui/anaconda3/envs/BEC1_Calculator/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Users/huanbui/anaconda3/envs/BEC1_Calculator/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Solving images:  27%|       | 27/101 [00:09<00:17,  4.24it/s]/Users/huanbui/anaconda3/envs/BEC1_Calculator/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Solving images:  42%|     | 42/101 [00:14<00:10,  5.40it/s]/Users/huanbui/anaconda3/envs/BEC1_Calculator/lib/python3.9/site-packages/scipy/optimize/_minpack_py.py:178: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Solving images: 100%|| 101/101 [00:31<00:00,  3.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# get column densities from PR solver\n",
    "data_frame_Sound_Scan_PR = add_background_subtracted_ROI_to_dataframe_fast(data_frame_Sound_Scan_PR, \n",
    "                                                                           ROI_Sound_Scan_PR, \n",
    "                                                                           norm_box_Sound_Scan_PR)\n",
    "# get column densities\n",
    "data_frame_Sound_Scan_PR = add_polrot_column_densities_to_dataframe(data_frame_Sound_Scan_PR, \n",
    "                                                                     experiment_parameters_dict_Sound_Scan_PR, \n",
    "                                                                     ROI_Sound_Scan_PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b34cedb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get counts, filter data, justify images, get n3D(z), then get box boundary\n",
    "data_frame_Sound_Scan_PR = add_counts_from_PR_column_densities_to_dataframe(data_frame_Sound_Scan_PR, \n",
    "                                                                             experiment_parameters_dict_Sound_Scan_PR)\n",
    "# FILTER DATA\n",
    "data_frame_Sound_Scan_PR = data_filter(data_frame_Sound_Scan_PR, 'atom_count', 1.5, ['image_type','TopA'])\n",
    "data_frame_Sound_Scan_PR = data_filter(data_frame_Sound_Scan_PR, 'atom_count', 1.5, ['image_type','TopB'])\n",
    "   \n",
    "# plot unfiltered and filtered data:    \n",
    "fig_sound_scan_counts_unfiltered = plot_box_counts_and_imbalance(data_frame_Sound_Scan_PR, filter=False)\n",
    "fig_sound_scan_counts_filtered = plot_box_counts_and_imbalance(data_frame_Sound_Scan_PR, filter=True)\n",
    "\n",
    "# justify images\n",
    "data_frame_Sound_Scan_PR = add_justified_column_density_to_dataframe(data_frame_Sound_Scan_PR, experiment_parameters_dict_Sound_Scan_PR)\n",
    "# plt.imshow(data_frame_Sound_Scan_PR['justified_column_density'][0])\n",
    "# plt.show()\n",
    "\n",
    "# add n3d along harmonic axis of hybrid trap to df\n",
    "data_frame_Sound_Scan_PR = add_n3d_along_harmonic_axis_to_dataframe(data_frame_Sound_Scan_PR, experiment_parameters_dict_Sound_Scan_PR)\n",
    "\n",
    "# get box boundary along z\n",
    "data_frame_Sound_Scan_PR = add_box_boundary_with_sigmoid_along_z_to_dataframe(data_frame_Sound_Scan_PR, cut_depth=0.5)\n",
    "\n",
    "# get Fermi energies:\n",
    "data_frame_Sound_Scan_PR, avg_EF_sound_scan_A, avg_EF_sound_scan_B = add_box_Fermi_energy_to_dataframe(data_frame_Sound_Scan_PR, print_result = True, filter = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcb324ab",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Subtract no-shake from shake</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d1ff2d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# subtract no-shake from shake\n",
    "# extract the no shaking justified_column_densities:\n",
    "if 'justified_column_density' in data_frame_Sound_Scan_PR.columns:\n",
    "    no_shake_justified_density_A = data_frame_Sound_Scan_PR[(data_frame_Sound_Scan_PR['image_type'] == 'TopA') & \n",
    "                                                            (data_frame_Sound_Scan_PR['ShakingCycles'] == 0)]['justified_column_density']\n",
    "    no_shake_justified_density_B = data_frame_Sound_Scan_PR[(data_frame_Sound_Scan_PR['image_type'] == 'TopB') & \n",
    "                                                            (data_frame_Sound_Scan_PR['ShakingCycles'] == 0)]['justified_column_density']    \n",
    "\n",
    "# now take average of all no shake shots:\n",
    "avg_no_shake_justified_density_A = sum(no_shake_justified_density_A)/len(no_shake_justified_density_A)\n",
    "avg_no_shake_justified_density_B = sum(no_shake_justified_density_B)/len(no_shake_justified_density_B)\n",
    "\n",
    "# now subtract shake from no shake:\n",
    "no_shake_subtracted = []\n",
    "for idx, row in data_frame_Sound_Scan_PR.iterrows():\n",
    "    if row['image_type'] == 'TopA':\n",
    "        no_shake_subtracted.append(row['justified_column_density'] - avg_no_shake_justified_density_A)\n",
    "    if row['image_type'] == 'TopB':\n",
    "        no_shake_subtracted.append(row['justified_column_density'] - avg_no_shake_justified_density_B)\n",
    "data_frame_Sound_Scan_PR['no_shake_subtracted'] = no_shake_subtracted\n",
    "        \n",
    "# show a no_shake_subtracted shot:\n",
    "plt.imshow(data_frame_Sound_Scan_PR['no_shake_subtracted'][1])\n",
    "plt.show()\n",
    "\n",
    "# now get subtracted 3d density along harmonic axis\n",
    "data_frame_Sound_Scan_PR = add_delta_n3d_with_no_shake_subtracted_to_dataframe(data_frame_Sound_Scan_PR, experiment_parameters_dict_Sound_Scan_PR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ee2d6f5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Show sound resonance curve and fit</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2e353",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show sound resonance curve and fit\n",
    "sound_resonance_results = first_sound_resonance_curve_fit(data_frame_Sound_Scan_PR, symmetric_mode = 1, fit = True, real = True, normalize = False, with_offset = False)\n",
    "\n",
    "fig_sound_resonance = sound_resonance_results['figure']\n",
    "center_A            = sound_resonance_results['center_A']\n",
    "gamma_A             = sound_resonance_results['gamma_A'] \n",
    "center_B            = sound_resonance_results['center_B']\n",
    "gamma_B             = sound_resonance_results['gamma_B'] \n",
    "center_A_error      = sound_resonance_results['center_A_error']\n",
    "center_B_error      = sound_resonance_results['center_B_error']\n",
    "gamma_A_error       = sound_resonance_results['gamma_A_error']\n",
    "gamma_B_error       = sound_resonance_results['gamma_B_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2c22e8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# do the same, but with delta n/n instead of just delta_n/n\n",
    "data_frame_Sound_Scan_PR = add_delta_n3d_over_n3d_along_z_to_dataframe(data_frame_Sound_Scan_PR, \n",
    "                                                                       experiment_parameters_dict_Sound_Scan_PR,\n",
    "                                                                       avg_no_shake_justified_density_A, \n",
    "                                                                       avg_no_shake_justified_density_B)\n",
    "\n",
    "# taking the real part helps with distilling the symmetric mode better\n",
    "sound_resonance_results_normed = first_sound_resonance_curve_fit(data_frame_Sound_Scan_PR, symmetric_mode = 1, fit = True, real = True, normalize = True, with_offset=False)\n",
    "\n",
    "fig_sound_resonance_normed = sound_resonance_results_normed['figure']\n",
    "center_A_normed            = sound_resonance_results_normed['center_A']\n",
    "gamma_A_normed             = sound_resonance_results_normed['gamma_A'] \n",
    "center_B_normed            = sound_resonance_results_normed['center_B']\n",
    "gamma_B_normed             = sound_resonance_results_normed['gamma_B'] \n",
    "center_A_error_normed      = sound_resonance_results_normed['center_A_error']\n",
    "center_B_error_normed      = sound_resonance_results_normed['center_B_error']\n",
    "gamma_A_error_normed       = sound_resonance_results_normed['gamma_A_error']\n",
    "gamma_B_error_normed       = sound_resonance_results_normed['gamma_B_error']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2af38172",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Save dataframe and results associated with data folder</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6b577a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save df and results \n",
    "folder_name = os.path.basename(os.path.dirname(data_frame_Sound_Scan_PR['fullpaths'][0]))\n",
    "today = str(datetime.date.today())\n",
    "path = \"/Users/huanbui/Desktop/BEC1_dataframes/\"\n",
    "# make directory if it's not there yet\n",
    "path_name = path+today+'/'+folder_name+'/'\n",
    "if os.path.isdir(path+today) == False:\n",
    "    os.mkdir(path+today)\n",
    "if os.path.isdir(path_name) == False:\n",
    "    os.mkdir(path_name)\n",
    "file_name = path_name + folder_name + \".pkl\"\n",
    "metadata_name = path_name + 'run_params_dump.json'\n",
    "run_params_name = path_name + 'experiment_parameters.json'\n",
    " \n",
    "# save dataframe as file_name:\n",
    "data_frame_Sound_Scan_PR.to_pickle(file_name)\n",
    "\n",
    "# also save metadata and exp params:\n",
    "with open(metadata_name, 'w') as fp:\n",
    "    json.dump(metadata_dict_Sound_Scan_PR, fp)\n",
    "with open(run_params_name, 'w') as fp:\n",
    "    json.dump(experiment_parameters_dict_Sound_Scan_PR, fp)\n",
    "    \n",
    "# save images:\n",
    "fig_sound_scan_counts_unfiltered.savefig(path_name+'counts_and_imbalances_unfiltered.png')\n",
    "fig_sound_scan_counts_filtered.savefig(path_name+'counts_and_imbalances_filtered.png')\n",
    "fig_sound_resonance.savefig(path_name+'sound_resonance_fit.png')\n",
    "fig_sound_resonance_normed.savefig(path_name+'sound_resonance_normed_fit.png')\n",
    "\n",
    "# save numerical results as txt file:\n",
    "counts_A_Sound_Scan_PR = data_frame_Sound_Scan_PR[data_frame_Sound_Scan_PR['image_type']=='TopA']['atom_count']\n",
    "counts_B_Sound_Scan_PR = data_frame_Sound_Scan_PR[data_frame_Sound_Scan_PR['image_type']=='TopB']['atom_count']\n",
    "counts_A_Sound_Scan_PR = np.array(counts_A_Sound_Scan_PR)\n",
    "counts_B_Sound_Scan_PR = np.array(counts_B_Sound_Scan_PR)\n",
    "\n",
    "imbalance_Sound_Scan_PR = (counts_B_Sound_Scan_PR-counts_A_Sound_Scan_PR)/(counts_A_Sound_Scan_PR+counts_B_Sound_Scan_PR)\n",
    "\n",
    "with open(path_name+folder_name+ '_results.txt', 'w') as f:\n",
    "    f.write('--- Counts, Energies per particle, and Fermi Energies ---' + \"\\n\")\n",
    "    f.write('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_Sound_Scan_PR))) + \"\\n\")\n",
    "    f.write('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_Sound_Scan_PR))) + \"\\n\")\n",
    "    f.write('Mean State 1 Fermi energy: ' + str(\"{:.2f}\".format(avg_EF_sound_scan_A)) + \"\\n\")\n",
    "    f.write('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_Sound_Scan_PR))) + \"\\n\")\n",
    "    f.write('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_Sound_Scan_PR))) + \"\\n\")\n",
    "    f.write('Mean State 3 Fermi energy: ' + str(\"{:.2f}\".format(avg_EF_sound_scan_B)) + \"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write('Mean imbalance:            ' + str(\"{:.2f}\".format(np.mean(imbalance_Sound_Scan_PR))) + \"\\n\")\n",
    "    f.write('Std imbalance:             ' + str(\"{:.2f}\".format(np.std(imbalance_Sound_Scan_PR))) + \"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write('--- Sound resonance fit ---' + \"\\n\")\n",
    "    f.write('Center A (Hz):       ' + str(\"{:.2f}\".format(center_A)) + \"\\n\")\n",
    "    f.write('Center A error (Hz): ' + str(\"{:.2f}\".format(center_A_error)) + \"\\n\")\n",
    "    f.write('Gamma A (Hz):        ' + str(\"{:.2f}\".format(gamma_A)) + \"\\n\")\n",
    "    f.write('Gamma A error (Hz):  ' + str(\"{:.2f}\".format(gamma_A_error)) + \"\\n\")\n",
    "    f.write('Center B (Hz):       ' + str(\"{:.2f}\".format(center_B)) + \"\\n\")\n",
    "    f.write('Center B error (Hz): ' + str(\"{:.2f}\".format(center_B_error)) + \"\\n\")\n",
    "    f.write('Gamma B (Hz):        ' + str(\"{:.2f}\".format(gamma_B)) + \"\\n\")\n",
    "    f.write('Gamma B error (Hz):  ' + str(\"{:.2f}\".format(gamma_B_error)) + \"\\n\")\n",
    "    \n",
    "print('Results and images saved!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bf166bc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size = 5, color='black'> Li Box Top: Sound Scan with Mixed Heating (PR) </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a403f4fc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=4, color=#399FD5>Load existing dataframe</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583348a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load existing dataframe\n",
    "df_file_name = filedialog.askopenfilename()\n",
    "df_sound_mixedheat = pd.read_pickle(df_file_name)\n",
    "\n",
    "folder_path = os.path.dirname(df_file_name)\n",
    "metadata_fullpath = folder_path + \"/run_params_dump.json\"\n",
    "experiment_parameters_fullpath = folder_path + \"/experiment_parameters.json\"\n",
    "\n",
    "with open(metadata_fullpath, 'r') as json_file:\n",
    "    metadata_dict_sound_mixedheat = json.load(json_file)  \n",
    "with open(experiment_parameters_fullpath, 'r') as json_file:\n",
    "    experiment_parameters_dict_sound_mixedheat = json.load(json_file) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2f6bf89",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aafbe81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "df_sound_mixedheat, metadata_dict_sound_mixedheat, experiment_parameters_dict_sound_mixedheat = init_dataframe_metadata_and_exp_params(['RF12_Time', \n",
    "                                                                                                                                        'ShakingCycles',\n",
    "                                                                                                                                        'BoxShakeFreq',\n",
    "                                                                                                                                        'HeatCycles'])\n",
    "# xmin, xmax, ymin, ymax\n",
    "ROI_sound_mixedheat = [1150, 1350, 1280, 1440] # to get counts right...\n",
    "norm_box_sound_mixedheat = [1150, 1300, 1000, 1100]\n",
    "\n",
    "# display image:\n",
    "frame_type_sound_mixedheat = 'FakeOD'\n",
    "current_file_fullpath_sound_mixedheat = df_sound_mixedheat['fullpaths'][0]\n",
    "fig, ax = display_image(current_file_fullpath_sound_mixedheat, \n",
    "                        ROI_sound_mixedheat, \n",
    "                        norm_box_sound_mixedheat, \n",
    "                        frame_type_sound_mixedheat)\n",
    "\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_sound_mixedheat)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_sound_mixedheat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f1e86b6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get column densities, counts, imbalance, filter data, justify, get n3D(z), get Fermi energies</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf6e89",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get column densities from PR solver\n",
    "df_sound_mixedheat = add_background_subtracted_ROI_to_dataframe_fast(df_sound_mixedheat, \n",
    "                                                                     ROI_sound_mixedheat, \n",
    "                                                                     norm_box_sound_mixedheat)\n",
    "# get column densities\n",
    "df_sound_mixedheat = add_polrot_column_densities_to_dataframe(df_sound_mixedheat, \n",
    "                                                              experiment_parameters_dict_sound_mixedheat, \n",
    "                                                              ROI_sound_mixedheat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd6c05",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get counts, then filter and plot counts, imbalance, etc.\n",
    "df_sound_mixedheat = add_counts_from_PR_column_densities_to_dataframe(df_sound_mixedheat, \n",
    "                                                                      experiment_parameters_dict_sound_mixedheat)\n",
    "# Filter WITHOUT HEAT data\n",
    "df_sound_mixedheat[df_sound_mixedheat['HeatCycles']==0] = data_filter(df_sound_mixedheat[df_sound_mixedheat['HeatCycles']==0], 'atom_count', 2.0, ['image_type','TopA'])\n",
    "df_sound_mixedheat[df_sound_mixedheat['HeatCycles']==0] = data_filter(df_sound_mixedheat[df_sound_mixedheat['HeatCycles']==0], 'atom_count', 2.0, ['image_type','TopB'])\n",
    "# filter WITH HEAT data\n",
    "df_sound_mixedheat[df_sound_mixedheat['HeatCycles']!=0] = data_filter(df_sound_mixedheat[df_sound_mixedheat['HeatCycles']!=0], 'atom_count', 2.0, ['image_type','TopA'])\n",
    "df_sound_mixedheat[df_sound_mixedheat['HeatCycles']!=0] = data_filter(df_sound_mixedheat[df_sound_mixedheat['HeatCycles']!=0], 'atom_count', 2.0, ['image_type','TopB'])\n",
    "\n",
    "# plot unfiltered data for WITHOUT HEAT  \n",
    "fig_counts_unfiltered_noheat = plot_box_counts_and_imbalance(df_sound_mixedheat[df_sound_mixedheat['HeatCycles']==0], filter=False, title_extra='no heat')\n",
    "# plot unfiltered data for WITH HEAT  \n",
    "fig_counts_unfiltered_heat = plot_box_counts_and_imbalance(df_sound_mixedheat[df_sound_mixedheat['HeatCycles']!=0], filter=False, title_extra='heated')\n",
    "\n",
    "# plot filtered data for WITHOUT HEAT  \n",
    "fig_counts_filtered_noheat = plot_box_counts_and_imbalance(df_sound_mixedheat[df_sound_mixedheat['HeatCycles']==0], filter=True, title_extra='no heat')\n",
    "# plot filtered data for WITH HEAT  \n",
    "fig_counts_filtered_heat = plot_box_counts_and_imbalance(df_sound_mixedheat[df_sound_mixedheat['HeatCycles']!=0], filter=True, title_extra ='heated')\n",
    "\n",
    "# Justify images, get n3D(z), and subtract no-shake from shake\n",
    "df_sound_mixedheat = add_justified_column_density_to_dataframe(df_sound_mixedheat, experiment_parameters_dict_sound_mixedheat)\n",
    "#plt.imshow(df_sound_mixedheat['justified_column_density'][0])\n",
    "#plt.show()\n",
    "\n",
    "# add n3d along harmonic axis of hybrid trap to df\n",
    "df_sound_mixedheat = add_n3d_along_harmonic_axis_to_dataframe(df_sound_mixedheat, experiment_parameters_dict_sound_mixedheat)\n",
    "\n",
    "# get box boundary along z\n",
    "df_sound_mixedheat = add_box_boundary_with_sigmoid_along_z_to_dataframe(df_sound_mixedheat, cut_depth=0.5)\n",
    "\n",
    "# get Fermi energies:\n",
    "df_sound_mixedheat, avg_EF_mixedheat_A, avg_EF_mixedheat_B = add_box_Fermi_energy_to_dataframe(df_sound_mixedheat, print_result = False, filter = True)\n",
    "\n",
    "# now extract EF_A and EF_B for heat and noheat:\n",
    "avg_EF_A_noheat = np.mean(np.array( df_sound_mixedheat[(df_sound_mixedheat['image_type'] == 'TopA') & \n",
    "                                                       (df_sound_mixedheat['good_shot']  == True)   & \n",
    "                                                       (df_sound_mixedheat['HeatCycles'] == 0)        ]['Fermi_energy']))\n",
    "avg_EF_B_noheat = np.mean(np.array( df_sound_mixedheat[(df_sound_mixedheat['image_type'] == 'TopB') & \n",
    "                                                       (df_sound_mixedheat['good_shot']  == True)   & \n",
    "                                                       (df_sound_mixedheat['HeatCycles'] == 0)        ]['Fermi_energy']))\n",
    "avg_EF_A_heat   = np.mean(np.array( df_sound_mixedheat[(df_sound_mixedheat['image_type'] == 'TopA') & \n",
    "                                                       (df_sound_mixedheat['good_shot']  == True)   & \n",
    "                                                       (df_sound_mixedheat['HeatCycles'] != 0)        ]['Fermi_energy']))\n",
    "avg_EF_B_heat   = np.mean(np.array( df_sound_mixedheat[(df_sound_mixedheat['image_type'] == 'TopB') & \n",
    "                                                       (df_sound_mixedheat['good_shot']  == True)   & \n",
    "                                                       (df_sound_mixedheat['HeatCycles'] != 0)        ]['Fermi_energy']))\n",
    "\n",
    "# print results\n",
    "print('-- No heat --')\n",
    "print('Average Fermi energy (A) in Hz: ' + str(\"{:.2f}\".format(avg_EF_A_noheat)))\n",
    "print('Average Fermi energy (B) in Hz: ' + str(\"{:.2f}\".format(avg_EF_B_noheat)))\n",
    "print('-- Heated --')\n",
    "print('Average Fermi energy (A) in Hz: ' + str(\"{:.2f}\".format(avg_EF_A_heat)))\n",
    "print('Average Fermi energy (B) in Hz: ' + str(\"{:.2f}\".format(avg_EF_B_heat)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b466154",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Subtract no-shake from shake, for each value of HeatCycles</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99739e8d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Subtract no-shake from shake\n",
    "# extract the no shaking justified_column_densities with WITH heat and WITHOUT heat:\n",
    "if 'justified_column_density' in df_sound_mixedheat.columns:\n",
    "    no_shake_A_noheat = df_sound_mixedheat[(df_sound_mixedheat['image_type'] == 'TopA') & \n",
    "                                           (df_sound_mixedheat['ShakingCycles'] == 0) & \n",
    "                                           (df_sound_mixedheat['HeatCycles'] == 0)]['justified_column_density']\n",
    "    no_shake_B_noheat = df_sound_mixedheat[(df_sound_mixedheat['image_type'] == 'TopB') & \n",
    "                                           (df_sound_mixedheat['ShakingCycles'] == 0) & \n",
    "                                           (df_sound_mixedheat['HeatCycles'] == 0)]['justified_column_density']\n",
    "    no_shake_A_heat = df_sound_mixedheat[(df_sound_mixedheat['image_type'] == 'TopA') & \n",
    "                                           (df_sound_mixedheat['ShakingCycles'] == 0) & \n",
    "                                           (df_sound_mixedheat['HeatCycles'] != 0)]['justified_column_density']\n",
    "    no_shake_B_heat = df_sound_mixedheat[(df_sound_mixedheat['image_type'] == 'TopB') & \n",
    "                                           (df_sound_mixedheat['ShakingCycles'] == 0) & \n",
    "                                           (df_sound_mixedheat['HeatCycles'] != 0)]['justified_column_density']\n",
    "    \n",
    "# now take average of all no shake shots WITHOUT HEAT:\n",
    "avg_no_shake_A_noheat = sum(no_shake_A_noheat)/len(no_shake_A_noheat)\n",
    "avg_no_shake_B_noheat = sum(no_shake_B_noheat)/len(no_shake_B_noheat)\n",
    "# now take average of all no shake shots WITHOUT HEAT:\n",
    "avg_no_shake_A_heat = sum(no_shake_A_heat)/len(no_shake_A_heat)\n",
    "avg_no_shake_B_heat = sum(no_shake_B_heat)/len(no_shake_B_heat)\n",
    "\n",
    "no_shake_subtracted = []\n",
    "# have to treat WITH HEAT vs WITHOUT HEAT separately:\n",
    "for idx, row in df_sound_mixedheat.iterrows():\n",
    "    if row['image_type'] == 'TopA':\n",
    "        if row['HeatCycles'] == 0:\n",
    "            no_shake_subtracted.append(row['justified_column_density'] - avg_no_shake_A_noheat)\n",
    "        else:\n",
    "            no_shake_subtracted.append(row['justified_column_density'] - avg_no_shake_A_heat)\n",
    "    if row['image_type'] == 'TopB':\n",
    "        if row['HeatCycles'] == 0:\n",
    "            no_shake_subtracted.append(row['justified_column_density'] - avg_no_shake_B_noheat)\n",
    "        else:\n",
    "            no_shake_subtracted.append(row['justified_column_density'] - avg_no_shake_B_heat)\n",
    "df_sound_mixedheat['no_shake_subtracted'] = no_shake_subtracted\n",
    "        \n",
    "# show a no_shake_subtracted shot:\n",
    "# plt.imshow(df_sound_mixedheat['no_shake_subtracted'][1])\n",
    "# plt.show()\n",
    "\n",
    "# now get subtracted 3d density along harmonic axis\n",
    "df_sound_mixedheat = add_delta_n3d_with_no_shake_subtracted_to_dataframe(df_sound_mixedheat, experiment_parameters_dict_sound_mixedheat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb67d9c1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Show sound resonance curve and fit</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7e2616",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Show sound resonance curve(s) and fit\n",
    "# WITHOUT HEAT\n",
    "res_results_noheat = first_sound_resonance_curve_fit(df_sound_mixedheat[df_sound_mixedheat['HeatCycles']==0], \n",
    "                                                     symmetric_mode = 1, fit = True, real = False, normalize = False, with_offset = False)\n",
    "\n",
    "fig_res_noheat        = res_results_noheat['figure']\n",
    "center_A_noheat       = res_results_noheat['center_A']\n",
    "gamma_A_noheat        = res_results_noheat['gamma_A']\n",
    "center_B_noheat       = res_results_noheat['center_B']\n",
    "gamma_B_noheat        = res_results_noheat['gamma_B']\n",
    "center_A_error_noheat = res_results_noheat['center_A_error']\n",
    "center_B_error_noheat = res_results_noheat['center_B_error']\n",
    "gamma_A_error_noheat  = res_results_noheat['gamma_A_error']\n",
    "gamma_B_error_noheat  = res_results_noheat['gamma_B_error']\n",
    "\n",
    "# WITH HEAT\n",
    "res_results_heat = first_sound_resonance_curve_fit(df_sound_mixedheat[df_sound_mixedheat['HeatCycles']!=0], \n",
    "                                                   symmetric_mode = 1, fit = True, real = False, normalize = False, with_offset = False)\n",
    "\n",
    "fig_res_heat        = res_results_heat['figure']\n",
    "center_A_heat       = res_results_heat['center_A']\n",
    "gamma_A_heat        = res_results_heat['gamma_A']\n",
    "center_B_heat       = res_results_heat['center_B']\n",
    "gamma_B_heat        = res_results_heat['gamma_B']\n",
    "center_A_error_heat = res_results_heat['center_A_error']\n",
    "center_B_error_heat = res_results_heat['center_B_error']\n",
    "gamma_A_error_heat  = res_results_heat['gamma_A_error']\n",
    "gamma_B_error_heat  = res_results_heat['gamma_B_error']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b3346af",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Save dataframe and results associated with data folder</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a03475",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save df and results in associated with data folder\n",
    "folder_name = os.path.basename(os.path.dirname(df_sound_mixedheat['fullpaths'].iloc[0]))\n",
    "today = str(datetime.date.today())\n",
    "path = \"/Users/huanbui/Desktop/BEC1_dataframes/\"\n",
    "# make directory if it's not there yet\n",
    "path_name = path+today+'/'+folder_name+'/'\n",
    "if os.path.isdir(path+today) == False:\n",
    "    os.mkdir(path+today)\n",
    "if os.path.isdir(path_name) == False:\n",
    "    os.mkdir(path_name)\n",
    "file_name = path_name + folder_name + \".pkl\"\n",
    "metadata_name = path_name + 'run_params_dump.json'\n",
    "run_params_name = path_name + 'experiment_parameters.json'\n",
    " \n",
    "# save dataframe as file_name:\n",
    "df_sound_mixedheat.to_pickle(file_name)\n",
    "\n",
    "# also save metadata and exp params:\n",
    "with open(metadata_name, 'w') as fp:\n",
    "    json.dump(metadata_dict_sound_mixedheat, fp)\n",
    "with open(run_params_name, 'w') as fp:\n",
    "    json.dump(experiment_parameters_dict_sound_mixedheat, fp)\n",
    "    \n",
    "# save images:\n",
    "fig_counts_unfiltered_noheat.savefig(path_name+'counts_unfiltered_noheat.png')\n",
    "fig_counts_unfiltered_heat.savefig(path_name+'counts_unfiltered_heat.png')\n",
    "fig_counts_filtered_noheat.savefig(path_name+'counts_filtered_noheat.png')\n",
    "fig_counts_filtered_heat.savefig(path_name+'counts_filtered_heat.png')\n",
    "fig_res_noheat.savefig(path_name+'sound_resonance_fit_noheat.png')\n",
    "fig_res_heat.savefig(path_name+'sound_resonance_fit_heat.png')\n",
    "\n",
    "# save numerical results as txt file:\n",
    "counts_A_sound_noheat = df_sound_mixedheat[(df_sound_mixedheat['image_type']=='TopA') & \n",
    "                                           (df_sound_mixedheat['HeatCycles']==0)]['atom_count']\n",
    "counts_B_sound_noheat = df_sound_mixedheat[(df_sound_mixedheat['image_type']=='TopB') & \n",
    "                                           (df_sound_mixedheat['HeatCycles']==0)]['atom_count']\n",
    "counts_A_sound_heat = df_sound_mixedheat[(df_sound_mixedheat['image_type']=='TopA') & \n",
    "                                           (df_sound_mixedheat['HeatCycles']!=0)]['atom_count']\n",
    "counts_B_sound_heat = df_sound_mixedheat[(df_sound_mixedheat['image_type']=='TopB') & \n",
    "                                           (df_sound_mixedheat['HeatCycles']!=0)]['atom_count']\n",
    "\n",
    "counts_A_sound_noheat = np.array(counts_A_sound_noheat)\n",
    "counts_B_sound_noheat = np.array(counts_B_sound_noheat)\n",
    "counts_A_sound_heat = np.array(counts_A_sound_heat)\n",
    "counts_B_sound_heat = np.array(counts_B_sound_heat)\n",
    "\n",
    "imbalance_sound_noheat = (counts_B_sound_noheat-counts_A_sound_noheat)/(counts_A_sound_noheat+counts_B_sound_noheat)\n",
    "imbalance_sound_heat = (counts_B_sound_heat-counts_A_sound_heat)/(counts_A_sound_heat+counts_B_sound_heat)\n",
    "\n",
    "with open(path_name+folder_name+ '_results.txt', 'w') as f:\n",
    "    f.write('--- Counts and Energies per particle (WITHOUT HEAT) ---' + \"\\n\")\n",
    "    f.write('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_sound_noheat))) + \"\\n\")\n",
    "    f.write('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_sound_noheat))) + \"\\n\")\n",
    "    f.write('Mean State 1 Fermi energy: ' + str(\"{:.2f}\".format(avg_EF_A_noheat)) + \"\\n\")\n",
    "    f.write('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_sound_noheat))) + \"\\n\")\n",
    "    f.write('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_sound_noheat))) + \"\\n\")\n",
    "    f.write('Mean State 3 Fermi energy: ' + str(\"{:.2f}\".format(avg_EF_B_noheat)) + \"\\n\")\n",
    "    f.write('Mean imbalance:            ' + str(\"{:.2f}\".format(np.mean(imbalance_sound_noheat))) + \"\\n\")\n",
    "    f.write('Std imbalance:             ' + str(\"{:.2f}\".format(np.std(imbalance_sound_noheat))) + \"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write('--- Sound resonance fit ---' + \"\\n\")\n",
    "    f.write('Center A (Hz):             ' + str(\"{:.2f}\".format(center_A_noheat)) + \"\\n\")\n",
    "    f.write('Center A error (Hz):       ' + str(\"{:.2f}\".format(center_A_error_noheat)) + \"\\n\")\n",
    "    f.write('Gamma A (Hz):              ' + str(\"{:.2f}\".format(gamma_A_noheat)) + \"\\n\")\n",
    "    f.write('Gamma A error (Hz):        ' + str(\"{:.2f}\".format(gamma_A_error_noheat)) + \"\\n\")\n",
    "    f.write('Center B (Hz):             ' + str(\"{:.2f}\".format(center_B_noheat)) + \"\\n\")\n",
    "    f.write('Center B error (Hz):       ' + str(\"{:.2f}\".format(center_B_error_noheat)) + \"\\n\")\n",
    "    f.write('Gamma B (Hz):              ' + str(\"{:.2f}\".format(gamma_B_noheat)) + \"\\n\")\n",
    "    f.write('Gamma B error (Hz):        ' + str(\"{:.2f}\".format(gamma_B_error_noheat)) + \"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write('--- Counts and Energies per particle (WITH HEAT) ---' + \"\\n\")\n",
    "    f.write('Mean State 1 count:        ' + str(\"{:.2f}\".format(np.mean(counts_A_sound_heat))) + \"\\n\")\n",
    "    f.write('Stdev state 1 count:       ' + str(\"{:.2f}\".format(np.std(counts_A_sound_heat))) + \"\\n\")\n",
    "    f.write('Mean State 1 Fermi energy: ' + str(\"{:.2f}\".format(avg_EF_B_heat)) + \"\\n\")\n",
    "    f.write('Mean State 3 count:        ' + str(\"{:.2f}\".format(np.mean(counts_B_sound_heat))) + \"\\n\")\n",
    "    f.write('Stdev state 3 count:       ' + str(\"{:.2f}\".format(np.std(counts_B_sound_heat))) + \"\\n\")\n",
    "    f.write('Mean State 3 Fermi energy: ' + str(\"{:.2f}\".format(avg_EF_B_heat)) + \"\\n\")\n",
    "    f.write('Mean imbalance:            ' + str(\"{:.2f}\".format(np.mean(imbalance_sound_heat))) + \"\\n\")\n",
    "    f.write('Std imbalance:             ' + str(\"{:.2f}\".format(np.std(imbalance_sound_heat))) + \"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write('--- Sound resonance fit ---' + \"\\n\")\n",
    "    f.write('Center A (Hz):             ' + str(\"{:.2f}\".format(center_A_heat)) + \"\\n\")\n",
    "    f.write('Center A error (Hz):       ' + str(\"{:.2f}\".format(center_A_error_heat)) + \"\\n\")\n",
    "    f.write('Gamma A (Hz):              ' + str(\"{:.2f}\".format(gamma_A_heat)) + \"\\n\")\n",
    "    f.write('Gamma A error (Hz):        ' + str(\"{:.2f}\".format(gamma_A_error_heat)) + \"\\n\")\n",
    "    f.write('Center B (Hz):             ' + str(\"{:.2f}\".format(center_B_heat)) + \"\\n\")\n",
    "    f.write('Center B error (Hz):       ' + str(\"{:.2f}\".format(center_B_error_heat)) + \"\\n\")\n",
    "    f.write('Gamma B (Hz):              ' + str(\"{:.2f}\".format(gamma_B_heat)) + \"\\n\")\n",
    "    f.write('Gamma B error (Hz):        ' + str(\"{:.2f}\".format(gamma_B_error_heat)) + \"\\n\")\n",
    "    \n",
    "print('Results and images saved!')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beaaf736",
   "metadata": {},
   "source": [
    "# <font size=5, color='black'>Li Box Top: Traveling Waves versus Wait Time mixed Heating/RF12 Time (PR)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae4a923",
   "metadata": {},
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb0c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "df_tr_wave_movie, metadata_dict_tr_wave_movie, experiment_parameters_dict_tr_wave_movie = init_dataframe_metadata_and_exp_params(['RF12_Time', \n",
    "                                                                                                                'ShakingCycles', \n",
    "                                                                                                                'EShakeWait', \n",
    "                                                                                                                'HeatCycles'])\n",
    "# xmin, xmax, ymin, ymax\n",
    "ROI_tr_wave_movie = [1150, 1350, 1245, 1455] # to get counts right...\n",
    "norm_box_tr_wave_movie = [1150, 1300, 1000, 1100]\n",
    "\n",
    "# display image:\n",
    "frame_type_tr_wave_movie = 'FakeOD'\n",
    "current_file_fullpath_tr_wave_movie = df_tr_wave_movie['fullpaths'][0]\n",
    "fig, ax = display_image(current_file_fullpath_tr_wave_movie, \n",
    "                        ROI_tr_wave_movie, \n",
    "                        norm_box_tr_wave_movie, \n",
    "                        frame_type_tr_wave_movie)\n",
    "\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_tr_wave_movie)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_tr_wave_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb8940",
   "metadata": {},
   "source": [
    "## <font size=3, color=#399FD5>Get column densities, counts, imbalance, filter data, justify, get n3D(z), get Fermi energies </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5dea11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column densities from PR solver\n",
    "df_tr_wave_movie = add_background_subtracted_ROI_to_dataframe_fast(df_tr_wave_movie, ROI_tr_wave_movie, norm_box_tr_wave_movie)\n",
    "# get column densities\n",
    "df_tr_wave_movie = add_polrot_column_densities_to_dataframe(df_tr_wave_movie, experiment_parameters_dict_tr_wave_movie, ROI_tr_wave_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be793cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts, filter data, justify images, get n3D(z), then get box boundary\n",
    "df_tr_wav_movie = add_counts_from_PR_column_densities_to_dataframe(df_tr_wave_movie, experiment_parameters_dict_tr_wave_movie)\n",
    "\n",
    "# # FILTER DATA\n",
    "# df_tr_wave_movie = data_filter(df_tr_wave_movie, 'atom_count', 3.0, ['image_type','TopA'])\n",
    "# df_tr_wave_movie = data_filter(df_tr_wave_movie, 'atom_count', 3.0, ['image_type','TopB'])\n",
    "   \n",
    "# # plot unfiltered and filtered data:    \n",
    "fig_tr_wave_movie_counts_unfiltered = plot_box_counts_and_imbalance(df_tr_wave_movie, filter=False)\n",
    "# fig_tr_wave_movie_counts_filtered = plot_box_counts_and_imbalance(df_tr_wave_movie, filter=True)\n",
    "\n",
    "# justify images\n",
    "df_tr_wave_movie = add_justified_column_density_to_dataframe(df_tr_wave_movie, experiment_parameters_dict_tr_wave_movie)\n",
    "\n",
    "# add n3d along harmonic axis of hybrid trap to df\n",
    "df_tr_wave_movie = add_n3d_along_harmonic_axis_to_dataframe(df_tr_wave_movie, experiment_parameters_dict_tr_wave_movie)\n",
    "\n",
    "# get box boundary along z\n",
    "df_tr_wave_movie = add_box_boundary_with_sigmoid_along_z_to_dataframe(df_tr_wave_movie, cut_depth=0.5)\n",
    "\n",
    "# get Fermi energies:\n",
    "df_tr_wave_movie, avg_EF_tr_wave_A, avg_EF_tr_wave_B = add_box_Fermi_energy_to_dataframe(df_tr_wave_movie, print_result = True, filter = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "032d85b5",
   "metadata": {},
   "source": [
    "## <font size=3, color=#399FD5>Subtract no-shake from shake, for each value of wait times, then integrate to get delta n3D(z)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb26bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF12 = 11 ms data\n",
    "wait_times = sorted(set(df_tr_wave_movie['EShakeWait'].tolist()))\n",
    "no_shake_waited_averaged = dict()\n",
    "for t in wait_times:\n",
    "    no_shake_A = df_tr_wave_movie[(df_tr_wave_movie['image_type']=='TopA') & \n",
    "                                  (df_tr_wave_movie['ShakingCycles']==0) & \n",
    "                                  (df_tr_wave_movie['EShakeWait']==t) & \n",
    "                                  (df_tr_wave_movie['RF12_Time']==11)]['n3D_along_harmonic_ax']\n",
    "    no_shake_B = df_tr_wave_movie[(df_tr_wave_movie['image_type']=='TopB') & \n",
    "                                  (df_tr_wave_movie['ShakingCycles']==0) & \n",
    "                                  (df_tr_wave_movie['EShakeWait']==t) & \n",
    "                                  (df_tr_wave_movie['RF12_Time']==11)]['n3D_along_harmonic_ax']\n",
    "    avg_no_shake_A = sum(no_shake_A)/len(no_shake_A)\n",
    "    avg_no_shake_B = sum(no_shake_B)/len(no_shake_B)\n",
    "    no_shake_waited_averaged[str(t)] = [avg_no_shake_A, avg_no_shake_B]\n",
    "\n",
    "# now for each value of heat cycle, get average n3d(z) profile...\n",
    "shake_waited_averaged = dict()\n",
    "for t in wait_times:\n",
    "    shake_A = df_tr_wave_movie[(df_tr_wave_movie['image_type']=='TopA') & \n",
    "                               (df_tr_wave_movie['ShakingCycles']!=0) & \n",
    "                               (df_tr_wave_movie['EShakeWait']==t) & \n",
    "                               (df_tr_wave_movie['RF12_Time'] == 11)]['n3D_along_harmonic_ax']\n",
    "    shake_B = df_tr_wave_movie[(df_tr_wave_movie['image_type']=='TopB') & \n",
    "                               (df_tr_wave_movie['ShakingCycles']!=0) & \n",
    "                               (df_tr_wave_movie['EShakeWait']==t) & \n",
    "                               (df_tr_wave_movie['RF12_Time'] == 11)]['n3D_along_harmonic_ax']\n",
    "    avg_shake_A = sum(shake_A)/len(shake_A)\n",
    "    avg_shake_B = sum(shake_B)/len(shake_B)\n",
    "    shake_waited_averaged[str(t)] = [avg_shake_A, avg_shake_B]\n",
    "\n",
    "lower_z = df_tr_wave_movie['box_boundary_along_z'].iloc[0][0]\n",
    "upper_z = df_tr_wave_movie['box_boundary_along_z'].iloc[0][1]\n",
    "\n",
    "plt.figure(figsize=(3,4))\n",
    "for i in range(len(wait_times)):\n",
    "    plt.plot(shake_waited_averaged[str(wait_times[i])][1][lower_z:upper_z] \n",
    "             - no_shake_waited_averaged[str(wait_times[i])][1][lower_z:upper_z] + 0.2*wait_times[i])\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ac79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF12 = 32 ms data\n",
    "wait_times = sorted(set(df_tr_wave_movie['EShakeWait'].tolist()))\n",
    "no_shake_waited_averaged = dict()\n",
    "for t in wait_times:\n",
    "    no_shake_A = df_tr_wave_movie[(df_tr_wave_movie['image_type']=='TopA') & \n",
    "                                  (df_tr_wave_movie['ShakingCycles']==0) & \n",
    "                                  (df_tr_wave_movie['EShakeWait']==t) & \n",
    "                                  (df_tr_wave_movie['RF12_Time']==32)]['n3D_along_harmonic_ax']\n",
    "    no_shake_B = df_tr_wave_movie[(df_tr_wave_movie['image_type']=='TopB') & \n",
    "                                  (df_tr_wave_movie['ShakingCycles']==0) & \n",
    "                                  (df_tr_wave_movie['EShakeWait']==t) & \n",
    "                                  (df_tr_wave_movie['RF12_Time']==32)]['n3D_along_harmonic_ax']\n",
    "    avg_no_shake_A = sum(no_shake_A)/len(no_shake_A)\n",
    "    avg_no_shake_B = sum(no_shake_B)/len(no_shake_B)\n",
    "    no_shake_waited_averaged[str(t)] = [avg_no_shake_A, avg_no_shake_B]\n",
    "\n",
    "# now for each value of heat cycle, get average n3d(z) profile...\n",
    "shake_waited_averaged = dict()\n",
    "for t in wait_times:\n",
    "    shake_A = df_tr_wave_movie[(df_tr_wave_movie['image_type']=='TopA') & \n",
    "                               (df_tr_wave_movie['ShakingCycles']!=0) & \n",
    "                               (df_tr_wave_movie['EShakeWait']==t) & \n",
    "                               (df_tr_wave_movie['RF12_Time'] == 32)]['n3D_along_harmonic_ax']\n",
    "    shake_B = df_tr_wave_movie[(df_tr_wave_movie['image_type']=='TopB') & \n",
    "                               (df_tr_wave_movie['ShakingCycles']!=0) & \n",
    "                               (df_tr_wave_movie['EShakeWait']==t) & \n",
    "                               (df_tr_wave_movie['RF12_Time'] == 32)]['n3D_along_harmonic_ax']\n",
    "    avg_shake_A = sum(shake_A)/len(shake_A)\n",
    "    avg_shake_B = sum(shake_B)/len(shake_B)\n",
    "    shake_waited_averaged[str(t)] = [avg_shake_A, avg_shake_B]\n",
    "\n",
    "lower_z = df_tr_wave_movie['box_boundary_along_z'].iloc[0][0]\n",
    "upper_z = df_tr_wave_movie['box_boundary_along_z'].iloc[0][1]\n",
    "\n",
    "plt.figure(figsize=(3,4))\n",
    "for i in range(len(wait_times)):\n",
    "    plt.plot(shake_waited_averaged[str(wait_times[i])][1][lower_z:upper_z] \n",
    "             - no_shake_waited_averaged[str(wait_times[i])][1][lower_z:upper_z] + 0.2*wait_times[i])\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c943856",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'>Li Box Top: Traveling Waves versus Axicon Heating (PR)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6933f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "df_tr_wave, metadata_dict_tr_wave, experiment_parameters_dict_tr_wave = init_dataframe_metadata_and_exp_params(['RF12_Time', \n",
    "                                                                                                                'ShakingCycles', \n",
    "                                                                                                                'BoxShakeFreq', \n",
    "                                                                                                                'HeatCycles'])\n",
    "# xmin, xmax, ymin, ymax\n",
    "ROI_tr_wave = [1150, 1350, 1245, 1455] # to get counts right...\n",
    "norm_box_tr_wave = [1150, 1300, 1000, 1100]\n",
    "\n",
    "# display image:\n",
    "frame_type_tr_wave = 'FakeOD'\n",
    "current_file_fullpath_tr_wave = df_tr_wave['fullpaths'][0]\n",
    "fig, ax = display_image(current_file_fullpath_tr_wave, \n",
    "                        ROI_tr_wave, \n",
    "                        norm_box_tr_wave, \n",
    "                        frame_type_tr_wave)\n",
    "\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_tr_wave)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_tr_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8e5221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column densities from PR solver\n",
    "df_tr_wave = add_background_subtracted_ROI_to_dataframe_fast(df_tr_wave, ROI_tr_wave, norm_box_tr_wave)\n",
    "# get column densities\n",
    "df_tr_wave = add_polrot_column_densities_to_dataframe(df_tr_wave, experiment_parameters_dict_tr_wave, ROI_tr_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3359526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts, filter data, justify images, get n3D(z), then get box boundary\n",
    "df_tr_wave = add_counts_from_PR_column_densities_to_dataframe(df_tr_wave, experiment_parameters_dict_tr_wave)\n",
    "\n",
    "# FILTER DATA\n",
    "df_tr_wave = data_filter(df_tr_wave, 'atom_count', 3.0, ['image_type','TopA'])\n",
    "df_tr_wave = data_filter(df_tr_wave, 'atom_count', 3.0, ['image_type','TopB'])\n",
    "   \n",
    "# plot unfiltered and filtered data:    \n",
    "fig_tr_wave_counts_unfiltered = plot_box_counts_and_imbalance(df_tr_wave, filter=False)\n",
    "fig_tr_wave_counts_filtered = plot_box_counts_and_imbalance(df_tr_wave, filter=True)\n",
    "\n",
    "# justify images\n",
    "df_tr_wave = add_justified_column_density_to_dataframe(df_tr_wave, experiment_parameters_dict_tr_wave)\n",
    "\n",
    "# add n3d along harmonic axis of hybrid trap to df\n",
    "df_tr_wave = add_n3d_along_harmonic_axis_to_dataframe(df_tr_wave, experiment_parameters_dict_tr_wave)\n",
    "\n",
    "# get box boundary along z\n",
    "df_tr_wave = add_box_boundary_with_sigmoid_along_z_to_dataframe(df_tr_wave, cut_depth=0.5)\n",
    "\n",
    "# get Fermi energies:\n",
    "df_tr_wave, avg_EF_tr_wave_A, avg_EF_tr_wave_B = add_box_Fermi_energy_to_dataframe(df_tr_wave, print_result = True, filter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb11a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract no-shake from shake for each value of HeatCycles\n",
    "# get number of distinct HeatCycles values, to see how many of them there are:\n",
    "heat_cycles_list = sorted(set(df_tr_wave['HeatCycles'].tolist()))\n",
    "\n",
    "# for every value of heat cycles, we have a no-shake shot and a bunch of shake shots\n",
    "# so we should make a list of no-shake shots:\n",
    "\n",
    "no_shake_heated_averaged = dict()\n",
    "for cycles in heat_cycles_list:\n",
    "    no_shake_A = df_tr_wave[(df_tr_wave['image_type']=='TopA') & (df_tr_wave['ShakingCycles']==0) & (df_tr_wave['HeatCycles']==cycles)]['n3D_along_harmonic_ax']\n",
    "    no_shake_B = df_tr_wave[(df_tr_wave['image_type']=='TopB') & (df_tr_wave['ShakingCycles']==0) & (df_tr_wave['HeatCycles']==cycles)]['n3D_along_harmonic_ax']\n",
    "    avg_no_shake_A = sum(no_shake_A)/len(no_shake_A)\n",
    "    avg_no_shake_B = sum(no_shake_B)/len(no_shake_B)\n",
    "    no_shake_heated_averaged[str(cycles)] = [avg_no_shake_A, avg_no_shake_B]\n",
    "\n",
    "df_tr_wave['no_shake_subtracted'] = ['']*len(df_tr_wave)\n",
    "for idx, row in df_tr_wave.iterrows():\n",
    "    cycles = row['HeatCycles']\n",
    "    if cycles in heat_cycles_list:\n",
    "        if row['image_type'] == 'TopA':\n",
    "            df_tr_wave['no_shake_subtracted'].iloc[idx] = row['n3D_along_harmonic_ax'] - no_shake_heated_averaged[str(cycles)][0]\n",
    "        if row['image_type'] == 'TopB':\n",
    "            df_tr_wave['no_shake_subtracted'].iloc[idx] = row['n3D_along_harmonic_ax'] - no_shake_heated_averaged[str(cycles)][1]\n",
    "\n",
    "# now for each value of heat cycle, get average n3d(z) profile...\n",
    "shake_heated_averaged = dict()\n",
    "for cycles in heat_cycles_list:\n",
    "    shake_A = df_tr_wave[(df_tr_wave['image_type']=='TopA') & (df_tr_wave['ShakingCycles']!=0) & (df_tr_wave['HeatCycles']==cycles)]['n3D_along_harmonic_ax']\n",
    "    shake_B = df_tr_wave[(df_tr_wave['image_type']=='TopB') & (df_tr_wave['ShakingCycles']!=0) & (df_tr_wave['HeatCycles']==cycles)]['n3D_along_harmonic_ax']\n",
    "    avg_shake_A = sum(shake_A)/len(shake_A)\n",
    "    avg_shake_B = sum(shake_B)/len(shake_B)\n",
    "    shake_heated_averaged[str(cycles)] = [avg_shake_A, avg_shake_B]\n",
    "\n",
    "lower_z = df_tr_wave['box_boundary_along_z'].iloc[0][0]\n",
    "upper_z = df_tr_wave['box_boundary_along_z'].iloc[0][1]\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "for i in range(len(heat_cycles_list)):\n",
    "    plt.plot(shake_heated_averaged[str(heat_cycles_list[i])][0][lower_z:upper_z] \n",
    "             - no_shake_heated_averaged[str(heat_cycles_list[i])][0][lower_z:upper_z] + 0.00000*heat_cycles_list[i])\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8963d3f",
   "metadata": {},
   "source": [
    "# <font size=5, color='black'>Li Box Top: Traveling Waves versus RF12 Time (PR)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d456c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "df_tr_wave, metadata_dict_tr_wave, experiment_parameters_dict_tr_wave = init_dataframe_metadata_and_exp_params(['RF12_Time', \n",
    "                                                                                                                'ShakingCycles', \n",
    "                                                                                                                'BoxShakeFreq', \n",
    "                                                                                                                'HeatCycles'])\n",
    "# xmin, xmax, ymin, ymax\n",
    "ROI_tr_wave = [1150, 1350, 1245, 1455] # to get counts right...\n",
    "norm_box_tr_wave = [1150, 1300, 1000, 1100]\n",
    "\n",
    "# display image:\n",
    "frame_type_tr_wave = 'FakeOD'\n",
    "current_file_fullpath_tr_wave = df_tr_wave['fullpaths'][0]\n",
    "fig, ax = display_image(current_file_fullpath_tr_wave, \n",
    "                        ROI_tr_wave, \n",
    "                        norm_box_tr_wave, \n",
    "                        frame_type_tr_wave)\n",
    "\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_tr_wave)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_tr_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c62f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get column densities from PR solver\n",
    "df_tr_wave = add_background_subtracted_ROI_to_dataframe_fast(df_tr_wave, ROI_tr_wave, norm_box_tr_wave)\n",
    "# get column densities\n",
    "df_tr_wave = add_polrot_column_densities_to_dataframe(df_tr_wave, experiment_parameters_dict_tr_wave, ROI_tr_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc9489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get counts, filter data, justify images, get n3D(z), then get box boundary\n",
    "df_tr_wave = add_counts_from_PR_column_densities_to_dataframe(df_tr_wave, experiment_parameters_dict_tr_wave)\n",
    "   \n",
    "# plot unfiltered and filtered data:    \n",
    "fig_tr_wave_counts_unfiltered = plot_box_counts_and_imbalance(df_tr_wave, filter=False)\n",
    "\n",
    "# justify images\n",
    "df_tr_wave = add_justified_column_density_to_dataframe(df_tr_wave, experiment_parameters_dict_tr_wave)\n",
    "\n",
    "# add n3d along harmonic axis of hybrid trap to df\n",
    "df_tr_wave = add_n3d_along_harmonic_axis_to_dataframe(df_tr_wave, experiment_parameters_dict_tr_wave)\n",
    "\n",
    "# get box boundary along z\n",
    "df_tr_wave = add_box_boundary_with_sigmoid_along_z_to_dataframe(df_tr_wave, cut_depth=0.5)\n",
    "\n",
    "# get Fermi energies:\n",
    "df_tr_wave, avg_EF_tr_wave_A, avg_EF_tr_wave_B = add_box_Fermi_energy_to_dataframe(df_tr_wave, print_result = True, filter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract no-shake from shake for each value of HeatCycles\n",
    "# get number of distinct HeatCycles values, to see how many of them there are:\n",
    "RF12_Time_list = sorted(set(df_tr_wave['RF12_Time'].tolist()))\n",
    "\n",
    "no_shake_RF12_averaged = dict()\n",
    "shake_RF12_averaged = dict()\n",
    "\n",
    "for t in RF12_Time_list:\n",
    "    no_shake_A = df_tr_wave[(df_tr_wave['image_type']=='TopA') & (df_tr_wave['ShakingCycles']==0) & (df_tr_wave['RF12_Time']==t)]['n3D_along_harmonic_ax']\n",
    "    no_shake_B = df_tr_wave[(df_tr_wave['image_type']=='TopB') & (df_tr_wave['ShakingCycles']==0) & (df_tr_wave['RF12_Time']==t)]['n3D_along_harmonic_ax']\n",
    "\n",
    "    avg_no_shake_A = sum(no_shake_A)/len(no_shake_A)\n",
    "    avg_no_shake_B = sum(no_shake_B)/len(no_shake_B)\n",
    "    no_shake_RF12_averaged[str(t)] = [avg_no_shake_A, avg_no_shake_B]\n",
    "\n",
    "    shake_A = df_tr_wave[(df_tr_wave['image_type']=='TopA') & (df_tr_wave['ShakingCycles']!=0) & (df_tr_wave['RF12_Time']==t)]['n3D_along_harmonic_ax']\n",
    "    shake_B = df_tr_wave[(df_tr_wave['image_type']=='TopB') & (df_tr_wave['ShakingCycles']!=0) & (df_tr_wave['RF12_Time']==t)]['n3D_along_harmonic_ax']\n",
    "\n",
    "    avg_shake_A = sum(shake_A)/len(shake_A)\n",
    "    avg_shake_B = sum(shake_B)/len(shake_B)\n",
    "    shake_RF12_averaged[str(t)] = [avg_shake_A, avg_shake_B]\n",
    "\n",
    "lower_z = df_tr_wave['box_boundary_along_z'].iloc[0][0]\n",
    "upper_z = df_tr_wave['box_boundary_along_z'].iloc[0][1]\n",
    "\n",
    "lower_z = 0\n",
    "upper_z = -1\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "for i in range(len(RF12_Time_list)):\n",
    "    plt.plot(shake_RF12_averaged[str(RF12_Time_list[i])][1][lower_z:upper_z] \n",
    "             - no_shake_RF12_averaged[str(RF12_Time_list[i])][1][lower_z:upper_z] + 0.00000*RF12_Time_list[i])\n",
    "ax = plt.gca()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b954c8fd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'>RF Spectroscopy (Abs)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5f6acb2",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74bde2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "data_frame_RF_spec, metadata_dict_RF_spec, experiment_parameters_dict_RF_spec = init_dataframe_metadata_and_exp_params(['RF23_Box_Center', 'SpectPulseTime'])\n",
    "\n",
    "# ROI Box and norm_box for RF spec\n",
    "ROI_Li_RF_spec = [850,  # x min\n",
    "                  1150, # x max \n",
    "                  900,  # y min \n",
    "                  1800] # y max\n",
    "\n",
    "norm_box_Li_RF_spec = [1200, # x min\n",
    "                       1300, # x max\n",
    "                       1000, # y min\n",
    "                       1500] # y max\n",
    "\n",
    "# display some Li RF spec image:\n",
    "frame_type_Li_RF_spec = 'FakeOD'\n",
    "current_file_fullpath_Li_RF_spec = data_frame_RF_spec['fullpaths'][0]\n",
    "fig_RF_spec, ax_RF_spec = display_image(current_file_fullpath_Li_RF_spec, ROI_Li_RF_spec, norm_box_Li_RF_spec, frame_type_Li_RF_spec)\n",
    "\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_Li_RF_spec)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_Li_RF_spec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b99412b7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Li RF transfer from pixel sum</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2cf3e",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add background-subtracted FakeOD ROI to dataframe:\n",
    "data_frame_RF_spec = add_background_subtracted_ROI_to_dataframe_fast(data_frame_RF_spec, \n",
    "                                                                    ROI_Li_RF_spec, norm_box_Li_RF_spec)\n",
    "# compute, for each shot, a pixel sum\n",
    "data_frame_RF_spec = add_pixel_sums_to_data_frame_from_FakeOD_ROI(data_frame_RF_spec)\n",
    "\n",
    "# get pixel sums and RF freqs from dataframe:\n",
    "pixel_sums_A_RF = np.array(data_frame_RF_spec[data_frame_RF_spec['image_type']=='TopA']['pixel_sum'])\n",
    "pixel_sums_B_RF = np.array(data_frame_RF_spec[data_frame_RF_spec['image_type']=='TopB']['pixel_sum'])\n",
    "RF_freqs = np.array(data_frame_RF_spec[data_frame_RF_spec['image_type']=='TopA']['RF23_Box_Center'])\n",
    "        \n",
    "# compute RF_transfer:\n",
    "RF_transfer_pixel_sum = pixel_sums_B_RF/(pixel_sums_A_RF + pixel_sums_B_RF)\n",
    "\n",
    "# plot pixel sums versus FreqsA\n",
    "plt.scatter(RF_freqs, pixel_sums_A_RF, color='black', s=10)\n",
    "plt.xlabel('RF23_Box_Center')\n",
    "plt.ylabel('Pixel sum Top A')\n",
    "plt.title('Top A vs RF12_Box_Center')\n",
    "plt.show()\n",
    "\n",
    "# plot pixel sums versus FreqsA\n",
    "plt.scatter(RF_freqs, pixel_sums_B_RF, color='black', s=10)\n",
    "plt.xlabel('RF23_Box_Center')\n",
    "plt.ylabel('Pixel sum Top B')\n",
    "plt.title('Top B vs RF12_Box_Center')\n",
    "plt.show()\n",
    "\n",
    "# plot transfer, using pixel sums:\n",
    "plt.scatter(RF_freqs, RF_transfer_pixel_sum, color='black',s=10)\n",
    "plt.xlabel('RF23_Box_Center')\n",
    "plt.ylabel('Transfer B/(A+B)')\n",
    "plt.title('RF Transfer vs RF23_Box_Center')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd39f963",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Li RF transfer from atom count</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bc9a052",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font size=2, color=#6C828D>Get densities and atom counts</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970a864",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get imaging parameters here:\n",
    "AOM_factor_RF_spec = experiment_parameters_dict_RF_spec[\"Values\"]['li_hf_freq_multiplier']\n",
    "omega0_RF_spec_A = experiment_parameters_dict_RF_spec[\"Values\"]['state_2_unitarity_res_freq_MHz']\n",
    "omega0_RF_spec_B = experiment_parameters_dict_RF_spec[\"Values\"]['state_3_unitarity_res_freq_MHz']\n",
    "saturation_parameter_RF_spec_A = 0 # unknown, so assume 0\n",
    "saturation_parameter_RF_spec_B = 0 # unknown, so assume 0\n",
    "um_per_pixel_RF_spec = experiment_parameters_dict_RF_spec['Values']['top_um_per_pixel'] # in um\n",
    "\n",
    "# get densities:\n",
    "data_frame_RF_spec = add_atom_densities_abs_to_data_frame_TopAB_fast(data_frame_RF_spec, \n",
    "                                                                     sigma0 = Li6D2sigma0,\n",
    "                                                                     Gamma = Li6D2Gamma, \n",
    "                                                                     s_A = saturation_parameter_RF_spec_A, \n",
    "                                                                     s_B = saturation_parameter_RF_spec_B,\n",
    "                                                                     omega0_A = omega0_RF_spec_A,\n",
    "                                                                     omega0_B = omega0_RF_spec_B,\n",
    "                                                                     AOM_factor = AOM_factor_RF_spec)\n",
    "# now get counts from densities:\n",
    "data_frame_RF_spec = add_atom_counts_from_densities_to_data_frame(data_frame_RF_spec, \n",
    "                                                                  um_per_pixel_RF_spec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9da4fb4d",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### <font size=2, color=#6C828D>Calculate RF transfers and filter data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79f3fb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get RF_transfers from counts:\n",
    "atom_counts_RF_spec_A = np.array(data_frame_RF_spec[data_frame_RF_spec['image_type']=='TopA']['atom_count'])\n",
    "atom_counts_RF_spec_B = np.array(data_frame_RF_spec[data_frame_RF_spec['image_type']=='TopB']['atom_count'])\n",
    "\n",
    "# compute RF_transfer:\n",
    "RF_transfer_counts_B = atom_counts_RF_spec_B/(atom_counts_RF_spec_A + atom_counts_RF_spec_B)\n",
    "\n",
    "# interweave the two lists like BB,BB,BB\n",
    "RF_transfer_counts_BB = [None]*(RF_transfer_counts_B.size + RF_transfer_counts_B.size)\n",
    "RF_transfer_counts_BB[::2] = RF_transfer_counts_B\n",
    "RF_transfer_counts_BB[1::2] = RF_transfer_counts_B\n",
    "\n",
    "# add RF transfers to data frame:\n",
    "data_frame_RF_spec['RF_transfers_counts'] = RF_transfer_counts_BB\n",
    "\n",
    "# call data filter here:\n",
    "data_frame_RF_spec = data_filter(data_frame_RF_spec, 'RF_transfers_counts', 2)\n",
    "\n",
    "# get good shot data:\n",
    "RF_transfers_counts_good_shots = np.array(data_frame_RF_spec[(data_frame_RF_spec['image_type'] == 'TopB') & \n",
    "                                                             (data_frame_RF_spec['good_shot'] == True)]['RF_transfers_counts'])\n",
    "RF_freqs_good_shots = np.array(data_frame_RF_spec[(data_frame_RF_spec['image_type'] == 'TopB') & \n",
    "                                                             (data_frame_RF_spec['good_shot'] == True)]['RF23_Box_Center'])\n",
    "SpectPulseTimes_good_shot = np.array(data_frame_RF_spec[(data_frame_RF_spec['image_type'] == 'TopB') & \n",
    "                                                             (data_frame_RF_spec['good_shot'] == True)]['SpectPulseTime'])\n",
    "\n",
    "# plot RF transfer from atom counts:\n",
    "plt.scatter(RF_freqs_good_shots, RF_transfers_counts_good_shots, color = 'black', s=10)\n",
    "#plt.ylim([0, 1.1 * max(RF_transfer_counts)])\n",
    "plt.title('RF transfer vs RF frequency')\n",
    "plt.xlabel('RF frequency (MHz)')\n",
    "plt.ylabel('Transfer B/(B+A)')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "102756a3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Li RF resonance curve fitting</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc15ed",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some theory for this: The exact solution to the Rabi problem (without assuming spontaneous decay) is given by \n",
    "\n",
    "$P_2(\\tau) = \\frac{\\omega_R^2}{\\omega_R^2 + \\delta^2} \\sin^2\\left( \\tau  \\frac{\\sqrt{\\delta^2 + \\omega_R^2} }{2} \\right), $ \n",
    "\n",
    "\n",
    "where we have assumed that initially $P_1 = 1$. Here $\\tau$ is the width of the RF pulse, $\\Omega_R$ is the bare Rabi frequency, and $\\delta$ is the detuning. The setting in our case is that we know $\\tau$ and $\\delta$. So, the fit will tell us $\\Omega_R$. \n",
    "\n",
    "For now, we will attempt to fit using the RF transfer computed using pixel summing. The method should work for atom counts once it is better-calibrated (i.e. once background \"normalization\" has been taken into account).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebd76b5",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now fit\n",
    "fit_result_RF_spec = Li_P2_Rabi_RF_curve_fit((RF_freqs_good_shots, SpectPulseTimes_good_shot), \n",
    "                                             RF_transfers_counts_good_shots, \n",
    "                                             #omega0_guess =  np.average(RF_freqs_good_shots), # temp solution\n",
    "                                             #omegaR_guess = 0.0005, # MHz \n",
    "                                             smart_guesses = True,\n",
    "                                             peaks_ratio_threshold = 0.8,\n",
    "                                             plot_xlabel = 'RF frequency (MHz)',\n",
    "                                             plot_title = 'RF Resonance Curve')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ceb236a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <font size=5, color='black'>Residual Harmonic Trap Frequency with Axial Pluck (Abs)</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8aec5be1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Data preview and preparation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305655c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# initializes data frame and load metadata & exp params:\n",
    "data_frame_AxPluck, metadata_dict_AxPluck, experiment_parameters_dict_AxPluck = init_dataframe_metadata_and_exp_params(['PluckWait'])\n",
    "\n",
    "ROI_AxPluck = [750,  # x min\n",
    "                  1150, # x max \n",
    "                  900,  # y min \n",
    "                  1900] # y max\n",
    "\n",
    "norm_box_AxPluck = [1200, # x min\n",
    "                       1300, # x max\n",
    "                       1000, # y min\n",
    "                       1500] # y max\n",
    "\n",
    "frame_type_AxPluck = 'FakeOD'\n",
    "current_file_fullpath_AxPluck = data_frame_AxPluck['fullpaths'][0]\n",
    "fig_AxPluck, ax_AxPluck= display_image(current_file_fullpath_AxPluck, ROI_AxPluck, norm_box_AxPluck, frame_type_AxPluck)\n",
    "\n",
    "# add background-subtracted FakeOD ROI to dataframe:\n",
    "data_frame_AxPluck = add_background_subtracted_ROI_to_dataframe_fast(data_frame_AxPluck, \n",
    "                                                                    ROI_AxPluck, norm_box_AxPluck)\n",
    "\n",
    "#################################################\n",
    "print('Displaying image: ')\n",
    "print(current_file_fullpath_AxPluck)\n",
    "print('')\n",
    "print('Frame type: ' + frame_type_AxPluck)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdc92abd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get densities and counts</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c7eb5c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get imaging parameters here:\n",
    "AOM_factor_AxPluck = experiment_parameters_dict_AxPluck[\"Values\"]['li_hf_freq_multiplier']\n",
    "omega0_AxPluck_A = experiment_parameters_dict_AxPluck[\"Values\"]['state_1_unitarity_res_freq_MHz']\n",
    "omega0_AxPluck_B = experiment_parameters_dict_AxPluck[\"Values\"]['state_2_unitarity_res_freq_MHz']\n",
    "saturation_parameter_AxPluck_A = 0 # unknown, so assume 0\n",
    "saturation_parameter_AxPluck_B = 0 # unknown, so assume 0\n",
    "um_per_pixel_AxPluck = experiment_parameters_dict_AxPluck['Values']['top_um_per_pixel'] # in um\n",
    "\n",
    "# get densities from Top absorption imaging\n",
    "data_frame_AxPluck = add_atom_densities_abs_to_data_frame_TopAB_fast(data_frame_AxPluck, \n",
    "                                                                     sigma0 = Li6D2sigma0,\n",
    "                                                                     Gamma = Li6D2Gamma, \n",
    "                                                                     s_A = saturation_parameter_AxPluck_A, \n",
    "                                                                     s_B = saturation_parameter_AxPluck_B,\n",
    "                                                                     omega0_A = omega0_AxPluck_A,\n",
    "                                                                     omega0_B = omega0_AxPluck_B,\n",
    "                                                                     AOM_factor = AOM_factor_AxPluck)\n",
    "# now get counts from densities:\n",
    "data_frame_AxPluck = add_atom_counts_from_densities_to_data_frame(data_frame_AxPluck, \n",
    "                                                                  um_per_pixel_AxPluck)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e7e0766",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size = 3, color=#399FD5>Justify images and get 3d densities along harmonic axis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16414d2c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# justify image\n",
    "data_frame_AxPluck = add_justified_column_density_to_dataframe(data_frame_AxPluck, experiment_parameters_dict_AxPluck)\n",
    "\n",
    "# look at a rotated image:\n",
    "plt.imshow(data_frame_AxPluck['justified_column_density'][5])\n",
    "plt.show()\n",
    "\n",
    "# add n3d along harmonic axis of hybrid trap and harmonic trap center to df\n",
    "data_frame_AxPluck = add_n3d_along_harmonic_axis_to_dataframe(data_frame_AxPluck,\n",
    "                                                                    experiment_parameters_dict_AxPluck)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d72f1e36",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## <font size=3, color=#399FD5>Get harmonic trap centers and find trapping frequency</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112be3e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add harmonic trap centers to df\n",
    "data_frame_AxPluck = add_hybrid_harmonic_trap_centers_to_dataframe(data_frame_AxPluck)\n",
    "\n",
    "# fit sloshing to get harmonic trap frequency from Top A shots:\n",
    "pluck_wait_times = []\n",
    "harmonic_trap_center_TopA = []\n",
    "for idx, row in data_frame_AxPluck.iterrows():\n",
    "    if row['image_type'] == 'TopA':\n",
    "        pluck_wait_times.append(row['PluckWait'])\n",
    "        harmonic_trap_center_TopA.append(row['hybrid_harmonic_trap_center'])\n",
    "\n",
    "hyb_sloshing_fit_results = hybrid_sloshing_fit(pluck_wait_times, \n",
    "                                               harmonic_trap_center_TopA,\n",
    "                                               plot_xlabel = 'PluckWait time (s)', \n",
    "                                               plot_ylabel = 'Harmonic trap center (TopA)',\n",
    "                                               plot_title = 'Fit to cos')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
