\documentclass[11pt]{article}
\usepackage[total={7in, 8in}]{geometry}
\usepackage{graphicx}
\usepackage[margin=0.5in]{caption}
\usepackage{comment}
\usepackage{amsmath, amsthm, latexsym, amssymb, color,cite,enumerate, physics, framed}
%\usepackage{ulem} %For sout
\usepackage{caption,subcaption,verbatim, empheq, cancel}
\usepackage[inline]{enumitem}
\usepackage{mathtools}
\pagenumbering{arabic}
%\theoremstyle{theorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{convention}[theorem]{Convention}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{examplex}{Example}
\newenvironment{example}
  {\pushQED{\qed}\renewcommand{\qedsymbol}{$\triangle$}\examplex}
  {\popQED\endexamplex}
\theoremstyle{remark}
\newtheorem{remark}{Remark}

\newcommand*{\myproofname}{Proof}
\newenvironment{subproof}[1][\myproofname]{\begin{proof}[#1]\renewcommand*{\qedsymbol}{$\mathbin{/\mkern-6mu/}$}}{\end{proof}}
\renewcommand\Re{\operatorname{Re}}%%redefined Re and Im
\renewcommand\Im{\operatorname{Im}}
\newcommand\MdR{\mbox{M}_d(\mathbb{R})} %dxd matrices
\newcommand\End{\operatorname{End}} %Prefix linear transformations
\newcommand\GldR{\mbox{Gl}_d(\mathbb{R})}%dxd invertible matrices
\newcommand\Gl{\operatorname{Gl}} %Prefix for general linear group
\newcommand\OdR{\mbox{O}(\mathbb{R}^d)} %Orthogonal transformations
\newcommand\Sym{\operatorname{Sym}}
\newcommand\Exp{\operatorname{Exp}}
%\newcommand\tr{\operatorname{tr}}
\newcommand\diag{\operatorname{diag}}
\newcommand\supp{\operatorname{Supp}}
\newcommand\Spec{\operatorname{Spec}}
\renewcommand\det{\operatorname{det}}
\newcommand\Ker{\operatorname{Ker}}
\newcommand\Interior{\operatorname{Int}}
\newcommand\R{\mathbb{R}}
\newcommand{\lp}{\left(}
\newcommand{\rp}{\right)}
\newcommand{\lb}{\left[}
\newcommand{\rb}{\right]}
\newcommand{\lc}{\left\{}
\newcommand{\rc}{\right\}}
\newcommand{\p}{\partial}
\newcommand{\f}[2]{\frac{#1}{#2}}
\newcommand{\Vol}{\operatorname{Vol}}
\newcommand{\iprod}{\mathbin{\lrcorner}}
\newcommand{\al}{\alpha}
\newcommand{\be}{\beta}
\newcommand{\FT}{\mathcal{F}}
\newcommand{\LT}{\mathcal{L}}
\usepackage{hyperref}
\usepackage{tensor}
\usepackage{xcolor}
\hypersetup{
	colorlinks,
	linkcolor={black!50!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black}
}
\newcommand{\slantedslash}{\mathbin{\rotatebox[origin=c]{23}{$-$}}}
\newcommand{\rint}{\mathop{\mathpalette\docircint\relax}\!\int}
\newcommand{\docircint}[2]{%
  \ifx#1\displaystyle
    \displayrint
  \else
    \normalrint{#1}%
  \fi
}
\newcommand{\displayrint}{\displaystyle \slantedslash \mkern-18mu}
\newcommand{\normalrint}[1]{%
  \smallerc{#1}\ifx#1\textstyle\mkern-9mu\else\mkern-8.2mu\fi
}
\newcommand{\smallerc}[1]{%
  \vcenter{\hbox{$\ifx#1\textstyle\scriptstyle\else\scriptscriptstyle\fi \slantedslash $}}%
}




\author{Huan Bui and Evan Randles}
\title{A generalized polar-coordinate integration formula with applications to the study of convolution powers of complex-valued functions on $\mathbb{Z}^d$. }
\date{}
\begin{document}
\maketitle


\abstract{The classical polar-coordinate integration formula is an essential tool in harmonic analysis and, especially, the analysis of radial functions in $\mathbb{R}^d$. In this paper, we discuss a generalization of the polar-coordinate integration formula where integration with respect to spherical measure $d\Theta$ over the unit sphere $\mathbb{S}^{d-1}$ is replaced by integration with respect to a certain surface-carried measure $d\sigma$ over a compact (non-smooth and non-convex) hypersurface $S$ and where the isotropic dilation $x\mapsto r\cdot x$ is replaced by a generally anisotropic dilation $x\mapsto T_r x$. Using oscillatory integral techniques, we will then discuss applications of this work to local (central) limit theorems and \textcolor{blue}{operator semigroups.}}\\

\noindent{\small\bf Keywords:} Polar-coordinate Integration Formula,  Spherical Measure, Oscillatory Integrals, Convolution Powers.\\

\noindent{\small\bf Mathematics Subject Classification:} Primary 28A25 \& 58C35; Secondary 42B20 \& 42A85

\section{Introduction}\label{sec:Introduction}


The spherical measure and the related polar-coordinate integration formula are important tools and objects of study in harmonic analysis \cite{SteinHarmonicAnalysis} \cite{Baker1997} (\textcolor{red}{Can we find a reference better for this?}). To have them at our fingertips, let us denote by $\mathbb{S}$ and $\mathbb{B}$ the unit sphere and unit ball in $\mathbb{R}^d$, respectively, let $m$ be the Lebesgue measure on $\mathbb{R}^d$, and write $dx=m(dx)=dm(x)$. The spherical measure is the canonical Radon measure on $\mathbb{S}$ for which $\Theta(\mathbb{S})=d\cdot m(\mathbb{B})$ and $\Theta(OF)=\Theta(F)$ for every orthogonal transformation $O$ and Borel set $F\subseteq\mathbb{S}$. With this measure, we state the classical polar coordinate integration formula as follows: For every $f\in L^1(\mathbb{R}^d)$ (or non-negative measurable $f$),
\begin{equation}\label{eq:StandardPolarIntegrationFormula}
\int_{\mathbb{R}^d}f(x)\,dx=\int_{\mathbb{S}}\left(\int_0^\infty f(r\eta)r^{d-1}\,dr\right)\,\Theta(d\eta)=\int_0^\infty\left(\int_\mathbb{S}f(r\eta)\Theta(d\eta)\right)r^{d-1}\,dr.
\end{equation}
Precise formulation of this classical result can be found in \cite{Stein2005} and \cite{Folland1984}. For two interesting applications which provide some useful context, we encourage the reader to see \cite{Baker1997} and \cite{Folland2001}.  In this article, we generalize the polar coordinate integration formula \eqref{eq:StandardPolarIntegrationFormula} and its corresponding measure $\Theta$ in a way that is well-aligned to the analysis of certain oscillatory integrals which appear in the study of convolution powers of complex-valued functions on $\mathbb{Z}^d$. \\


\noindent To describe the generalized polar coordinate integration formula treated in this article, we must first introduce a class of functions on $\mathbb{R}^d$ which share several desirable properties with the Euclidean norm. The first such property is that such functions ``play well" with spatial dilations of the following form: Let $\{T_r\}_{r>0}\subseteq \Gl(\mathbb{R}^d)$ be a continuous one-parameter group, i.e., $T$ is a continuous group homomorphism from the multiplicative group of positive real numbers into the general linear group, $\Gl(\mathbb{R}^d)$. It is well-known (c.f., \cite{Randles2017,Engel2000,Engel2005}) that every continuous one-parameter group $\{T_r\}$ has the unique representation
\begin{equation*}
T_r=r^E=\exp((\ln r) E)=\sum_{k=0}^\infty \frac{(\ln r)^k}{k!}E^k
\end{equation*}
for some $E\in\End(\mathbb{R}^d)$; here,  $\End(\mathbb{R}^d)$ is the algebra of endomorphisms of $\mathbb{R}^d$ which we take equipped with the operator norm $\|\cdot\|$. $E$ is called the (infinitesimal) generator of $\{T_r\}$ and $\{T_r\}$ is said to be generated by $E$. This, of course, gives a one-to-one correspondence between $\End(\mathbb{R}^d)$ and the collection of continuous one-parameter groups.  A continuous one-parameter group $\{T_r\}$ is said to be \textbf{contracting} if
\begin{equation*}
\lim_{r\to 0}\|T_r\|=0. 
\end{equation*}
We note that, if $E$ is the generator of a contracting group $\{T_r\}$, then $\tr(E)>0$. This fact (Proposition \ref{prop:ContractingTrace}) and its proof can be found in Appendix \ref{subsec:OneParameterGroups} along with some other basic results on one-parameter groups. Also, we encourage the reader to look at the excellent texts \cite{Engel2005} and \cite{Engel2000} on one-parameter (semi) groups.\\

\noindent Consider a function $P:\mathbb{R}^d\to\mathbb{R}$ and denote by
\begin{equation*}
    S=\{\eta\in\mathbb{R}^d:P(\eta)=1\}\hspace{1cm}\mbox{and}\hspace{1cm}B=\{\eta\in\mathbb{R}^d:P(\eta)<1\}; 
\end{equation*}
we shall call $S$ \textbf{ the unital level set of $P$}. We say that $P$ is \textbf{positive-definite} if $P$ is non-negative and $P(x)=0$ only when $x=0$. Given a continuous one-parameter group $\{T_r\}$, we say that $P$ is \textbf{homogeneous with respect to $\{T_r\}$} if
\begin{equation}\label{eq:IntroductionHomogeneous}
    rP(x)=P(T_r x)=P(r^Ex)
\end{equation}
for all $r>0$ and $x\in\mathbb{R}^d$. By an abuse of language, we will also say that $P$ is homogeneous with respect to $E$ whenever \eqref{eq:IntroductionHomogeneous} is satisfied. The set of all such $E\in \End(\mathbb{R}^d)$ for which \eqref{eq:IntroductionHomogeneous} holds is denoted by $\Exp(P)$ and called the \textbf{exponent set of $P$}. We have the following characterization.

\begin{proposition}\label{prop:PositiveHomogeneousCharacterization}
Let $P:\mathbb{R}^d\to\mathbb{R}$ be continuous, positive-definite, and have $\Exp(P)\neq \varnothing$. The following are equivalent:
\begin{enumerate}[label=(\alph*), ref=(\alph*)]
\item\label{cond:SisCompact} $S$ is compact.
\item\label{cond:PisAboveOne} There is a positive number $M$ for which
\begin{equation*}
P(x)>1
\end{equation*}
for all $|x|\geq M$. 
\item\label{cond:Contracting} For each $E\in\Exp(P)$, $T_r=r^E$ is contracting.
\item\label{cond:ThereExistsContracting} There exists $E\in\Exp(P)$ for which $T_r=r^E$ is contracting.
\item\label{cond:InfiniteLimit} We have
\begin{equation*}
\lim_{x\to\infty}P(x)=\infty.
\end{equation*}
\end{enumerate}
\end{proposition}



\begin{definition}
Let $P:\mathbb{R}^d\to\mathbb{R}$ be continuous, positive-definite and have $\Exp(P)\neq \varnothing$. If any one (and hence all) of the equivalent conditions in Proposition \ref{prop:PositiveHomogeneousCharacterization} are fulfilled, we say that $P$ is positive-homogeneous.
\end{definition}


\begin{example}\label{exp:EuclideanNorm}\normalfont
For any $\alpha>0$, the $\alpha$th-power of the Euclidean norm $x\mapsto |x|^\alpha$ is positive homogeneous.  In this case, the unital level set $S$ is the standard unit sphere $\mathbb{S}$ and
\begin{equation*}
    \Exp(|\cdot|^\alpha)=\frac{1}{\alpha}I+\mathfrak{o}(d)
\end{equation*}
where $I$ is the identity and $\mathfrak{o}(d)$ is the Lie algebra of the orthogonal group (characterized by the set of skew-symmetric matrices). 
\end{example}

\begin{example}\label{exp:Polynomial}\normalfont
In the language of L. H\"{o}rmander \cite{Hormander1983}, consider semi-elliptic polynomial of the form
\begin{equation}\label{eq:SemiEllipticIntro}
    P(x)=\sum_{|\alpha:\mathbf{n}|=1}a_\alpha x^\alpha,
\end{equation}
where $\mathbf{n}=(n_1,n_2,\dots,n_d)$ is a $d$-tuple of positive even natural numbers, and, for each multi-index $\alpha =(\alpha_1,\alpha_2,\dots,\alpha_d)\in\mathbb{N}^d$,
\begin{equation*}
    |\alpha:\mathbf{n}|:=\sum_{k=1}^d\frac{\alpha_k}{n_k},
\end{equation*}
and
\begin{equation*}
    x^\alpha=\left(x^1\right)^{\alpha_1}\left(x^2\right)^{\alpha_2}\cdots\left(x^d\right)^{\alpha_d}
\end{equation*}
for $x=\left(x^1,x^2,\dots,x^d\right)\in\mathbb{R}^d$. If we consider $E\in\End(\mathbb{R}^d)$ whose standard matrix representation is $\diag(1/n_1,1/n_2,\dots,1/n_d)$, we have
\begin{equation*}
    P\left(r^Ex\right)=\sum_{|\alpha:\mathbf{n}|=1}a_{\alpha}\left(r^{1/n_1}x^1\right)^{\alpha_1}\left(r^{1/n_2}x^2\right)^{\alpha_2}\cdots\left(r^{1/n_d}x^d\right)^{\alpha_d}=\sum_{|\alpha:\mathbf{n}|=1}a_\alpha r^{|\alpha:\mathbf{n}|}x^\alpha=rP(x)
\end{equation*}
for all $x\in\mathbb{R}^d$ and $r>0$ and therefore $E\in\Exp(P)$. It is easy to see that $T_r=r^E$ is a contracting group and so we have the following statement by virtue of Proposition \ref{prop:PositiveHomogeneousCharacterization}: \begin{center}\textit{If a semi-elliptic polynomial $P(x)$ of the form \eqref{eq:SemiEllipticIntro} is positive-definite, then $P$ is positive homogeneous.}
\end{center}

\noindent For two concrete examples, consider the polynomials $P_1$ and $P_2$ on $\mathbb{R}^2$ defined by
\begin{equation*}
    P_1(x,y)=x^2+y^4\hspace{1cm}\mbox{and}\hspace{1cm}P_2(x,y)=x^2+\frac{3}{2}xy^2+y^4
\end{equation*}
defined for $(x,y)\in\mathbb{R}^2$. It is straightforward to see that $P_1$ and $P_2$ are both semi-elliptic of the form \eqref{eq:SemiEllipticIntro} with $\mathbf{n}=(2,4)$ and positive-definite. Figure \ref{fig:PoneAndtwo} illustrates $P_1$ and $P_2$ and their unital level sets $S_1$ and $S_2$.
\begin{figure}[!htb]
    \centering
    \hspace{10pt}
    \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.45]{non_convex_SP.png}
    \vspace{-10pt}
    \includegraphics[scale=0.45]{non_convex_SP_levelsets.png}
    %\caption{}
    %\label{fig:convex_SP}
    \end{subfigure}%
    \hspace{-20pt}
    \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.45]{non_convex_S.png}
    \vspace{-10pt}
    \includegraphics[scale=0.45]{non_convex_S_levelsets.png}
    %\caption{}
    %\label{fig:non_convex_SQ}
    \end{subfigure}
    \caption{$P_1$ and convex $S_{1}$ (red); $P_2$ and non-convex $S_2$ (red)}
    \label{fig:PoneAndtwo}
\end{figure}
\begin{remark}\label{rmk:PositiveHomogeneousPolynomialsVSFunctions}
 In \cite{Randles2017}, a positive-homogeneous polynomial $P$ is, by definition, a complex-valued multivariate polynomial on $\mathbb{R}^d$ for which $\Exp(P)$ contains an element of $\End(\mathbb{R}^d)$ whose spectrum is purely real and for which $R=\Re P$ is positive-definite (See Proposition \ref{prop:PosHomSufficientCondition} below). By virtue of Proposition 2.2 of \cite{Randles2017}, for each such polynomial $P$ and $E\in\Exp(P)$ with real spectrum, there exists $A\in\Gl(\mathbb{R}^d)$ (representing a change of basis of $\mathbb{R}^d$) and a $d$-tuple of positive even integers $\mathbf{n}=(n_1,n_2,\dots,n_d)\in\mathbb{N}_+^d$ for which $A^{-1}EA$ has standard matrix representation $\diag(1/n_1,1/n_2,\dots,1/n_d)$ and $(P\circ A)(x)$ is semi-elliptic of the form \eqref{eq:SemiEllipticIntro} with, in this case, complex coefficients. It follows that every real-valued positive-homogeneous polynomial (in the sense of \cite{Randles2017}) is a positive-homogeneous function in the sense of the present article. Of course, the semi-elliptic polynomials discussed above are positive-homogeneous polynomials in the sense of \cite{Randles2017} where $A=I$. We refer the reader to Section 7.3 of \cite{Randles2017} which presents a real-valued positive-homogeneous polynomial which is not semi-elliptic (and so $A\neq I$).
\end{remark}
\end{example}

\begin{example}\label{exp:Weierstrass}\normalfont
Let $Q$ be a positive-homogeneous function with exponent set $\Exp(Q)$ and compact level set $S_Q=\{\eta:Q(\eta)=1\}$. Given any $f\in C^0(S_Q)$ for which $f(\eta)>0$ for all $\eta\in S_Q$ and $E\in \Exp(Q)$, define $P=P_{f,E,Q}:\mathbb{R}^d\to\mathbb{R}$ by
\begin{equation*}
P(x)=\begin{cases}
Q(x)f\left((Q(x))^{-E}x\right) & x\neq 0\\
0 & x=0
\end{cases}
\end{equation*}
for $x\in\mathbb{R}^d$. We claim that $P$ is positive-homogeneous and $E\in\Exp(P)$.

\begin{subproof}To see this, we first observe that, for any $x\in\mathbb{R}^d\setminus \{0\}$, $Q((Q(x))^{-E}x)=Q(x)/Q(x)=1$ and hence $Q(x)^{-E}x\in S_Q$ and so the above formula makes sense and ensures that $P$ is continuous on $\mathbb{R}^d\setminus\{0\}$. Furthermore, because $f$ is continuous and positive on the compact set $S_Q$, we have $0<\min f\leq \max f<\infty$. From this it follows that $P$ is positive-definite and, by virtue of the squeeze theorem, continuous at $x=0$. For any $r>0$ and $x\in\mathbb{R}^d$, we have
\begin{equation*}
P(r^Ex)=Q(r^Ex)f(Q(r^Ex)^{-E}r^Ex)=rQ(x)f(Q(x)^{-E}x)=rP(x)
\end{equation*}
and therefore $E\in\Exp(P)$. Upon noting that $\{r^E\}$ is contracting by virtue of Proposition \ref{prop:PositiveHomogeneousCharacterization}, we conclude that $P$ is positive-homogeneous.
\end{subproof}
\noindent The utility of this construction allows us to see that ``most'' positive-homogeneous functions are not smooth. To see this, take any positive-definite function $Q\in C^{\infty}(\mathbb{R}^d)$. It follows (See Section \ref{sec:SigmaForSmoothP}) that $S_Q$ is a smooth compact embedded hypersurface of $\mathbb{R}^d$. If $P=P_{f,Q}$ is $C^\infty(\mathbb{R}^d)$, $P\vert_{S_Q}=f$ is necessarily $C^\infty(S_Q)$. It follows that $P\notin C^\infty(\mathbb{R}^d)$ whenever $f$ is chosen from $C^0(S_Q)\setminus C^\infty(S_Q)$. By precisely the same argument, we see that $P\in C^0(\mathbb{R}^d)\setminus C^k(\mathbb{R}^d)$ whenever $f\in C^0(S_Q)\setminus C^k(S_Q)$ for each $k\in\mathbb{N}$.\\

\noindent  As a straightforward example, consider $Q(x,y)=|(x,y)|=\sqrt{x^2+y^2}$ on $\mathbb{R}^2$ with $S_Q=\mathbb{S}$ and define
\begin{equation*}
f(x,y)=w(\mbox{Arg}(x,y))+3
\end{equation*}
where $w:\mathbb{R}\to\mathbb{R}$ is defined by
\begin{equation*}
    w(t) = \sum_{n=0}^\infty 2^{-n} \cos\lp 3^n t \rp
\end{equation*}
for $t\in\mathbb{R}$; $w$ is a continuous $2\pi$-periodic version of the Weierstrass function. The resulting positive-homogeneous function $P$ is continuous but nowhere differentiable. Figure \ref{fig:Weierstrass} illustrates this function $P$ alongside $Q$ and together with their associated level sets. We note that $S_P\neq S_Q$ and this is generally the case unless $f\equiv 1$.

\begin{figure}[!htb]
    \centering
    \hspace{10pt}
    \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.4]{WeierstrassP_and_levelsets.png}
    \vspace{-10pt}
    \includegraphics[scale=0.4]{WeierstrassP_levelsets.png}
    %\caption{}
    %\label{fig:WeierstrassP_levelsets}
    \end{subfigure}%
    \hspace{-20pt}
    \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.4]{Q_and_levelsets.png}
    \vspace{-10pt}
    \includegraphics[scale=0.4]{Q_levelsets.png}
    %\caption{}
    %\label{fig:Q_levelsets}
    \end{subfigure}
    \caption{$P$ with $S_P$ highlighted in red; $Q$ with $S_Q$ highlighted in red }
    \label{fig:Weierstrass}
\end{figure}
\end{example}

\noindent Given a positive-homogeneous function $P$, let $\Sym(P)$ be the set of $O\in\End(\mathbb{R}^d)$ for which
\begin{equation*}
P(Ox)=P(x)
\end{equation*}
for all $x\in\mathbb{R}^d$. By virtue of the positive-definiteness of $P$, it is easy to see that $\Sym(P)$ is a subgroup of $\Gl(\mathbb{R}^d)$. For this reason, $\Sym(P)$ is said to be the \textbf{symmetry group associated to $P$}. In fact, we will show that $\Sym(P)$ is a compact subgroup of $\Gl(\mathbb{R}^d)$ and hence a subgroup of the orthogonal group; this is proposition \ref{prop:SymCompact}. As a consequence of this, we will prove that $\tr E=\tr E'$ for all $E,E'\in\Exp(P)$ (Corollary \ref{cor:TraceisInvariant}) and this allows us to define the \textbf{homogeneous order of $P$} to be the unique positive number $\mu_P$ for which
\begin{equation*}
\mu_P=\tr E
\end{equation*}
for all $E\in\Exp(P)$. 

\begin{example}
In Example \ref{exp:EuclideanNorm}, $\Sym(|\cdot|^\alpha)$ is precisely the orthogonal group $\OdR$ and $\mu_{|\cdot|^\alpha}=d/\alpha$. In Example \ref{exp:Polynomial}, the symmetric set of a semi-elliptic polynomial $P$ of the form \eqref{eq:SemiEllipticIntro} depends on the specific nature of the polynomial in question. Concerning the polynomials $P_1$ and $P_2$ in that example, it is easily shown that $\Sym(P_1)$ is the four-element dihedral group $D_2$ and $\Sym(P_2)$ is the two-element group consisting of the identity and the transformation $(x,y)\mapsto (x,-y)$. For a semi-elliptic polynomial $P$ of the form \eqref{eq:SemiEllipticIntro}, 
\begin{equation*}
    \mu_P=|\mathbf{1}:\mathbf{n}|=\frac{1}{n_1}+\frac{1}{n_2}+\cdots+\frac{1}{n_d}
\end{equation*}
and, in particular, $\mu_{P_1}=\mu_{P_2}=1/2+1/4=3/4.$
\end{example}

\noindent Armed with the notion of positive-homogeneous functions and their associated contracting groups, we are ready to state our generalization of spherical measure and the polar-coordinate integration formula \eqref{eq:StandardPolarIntegrationFormula}. To this end, denote by $\mathcal{M}_d$ the Lebesgue $\sigma$-algebra on $\mathbb{R}^d\setminus\{0\}$ and by $\mathcal{L}$ the Lebesgue $\sigma$-algebra on $(0,\infty)$. Given a positive-homogeneous function $P$ with homogeneous order $\mu_P>0$, we let $\lambda_P$ denote the $\sigma$-finite measure on $((0,\infty),\mathcal{L})$ with $\lambda_P(dr)=r^{\mu_P-1}\,dr$. Our main theorem is as follows\footnote{We refer the reader to Section 3.6 and 9.2 of \cite{Bogachev2007} which provides some basic context and vocabulary.}. 

\begin{comment} is dedicated to constructing a surface measure on the compact level set $S$ associated to a positive-homogeneous function and using it to generalize the polar integration formula \eqref{eq:StandardPolarIntegrationFormula}. To introduce our main theorem, let $P$ be a positive-homogeneous function with homogeneous order $\mu_P>0$, exponent set $\Exp(P)$ and symmetry group $\Sym(P)$. We shall denote by $\mathcal{M}_d$ the Lebesgue $\sigma$-algebra on $\mathbb{R}^d\setminus\{0\}$ and by $m$ the Lebesgue measure.  Also, let the compact set $S=S_P=\{\eta\in\mathbb{R}^d:P(\eta)=1\}$ in $\mathbb{R}^d$ be equipped with its relative topology and denote by $\mathcal{B}(S)$ the Borel $\sigma$-algebra on $S$. We denote by $\mathcal{L}=\mathcal{L}(0,1)$ the $\sigma$-algebra of Lebesgue measureable sets on $(0,\infty)$ and let $\lambda_P$ be the $\sigma$-finite measure on $((0,\infty),\mathcal{L})$ with $\lambda_P(dr)=r^{\mu_P-1}\,dr$. \end{comment}



\begin{theorem}\label{thm:BestIntegrationFormula} Let $P$ be a positive-homogeneous function on $\mathbb{R}^d$ and let $S$, $\Exp(P)$, $\Sym(P)$, and $\mu_P$ be $P$'s associated unital level set, exponent set, symmetric group, and homogeneous order, respectively.
There exists a $\sigma$-algebra $\Sigma$ on $S$ containing the Borel $\sigma$-algebra on $S$, $\mathcal{B}(S)$,
and a finite Radon measure $\sigma_P$ on $(S,\Sigma)$ which satisfies the following properties:
\begin{enumerate}
\item\label{property:Completion} $(S,\Sigma,\sigma_P)$ is the completion of $(S,\mathcal{B}(S),\sigma_P)$. In particular, $(S,\Sigma,\sigma_P)$ is a complete measure space.
\item\label{property:Invariance} For any $F\in\Sigma$ and $O\in\Sym(P)$, $\sigma(OF)=\sigma(F)$.
\item\label{property:DefiningConditionofsigma} For any $F\in\Sigma$ and $E\in\Exp(P)$, 
\begin{equation*}
\widetilde{F_E}:=\bigcup_{0<r<1}\left(r^E F\right)=\left\{r^E\eta\in\mathbb{R}^d\setminus\{0\}:0<r<1,\eta\in F\right\}
\end{equation*}
is a Lebesgue measurable subset of $\mathbb{R}^d\setminus \{0\}$, i.e., $\widetilde{F_E}\in\mathcal{M}_d$, and
\begin{equation*}
\sigma_P(F)=\mu_P\cdot m\left(\widetilde{F_E}\right)
\end{equation*}
where $m$ denotes the Lebesgue measure on $\mathbb{R}^d$.
\end{enumerate}
Further, denote by $\left((0,\infty)\times S,(\mathcal{L}\times\Sigma)',\lambda_P\times\sigma_P\right)$ the completion of the product measure space $((0,\infty)\times S,\mathcal{L}\times\Sigma,\lambda_P\times\sigma_P)$. We have
\begin{enumerate}
\item\label{property:BestPointIsomorphism} Given any $E\in \Exp(P)$, the map $\psi_E:(0,\infty)\times S\to\mathbb{R}^d\setminus\{0\}$, defined by $\psi_E(r,\eta)=r^E\eta$ for $r>0$ and $\eta\in S$, is a point isomorphism of the measure spaces $\left((0,\infty)\times S,(\mathcal{L}\times\Sigma)',\lambda_P\times\sigma_P\right)$ and $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d,m)$. That is
\begin{equation*}
\mathcal{M}_d=\left\{A\subseteq \mathbb{R}^d\setminus\{0\}:\psi_E^{-1}(A)\in (\mathcal{L}\times\Sigma)'\right\}
\end{equation*}
and, for each $A\in\mathcal{M}_d$,
\begin{equation*}
m(A)=(\lambda_P\times\sigma_P)(\psi_E^{-1}(A)).
\end{equation*}
\item\label{property:BestIntegrationFormula} Given any Lebesgue measurable function $f:\mathbb{R}^d\to\mathbb{C}$ and $E\in \Exp(P)$, $f\circ \psi_E$ is $(\mathcal{L}\times\Sigma)'$-measurable and the following statements hold:
\begin{enumerate}
\item If $f\geq 0$, then
\begin{equation}\label{eq:BestIntegrationFormula}
\int_{\mathbb{R}^d}f(x)\,dx=\int_0^\infty\left(\int_S f(r^E\eta)\,\sigma_P(d\eta)\right)r^{\mu_P-1}\,dr=\int_S\left(\int_0^\infty f(r^E\eta)r^{\mu_P-1}\,dr\right)\sigma_P(d\eta).
\end{equation}
\item When $f$ is complex-valued, we have 
\begin{equation*}f\in L^1(\mathbb{R}^d)\hspace{.5cm}\mbox{ if and only if}\hspace{.5cm}f\circ\psi_E\in L^1\left((0,\infty)\times S,(\mathcal{L}\times\Sigma)',\lambda_P\times\sigma_P\right)
\end{equation*} 
and, in this case, \eqref{eq:BestIntegrationFormula} holds.
\end{enumerate}
\end{enumerate}
\end{theorem}


\textcolor{red}{commented out here is an idea for a corollary which parallels Theorem 1 in \cite{Baker1997}. Its corollary has something to do with the Fourier transform and actually might be useful to Greenblatt and company -- so we should look at that or remove it.}
%\begin{comment}

A couple of things. For each $r>0$, denote by $B_r=\{x\in\mathbb{R}^d:P(x)<r\}$. Of course, $B_1=B$. 

\begin{proposition}
For $x\in\mathbb{R}^d$, let $d(x,B)=\inf\{|x-\eta|:\eta\in B\}$ and, for $\epsilon>0$ define $\mathcal{N}_B(\epsilon)=\{x\in\mathbb{R}^d:d(x,B)<\epsilon\}$. Suppose that, for some $\epsilon>0$, $f$ is bounded on $B_{1+\epsilon}$ and continuous on $N_B(\epsilon)$, then
\begin{equation*}
    \int_{S}f(\eta)\sigma_P(d\eta)=\frac{d}{dt}\left(\int_{B_t}f(x)\,dx\right)\Big\vert_{t=1}.
\end{equation*}
\end{proposition}
\begin{proof}
We have, for $0<h<\epsilon$,
\begin{eqnarray*}
\int_{B_{1+h}}f(x)\,dx-\int_{B}f(x)\,dx &=& \int_{B_{1+h}\setminus B}f(x)\,dx\\
&=&\int_0^\infty \int_S \chi_{B_{1+h}\setminus B}(t^E\eta)f(t^E\eta)\,\sigma_P(d\eta)t^{\mu_P-1}\,dt\\
&=&\int_1^{1+h}\int_S f(t^E\eta)\,\sigma_P(d\eta)\,t^{\mu_P-1}\,dt\\
&=&\int_1^{1+h}g(t)t^{\mu_P-1}\,dt
\end{eqnarray*}
where we have written
\begin{equation*}
    g(t)=\int_S f(t^E\eta)\sigma_P(d\eta)
\end{equation*}
and made use of Theorem \ref{thm:BestIntegrationFormula} and the fact that $B_1=B$. Because $f$ is continuous on $N_B(\epsilon)$ and $S$ is compact, it follows by standard facts that $g$ is continuous on its domain $[1,1+h]$ and, in particular, $g$ is continuous at $t=1$. Therefore, an application of the fundamental theorem of calculus gives
\begin{equation*}
    \lim_{h\searrow 0}\frac{1}{h}\left(\int_{B_{1+h}}f(x)\,dx-\int_B f(x)\,dx\right) =\lim_{h\searrow 0}\frac{1}{h}\int_1^{1+h}g(t)t^{\mu_P-1}\,dt=g(1)\cdot 1=\int_S f(\eta)\sigma_P(d\eta).
\end{equation*}
An analogous argument gives the same result for $h\nearrow 0$ and, from this, the desired result follows.
\end{proof}

By applying the proposition above to $\xi\mapsto e^{ix\cdot\xi}$, we immediately obtain the following result.
\begin{corollary}
For all $x\in\mathbb{R}^d$,
\begin{equation*}
    \widehat{\sigma_P}(x)=\frac{d}{dt} \widehat{\chi_{B_t}}(x)\Big\vert_{t=1}.
\end{equation*}
\end{corollary}

\noindent The preceding corollary tells us that our knowledge of the Fourier transform of $\chi_{B_t}$ informs our knowledge of the Fourier transform of the measusre $\Sigma_P$. The follows proposition gives useful information in the reverse direction.
\begin{proposition}
For all $x\in\mathbb{R}^d$,
\begin{equation*}
    \widehat{\chi_B}(x)=\int_0^1 \widehat{\sigma_P}(t^{E^*}x) t^{\mu_P-1}\,dt.
\end{equation*}
\end{proposition}
The proof of the proposition is a straightforward application of Theorem \ref{thm:MainIntegrationFormula} and its proof is omitted.


Our next proposition treats the behavior of the Fourier transform $\widehat{\sigma_P}$ under rigid transformations. To this end, let $P$ be a positive-homogeneous function and let $(S_P,\Sigma_P,\sigma_P)$ be the measure space associated to $P$. Also, let $R:\mathbb{R}^d\to\mathbb{R}^d$ be a rigid transformation, i.e., a transformation of the form
\begin{equation*}
    R(x)=Ox+x_0
\end{equation*}
for $x\in\mathbb{R}^d$ where $O\in\Gl(\mathbb{R}^d)$ is an orthogonal transformation and $x_0$ is a fixed element of $\mathbb{R}^d$.

\begin{proposition}
Let $R : \R^d \to \R^d$ be a rigid transformation defined as above: 
\begin{equation*}
    R(x) = Ox + x_0,
\end{equation*}
\textcolor{red}{then?}
\end{proposition}




%\end{comment}

\textcolor{red}{
\begin{enumerate}
    \item Talk about the theorems on Riemannian manifolds and homogeneous groups which are similar to that above. We need to discuss, in particular, that our result is slightly better.
    \item derive two corollaries. I think the ones I want we had in a much earlier version and, at least one of which parallels Theorem 1 of \cite{Baker1997}.
    \item We then need to discuss the purpose of the article. 1) To give constructive proof (in the spirit of Remark 2 of \cite{Folland2001}) of high expository quality of Theorem \ref{eq:BestIntegrationFormula}. To give a simple application of \ref{eq:BestIntegrationFormula} to the study of convolution powers.
    \item Then describe all we do and in what order. 1) We delve into the theory of positive-homogeneous functions and sub-homogeneous functions. We prove Theorem \ref{thm:BestIntegrationFormula}, by first constructing the measure $\sigma_P$, worrying about its independence on the one-parameter group. Then we study the case in which $P$ (and $S$) is smooth. Then(?) we treat the application to convolution powers?
\end{enumerate}}





\section{Positive-Homogeneous Functions}\label{sec:Homogeneous}

Our setting is $d$-dimensional Euclidean space $\mathbb{R}^d$ with coordinates $(x^1,x^2,\dots,x^d)$ equipped with the inner product $x\cdot y=\sum_{k=1}^d(x^k)(y^k)$ and associated Euclidean norm $|x|=\sqrt{(x^1)^2+(x^2)^2+\cdots+(x^d)^2}$. We will take $\mathbb{R}^d$ to be equipped with its usual topology and (oriented) smooth structure. Given $x\in\mathbb{R}^d$ and $R>0$, the open ball with center $x$ and radius $R$ is denoted by $\mathbb{B}_R(x)$ and its corresponding sphere is denoted by $\mathbb{S}_R(x)$. We write $\mathbb{B}=\mathbb{B}_1(0)$ and $\mathbb{S}=\mathbb{S}_1(0)$ to denote the standard unit ball and unit sphere, respectively, in $\mathbb{R}^d$. We shall denote by $\End(\mathbb{R}^d)$ the collection of linear transformations on $\mathbb{R}^d$ and by $\MdR$ the corresponding set of $d\times d$ real matrices. Also, we shall denote by $\Gl(\mathbb{R}^d)$ the general linear group and by $\GldR$ the corresponding group of $d\times d$ invertible real matrices. For $E\in \End(\mathbb{R}^d)$ (or $E\in\MdR$), $\|E\|$ will denote the so-called operator norm.\\

\noindent Let $\{T_r\}_{r>0}\subseteq \Gl(\mathbb{R}^d)$ be a continuous one-parameter group, i.e., $T$ is a continuous group homomorphism from the multiplicative group of positive real numbers into the general linear group, $\Gl(\mathbb{R}^d)$. It is well-known (c.f., \cite{Randles2017,Engel2000,Engel2005}) that every continuous one-parameter group $\{T_r\}$ has the unique representation
\begin{equation*}
T_r=r^E=\exp((\ln r) E)=\sum_{k=0}^\infty \frac{(\ln r)^k}{k!}E^k
\end{equation*}
for some $E\in\End(\mathbb{R}^d)$. $E$ is called (infinitesimal) generator of $\{T_r\}$ and $\{T_r\}$ is said to be generated by $E$. This, of course, gives a one-to-one correspondence between $\End(\mathbb{R}^d)$ and the collection of continuous one-parameter groups. Some basic results on one-parameter contracting groups are presented in Appendix \ref{subsec:OneParameterGroups}. Also, we encourage the reader to look at the excellent texts \cite{Engel2005} and \cite{Engel2000} on one-parameter (semi) groups.

\begin{definition} A continuous one-parameter group $\{T_r\}$ is said to be \textbf{contracting} if
\begin{equation*}
\lim_{r\to 0}\|T_r\|=0. 
\end{equation*}
\end{definition}

\noindent The notion of a contracting group (or semigroup) is closely related to notion of asymptotic stability of solutions to linear systems \cite{Braun1993}. The following necessary condition will be useful for us when constructing measures on surfaces in $\mathbb{R}^d$.

\begin{proposition}\label{prop:ContractingTrace}
Let $\{T_r\}\subseteq \Gl(\mathbb{R}^d)$ be a continuous one-parameter group with generator $E$. If $\{T_r\}$ is  contracting, then $\tr E>0$. 
\end{proposition}
\begin{proof}
The supposition that $\{T_r\}$ is a contracting group implies that $r^E\to \mathbf{0}$ as $r\to 0$ in the operator-norm topology on $\End(\mathbb{R}^d)$; here $\mathbf{0}$ is zero transformation. Because the determinant is a continuous function from $\End(\mathbb{R}^d)$, equipped with operator-norm topology, into $\mathbb{R}$, we have
\begin{equation*}
0=\det(\mathbf{0})=\det\left(\lim_{r\to 0}r^E\right)=\lim_{r\to 0}\det\left(r^E\right)=\lim_{r\to 0}r^{\tr E}
\end{equation*}
in view of the preceding proposition. Therefore, $\tr E>0$.
\end{proof}

\noindent As we discussed in the introduction, one main goal of this article is to construct measures on certain surfaces in $\mathbb{R}^d$ (analogous to $\mathbb{S}$) with which we can formulate generalizations of \eqref{eq:StandardPolarIntegrationFormula}. As the unit sphere $\mathbb{S}$ can be defined as a level set of the Euclidean norm $|\cdot|$ on $\mathbb{R}^d$, a function which is continuous,  positive-definite\footnote{Given a function $P:\mathbb{R}^d\to\mathbb{R}$, we say that $P$ is positive-definite if $P\geq 0$ and $P(x)=0$ only when $x=0$.}, and homogeneous in the sense that $r|x|=|rx|$ for all $r>0$ and $x\in\mathbb{R}^d$, the surfaces of interest for us are level sets of certain continuous functions which we will call \textit{positive-homogeneous}. The remainder of this section is dedicated to introducing this class of functions.\\

\noindent In what follows, let $P:\mathbb{R}^d\to\mathbb{R}$ be continuous and define
\begin{equation}
S=\{\eta\in\mathbb{R}^d:P(\eta)=1\}
\end{equation}
and
\begin{equation*}
B=\{\eta\in\mathbb{R}^d:P(\eta)<1\}.
\end{equation*}
Given a continuous one-parameter group $\{T_r\}$ with infinitesimal generator $E$, we say that \textit{$P$ is homogeneous with respect to $\{T_r\}$ (and, by an abuse of language, homogeneous with respect to $E$)} if
\begin{equation}\label{eq:Homogeneous}
rP(x)=P(T_rx)=P\left(r^Ex\right)
\end{equation}
for all $x\in\mathbb{R}^d$ and $r>0$. For a given map $P:\mathbb{R}^d\to\mathbb{R}$, the set of all $E$ for which \eqref{eq:Homogeneous} is satisfied is called the \textit{exponent set of $P$} and shall be denoted by $\Exp(P)$. 








\begin{example}\label{exp:non_convex}\normalfont
Consider the polynomials $P_1$ and $P_2$ defined by
\begin{equation*}
P_1(x,y)=x^2+y^4\hspace{1cm}\mbox{and}\hspace{1cm}P_2(x,y)=x^2 + \f{3}{2} xy^2 + y^4
\end{equation*}
for $(x,y)\in\mathbb{R}^2$. It is easy to see that $P_1$ and $P_2$ are both positive definite and homogeneous with respect to the linear transformation $E$ with standard matrix representation $\diag(1/2,1/4)$. Figure \ref{fig:non_convex_SQ} illustrates the graphs and associated level sets $S_{1}$ and $S_{2}$ associated, respectively to $P_1$ and $P_2$. 

\begin{figure}[!htb]
    \centering
    \hspace{10pt}
    \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.45]{non_convex_SP.png}
    \vspace{-10pt}
    \includegraphics[scale=0.45]{non_convex_SP_levelsets.png}
    %\caption{}
    %\label{fig:convex_SP}
    \end{subfigure}%
    \hspace{-20pt}
    \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.45]{non_convex_S.png}
    \vspace{-10pt}
    \includegraphics[scale=0.45]{non_convex_S_levelsets.png}
    %\caption{}
    %\label{fig:non_convex_SQ}
    \end{subfigure}
    \caption{$P_1$ and convex $S_{1}$ (red); $P_2$ and non-convex $S_2$ (red)}
    \label{fig:non_convex_SQ}
\end{figure}
\end{example}











\noindent Given a positive-homogeneous function $P$, let $\Sym(P)$ be the set of $O\in\End(\mathbb{R}^d)$ for which
\begin{equation*}
P(Ox)=P(x)
\end{equation*}
for all $x\in\mathbb{R}^d$. By virtue of the positive-definiteness of $P$, it is easy to see that $\Sym(P)$ is a subgroup of $\Gl(\mathbb{R}^d)$. For this reason, $\Sym(P)$ is said to be the \textit{symmetry group associated to $P$}. 

\begin{proposition}\label{prop:SymCompact}
For each positive-homogeneous function $P$, $\Sym(P)$ is a compact subgroup of $\Gl(\mathbb{R}^d)$. In particular, it is a subgroup of the orthogonal group $O(\mathbb{R}^d)$.
\end{proposition}
\begin{proof}
By virtue of the Heine-Borel theorem (and the fact that $\Gl(\mathbb{R}^d)$ is finite dimensional), we prove that $\Sym(P)$ is closed and bounded. To this end, let $\{O_n\}\subseteq\Sym(P)$ be a sequence converging to $O\in \Gl(\mathbb{R}^d)$. For each $x\in\mathbb{R}^d$, the continuity of $P$ guarantees that
\begin{equation*}
P(Ox)=P\left(\lim_{n\to\infty}O_nx\right)=\lim_{n\to\infty}P(O_nx)=\lim_{n\to\infty}P(x)=P(x).
\end{equation*}
Hence, $O\in\Sym(P)$ and so $\Sym(P)$ is closed.

We assume, to reach a contradiction, that $\Sym(P)$ is not bounded. In this case, there is a sequence $\{\eta_n\}\subseteq \mathbb{S}$ for which $\lim_{n\to\infty}|O_n\eta_n|=\infty$. Given that $\mathbb{S}$ is compact, by passing to a subsequence if needed, we may assume without loss in generality that $\lim_{n\to\infty}\eta_n=\eta\in\mathbb{S}$. By virtue of Proposition \ref{prop:PositiveHomogeneousCharacterization} and the continuity of $P$,
\begin{equation*}
P(\eta)=\lim_{n\to\infty}P(\eta_n)=\lim_{n\to\infty}P(O_n\eta_n)=\infty
\end{equation*}
which is impossible. Hence $\Sym(P)$ is bounded.
\end{proof}

\begin{corollary}\label{cor:TraceisInvariant}
Let $P$ be a positive-homogeneous function, then
\begin{equation*}
\tr E=\tr E'>0
\end{equation*}
for all $E,E'\in\Exp(P)$.
\end{corollary}
\begin{proof}
By virtue of Propositions \ref{prop:ContractingTrace} and \ref{prop:PositiveHomogeneousCharacterization}, $\tr E>0$ for all $E\in\Exp(P)$. It remains to show that the trace map is constant on $\Exp(P)$. To this end, let $E,E'\in\Exp(P)$. Then, for all $r>0$ and $x\in\mathbb{R}^d$,
\begin{equation*}
P(x)=r(1/r)P(x)=rP((1/r)^{E'}x)=P(r^E(1/r)^{E'}x)=P(r^{E}r^{-E'}x).
\end{equation*}
Thus $O_r=r^{E}r^{-E'}\in\Sym(P)$ for each $r>0$. In view of the Propositions \ref{prop:ContinuousGroupProperties} and \ref{prop:SymCompact} and the homomorphism property of the determinant,
\begin{equation*}
1=\det(O_r)=\det(r^{E}r^{E'})=\det(r^{E})\det(r^{-E'})=r^{\tr E}r^{\tr E}=r^{\tr E-\tr E'}
\end{equation*}
for all $r>0$ and therefore $\tr E=\tr E'$.
\end{proof}

\noindent In view of the preceding corollary, to each positive-homogeneous function $P$, we define the \textit{homogeneous order of $P$} to be the unique positive number $\mu_P$ for which
\begin{equation*}
\mu_P=\tr E
\end{equation*}
for all $E\in\Exp(P)$. 

\begin{example}\normalfont The homogeneous orders of the positive-homogeneous functions in Examples \ref{exp:EuclideanNorm}, \ref{exp:non_convex}, \ref{exp:Polynomial}, and \ref{exp:Weierstrass} are given as follows. \ref{exp:EuclideanNorm}: $\mu_{|\cdot|^{\alpha}}=d/\alpha$ for each $\alpha>0$. \ref{exp:non_convex}: $\mu_{P_1}=\mu_{P_2}=3/4$. \ref{exp:Polynomial}: $\mu_P=(2m_1)^{-1}+(2m_2)^{-1}+\cdots+(2m_d)^{-1}$. \ref{exp:Weierstrass}: $\mu_P=\mu_Q$.
\end{example}








%\section{A surface measure on $S$ and a generalized polar integration formula}\label{sec:IntegrationFormula}

\textcolor{red}{This section} is dedicated to constructing a surface measure on the compact level set $S$ associated to a positive-homogeneous function and using it to generalize the polar integration formula \eqref{eq:StandardPolarIntegrationFormula}. To introduce our main theorem, let $P$ be a positive-homogeneous function with homogeneous order $\mu_P>0$, exponent set $\Exp(P)$ and symmetry group $\Sym(P)$. We shall denote by $\mathcal{M}_d$ the Lebesgue $\sigma$-algebra on $\mathbb{R}^d\setminus\{0\}$ and by $m$ the Lebesgue measure.  Also, let the compact set $S=S_P=\{\eta\in\mathbb{R}^d:P(\eta)=1\}$ in $\mathbb{R}^d$ be equipped with its relative topology and denote by $\mathcal{B}(S)$ the Borel $\sigma$-algebra on $S$. We denote by $\mathcal{L}=\mathcal{L}(0,1)$ the $\sigma$-algebra of Lebesgue measureable sets on $(0,\infty)$ and let $\lambda_P$ be the $\sigma$-finite measure on $((0,\infty),\mathcal{L})$ with $\lambda_P(dr)=r^{\mu_P-1}\,dr$. Our main theorem is as follows\footnote{We refer the reader to Section 3.6 and 9.2 of \cite{Bogachev2007} which provides some basic context and vocabulary.}. 

\textcolor{red}{\noindent Throughout this section, $P$ denotes a fixed positive-homogeneous function on $\mathbb{R}^d$ with homogeneous order $\mu_P>0$ and exponent set $\Exp(P)$. We will take $S=S_P=\{\eta\in\mathbb{R}^d:P(\eta)=1\}$ to be equipped with the relative topology inherited from $\mathbb{R}^d$ and, given $(0,\infty)$ with its usual topology, we take $(0,\infty)\times S$ to be equipped with the product topology. }


\begin{theorem}\label{thm:BestIntegrationFormula}
There exists a $\sigma$-algebra $\Sigma$ on $S$ containing $\mathcal{B}(S)$ and a finite Radon measure $\sigma_P$ on $(S,\Sigma)$ which satisfies the following properties:
\begin{enumerate}
\item\label{property:Completion} $(S,\Sigma,\sigma_P)$ is the completion of $(S,\mathcal{B}(S),\sigma_P)$. In particular, $(S,\Sigma,\sigma_P)$ is a complete measure space.
\item\label{property:Invariance} For any $F\in\Sigma$ and $O\in\Sym(P)$, $\sigma(OF)=\sigma(F)$.
\item\label{property:DefiningConditionofsigma} For any $F\in\Sigma$ and $E\in\Exp(P)$, 
\begin{equation*}
\widetilde{F_E}:=\bigcup_{0<r<1}\left(r^E F\right)=\left\{r^E\eta\in\mathbb{R}^d\setminus\{0\}:0<r<1,\eta\in F\right\}
\end{equation*}
is a Lebesgue measurable subset of $\mathbb{R}^d\setminus \{0\}$, i.e., $\widetilde{F_E}\in\mathcal{M}_d$, and
\begin{equation*}
\sigma_P(F)=\mu_P\cdot m\left(\widetilde{F_E}\right)
\end{equation*}
where $m$ denotes the Lebesgue measure on $\mathbb{R}^d$.
\end{enumerate}
Further, denote by $\left((0,\infty)\times S,(\mathcal{L}\times\Sigma)',\lambda_P\times\sigma_P\right)$ the completion of the product measure space $((0,\infty)\times S,\mathcal{L}\times\Sigma,\lambda_P\times\sigma_P)$. We have
\begin{enumerate}
\item\label{property:BestPointIsomorphism} Given any $E\in \Exp(P)$, the map $\psi_E:(0,\infty)\times S\to\mathbb{R}^d\setminus\{0\}$, defined by $\psi_E(r,\eta)=r^E\eta$ for $r>0$ and $\eta\in S$, is a point isomorphism of the measure spaces $\left((0,\infty)\times S,(\mathcal{L}\times\Sigma)',\lambda_P\times\sigma_P\right)$ and $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d,m)$. That is
\begin{equation*}
\mathcal{M}_d=\left\{A\subseteq \mathbb{R}^d\setminus\{0\}:\psi_E^{-1}(A)\in (\mathcal{L}\times\Sigma)'\right\}
\end{equation*}
and, for each $A\in\mathcal{M}_d$,
\begin{equation*}
m(A)=(\lambda_P\times\sigma_P)(\psi_E^{-1}(A)).
\end{equation*}
\item\label{property:BestIntegrationFormula} Given any Lebesgue measurable function $f:\mathbb{R}^d\to\mathbb{C}$ and $E\in \Exp(P)$, $f\circ \psi_E$ is $(\mathcal{L}\times\Sigma)'$-measurable and the following statements hold:
\begin{enumerate}
\item If $f\geq 0$, then
\begin{equation}\label{eq:BestIntegrationFormula}
\int_{\mathbb{R}^d}f(x)\,dx=\int_0^\infty\left(\int_S f(r^E\eta)\,\sigma_P(d\eta)\right)r^{\mu_P-1}\,dr=\int_S\left(\int_0^\infty f(r^E\eta)r^{\mu_P-1}\,dr\right)\sigma_P(d\eta).
\end{equation}
\item When $f$ is complex-valued, we have 
\begin{equation*}f\in L^1(\mathbb{R}^d)\hspace{.5cm}\mbox{ if and only if}\hspace{.5cm}f\circ\psi_E\in L^1\left((0,\infty)\times S,(\mathcal{L}\times\Sigma)',\lambda_P\times\sigma_P\right)
\end{equation*} 
and, in this case, \eqref{eq:BestIntegrationFormula} holds.
\end{enumerate}
\end{enumerate}
\end{theorem}
\noindent As \eqref{eq:StandardPolarIntegrationFormula} finds utility in the harmonic analysis of radial functions, i.e., those functions of the form $f(x)=f_0(|x|)$, Theorem \ref{thm:BestIntegrationFormula} will aid the analysis of functions of the form $f(x)=f_0(P(x))$. In fact, this is a primary motivation for our work. \textcolor{red}{(More needed)}\\

\noindent Our construction proceeds as follows. In Subsection \ref{subsec:ConstructionofSigma}, we fix $E\in\Exp(P)$ and consider the one-parameter contracting group $\{r^E\}$. As the standard isotropic one-parameter group $r\mapsto rI=r^I$ is well-fitted to the unit sphere $\mathbb{S}$ and allows every non-zero $x\in\mathbb{R}^d$ to be written uniquely as $x=r\eta$ for $r\in (0,\infty)$ and $\eta\in \mathbb{S}$, $\{r^E\}$ is well-fitted to $S$ and has the property that every non-zero $x\in\mathbb{R}^d$ can be written uniquely as $x=r^E\eta$ where $r\in(0,\infty)$ and $\eta\in S$. With this one-parameter group as a tool, we define a \textit{surface-carried}\footnote{\textcolor{red}{We really need to see if this is standard vocabulary}} measure $\sigma_{P,E}$ on $S$ by taking sufficiently nice sets $F\subseteq S$, stretching them into a quasi-conical region of the associated ``ball" $B$ with the contracting group $\{r^E\}$, and computing the Lebesgue measure of the result. Figure \ref{fig:level_set_F} illustrates the action of $r^E$ for $r\in (0,1)$ on a set $F$ (red) in $S$ (blue) to create the set $\widetilde{F}$. Here, we choose $P(x,y) = x^2 + 3xy^2/2 + y^4$ and $E= \diag(1/2, 1/4)$. Figure \ref{fig:level_set_F_3D} illustrates a different example with $P(x,y,z) = x^2 + xy^2 + y^4 + z^4$.

\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.7, trim={1cm 1cm 1cm 0.5cm},clip]{level_set_F.eps}
    \caption{$S$ (blue) is the compact unital level set of the positive homogeneous polynomial $P(x,y) = x^2 + 3xy^2/2 + y^4$ with $E = \diag(1/2,1/4)\in \Exp(P)$. We choose a set $F\subseteq S$ (red) and construct the set $\widetilde{F}$ by letting $\widetilde{F} = \bigcup_{0<r<1} r^E F $. }
    \label{fig:level_set_F}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.7, trim={1cm 3cm 1cm 2cm},clip]{level_set_F_3D.eps}
    \caption{$S$ (blue) is the compact unital level set of the positive homogeneous polynomial $P(x,y,z) = x^2 + xy^2 + y^4 + z^4$ with $E = \diag(1/2,1/4,1/4)\in \Exp(P)$. We choose a set $F\subseteq S$ (red) and construct the set $\widetilde{F}$ by letting $\widetilde{F} = \bigcup_{0<r<1} r^E F $. }
    \label{fig:level_set_F_3D}
\end{figure}


In Subsection \ref{subsec:ProductMeasure}, we turn our focus to an associated product measure $\lambda_P\times\sigma_{P,E}$ on $(0,\infty)\times S$ with which we are able to formulate and prove a generalization of \eqref{eq:StandardPolarIntegrationFormula}; this is Theorem \ref{thm:MainIntegrationFormula}. We then derive a number of corollaries of Theorem \ref{thm:MainIntegrationFormula}, including the result that $\sigma_{P,E}$ is a Radon measure on $S$. As everything done in Subsections \ref{subsec:ConstructionofSigma} and \ref{subsec:ProductMeasure} is done using the contracting group $\{r^E\}$ for a chosen $E\in\Exp(P)$, it isn't clear, \textit{a priori}, exactly how $\sigma_{P,E}$ is dependent on the choice of $E\in\Exp(P)$, if at all. In Subsection \ref{subsec:IndependentofE}, we prove that $\sigma_{P,E}$ is, in fact, independent of the choice of $E\in \Exp(P)$ (and so we write $\sigma_P=\sigma_{P,E}$ and this quickly yields a stronger version of Theorem \ref{thm:MainIntegrationFormula}; this is Theorem \ref{thm:BestIntegrationFormula} (\textcolor{red}{We have to make sure this is referring to the right thing and makes sense}). All throughout this section, our construction uses only tools from point-set topology and measure theory.  In Section \ref{sec:SigmaForSmoothP}, we study the special case in which a positive-homogeneous function $P$ is additionally smooth. In that case, we will find that $S$ is a smooth compact embedded hypersurface of $\mathbb{R}^d$ and the measure $\sigma$ is closely related to the Riemannian volume on $S$; see Theorem \ref{thm:RiemannLebesgue}.\\


Before we move to construct $\sigma_P$, we address a useful corollary \textcolor{red}{(Need to quote John A. Baker's paper that, essentially, says that the above formula actually defines $\sigma_S$.)} 
\begin{corollary}\label{cor:IntegrateOnS}
Given $g:S\to\mathbb{C}$ and $E\in\Exp(P)$, define $f:\mathbb{R}^d\setminus \{0\}\to\mathbb{C}$ by
\begin{equation*}
f(x)=\mu_P\cdot \chi_{(0,1)}(P(x))g(P(x)^{-E}x)
\end{equation*}
for $x\in\mathbb{R}^d\setminus\{0\}$ where $\chi_{(0,1)}(\cdot)$ is the indicator function of the interval $(0,1)$. If $g\in L^1(S,\Sigma_P,\sigma_p)$, then $f\in L^1(\mathbb{R}^d\setminus\{0\})$, and 
\begin{equation*}
    \int_{\mathbb{R}^d}f(x)\,dx=\int_Sg(\eta)\sigma_P(d\eta).
\end{equation*}
\end{corollary}
\begin{proof}
Observe that, for the $(\mathcal{L}\times\Sigma_P)'$-measurable function $k(r,\eta)=\chi_{(0,1)}(r)g(\eta)$,
\begin{equation*}
    k\circ\psi_E^{-1}(x)=k(P(x),P(x)^{-E}x)=f(x)
\end{equation*}
for $x\in\mathbb{R}^d\setminus \{0\}$. By virtue of Theorem \ref{thm:BestIntegrationFormula}, it follows that $f$ is $\mathcal{M}_d$ measurable and 
\begin{eqnarray*}
   \int_{\mathbb{R}^d}|f(x)|\,dx&=&\int_{S}\left(\int_{(0,\infty)}|k(r,\eta)|r^{\mu_P-1}\,dr\right)\sigma_P(d\eta)\\
    &=&\left(\int_S|g(\eta)|\sigma_P(d\eta)\right)\left(\int_0^1 \mu_Pr^{\mu_P-1}\,dr\right)=\|g\|_{L^1(\sigma_P)}<\infty.
\end{eqnarray*}
Therefore, by an analogous computation (for $f$ instead of $|f|$), we have
\begin{equation*}
    \int_{\mathbb{R}^d}f(x)\,dx=\int_S g(\eta)\sigma_P(d\eta),
\end{equation*}
by virtue of Property \ref{property:BestIntegrationFormula} of Theorem \ref{thm:BestIntegrationFormula}. 
\end{proof}



\section{An application: Estimates for convolution powers}\label{sec:ConvolutionPowers}

We denote by $\mathcal{S}_d$ the subspace of $\ell^1(\mathbb{Z}^d)$ consisting of those $\phi:\mathbb{Z}^d\to\mathbb{C}$ for which
\begin{equation*}
    \|x^\beta \phi(x)\|_1=\sum_{x\in\mathbb{Z}^d}\abs{x^\beta\phi(x)}=\sum_{x\in\mathbb{Z}^d}\abs{(x^1)^{\beta_1}(x^2)^{\beta_2}\cdots(x^d)^{\beta_d}\phi(x^1,x^2,\dots,x^d)}<\infty
\end{equation*}
for each multi-index $\beta=(\beta_1,\beta_2,\dots,\beta_d)\in\mathbb{N}^d$; we remark that $\mathcal{S}_d$ contains all finitely supported complex-valued functions on $\mathbb{Z}^d$. It is straightforward to see that $\widehat{\phi}(\xi)\in C^\infty(\mathbb{R}^d)$ whenever $\phi\in \mathcal{S}_d$. As discussed in \cite{Thomee1965,DSC2014,Randles2015,Randles2017}, the asymptotic behavior of the iterative convolution powers $\phi^{(n)}$ of $\phi\in\mathcal{S}_d$ is characterized by the local behavior of $\widehat{\phi}$ near points at which $\widehat{\phi}$ is maximized in absolute value. For simplicity of our analysis, we shall focus on those $\phi\in\mathcal{S}_d$ which have been suitably normalized so that $\sup_{\xi}|\widehat{\phi}(\xi)|=1$ and, in this case, we define
\begin{equation*}
    \Omega(\phi)=\left\{\xi\in \mathbb{T}^d:\abs{\widehat{\phi}(\xi)}=1\right\}.
\end{equation*}
For each $\xi_0\in \Omega(\phi)$, consider $\Gamma_{\xi_0}:\mathcal{U}\to\mathbb{C}$ defined by
\begin{equation*}\Gamma_{\xi_0}(\xi)=\log\left(\frac{\widehat{\phi}(\xi+\xi_0)}{\widehat{\phi}(\xi_0)}\right)
\end{equation*}
for $\xi\in \mathcal{U}$ where $\mathcal{U}$ is a convex open neighborhood of $0$ which is small enough to ensure that $z\mapsto\log(z)$, the principal branch of logarithm, is defined and continuous on $\{\widehat{\phi}(\xi+\xi_0)/\widehat{\phi}(\xi_0):\xi\in\mathcal{U}\}$. Because $\widehat{\phi}$ is smooth, $\Gamma_{\xi_0}\in C^{\infty}(\mathcal{U})$ and so we can use Taylor's theorem to approximate $\Gamma_{\xi_0}$ near $0$. More precisely, we can write
\begin{equation}\label{eq:GammaExpansion}
    \Gamma_{\xi_0}(\xi)=i\alpha_{\xi_0}\cdot\xi -i\left(Q_{\xi_0}(\xi)+\widetilde{Q}_{\xi_0}(\xi)\right)-\left(R_{\xi_0}(\xi)+\widetilde{R}_{\xi_0}(\xi)\right)
\end{equation}
where $\alpha_{\xi_0}\in\mathbb{R}^d$, $Q_{\xi_0}$ and $R_{\xi_0}$ are real-valued polynomials which vanish at $0$ and contain no linear terms, and $\widetilde{Q}_{\xi_0}$ and $\widetilde{R}_{\xi_0}$ are real-valued once continuously differentiable functions on $\mathcal{U}$ which vanish at $0$. The assumptions that this expansion contains no real linear part and all constituent functions vanish at $0$ are seen necessary because $\xi_0$ is a local maximum for $|\widehat{\phi}|$ and $\Gamma_{\xi_0}(0)=0$. The vector $\alpha_{\xi_0}\in\mathbb{R}^d$ is said to be the \textbf{drift}\footnote{In the case that $\phi$ defines a probability measure and a $\mathbb{Z}^d$-valued random vector $X$ has this measure as its distribution, then $\alpha_{\xi_0}$ is $X$'s mean. For a precise statement and details, see Proposition 7.4 of \cite{Randles2017}.} associated to $\xi_0$. Motivated by Thom\'{e}e \cite{Thomee1965}, we introduce the following definition. 


\textcolor{red}{\subsection{Subhomogeneous functions}\label{subsec:SubhomogeneousFunctions}
In this subsection, we introduce the notions of subhomogeneous functions and strongly subhomogeneous functions with respect to a given endomorphism $E\in\End(\mathbb{R}^d)$. When studying convolutions powers of a general complex-valued function $\phi$ on $\mathbb{Z}^d$, along with positive homogeneous polynomials, such functions are commonly seen in Taylor expansions of the Fourier transform of $\widehat{\phi}$. Though the content of this subsection naturally follows the preceding treatment of positive-homogeneous  functions, we shall not make use of this material until Section \ref{sec:ConvolutionPowers}. The reader should feel free to delay reading this subsection until \textcolor{red}{he/she/they} is ready to read Section \ref{sec:ConvolutionPowers}.
\begin{definition}\label{def:homogeneous_types}
Let $Q$ be a complex-valued function defined on an open neighborhood of $0$ in $\mathbb{R}^d$ and let $E\in\End(\mathbb{R}^d)$ be such that $\{r^E\}$ is a contracting group.
\begin{enumerate}
\item We say that $Q$ is \textbf{subhomogeneous} with respect to $E$ if, for each $\epsilon>0$ and compact set $K$, there is a $\delta>0$ for which
\begin{equation*}
\abs{Q(r^E\xi)}\leq \epsilon r
\end{equation*}
for all $0<r<\delta$ and $\xi\in K$.
\item In the case that $Q$ is differentiable on its domain, we say that $Q$ is \textbf{strongly subhomogeneous} with respect to $E$ if, for each $\epsilon>0$ and compact set $K$, there is a $\delta>0$ for which
\begin{equation*}
\abs{\partial_r Q(r^E\xi)}\leq \epsilon
\end{equation*}
for all $0<r<\delta$ and $\xi\in K$.
\end{enumerate}
\end{definition}}
\begin{definition}\label{def:Types}
Let $\phi\in\mathcal{S}_d$ with $\sup_{\xi}|\widehat{\phi}(\xi)|=1$ and, given $\xi_0\in\Omega(\phi)$, consider the expansion \eqref{eq:GammaExpansion} above.
\begin{enumerate}
    \item We say that $\xi_0$ is of \textbf{positive-homogeneous type} for $\widehat{\phi}$ if $R_{\xi_0}$ is positive-homogeneous and, there exists $E\in \Exp(R_{\xi_0})$ for which $Q_{\xi_0}$ is homogeneous with respect to $E$ and both $\widetilde{R}_{\xi_0}$ and $\widetilde{Q}_{\xi_0}$ are subhomogeneous with respect to $E$. In this case, we will write  $\mu_{\xi_0}=\mu_{R_{\xi_0}}$.
\item We say that $\xi_0$ is of \textbf{imaginary-homogeneous type} for $\widehat{\phi}$ if $|Q_{\xi_0}|$ and $R_{\xi_0}$ are both positive homogeneous and, there exists $E\in\Exp(|Q_{\xi_0}|)$ and $k>1$ for which $R_{\xi_0}$ is homogeneous with respect to $E/k$ and $\widetilde{Q}_{\xi_0}$ and $\widetilde{R}_{\xi_0}$ are strongly subhomogeneous with respect to $E$ and $E/k$, respectively. In this case, we write $\mu_{\xi_0}=\mu_{|Q_{\xi_0}|}$.
\end{enumerate}
In either case, $\mu_{\xi_0}$ is said to be the homogeneous order associated to $\xi_0$.
\end{definition}


\noindent In his study of approximation schemes to solutions of parabolic partial differential equations, V. Thom\'{e}e introduced the notions of points of type $\gamma$ and $\beta$, arising in local approximations of the Fourier transforms of (schemes) $\phi:\mathbb{Z}\to\mathbb{C}$, to dichotomize the stability of approximation schemes in the $\ell^\infty$ norm\cite{Thomee1965}. Thom\'{e}e's definition provided a key insight which led to the characterization of the asymptotic behavior of convolution powers of finitely supported functions on $\mathbb{Z}$ (both in terms of local/pointwise limits and $\ell^\infty$ asymptotics) resolving the long-outstanding de Forest's problem \cite{Randles2015}. The points of positive-homogeneous type and imaginary-homogeneous type in the definition above parallel (and generalize) Thom\'{e}e's points of type $\gamma$ and $\beta$ (and points of type 1 and type 2 of \cite{Randles2015}), respectively.\\

\noindent In Definition 1.3 of \cite{Randles2017}, a point $\xi_0\in\Omega(\phi)$ is said to be of positive-homogeneous type for $\widehat{\phi}$ provided that the expansion for $\Gamma_{\xi_0}$ is of the form
\begin{equation}\label{eq:GammaInTermsofP}
    \Gamma_{\xi_0}(\xi)=i\alpha_{\xi_0}\cdot\xi-P_{\xi_0}(\xi)+\widetilde{P}_{\xi_0}(\xi)
\end{equation}
for $\xi\in\mathcal{U}$ where $P_{\xi_0}$ is a positive-homogeneous polynomial in the sense of Example \ref{exp:Polynomial} and $\widetilde{P}_{\xi_0}(\xi)=o(R_{\xi_0}(\xi))$ as $\xi\to 0$ where $R_{\xi_0}=\Re P_{\xi_0}$. To put this into context with our definition above, let's write $P_{\xi_0}(\xi)=R_{\xi_0}(\xi)+iQ_{\xi_0}(\xi)$ and $\widetilde{P}_{\xi_0}(\xi)=\widetilde{R}_{\xi_0}(\xi)+i\widetilde{Q}_{\xi_0}(\xi)$ in which case \eqref{eq:GammaExpansion} coincides with \eqref{eq:GammaInTermsofP}. If $\xi_0$ is of positive-homogeneous type for $\widehat{\phi}$ in the sense of the definition above, it follows that $P_{\xi_0}$ is a complex-valued polynomial which is homogeneous with respect to $E$ (and so $\Exp(P_{\xi_0})$ contains $E\in\End(\mathbb{R}^d)$ for which $\{r^E\}$ is contracting) and $R_{\xi_0}=\Re P_{\xi_0}$ is positive definite. In view of Remark \ref{rmk:PositiveHomogeneousPolynomialsVSFunctions}, this is consistent (and perhaps generalizes) the assumption in which $P_{\xi_0}$ is a positive-homogeneous polynomial. Further, the assumption that $\widetilde{Q}_{\xi_0}$ and $\widetilde{R}_{\xi_0}$ are subhomogeneous with respect to $E$ guarantees that $\widetilde{P}_{\xi_0}(\xi)=o(R_{\xi_0}(\xi))$ as $\xi\to 0$ by virtue of Proposition \ref{prop:Subhomequivtolittleoh}. With these two observations, we see that our definition, which is stated in terms of subhomogeneity, is consistent with that of \cite{Randles2017}. \\


\noindent The essential difference between the cases in Definition \ref{def:Types} 
concerns the nature of the dominant (at low order) term in the expansion. When $\xi_0$ is of positive-homogeneous type for $\widehat{\phi}$, the dominant term $P_{\xi_0}$ contains the real-valued positive-definite polynomial $R_{\xi_0}$. In this case, local limit theorems for $\phi^{(n)}(x)$ contains attractors/approximants of the form
\begin{equation*}
    H^n_{P_{\xi_0}}(x)=\frac{1}{(2\pi)^d}\int_{\mathbb{R}^d}e^{-nP_{\xi_0}(\xi)-ix\cdot\xi}\,d\xi
\end{equation*}
which can be seen, for example, in Theorem 1.5 \cite{Randles2017}. These are necessarily Schwartz functions and appear as fundamental solutions to higher-order parabolic partial differential equations. When $\xi_0$ is of imaginary-homogeneous type for $\widehat{\phi}$, the dominant term in the expansion is the purely imaginary polynomial $iQ_{\xi_0}(\xi)$ and its existence (without a real counterpart) profoundly affects the asymptotic behavior of $\phi^{(n)}(x)$. In fact, as will be shown in a forthcoming article, local limit theorems for $\phi^{(n)}(x)$ will contain approximants/attractors which are (formally) given by the oscillatory integral
\begin{equation*}
    H_{iQ_{\xi_0}}^{n}(x)=\frac{1}{(2\pi)^d}\int_{\mathbb{R}^d}e^{-inQ_{\xi_0}(\xi)-ix\cdot \xi}\,d\xi
\end{equation*}
whose convergence is a delicate matter.  \\






\noindent Our theorem will be stated under the assumption that, for $\phi\in\mathcal{S}_d$ with $\sup_\xi|\widehat{\phi}(\xi)|=1$, each $\xi_0\in\Omega(\phi)$ is either of positive-homogeneous type or of imaginary-homogeneous type for $\widehat{\phi}$. In both cases, the positive definiteness of $R_{\xi_0}$ guarantee that each $\xi_0\in\Omega(\phi)$ is an isolated point of $\mathbb{T}^d$. Consequently, if each $\xi_0\in\Omega(\phi)$ is of positive homogeneous or imaginary homogeneous type for $\widehat{\phi}$, the set $\Omega(\phi)$ is finite and we set
\begin{equation*}
    \mu_{\phi}=\min_{\xi\in\Omega(\phi)}\mu_{P_\xi}.
\end{equation*}

\begin{theorem}\label{thm:ConvolutionPowerEstimate}
Let $\phi\in\mathcal{S}_d$ be such that $\sup |\widehat{\phi}|=1$ and suppose that each $\xi_0\in\Omega(\phi)$ is of positive homogeneous or imaginary homogeneous type for $\widehat{\phi}$. If $\alpha_{\xi_0}=0$ for each $\xi_0\in\Omega(\phi)$ which is of imaginary-homogeneous type for $\widehat{\phi}$ and $\mu_{\phi}\leq 1$, then, for any compact set $K$, 
\begin{equation*}
    \left|\phi^{(n)}(x)\right|\leq\frac{C_K}{n^{\mu_\phi}}
\end{equation*}
for all $x\in K$ and $n\in\mathbb{N}_+$.
\end{theorem}
\noindent Our proof will make use of the Fourier inversion formula
\begin{equation}\label{eq:FourierInversionConvolutionPower}
\phi^{(n)}(x)=\frac{1}{(2\pi)^d}\int_{\mathbb{T}_\phi^d}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi
\end{equation}
which is valid for all $n\in\mathbb{N}_+$ and $x\in\mathbb{R}^d$; here $\mathbb{T}_\phi^d=\mathbb{T}^d+\xi_\phi\subseteq\mathbb{R}^d$
is a representation of the $d$-dimensional torus chosen so that $\Omega(\phi)\subseteq \Interior(\mathbb{T}_{\phi}^d)$; this can always be arranged, i.e., some $\xi_\phi\in\mathbb{R}^d$ can be selected, because $\Omega(\phi)$ is a finite set (See Remark 3 of \cite{Randles2017}).


As discussed in \cite{Randles2017}, the asymptotic behavior of $\phi^{(n)}$ is characterized by the contributions to the above integral produced by integration over neighborhoods of points $\xi_0\in\Omega(\phi).$ Specifically, we shall study integrals of the form
\begin{equation}\label{eq:LocalizedFourierInversionConvolutionPower}
\frac{1}{(2\pi)^d}\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi
\end{equation}
where $\mathcal{O}_{\xi_0}$ is some (small and to be determined) neighborhood of $\xi_0\in\Omega(\phi)$. When $\xi_0$ is of positive-homogeneous type for $\widehat{\phi}$, such integrals are very well behaved (the integrand is dominated uniformly by $e^{-nR_{\xi_0}(\xi)/2}$, a member of the Schwartz class). When $\xi_0$ is of imaginary-homogeneous type, such integrals are oscillatory in nature and therefore much more difficult to handle. Our first lemma below handles the ``easy" case in which $\xi_0$ is of positive-homogeneous type for $\widehat{\phi}$. This lemma appears, essentially, as Lemma 4.3 of \cite{Randles2017}. For illustrative purposes, we have decided to present a distinct proof here which makes use of the polar coordinate integration formula in Theorem \ref{thm:BestIntegrationFormula}. 
\begin{lemma}\label{lem:EstPosHom}
Let $\xi_0\in\Omega(\phi)$ be of positive-homogeneous type for $\widehat{\phi}$ with homogeneous order $\mu_{\xi_0}$. Then, there exists an open neighborhood $\mathcal{O}_{\xi_0}\subseteq\Interior(\mathbb{T}^d_\phi)$ of $\xi_0$, which can be taken as small as desired, and a constant $C=C_{\xi_0}$ for which
\begin{equation*}
    \left|\frac{1}{(2\pi)^d}\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi\right|\leq 
    C_{\xi_0} n^{-\mu_{\xi_0}}
\end{equation*}
for all $n\in\mathbb{N}_+$ and $x\in\mathbb{R}^d$.
\end{lemma}

\begin{proof}
For simplicity, we write $R=R_{\xi_0}$, $\widetilde{R}=\widetilde{R}_{\xi_0}$ and $\mu=\mu_{\xi_0}$. Given that $\xi_0$ is of positive-homogeneous type for $\widehat{\phi}$, there is an open neighborhood $\mathcal{U}$ of $0$ for which
\begin{equation*}
    \left|\widehat{\phi}(\xi+\xi_0)\right|=\left|\widehat{\phi}(\xi_0)e^{\Gamma_{\xi_0}(\xi)}\right|=e^{-\left(R(\xi)+\widetilde{R}(\xi)\right)}
\end{equation*}
for $\xi\in \mathcal{U}$. Using the fact that $\widetilde{R}(\xi)=o(R(\xi))$ as $\xi\to 0$ in view of Proposition \ref{prop:Subhomequivtolittleoh}, we can further restrict $\mathcal{U}$ so that
\begin{equation*}
    \left|\widehat{\phi}(\xi+\xi_0)\right|\leq e^{-R(\xi)/2}
\end{equation*}
for all $\xi\in\mathcal{U}$. Take $E\in\Exp(R)$ and let $\sigma_R$ be the surface measure on  $S=\{\eta\in\mathbb{R}^d:R(\eta)=1\}$ guaranteed by Theorem \ref{thm:BestIntegrationFormula}. We fix an open neighborhood $\mathcal{O}_{\xi_0}$ of $\xi_0$ which is as small as desired and has the property that
\begin{equation*}
    \mathcal{O}:=\mathcal{O}_{\xi_0}-\xi_0\subseteq\mathcal{U}.
\end{equation*}
With this, we observe that
\begin{equation}\label{eq:WlogCenterAtZero}
\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi=\int_{\mathcal{O}}\widehat{\phi}^n(\xi+\xi_0)e^{-ix\cdot(\xi+\xi_0)}\,d\xi
\end{equation}
and therefore
\begin{eqnarray*}
    \left|\frac{1}{(2\pi)^d}\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi\right|&\leq& \frac{1}{(2\pi)^d}\int_{\mathcal{O}}\left|\widehat{\phi}^n(\xi+\xi_0)e^{-i x\cdot(\xi+\xi_0)}\right|\,d\xi\\
    &\leq& \frac{1}{(2\pi)^d}\int_{\mathcal{U}}e^{-nR(\xi)/2}\,d\xi\\
    &\leq&\frac{1}{(2\pi)^d}\int_{\mathbb{R}^d} e^{-(n/2)R(\xi)}\,d\xi
\end{eqnarray*}
for all $x\in\mathbb{R}^d$ and $n\in\mathbb{N}_+$. By virtue of Theorem \ref{thm:BestIntegrationFormula}, we have
\begin{equation*}
\int_{\mathbb{R}^d}e^{-(n/2)R(\xi)}\,d\xi=\int_S \int_0^\infty e^{-(n/2)r}r^{\mu-1}\,dr\,d\sigma_R(\eta)=\int_S \frac{2^\mu\Gamma(\mu)}{n^{\mu}}\,d\sigma_R(\eta)=2^\mu\Gamma(\mu)\sigma_R(S)n^{-\mu}
\end{equation*}
where $\Gamma$ denotes the Gamma function. Consequently,
\begin{equation*}
    \left|\frac{1}{(2\pi)^d}\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi\right|\leq C n^{-\mu}
\end{equation*}
for all $x\in\mathbb{R}^d$ and $n\in\mathbb{N}_+$ where $C=2^\mu \Gamma(\mu)\sigma_R(S)/(2\pi)^d.$
\end{proof}
\noindent We shall now focus on the case in which $\xi_0\in\Omega(\phi)$ is of imaginary-homogeneous type for $\widehat{\phi}$. As discussed above,  \eqref{eq:LocalizedFourierInversionConvolutionPower} is oscillatory in nature; this is due to the fact that the ``principal" behavior of $\Gamma_{\xi_0}(\xi)$, for small $\xi$, is characterized by the purely imaginary polynomial $iQ_{\xi_0}$. Our main estimate is presented in Lemma \ref{lem:EstImagHom} and its proof makes use of \eqref{eq:BestIntegrationFormula} and the following version of the Van der Corput lemma.

\begin{proposition}\label{prop:VanderCorput}
Let $f,g\in C^1([a,b])$ with $f$ real-valued and such that $f'(x)\neq 0$ for all $x\in [a,b]$. Then
\begin{equation*}
\abs{\int_a^b e^{if(x)}g(x)\,dx}\leq 4\frac{\|g\|_{L^\infty[a,b]}+\|g'\|_{L^1[a,b]}}{\inf_{x\in[a,b]}\abs{f'(x)}}.
\end{equation*}
\end{proposition}

\noindent For a proof of the above proposition, we refer the reader to Chapter 8 of \cite{SteinHarmonicAnalysis} or Section 3 of \cite{Randles2015} (see Lemma 3.2 and 3.4 therein).  To effectively make use of the proposition above to estimate \eqref{eq:LocalizedFourierInversionConvolutionPower} in the case that $\xi_0$ is of imaginary-homogeneous type, we first treat two preliminary lemmas. 

\begin{lemma}\label{lem:PhaseDerivativeEstimate}
Let $Q:\mathbb{R}^d\to\mathbb{R}$ be a continuous function for which $\abs{Q}$ is positive-homogeneous and set $\mu=\mu_{\abs{Q}}$. Given a compact subset $S$ of $\mathbb{R}^d$ for which $0\notin S$, set
\begin{equation*}
    \rho=\inf_{\eta\in S}|Q(\eta)|/3>0.
\end{equation*}
For an open neighborhood $\mathcal{O}$ of $0$ in $\mathbb{R}^d$, suppose that $\widetilde{Q}:\mathcal{O}\to\mathbb{R}$ is a once continuously differentiable function which is strongly subhomogeneous with respect to $E$, set $F=E/\mu$, and define
\begin{eqnarray*}
f_{n,\eta,x}(\theta)&=&-nQ(\theta^F\eta)-n\widetilde{Q}(\theta^F\eta)-x\cdot \theta^F\eta\\
&=&-n\theta^{1/\mu}Q(\eta)-n\widetilde{Q}(\theta^{F}\eta)-x\cdot \theta^{F}\eta
\end{eqnarray*}
for $n\in\mathbb{N}_+$, $\eta\in S$, $x\in\mathbb{R}^d$ and $\theta>0$ sufficiently small so that $\theta^F\eta\in\mathcal{O}$. Then, given any compact set $K$, there is a $\delta>0$ for which
\begin{equation*}
    |\partial_\theta f_{n,x,\eta}(\theta)|\geq \frac{\rho}{\mu} n^{\min\{\mu,1\}}
\end{equation*}
for all $n\in\mathbb{N}_+$, $\eta\in S$,  $x\in K$, and $\theta>0$ for which $n^{-\mu}\leq \theta\leq \delta^\mu$.
\end{lemma}

\begin{proof}
Let $E$ and $S$ be as in the statement of the lemma. For $n\in\mathbb{N}_+$, $\eta\in S$ and $x\in \mathbb{R}^d$, define
\begin{eqnarray*}
\Phi_{n,\eta,x}(r)&=&nQ(r^E\eta)+n\widetilde{Q}(r^E\eta)+x\cdot r^E\eta\\
&=&nrQ(\eta)+n\widetilde{Q}(r^E\eta)+x\cdot r^E\eta
\end{eqnarray*}
for all $r>0$ sufficiently small so that $r^E\eta\in \mathcal{O}$.  We observe that, for $n\in\mathbb{N}_+$, $\eta\in S$ and $x\in\mathbb{R}^d$, 
\begin{equation*}
f_{n,\eta,x}(\theta)=-\Phi_{n,\eta,x}\left(\theta^{1/\mu}\right)
\end{equation*}
whenever $\theta^F\eta=(\theta^{1/\mu})^E\eta\in \mathcal{O}$. Let's suppose that, given a compact set $K$, there exists $0<\delta\leq 1$ for which
\begin{equation}\label{eq:PhaseDerivativeEstimate2}
\abs{\partial_r \Phi_{n,\eta,x}(r)}\geq\rho n
\end{equation}
for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $r>0$ for which $1/n\leq r\leq \delta$. Then, for this $\delta>0$, we have
\begin{equation*}
    \abs{\p_\theta f_{n,\eta,x} (\theta)} = 
     \abs{  \p_{\theta^{1/\mu}} \Phi_{n,\eta,x}\left(\theta^{1/\mu}\right)}
     \abs{ \f{\p \theta^{1/\mu}}{\p \theta}} 
     \geq 
    \rho n\f{\theta^{1/\mu - 1}  }{\mu}  \geq \f{\rho}{\mu}n^{\min\{\mu,1 \}}
\end{equation*}
for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $n^{-\mu}\leq \theta\leq \delta^{-\mu}$, which is our desired assertion. Thus, it suffices to prove \eqref{eq:PhaseDerivativeEstimate2}.


To this end, we fix a compact set $K\subseteq\mathbb{R}^d$. Given that $r^E$ is contracting and $S$ and $K$ are compact, there is $\delta_1>0$ for which $|x\cdot r^E E\eta|\leq \rho$ for all $x\in K$, $\eta\in S$ and $0<r<\delta_1$. Also, because $\widetilde{Q}$ is strongly subhomogeneous with respect to $E$, we may find $\delta_2>0$ for which
\begin{equation*}
    |\partial_r\widetilde{Q}(r^E\eta)|\leq \rho
\end{equation*}
for all $0<r<\delta_2$ and $\eta\in S$. We set $\delta=\min\{\delta_1,\delta_2,1\}$ and observe that, for any $x\in K$, $\eta\in S$ and $0<r<\delta$, we have
\begin{eqnarray*}
\left|\partial_r
\left(x\cdot r^E\eta
+n\widetilde{Q}
(r^E\eta)\right)
\right|
&\leq &
\left|\partial_r\left(x\cdot r^E\eta\right)\right|+n\left|
\partial_r\widetilde{Q}(r^E\eta)
\right|\\
&\leq&\frac{1}{r}|x\cdot r^E E\eta)|+n\rho\\
&\leq& n|x\cdot r^E E\eta)|+n\rho\\
&<&2n\rho.
\end{eqnarray*}
Therefore,
\begin{eqnarray*}
\abs{\partial_r\Phi_{n,\eta,x}(r)}&=&\abs{nQ(\eta)- \left(-\partial_r\left(x\cdot r^E\eta+n\widetilde{Q}(r^E\eta)\right)\right)}\\
&\geq& n|Q(\eta)|-\left|\partial_r
\left(x\cdot r^E\eta
+n\widetilde{Q}
(r^E\eta)\right)
\right|\\
&\geq& 3n\rho-2n\rho\\
&\geq &n\rho
\end{eqnarray*}
for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $r>0$ for which $1/n\leq r\leq \delta$, as asserted.
\end{proof}



\begin{lemma}\label{lem:AmplitudeSobolevEstimates}
Let $R$ be a positive-homogeneous function with $G\in\Exp(R)$, $\widetilde{R}:\mathcal{O}\to\mathbb{R}$ be once continuously differentiable on a neighborhood $\mathcal{O}$ of $0$ which is strongly subhomogeneous with respect to $G$, and let $k$ and $\mu$ be positive real numbers. Set $F=(k/\mu) G$ and, for each $\eta\in S=\{\eta:R(\eta)=1\}$ and $n\in\mathbb{N}_+$, set
\begin{equation*}
    g_{n,\eta}(\theta)=e^{-n\left(R\left(\theta^F\eta\right)+\widetilde{R}\left(\theta^F\eta\right)\right)}
\end{equation*}
for $\theta>0$ which is sufficiently small so that $\theta^F\eta\in\mathcal{O}$. Then, for each $\beta>1$ there is $\delta>0$ for which 
\begin{equation*}
    \|g_{n,\eta}\|_{L^\infty[\theta_1,\theta_2]}\leq 1
\end{equation*}
and
\begin{equation*}
    \|\partial_\theta g_{n,\eta}\|_{L^1[\theta_1,\theta_2]}\leq \beta
\end{equation*}
uniformly for $\eta\in S$, $n\in\mathbb{N}$ and $0<\theta_1\leq\theta_2\leq \delta^{\mu}$.
\end{lemma}
\begin{proof}
By virtue of the strong subhomogeneity of $\widetilde{R}$, Proposition \ref{prop:supersub_implies_sub}, and the fact that $r^G$ is a contracting group, we may choose $\delta>0$ for which 
\begin{equation}\label{eq:AmplitudeSobolevEstimates1}
    R(r^G\eta)+\widetilde{R}\left(r^G\eta\right)=r+\widetilde{R}\left(r^G\eta\right)\geq (1-\epsilon)r>0
\end{equation}
and
\begin{equation}\label{eq:AmplitudeSobolevEstimates2}
    \abs{\partial_r\left(R(r^G\eta)+\widetilde{R}(r^G\eta)\right)}\leq 1+\epsilon
\end{equation}
for all $0<r<\delta^k$ and $\eta\in S$ where
\begin{equation*}
    \epsilon=\frac{\beta-1}{\beta+1}\in(0,1).
\end{equation*}
In view of \eqref{eq:AmplitudeSobolevEstimates1}, for any $0<\theta_1\leq\theta_2<\delta^{\mu}$, $\eta\in S$ and $n\in\mathbb{N}_+$,
\begin{equation*}
\|g_{n,\eta}\|_{L^\infty[\theta_1,\theta_2]}\leq\sup_{0<\theta\leq\delta^{\mu}}\abs{g_{n,\eta}(\theta)}=\sup_{0<r\leq\delta^k}\abs{g_{n,\eta}(r^{\mu/k})}\leq \sup_{0<r\leq \delta^k}e^{-nr(1-\epsilon)}= 1
\end{equation*}
where we have used the fact that $(r^{\mu/k})^F=r^{(\mu/k)F}=r^G$ for $r>0$. By virtue of \eqref{eq:AmplitudeSobolevEstimates1} a \eqref{eq:AmplitudeSobolevEstimates2}, we find that
\begin{eqnarray*}
\|\partial_{\theta}g_{n,\eta}\|_{L^1[\theta_1,\theta_2]}
&=&\int_{\theta_1}^{\theta_2}\abs{\p_\theta g_{n,\eta}(\theta)}\,d\theta\\
&=&\int_{\theta_1^{k/\mu}}^{\theta_2^{k/\mu}}\abs{\p_r g_{n,\eta}(r^{\mu/k})}\,dr\\
&=&\int_{\theta_1^{k/\mu}}^{\theta_2^{k/\mu}}\abs{\p_r e^{-n(R(r^G\eta)+\widetilde{R}(r^G\eta))} }\,dr\\
&=&\int_{\theta_1^{k/\mu}}^{\theta_2^{k/\mu}}n\abs{\partial_r(R(r^G\eta)+\widetilde{R}(r^G\eta))}\abs{e^{-nR(r^G\eta)+\widetilde{R}(r^G\eta)}}\,dr\\
&\leq&\int_{\theta_1^{k/\mu}}^{\theta_2^{k/\mu}}n(1+\epsilon)e^{-n(1-\epsilon)r}\,dr\\
&\leq &\frac{1+\epsilon}{1-\epsilon}\int_0^\infty e^{-r}\,dr=\beta
\end{eqnarray*}
for all $n\in\mathbb{N}_+$, $\eta\in S$ and $0<\theta_1\leq\theta_2\leq\delta^{\mu}$, as desired.
\end{proof}




\begin{lemma}\label{lem:EstImagHom}
Suppose that $\xi_0$ is of imaginary-homogeneous type for $\widehat{\phi}$ with associated drift $\alpha_{\xi_0}$ and homogeneous order $\mu_{\xi_0}$. If $\alpha_{\xi_0}=0$, then, for each compact set $K$, there is an open neighborhood $\mathcal{O}_{\xi_0}\subseteq\Interior(\mathbb{T}_\phi^d)$ of $\xi_0$, which can be taken as small as desired, and a constant $C_{\xi_0}$ for which
\begin{equation*}
    \abs{\f{1}{(2\pi)^d}\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi}\leq C_{\xi_0}n^{-\min\{\mu_{\xi_0},1\}}
\end{equation*}
for all $x\in K$ and $n\in\mathbb{N}_+$.
\end{lemma}
\begin{proof}
For simplicity of notation, we will write $Q=Q_{\xi_0}$, $\widetilde{Q}=\widetilde{Q}_{\xi_0}$, $R=R_{\xi_0}$, $\widetilde{R}=\widetilde{R}_{\xi_0}$ and $\mu=\mu_{\xi_0}$. We fix a compact set $K\subseteq\mathbb{R}^d$ and let $E$ and $k$ as given in Definition \ref{def:Types}. In studying the proof of Lemma \ref{lem:EstPosHom} and \eqref{eq:WlogCenterAtZero}, in particular, it is evident that we may assume $\xi_0=0$ and $\widehat{\phi}(0)=1$ without loss of generality. Given that $G:=E/k\in\Exp(R)$, set
\begin{equation*}
    F=(k/\mu)G=E/\mu.
\end{equation*} Using the positive-homogeneous structure of $R$, let $\sigma_R$ be the measure on $S=\{\eta\in \mathbb{R}^d:R(\eta)=1\}$ as guaranteed by Theorem \ref{thm:BestIntegrationFormula}. By setting
\begin{equation*}
    \rho=\inf_{\eta\in S}|Q(\eta)|/3,
\end{equation*}
an appeal to Lemma \ref{lem:PhaseDerivativeEstimate} guarantees a $\delta_1>0$ for which 
\begin{equation}\label{eq:EstImagHom1}
    \abs{\partial_{\theta}f_{n,\eta,x}(\theta)}\geq \frac{\rho}{\mu}n^{\min\{\mu,1\}}
\end{equation} for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $\theta>0$ for which $n^{-\mu}\leq \theta\leq \delta_1^\mu$. An appeal to Lemma \ref{lem:AmplitudeSobolevEstimates} guarantees $\delta_2>0$ for which
\begin{equation}\label{eq:EstImagHom2}
    \|g_{n,\eta}\|_{L^\infty[\theta_1,\theta_2]}
    +
    \|\p_\theta g_{n,\eta} \|_{ L^1[\theta_1,\theta_2]}
    \leq 3
\end{equation}
for all $n\in\mathbb{N}_+$, $\eta\in S$ and $0<\theta_1\leq\theta_2\leq\delta_2^{\mu}$. We set
\begin{equation*}
    \mathcal{O}=\{\eta\in\mathbb{R}^d:R(\eta)<\delta^k\}=\{0\}\cup \psi_G\left((0,\delta^{k})\times S\right)
\end{equation*}
where $0<\delta\leq \min\{\delta_1,\delta_2\}$ is as small as desired; this is necessarily an open neighborhood of $0$. We have
\begin{eqnarray*}
    \int_{\mathcal{O}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi
    &=&
    \int_S\int_0^{\delta^{k}}\widehat{\phi}^n(r^G\eta)e^{-ix\cdot r^G\eta}r^{\mu/k-1}\,dr d\sigma_R(\eta)\\
    &=&
    \frac{k}{\mu}\int_S \int_0^{\delta^{\mu}} \widehat{\phi}^n(\theta^{F} \eta) e^{-i x\cdot\theta^F \eta}  \,d\theta \,d\sigma_R(\eta)\\
    &=&
    \frac{k}{\mu}\int_S I_{n,x}(\eta)\,d\sigma_R(\eta)
\end{eqnarray*}
where we have made the change of variables $\theta=r^{\mu/ k}$ and set
\begin{eqnarray*}
    I_{n,x}(\eta)&=&\int_0^{\delta^{\mu}}\widehat{\phi}^n(\theta^F\eta)e^{-ix\cdot\theta^F\eta}\,d\theta.
\end{eqnarray*}
For each $n\in\mathbb{N}_+$, $\eta\in S$, and $x\in\mathbb{R}^d$, we have
\begin{eqnarray*}
\abs{I_{n,x}(\eta)}
&\leq & 
\abs{\int_{n^{-\mu}}^{\delta^{\mu}}\widehat{\phi}^n(\theta^F\eta)e^{-ix\cdot\theta^F\eta}\,d\theta} +\int_{0}^{n^{-\mu}}\abs{\widehat{\phi}^n(\theta^F\eta)}\,d\theta\\
&\leq& \abs{\int_{n^{-\mu}}^{\delta^\mu} e^{-i\left(nQ\left(\theta^F\eta\right)+n\widetilde{Q}\left(\theta^F\eta\right)+x\cdot\theta^F\eta\right)}e^{-n\left(R\left(\theta^F\eta\right)+\widetilde{R}\left(\theta^F\eta\right)\right)}\,d\theta}+n^{-\mu}\\
& &\hspace{1cm}=\abs{\int_{n^{-\mu}}^{\delta^\mu} e^{i f_{n,\eta,x}(\theta) } g_{n,\eta}(\theta)\,d\theta} 
+ n^{-\mu}.
\end{eqnarray*}
In view of \eqref{eq:EstImagHom1} and \eqref{eq:EstImagHom2}, an appeal to Proposition \ref{prop:VanderCorput} guarantees that, for any $n\in\mathbb{N}_+$, $\eta\in S$ and $x\in K$,
\begin{eqnarray*}
 \hspace{-1cm}\abs{\int_{n^{-\mu}}^{\delta^\mu}e^{if_{n,\eta,x}(\theta)}g_{n,\eta}(\theta)\,d\theta}
    &\leq& 
    4
    \frac{ 
    \|g_{n,\eta}\|_{L^\infty[n^{-\mu},\delta^{\mu}]}
    +
    \|\partial_{\theta}g_{n,\eta}\|_{L^1[n^{-\mu},\delta^{\mu}]}
    }{
    \inf_{n^{-\mu}\leq\theta\leq \delta^{\delta}}|\partial_{\theta}f_{n,x,\eta}(\theta)|
    }\\
    &\leq& 4\frac{3}{(\rho/\mu) n^{\min\{\mu,1\}}}=\frac{12\mu}{\rho}n^{-\min\{\mu,1\}}
\end{eqnarray*}
and so
\begin{equation*}
    \abs{I_{n,x}(\eta)}\leq \left(\frac{12\mu}{\rho}\right)n^{-\min\{\mu,1\}}+n^{-\mu}\leq \left(\frac{12\mu}{\rho}+1\right)n^{-\min\{\mu,1\}}.
\end{equation*}
Thus, for all $n\in\mathbb{N}_+$ and $x\in K$,
\begin{eqnarray*}
\abs{\f{1}{(2\pi)^d}\int_{\mathcal{O}}\widehat{\phi}^n(\xi)e^{-i\xi\cdot x}\,d\xi}
&=&\frac{1}{(2\pi)^d}\f{k}{\mu}\abs{\int_S I_{n,x}(\eta)\,d\sigma_R(\eta)} \\
&\leq& \frac{1}{(2\pi)^d}\f{k}{\mu}\int_S \abs{I_{n,x}(\eta)}\,d\sigma_R(\eta)\\
&\leq& Cn^{-\min\{\mu,1\}}
\end{eqnarray*}
where
\begin{equation*}
    C=\f{1}{(2\pi)^d} \f{k}{\mu} \left(\frac{12\mu}{\rho}+1\right)\sigma_R(S).
\end{equation*}
\end{proof}




\begin{proof}[Proof of Theorem \ref{thm:ConvolutionPowerEstimate}]
Let $K\subseteq\mathbb{R}^d$ be a compact set. As we discussed in the paragraph preceding the theorem, the set $\Omega(\phi)$ is finite and so we may write
\begin{equation*}
    \Omega(\phi)=\{\xi_1,\xi_2,\dots,\xi_N,\xi_{N+1},\xi_{N+2},\dots,\xi_M\}
\end{equation*}
where $\xi_1,\xi_2,\dots,\xi_N$ are of purely imaginary type for $\widehat{\phi}$ with $\alpha_{\xi_j}=0$ for $j=1,2\dots,N$ and $\xi_{N+1},\xi_{N+2},\dots,\xi_M$ are of positive-homogeneous type for $\widehat{\phi}$. For each $j=1,2,\dots,N$, $\xi_j$ is of imaginary-homogeneous type with $\alpha_{\xi_j}=0$ and so an appeal to Lemma \ref{lem:EstImagHom} guarantees an open neighborhood $\mathcal{O}_j=\mathcal{O}_{\xi_j}\subseteq\Interior(\mathbb{T}_\phi^d)$ of $\xi_j$ and a constant $C_j=C_{\xi_j}$ for which
\begin{equation}\label{eq:ConvolutionPowerEstimate1}
    \abs{\frac{1}{(2\pi)^d}\int_{\mathcal{O}_j}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi}\leq C_j n^{-\min\{\mu_j,1\}}
\end{equation}
for all $n\in\mathbb{N}_+$ and $x\in K$. For each $j=N+1,N+2,\dots M$, an appeal to Lemma \ref{lem:EstPosHom} guarantees an open neighborhood $\mathcal{O}_j=\mathcal{O}_{\xi_j}\subseteq\Interior(\mathbb{T}_\phi^d)$ of $\xi_j$ and a constant $C_j=C_{\xi_j}$ for which 
\begin{equation}\label{eq:ConvolutionPowerEstimate2}
        \abs{\frac{1}{(2\pi)^d}\int_{\mathcal{O}_j}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi}\leq C_jn^{-\mu_j}\leq C_j n^{-\min\{\mu_j,1\}}
\end{equation}
for all $n\in\mathbb{N}_+$ and $x\in\mathbb{R}^d$. As guaranteed by the lemmas, let us take this collection of open sets $\mathcal{O}_1,\mathcal{O}_2,\dots,\mathcal{O}_M\subseteq\mathbb{T}_{\phi}^d$ to be mutually disjoint and define
\begin{equation}
    \mathcal{G}=\mathbb{T}_{\phi}^d\setminus\left(\bigcup_{j=1}^M \mathcal{O}_j\right).
\end{equation}
Given that $\mathcal{G}$ is a closed set which contains no elements of $\Omega(\phi)$,
\begin{equation*}
s:=\sup_{\xi\in\mathcal{G}}\abs{\widehat{\phi}(\xi)}<1.
\end{equation*}
By virtue of \eqref{eq:FourierInversionConvolutionPower}, \eqref{eq:ConvolutionPowerEstimate1}, \eqref{eq:ConvolutionPowerEstimate2}, and the disjointness of the collection $\mathcal{O}_1,\mathcal{O}_2,\dots,\mathcal{O}_M$, we have
\begin{eqnarray}\label{eq:ConvolutionPowerEstimate3}\nonumber
    \abs{\phi^{(n)}(x)}
    &=&\abs{\lb \sum_{j=1}^M\frac{1}{(2\pi)^d}\int_{\mathcal{O}_j}\widehat{\phi}^n(\xi)e^{-x\cdot\xi}\,d\xi \rb
    +\frac{1}{(2\pi)^d}\int_{\mathcal{G}}\widehat{\phi}^n(\xi)e^{-x\cdot\xi}\,d\xi}\\\nonumber
    &\leq&\sum_{j=1}^M\abs{\frac{1}{(2\pi)^d}\int_{\mathcal{O}_j}\widehat{\phi}^n(\xi)e^{-x\cdot\xi}\,d\xi}+\abs{\frac{1}{(2\pi)^d}\int_{\mathcal{G}}\widehat{\phi}^n(\xi)e^{-x\cdot\xi}\,d\xi}\\
    &\leq&\sum_{j=1}^M C_jn^{-\min\{\mu_j,1\}}+s^n
\end{eqnarray}
for all $n\in\mathbb{N}_+$ and $x\in K$. Upon noting that $\mu_\phi=\min\{\mu_1,\mu_2,\dots,\mu_M\}\leq 1$, we have
\begin{equation*}
    n^{-\min\{\mu_j,1\}}=O(n^{-\mu_\phi})
\end{equation*}
as $n\to\infty$ for each $j=1,2,\dots M$. Also, because $s<1$, $s^n=o(n^{-\mu_\phi})$ as $n\to \infty$. With these two observations, the theorem follows immediately from \eqref{eq:ConvolutionPowerEstimate3}.
\end{proof}


\section{Examples}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textcolor{red}{Okay, proving this is Way way way harder than I initially expected. Mostly because we can't generally assume that the series in question are real analytic on all of $\mathbb{R}^d$ (the domain of the principal branch of log limits this). I've given a first stab at the proof below. Please check all details and clean up as needed.}
\begin{proposition}\label{prop:ExpandGamma}
Let $\phi\in\mathcal{S}_d$ with $\sup_{\xi}|\widehat{\phi}(\xi)|=1$ and let $\xi_0\in\Omega(\phi)$. Suppose that there exists $\mathbf{m}\in \mathbb{N}^d_+$ and some natural number $k > 1$ such that the Taylor expansion of $\Gamma_{\xi_0} : \mathcal{U}\to\mathbb{C}$ centered at $0$ is a series of the form
\begin{eqnarray*}
    \Gamma_{\xi_0}(\xi) 
    &=& i\al_{\xi_0} \cdot \xi + i \left( \sum_{\abs{\be : 2\mathbf{m}} \geq 1} A_\be \xi^\be\right) + \sum_{\abs{\be : 2\mathbf{m}} \geq k} B_\be \xi^\be \\
    &=& i\al_{\xi_0} \cdot \xi + i \lp \sum_{\abs{\be : 2\mathbf{m}} = 1} A_\be \xi^\be + \sum_{\abs{\be : 2\mathbf{m}} > 1} A_\be \xi^\be\rp 
    + \lp \sum_{\abs{\be : 2\mathbf{m}} = k} B_\be \xi^\be + \sum_{\abs{\be : 2\mathbf{m}} > k} B_\be \xi^\be \rp \\
    &=&  i\al_{\xi_0} \cdot \xi + i\lp Q_{\xi_0}(\xi) + \widetilde{Q}_{\xi_0}(\xi)\rp + \lp R_{\xi_0}(\xi) + \widetilde{R}_{\xi_0}(\xi) \rp,
\end{eqnarray*}
where $\al_{\xi_0} \in \mathbb{R}^d$;    $Q_{\xi_0} and $ $R_{\xi_0}$ are real-valued polynomials for which $\abs{Q_{\xi_0}}$ and $R_{\xi_0}$ are positive-definite; and  $\widetilde{Q}_{\xi_0},$ and $\widetilde{R}_{\xi_0}$ are real multivariate power series which are \textcolor{red}{I don't think we need this: absolutely and} uniformly convergent on $\mathcal{U}$. Then $\xi_0$ is of imaginary-homogeneous type for $\widehat{\phi}$ \textcolor{red}{with
\begin{equation*}
    \mu_{\xi_0}=\abs{\mathbf{1}:2\mathbf{m}}=\sum_{j=1}^d\frac{1}{2m_j}.
\end{equation*}}
\end{proposition}

\begin{proof}
It is easy to see that, in the standard Euclidean basis, 
\begin{equation*}
    E = \diag((2m_1)^{-1}, (2m_2)^{-1},\dots, (2m_d)^{-1}) \in \Exp(\abs{Q_{\xi_0}})
\end{equation*}
and $E/k\in \Exp(R_{\xi_0})$. Thus, given that $\abs{Q_{\xi_0}}$ and $R_{\xi_0}$ are positive-definite, they must both be positive-homogeneous and
\begin{equation*}
    \mu_{\xi_0}=\mu_{\abs{Q_{\xi_0}}}=\tr E=|\mathbf{1}:2\mathbf{m}|.
\end{equation*}
Since all functions in sight are smooth (all are given by convergent Taylor series), it remains to show that $\widetilde{Q}=\widetilde{Q}_{\xi_0}$ is strongly subhomogeneous with respect to $E$ and $\widetilde{R}_{\xi_0}=\widetilde{R}$ is strongly subhomogeneous with respect to $E/k$. As the verification of these two statements are almost identical, we shall only prove the first.

Let $\epsilon > 0$ and fix a compact set $K\subseteq\mathbb{R}^d$. Let's write $\widetilde{Q}=\widetilde{Q}_1+\widetilde{Q}_2$ where
\begin{equation*}
    \widetilde{Q}_1(\xi)=\sum_{1< |\beta:2m|\leq 4}A_{\beta}\xi^\beta
\end{equation*}
and
\begin{equation*}
    \widetilde{Q}_2(\xi)=\sum_{ |\beta:2m|>4}A_{\beta}\xi^\beta.
\end{equation*}
Given that the set of multiindices $\beta$ for which  $1<|\beta:2\mathbf{m}|\leq 4$ is finite, 
\begin{equation*}
    M_1:=\sup\left\{\sum_{1<|\beta:2\mathbf{m}|\leq 4} \abs{A_\beta\xi^\beta}:\xi\in K\right\}<\infty
\end{equation*}
and
\begin{equation*}
    \rho:=\inf\left\{|\beta:2\mathbf{m}|-1:1<|\beta:2\mathbf{m}|\leq 4\right\}>0.
\end{equation*}
Because $\{r^E\}$ is a contracting group and $\widetilde{Q}_2$ is necessarily absolutely convergent on $\mathcal{U}$, it follows that there is $\delta_1>0$ for which
\begin{equation*}
    M_2:=\sup\left\{\sum_{|\beta:2\mathbf{m}|>4}\abs{A_\beta(r^{E/4}\xi)^\beta}:\xi\in K, 0\leq r\leq\delta_1\right\}<\infty.
\end{equation*}
\textcolor{red}{Okay, so we should ask why the above statement true. Well, first given that the series in question is absolutely convergent on $\mathcal{U}$, we can take a compact subset $0\leq K_0\subseteq \mathcal{U}$ on which the series is absolutely and uniformly convergent (we should look this up, but I think (?!?) this should be standard in the theory of multivariate power series). In particular,
\begin{equation*}
    K_0\ni \eta\mapsto \sum_{|\beta:2\mathbf{m}|>4}|A_{\beta}\eta^\beta|
\end{equation*}
is continuous as it is the uniform limit of continuous functions (the partial summands), c.f., Baby Rudin Theorem 7.12. It is therefore bounded on $K_0$.
Now, given that $\{r^E\}$ is contracting, $\{r^{E/4}\}$ is also contracting so, by taking $r$ small enough (there is a $\delta_1\leq 1$), $r^{E/8}\xi \in K_0$ for all $0\leq r\leq \delta_1$ and $\xi\in K$. Thus, we get the boundedness asserted.}

Also, there exists $\delta_2>0$ for which
   \begin{equation*}
       |\beta:2\mathbf{m}|r^{|\beta:8\mathbf{m}|}\leq 1
   \end{equation*}
   for all multiindices $\beta$ for which $|\beta:2\mathbf{m}|\geq 1$ and $0\leq r\leq \delta_2$.
(\textcolor{red}{Huan, try to prove this. I think $\delta_2=2^{-4}$ is sufficient.})\\

Finally, we let $0<\delta\leq\min\{\delta_1,\delta_2\}$ be chosen so that
\begin{equation*}
    4r^\rho M_1+r M_2<\epsilon. 
\end{equation*}
Observe that $r^{E}\xi\in K_0\subseteq\mathcal{U}$ for all $0<r<\delta$ and $\xi\in K$ and so it follows that
\begin{eqnarray*}
    \partial_r\widetilde{Q}(r^E\xi)&=&\partial_r\widetilde{Q}_1(r^E\xi)+\partial_r\widetilde{Q}_2(r^E\xi)\\
    &=&\sum_{1<|\beta:2\mathbf{m}|\leq 4}|\beta:2\mathbf{m}|r^{|\beta:2\mathbf{m}|-1}A_\beta\xi^\beta+\sum_{|\beta:2\mathbf{m}|> 4}|\beta:2\mathbf{m}|r^{|\beta:2\mathbf{m}|-1}A_\beta\xi^\beta\\
    &=&\sum_{1<|\beta:2\mathbf{m}|\leq 4}|\beta:2\mathbf{m}|r^{|\beta:2\mathbf{m}|-1}A_\beta\xi^\beta+\sum_{|\beta:2\mathbf{m}|>4} r^{|\beta:4\mathbf{m}|-1}\left(|\beta:2\mathbf{m}|r^{|\beta:8\mathbf{m}|}\right)\left(A_\beta (r^{E/4}\xi)^\beta\right)
\end{eqnarray*}
for all $0<r\leq\delta$ and $\xi\in K$. Consequently,
\begin{eqnarray*}
    \abs{\partial_r\widetilde{Q}(r^E\xi)}&\leq & \sum_{1<|\beta:2\mathbf{m}|\leq 4}|\beta:2\mathbf{m}|r^{|\beta:2\mathbf{m}|-1}\abs{A_\beta\xi^\beta}+\sum_{|\beta:2\mathbf{m}|>4}r^{|\beta:4\mathbf{m}|-1}\abs{|\beta:2\mathbf{m}|r^{|\beta:8\mathbf{m}|}}\abs{A_\beta (r^{E/4}\xi)^\beta}\\
    &\leq&4 r^\rho \sum_{1<|\beta:2\mathbf{m}|\leq 4}\abs{A_\beta \xi^\beta}+r\sum_{|\beta:2\mathbf{m}|>4}\abs{A_\beta(r^{E/4}\xi)^\beta}\\
    &=&4 r^\rho M_1+rM_2<\epsilon
\end{eqnarray*}
for all $0<r\leq\delta$ and $\xi\in K$.









\begin{comment}

Choose any fixed $\xi\in K$, we have
\begin{eqnarray*}
    \abs{\p_r \widetilde{Q}_{\xi_0}(r^E \xi)} 
    &=&  \abs{\p_r \sum_{\abs{\be : 2\mathbf{m}} > 1} b_\be \lp r^E\xi\rp^\be}\\
    &=&  \abs{\p_r \sum_{\abs{\be : 2\mathbf{m}} > 1} b_\be (r^{\be_1/2m_1})(\xi^1)^{\be_1}(r^{\be_2/2m_2})(\xi^2)^{\be_2}\dots (r^{\be_d/2m_d})(\xi^d)^{\be_d}}\\
    &=&  \abs{\p_r \sum_{\abs{\be : 2\mathbf{m}} > 1} b_\be r^{\abs{\be:2\mathbf{m}}} \xi^\be}\\
    &=&  \abs{\sum_{\abs{\be : 2\mathbf{m}} > 1} b'_\be r^{\abs{\be:2\mathbf{m}}-1} \xi^\be}.
\end{eqnarray*}
Observe that since $\abs{\be: 2\mathbf{m}} > 1$ for all $\be$'s in the summation, the function $l_\xi: \mathbb{R}_+ \to \mathbb{R}$ defined by $l_\xi(r) = \abs{\p_r \widetilde{Q}_{\xi_0}(r^E \xi)}$ is right-continuous at $r=0$. Moreover, because $l_\xi(0) = 0$, we are guaranteed a $\delta' >0$ for which $l_\xi \leq \epsilon$ whenever $0<r<\delta'$. Therefore, there exists a $\delta >0$ for which $\abs{\p_r \widetilde{Q}_{\xi_0}(r^E \xi)} \leq \epsilon$ for all $0<r<\delta$ and $\xi\in K$, i.e., $\widetilde{Q}_{\xi_0}$ is strongly subhomogeneous with respect to $E$. \textcolor{blue}{I don't know why I don't feel very good about this proof...}\textcolor{red}{That's okay, we're mostly on the right track. Beyond the first sentence, most things should be edited. Let me give you some guidance.
\begin{enumerate}
\item Change all $b$'s to $A$'s (to mirror my adjustments in the statement).
\item In the last line, you have a prime which shouldn't be there.
    \item As the size of everything above is determined by the smallest exponent, we should set
    \begin{equation*}
        \rho=\min\{|\beta:2\mathbf{m}|:|\beta:2\mathbf{m}|>1\}-1
    \end{equation*}
    and argue that $\rho>0$.
    \item Since we have assumed that Given what I said in the previous item, we should have an inequality which looks like
    \begin{equation*}
        \abs{\partial_r\widetilde{Q}_{\xi_0}(r^E\xi)}=\abs{\sum_{|\beta:2\mathbf{m}|>1}r^{|\beta:2\mathbf{m}|}A_\beta \xi^\beta}\leq \sum_{|\beta:2\mathbf{m}|>1}r^{|\beta:2\mathbf{m}|}\abs{A_\beta \xi^\beta}\leq r^{\rho}\sum_{|\beta:2\mathbf{m}|>1}|A_\beta\xi^\beta|
    \end{equation*}
\end{enumerate}} 



\begin{subproof}[Subproof]
Next, we want to show that ${R}_{\xi_0}$ is homogeneous with respect to $E/k$. This is follows fairly straightforwardly from a few multi-index manipulations and the fact that $R_{\xi_0}$ is a real-valued continuous function:
\begin{eqnarray*}
    R_{\xi_0}(r^{E/k} \xi) 
    &=& \sum_{\abs{\be:2\mathbf{m}} = k} c_\be \lp r^{E/k} \xi \rp^\be \\
    &=& \sum_{\abs{\be:2\mathbf{m}} = k} c_\be (r^{\be_1/2km_1})(\xi^1)^{\be_1}(r^{\be_2/2km_2})(\xi^2)^{\be_2}\dots (r^{\be_d/2km_d})(\xi^d)^{\be_d}\\
    &=& \sum_{\abs{\be:2\mathbf{m}} = k} c_\be r^{\abs{\be: 2\mathbf{m}}/k} \xi^\be\\
    &=& rR_{\xi_0}(\xi).
\end{eqnarray*}
\end{subproof}

\begin{subproof}[Subproof]
Finally, to show that $\widetilde{R}_{\xi_0}$ is strongly subhomogeneous with respect to $E/k$, we combine elements from the previous subproofs. Let $\epsilon > 0$ and a compact set $K$ be given. Writing out the multi-indices explicitly gives
\begin{eqnarray*}
    \abs{\p_r \widetilde{R}_{\xi_0}(r^E \xi)} 
    &=&  \abs{\p_r \sum_{\abs{\be : 2\mathbf{m}} > k} d_\be \lp r^E\xi\rp^\be}\\
    &=&  \abs{\p_r \sum_{\abs{\be : 2\mathbf{m}} > k} d_\be (r^{\be_1/2km_1})(\xi^1)^{\be_1}(r^{\be_2/2km_2})(\xi^2)^{\be_2}\dots (r^{\be_d/2km_d})(\xi^d)^{\be_d}}\\
    &=&  \abs{\p_r \sum_{\abs{\be : 2\mathbf{m}} > k} d_\be r^{\abs{\be:2\mathbf{m}}/k} \xi^\be}\\
    &=&  \abs{\sum_{\abs{\be : 2\mathbf{m}} > k} d'_\be r^{\abs{\be:2\mathbf{m}}/k-1} \xi^\be}.
\end{eqnarray*}
Observe that $\abs{\be: 2\mathbf{m}} > k$ for all $\be$'s in the summation. A similar argument as that in the first subproof for $\widetilde{Q}_{\xi_0}$ gives the desired result. 
\end{subproof}
\end{comment}
\end{proof}


\begin{example}\normalfont
Consider the function $\phi : \mathbb{Z}^2 \to \mathbb{C}$ defined by 
\begin{equation*}
    \phi(x,y) =
    \frac{1}{512}
    \begin{cases}
    346 - 112i &(x,y) = (0,0)\\
    64 + 32  &(x,y) = (\pm 1, 0)\\
    -16        &(x,y) = (\pm 2,0)\\
    56 + 32i  &(x,y) = (0,\pm 1)\\
    - 28 - 8i &(x,y) = (0,\pm 2)\\
    8     &(x,y) = (0,\pm 3)\\
    -1 &(x,y) = (0,\pm 4)\\
    0& \text{otherwise}.
    \end{cases}
\end{equation*}
Upon obtaining $\widehat{\phi}$, we find $\Omega(\phi) = \{ 0 \}$ and obtain the following expansion for $\Gamma_{\xi_0 =0}$:
\begin{eqnarray*}
\Gamma_{\xi_0 = 0}(x,y) 
&=& i\lp -\frac{x^2}{16} -\frac{y^4}{64}\rp + 
i\lp \frac{x^4}{192} + \frac{y^6}{384} - \frac{7 x^4y^4}{16384} + \frac{7x^4y^6}{98304}+ \dots\rp \\
&& + \lp -\frac{15x^4}{512} + \frac{x^2 y^4}{1024} - \f{15y^8}{8192} \rp 
+ \lp  -\frac{x^2y^6}{6144} - \frac{x^4y^4}{12288} + \frac{x^4y^6}{73728} + \dots\rp.
\end{eqnarray*}
In view of Proposition \ref{prop:ExpandGamma}, we can make the following identifications:
\begin{eqnarray*}
Q_{\xi_0 = 0}(x,y)
&=&  -\frac{x^2}{16} -\frac{y^4}{64}\\
\widetilde{Q}_{\xi_0 = 0}(x,y)
&=&   \frac{x^4}{192} + \frac{y^6}{384} - \frac{7 x^4y^4}{16384} + \frac{7x^4y^6}{98304}+ \dots\\
R_{\xi_0 = 0}(x,y)
&=&  -\frac{15x^4}{512} + \frac{x^2 y^4}{1024} - \f{15y^8}{8192} \\
\widetilde{R}_{\xi_0 = 0}(x,y)
&=& -\frac{x^2y^6}{6144} - \frac{x^4y^4}{12288} + \frac{x^4y^6}{73728} + \dots.
\end{eqnarray*}
Consider $\mathbf{m} = (1,2)$ and $k=2$. Following Proposition \ref{prop:ExpandGamma} we have $E = \diag(1/2, 1/4)$, from which we readily find that $Q_{\xi_0=0}$ is homogeneous with respect to $E$ and $\R_{\xi_0 = 0}$ with respect to $E/k$, and that $\widetilde{Q}_{\xi_0 = 0}$ and $\widetilde{R}_{\xi_0} = 0$ are strongly subhomogeneous with respect to $E$ and $E/k$, respectively. \\
\end{example}
%%%%%%%%%%%%%%%%%%%
\begin{example}\normalfont
Consider the function $\phi : \mathbb{Z}^2 \to \mathbb{C}$ defined by 
\begin{equation*}
    \phi(x,y) = 
    \f{1}{768}\times
    \begin{cases}
    602 - 112i &(x,y) = (0,0)\\
    56 + 32i   &(x,y) = (-1,0)\\
    72 + 32i   &(x,y) = (1,0)\\
    -16        &(x,y) = (\pm 2,0)\\
    56 + 32i   &(x,y) = (0,\pm 1)\\
    -28 - 8i   &(x,y) = (0,\pm 2)\\
    56         &(x,y) = (0,\pm 3)\\
    -1         &(x,y) = (0,\pm 4)\\
    4          &(x,y) = (-1,\pm 1)\\
    -4         &(x,y) = (1,\pm 1)\\
    0          &\text{otherwise}.
    \end{cases}
\end{equation*}
dUpon obtaining $\widehat{\phi}$, we find $\Omega(\phi) = \{ 0 \}$ and obtain the following expansion for $\Gamma_{\xi_0 =0}$:
\begin{eqnarray*}
\Gamma_{\xi_0 = 0}(x,y) 
&=& i\lp-\frac{x^2}{24}+ \frac{xy^2}{96} -\frac{ y^4}{96} \rp 
+ i\lp \frac{x^4}{288}-\frac{xy^4}{1152} -\frac{x^3y^2}{576}  +\frac{x^3y^4}{6912} - \frac{43 x^4y^4}{221184} + \dots \rp \\
&&+ \lp -\frac{23x^4}{1152} +\frac{x^2y^4}{2048} - \frac{23y^8}{18432} \rp 
+ \lp -\frac{x^3y^2}{2304} + \frac{x^3y^4}{27648} - \frac{x^4y^4}{18432} + \dots\rp.
\end{eqnarray*}
In view of Proposition \ref{prop:ExpandGamma}, we can make the following identifications:
\begin{eqnarray*}
Q_{\xi_0 = 0}(x,y)
&=& -\frac{x^2}{24}+ \frac{xy^2}{96} -\frac{ y^4}{96} \\
\widetilde{Q}_{\xi_0 = 0}(x,y)
&=& \frac{x^4}{288}-\frac{xy^4}{1152} -\frac{x^3y^2}{576}  +\frac{x^3y^4}{6912} - \frac{43 x^4y^4}{221184} + \dots \\
R_{\xi_0 = 0}(x,y)
&=&  -\frac{23x^4}{1152} +\frac{x^2y^4}{2048} - \frac{23y^8}{18432}\\
\widetilde{R}_{\xi_0 = 0}(x,y)
&=& -\frac{x^3y^2}{2304} + \frac{x^3y^4}{27648} - \frac{x^4y^4}{18432} + \dots.
\end{eqnarray*}
Consider $\mathbf{m} = (1,2)$ and $k=2$. Following Proposition \ref{prop:ExpandGamma} we have $E = \diag(1/2, 1/4)$, from which we readily find that $Q_{\xi_0=0}$ is homogeneous with respect to $E$ and $\R_{\xi_0 = 0}$ with respect to $E/k$, and that $\widetilde{Q}_{\xi_0 = 0}$ and $\widetilde{R}_{\xi_0} = 0$ are strongly subhomogeneous with respect to $E$ and $E/k$, respectively. 
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%






\section{Proof of Theorem \ref{thm:BestIntegrationFormula}}



\subsection{Construction of $\sigma_{P,E}$}\label{subsec:ConstructionofSigma}

Throughout this section, we fix $E\in\Exp(P)$. Define $\psi_E:(0,\infty)\times S\to\mathbb{R}^d\setminus\{0\}$ by
\begin{equation}\label{eq:Homeomorphism}
\psi_E(r,\eta)=r^E\eta
\end{equation}
for $r>0$ and $\eta\in S$. As $\psi_E$ is the restriction of the continuous function $(0,\infty)\times \mathbb{R}^d\ni (r,x)\mapsto r^E x\in\mathbb{R}^d$ to $(0,\infty)\times S$, it is necessarily continuous. As the following proposition shows, $\psi_E$ is, in fact, a homeomorphism.

\begin{proposition}\label{prop:PsiHomeomorphism}
The map $\psi_E:(0,\infty)\times S\to\mathbb{R}^d\setminus\{0\}$ is a homeomorphism with continuous inverse $\psi_E^{-1}:\mathbb{R}^d\setminus\{0\}\to (0,\infty)\times S$ given by
\begin{equation*}
\psi_E^{-1}(x)=(P(x),(P(x))^{-E}x)
\end{equation*}
for $x\in\mathbb{R}^d\setminus\{0\}$.
\end{proposition}

\begin{proof}
Given that $P$ is continuous and positive-definite, $P(x)>0$ for each $x\in \mathbb{R}^d\setminus\{0\}$ and the map $\mathbb{R}^d\setminus\{0\}\ni x \mapsto (P(x))^{-E}x\in \mathbb{R}^d$ is continuous. Further, in view of the homogeneity of $P$,
\begin{equation*}
P\left((P(x))^{-E} x \right)=P(x)^{-1}P(x)=1
\end{equation*}
for all $x\in\mathbb{R}^d\setminus\{0\}$. It follows from these two observations that
\begin{equation*}
\rho(x)=(P(x),(P(x))^{-E}x),
\end{equation*}
defined for $x\in\mathbb{R}^d\setminus\{0\}$, is a continuous function taking $\mathbb{R}^d\setminus\{0\}$ into $(0,\infty)\times S$. We have
\begin{equation*}
(\psi_E\circ \rho)(x)=\psi_E(P(x),(P(x))^{-E}x)=(P(x))^{E}(P(x))^{-E}x=x
\end{equation*}
for every $x\in \mathbb{R}^d\setminus \{0\}$ and
\begin{equation*}
(\rho\circ\psi_E)(r,\eta)=\rho(r^E\eta)=(P(r^{E}\eta),(P(r^{E}\eta))^{-E}(r^E\eta))=(rP(\eta),(rP(\eta))^{-E}(r^{E}\eta))=(r,\eta)
\end{equation*}
for every $(r,\eta)\in (0,\infty)\times S$. Thus $\rho$ is a (continuous) inverse for $\psi_E$ and so it follows that $\psi_E$ is a homeomorphism and $\rho=\psi_E^{-1}$.
\end{proof}



\noindent We shall now construct the $\sigma$-algebra $\Sigma_{P,E}$ on $S$; later, we will show that it is independent of our choice of $E$. As in the statement of Theorem \ref{thm:BestIntegrationFormula}, for each $F\subseteq S$, define
\begin{equation*}
\widetilde{F_E}=\bigcup_{0<r<1}\left(r^E F\right)=\{r^E\eta:0<r<1,\eta\in F\}. 
\end{equation*}
We shall denote by $\Sigma_{P,E}$ the collection of subsets $F$ of $S$ for which $\widetilde{F_E}\in\mathcal{M}_d$, i.e.,  
\begin{equation*}
\Sigma_{P,E}=\{F\subseteq S:\widetilde{F_E}\in\mathcal{M}_d\}.
\end{equation*}


\begin{proposition}\label{prop:BorelContainment}
$\Sigma_{P,E}$ is a $\sigma$-algebra on $S$ containing the Borel $\sigma$-algebra on $S$, $\mathcal{B}(S)$.
\end{proposition}

\begin{proof}
Throughout the proof, we write $\Sigma=\Sigma_{P,E}$ and $\widetilde{F}=\widetilde{F_E}$ for each $F\subseteq S$.
We first show that $\Sigma$ is a $\sigma$-algebra. Since $\widetilde S=B\setminus\{0\}$, it is open in $\mathbb{R}^d\setminus\{0\}$ and therefore Lebesgue measurable. Hence $S\in \Sigma$. Let $G, F\in \Sigma$ be such that $G\subseteq F$. Then,
\begin{equation*}
\widetilde{F\setminus G}=\bigcup_{0<r<1}r^E\left(F\setminus G\right)=\bigcup_{0<r<1}\left(r^EF\setminus r^E G\right)=\left(\bigcup_{0<r<1}r^E F\right)\setminus\left(\bigcup_{0<r<1}r^E G\right)=\widetilde F\setminus \widetilde G
\end{equation*}
where we have used the fact that the collection $\{r^E F\}_{0<r<1}$ is mutually disjoint to pass the union through the set difference. Consequently $\widetilde F\setminus \widetilde{G}$ is Lebesgue measurable and therefore $F\setminus G\in \Sigma$.  Now, given a countable collection $\{F_n\}\subseteq \Sigma_S$, observe that
\begin{equation*}
    \widetilde{\bigcup_{n=1}^\infty F_n}= \bigcup_{0<r<1}r^E \left(\bigcup_{n=1}^\infty F_n\right)= \bigcup_{0 <r< 1}  \bigcup_{n=1}^\infty  r^E F_n =\bigcup_{n=1}^\infty \bigcup_{0 <r < 1}  r^E F_n =\bigcup_{n=1}^\infty \widetilde{F_n} \in \mathcal{M}_d
\end{equation*}
whence $\cup_n F_n\in \Sigma_S$. Thus $\Sigma$ is a $\sigma$-algebra. 

Finally, we show that
\begin{equation*}
\mathcal{B}(S)\subseteq\Sigma.
\end{equation*}
As the Borel $\sigma$-algebra is the smallest $\sigma$-algebra containing the open subsets of $S$, it suffices to show that $\mathcal{O}\in \Sigma$ whenever $\mathcal{O}$ is open in $S$. Armed with Proposition \ref{prop:PsiHomeomorphism}, this is an easy task: Given an open set $\mathcal{O}\subseteq S$, observe that
\begin{equation*}
\widetilde{\mathcal{O}}=\{r^E\eta:0<r<1,\eta\in\mathcal{O}\}=\psi_E((0,1)\times\mathcal{O}).
\end{equation*}
Upon noting that $(0,1)\times\mathcal{O}$ is an open subset of $(0,\infty)\times S$, Proposition \ref{prop:PsiHomeomorphism} guarantees that $\widetilde{\mathcal{O}}=\psi_E((0,1)\times\mathcal{O})\subseteq\mathbb{R}^d\setminus\{0\}$ is open and therefore $\widetilde{\mathcal{O}} \in \mathcal{M}_d$. Thus, $\mathcal{O}\in \Sigma$.
\end{proof}

\noindent We are now ready to specify a measure on the measurable space $(S,\Sigma_{P,E})$. For each $F\in \Sigma_{P,E}$, we define
\begin{equation*}
\sigma_{P,E}(F)=\mu_P\cdot m(\widetilde{F_E})
\end{equation*}
where $m$ is the Lebesgue measure on $\mathbb{R}^d$ and $\mu_P=\tr E>0$ is the homogeneous order associated to $P$.

\begin{proposition}\label{prop:sigmaisameaure}
$\sigma_{P,E}$ is a finite measure on $(S,\Sigma_{P,E})$.
\end{proposition}
\begin{proof}

\noindent Throughout the proof, we will write $\sigma=\sigma_{P,E}$, $\Sigma=\Sigma_{P,E}$, and, $\widetilde{F}=\widetilde{F_E}$ for each $F\subseteq S$. It is clear that $\sigma$ is non-negative and $\sigma(\varnothing)=0$ because $\widetilde{\varnothing}=\varnothing$. Let $\{ F_n  \}^\infty_{n=1} \subseteq \Sigma $ be a mutually disjoint collection. We claim that $\{ \widetilde{F_n} \}_{n=1}^\infty\subseteq\mathcal{M}_d$ is also a mutually disjoint collection. To see this, suppose that $x = r_n^E \eta_n = r_m^E \eta_m\in \widetilde{F_n}\cap\widetilde{F_m}$, where $r_n,r_m \in (0,1)$, $\eta_n \in F_n$, and $\eta_m \in F_m $. Then
\begin{equation*}
    r_n = P(r_n^E \eta_n) = P(x) = P(r_m^E \eta_m) = r_m,
\end{equation*}
implying that $\eta_n = \eta_m\in F_n\cap F_m$. Because $\{F_n\}_{n=1}^\infty$ is mutually disjoint, we must have $n=m$ which verifies our claim. By virtue of the countable additivity of Lebesgue measure, we therefore have
\begin{equation*}
\sigma\left(\bigcup_{n=1}^\infty F_n\right)
    = \mu_P\cdot m\left( \widetilde{\bigcup^\infty_{n=1} F_n } \right)=\mu_P\cdot m\left( \bigcup^\infty_{n=1}\widetilde{F_n} \right)
    = \mu_P\sum^\infty_{n=1} m(\widetilde{F_n})
    = \sum^\infty_{n=1}\sigma(F_n).
\end{equation*}
Therefore $\sigma$ is a measure on $(S,\Sigma)$. In view of Condition \ref{cond:PisAboveOne} of Proposition \ref{prop:PositiveHomogeneousCharacterization}, $\widetilde{S}=B\setminus\{0\}$ is a bounded subset of $\mathbb{R}^d\setminus\{0\}$ and hence $\sigma(S)=\mu_P\cdot m(B\setminus\{0\})<\infty$ showing that $\sigma$ is finite.
\end{proof}

\noindent By virtue of the two preceding propositions, $\sigma_{P,E}$ is a finite Borel measure on $S$. In fact, as a consequence of next subsection's main result, Theorem \ref{thm:MainIntegrationFormula}, we will see that $\sigma_{P,E}$ is independent of our choice of $E\in\Exp(P)$ and is a Radon measure; see Subsection \ref{subsec:IndependentofE}.

\subsection{Product Measure and Point Isomorphism}\label{subsec:ProductMeasure}

Throughout this subsection, $E\in\Exp(P)$ will remain fixed and $(S,\Sigma_{P,E},\sigma_{P,E})$ will denote the finite measure space of Proposition \ref{prop:sigmaisameaure}. We recall that $\mathcal{L}$ denotes the $\sigma$-algebra of Lebesgue measurable subsets of $(0,\infty)$ and  $\lambda_P$ denotes the measure on $(0,\infty)$ with $\lambda_P(dr)=r^{\mu_P-1}\,dr$, i.e., for each $L\in\mathcal{L}$,
\begin{equation*}
\lambda_P(L)=\int_0^\infty \chi_L(r)r^{\mu_P-1}\,dr.
\end{equation*}
It is easy to see that $\lambda_P$ is $\sigma$-finite and so, in view of the finiteness of the measure $\sigma_{P,E}$, there exists a unique product measure $\lambda_P\times\sigma_{P,E}$ on $(0,\infty)\times S$ equipped with the product $\sigma$-algebra $\mathcal{L}\times\Sigma_{P,E}$ which satisfies
\begin{equation*}
    (\lambda_P\times\sigma_{P,E})(L\times F)=\lambda_P(L)\sigma_{P,E}(F)
\end{equation*}
for all $L\in\mathcal{L}$ and $F\in\Sigma_{P,E}$. We shall denote by $((0,\infty)\times S,(\mathcal{L}\times\Sigma_E)',\lambda_P\times\sigma_{P,E})$ the completion of the measure space $((0,\infty)\times S,\mathcal{L}\times\Sigma_E,\lambda_P\times\sigma_P)$. So that it is at our fingertips, we state the Fubini-Tonelli theorem associated to $\lambda_P\times \sigma_{P,E}$.
\begin{theorem}[Theorem 8.12 of \cite{Rudin1987}]\label{thm:Fubini}
Let $g:(0,\infty)\times S\to\mathbb{C}$ be $(\mathcal{L}\times\Sigma_E)'$-measurable. For each $r\in (0,\infty)$, define $g^r:S\to\mathbb{C}$ by $g^r(\eta)=g(r,\eta)$ for $\eta\in S$ and, for each $\eta\in S$, define $g_\eta:(0,\infty)\to\mathbb{C}$ by $g_\eta(r)=g(r,\eta)$ for $r\in (0,\infty)$. 
\begin{enumerate}
\item For $\lambda_P$-almost every $r$, $g^r$ is $\Sigma_E$-measurable and, for $\sigma_{P,E}$-almost every $\eta$, $g_\eta$ is $\mathcal{L}$-measurable.
\item\label{item:Fubini1} If $g\geq 0$, then:
\begin{enumerate}
\item For $\lambda_P$-almost every $r$, 
\begin{equation*}
H(r)=\int_S g^r(\eta)\,\sigma_{P,E}(d\eta)
\end{equation*}
exists as a non-negative extended real number. 
\item For $\sigma_{P,E}$-almost every $\eta$,
\begin{equation*}
G(\eta)=\int_0^\infty g_\eta(r)r^{\mu_P-1}\,dr
\end{equation*}
exists as a non-negative extended real number. 
\item We have
\begin{equation}\label{eq:Fubini1}
\int_0^\infty H(r)r^{\mu_P-1}dr=\int_{(0,\infty)\times S}g\,d(\lambda_P\times\sigma_{P,E})=\int_S G(\eta)\,\sigma_{P,E}(d\eta)
\end{equation}
and, in particular,
\begin{equation}\label{eq:Fubini2}
\int_0^\infty\left(\int_S g(r,\eta)\,\sigma_{P,E}(d\eta)\right)r^{\mu_P-1}\,dr=\int_S\left(\int_0^\infty g(r,\eta)r^{\mu_P-1}\,dr\right)\,\sigma_{P,E}(d\eta).
\end{equation}
\end{enumerate}
\item\label{item:Fubini2} If $g$ is complex valued and
\begin{equation*}
\int_S\left(\int_0^\infty |g(r,\eta)|r^{\mu_P-1}\,dr\right)\,\sigma_{P,E}(d\eta)<\infty\hspace{.5cm}\mbox{or}\hspace{.5cm}\int_0^\infty\left(\int_S|g(r,\eta)|\,\sigma_{P,E}(d\eta)\right)r^{\mu_P-1}\,dr<\infty,
\end{equation*}
then $g\in L^1((0,\infty)\times S,(\mathcal{L}\times\Sigma_E)',\lambda_P\times\sigma_{P,E})$.
\item If $g\in L^1((0,\infty)\times S,(\mathcal{L}\times\Sigma_E)',\lambda_P\times\sigma_{P,E})$, then $g^r\in L^1(S,\Sigma_E,\sigma_{P,E})$ for $\lambda_P$-almost every $r$, $g_\eta\in L^1((0,\infty),\mathcal{L},\lambda_P)$ for $\sigma_{P,E}$-almost every $\eta$, and Equations \eqref{eq:Fubini1} and \eqref{eq:Fubini2} hold.
\end{enumerate}
\end{theorem}

\noindent Our primary goal in this subsection is to prove the theorem below. We note that Properties \ref{item:MainIntegrationFormula1} and \ref{item:MainintegrationFormula2} in Theorem \ref{thm:MainIntegrationFormula} differ only from Properties \ref{property:BestPointIsomorphism} and \ref{property:BestIntegrationFormula} in Theorem \ref{thm:BestIntegrationFormula} in that, a priori, the $\sigma$-algebra $\Sigma_{P,E}$ and the measure $\sigma_{P,E}$ in Theorem \ref{thm:MainIntegrationFormula} depends on our choice of $E\in\Exp(P)$. As a consequence of Theorem \ref{thm:MainIntegrationFormula}, we shall see in Subsection \ref{subsec:IndependentofE} that $\Sigma_{P,E_1}=\Sigma_{P,E_2}$ and $\sigma_{P,E_1}=\sigma_{P,E_2}$ for all $E_1,E_2\in\Exp(P)$ and so this apparent dependence is superficial; this is Proposition \ref{prop:Endependence}. As a consequence of the proposition, we shall obtain Properties \ref{property:BestPointIsomorphism} and \ref{property:BestIntegrationFormula} of Theorem \ref{thm:BestIntegrationFormula} immediately from Properties of \ref{item:MainIntegrationFormula1} and \ref{item:MainintegrationFormula2} in Theorem \ref{thm:MainIntegrationFormula}.


\begin{theorem}\label{thm:MainIntegrationFormula}
Let $((0,\infty)\times S,(\mathcal{L}\times\Sigma_E)',\lambda_P\times\sigma_{P,E})$ be as above and let $m$ be the (restricted) Lebesgue measure on $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d)$.
\begin{enumerate}
\item\label{item:MainIntegrationFormula1} The map $\psi_E: (0,\infty)\times S\to\mathbb{R}^d\setminus\{0\}$, defined by \eqref{eq:Homeomorphism}, is a point isomorphism of the measure spaces $((0,\infty)\times S,(\mathcal{L}\times\Sigma_E)',\lambda_P\times\sigma_{P,E})$ and $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d,m)$. That is
\begin{equation*}
\mathcal{M}_d=\{A\subseteq \mathbb{R}^d\setminus\{0\}:\psi_E^{-1}(A)\in(\mathcal{L}\times\Sigma_E)'\}
\end{equation*}
and, for each $A\in\mathcal{M}_d$,
\begin{equation*}
m(A)=(\lambda_P\times\sigma_{P,E})(\psi_E^{-1}(A)).
\end{equation*}
\item\label{item:MainintegrationFormula2} If $f:\mathbb{R}^d\to\mathbb{C}$ is Lebesgue measurable, then $f\circ \psi_E$ is $(\mathcal{L}\times\Sigma_E)'$-measurable and the following statements hold:
\begin{enumerate}
\item If $f\geq 0$, then
\begin{equation}\label{eq:MainIntegrationFormula}
\int_{\mathbb{R}^d}f(x)\,dx=\int_0^\infty\left(\int_S f(r^E\eta)\,\sigma_{P,E}(d\eta)\right)r^{\mu_P-1}\,dr=\int_S\left(\int_0^\infty f(r^E\eta)r^{\mu_P-1}\,dr\right)\,\sigma_{P,E}(d\eta).
\end{equation}
\item When $f$ is complex-valued, we have 
\begin{equation*}f\in L^1(\mathbb{R}^d)\hspace{.5cm}\mbox{if and only if}\hspace{0.5cm}f\circ\psi_E\in L^1((0,\infty)\times S,(\mathcal{L}\times \Sigma_E)',\lambda_P\times\sigma_{P,E})
\end{equation*}
and, in this case, \eqref{eq:MainIntegrationFormula} holds.
\end{enumerate}
\end{enumerate}
\end{theorem}

\noindent To prove Theorem \ref{thm:MainIntegrationFormula}, we shall first treat several lemmas. These lemmas isolate and generalize several important ideas used in standard proofs of \eqref{eq:StandardPolarIntegrationFormula} (See, e.g., \cite{Folland1984} and \cite{Stein2005}). 

\begin{lemma}\label{lemma:Scaling}
Let $A\subseteq\mathbb{R}^d$ and $r>0$.  $A$ is Lebesgue measurable if and only if $r^E A=\{x=r^E a:a\in A\}$ is Lebesgue measurable and, in this case,
\begin{equation*}
m(r^E A)=r^{\mu_P}m(A).
\end{equation*}
\end{lemma}
%The linear isomorphism thing is standard. For reference it is Theorem 2.20 of \cite{Rudin1987}.
\begin{proof}
Because $x\mapsto r^E x$ is a linear isomorphism, $r^E A$ is Lebesgue measurable if and only if $A$ is Lebesgue measurable. Observe that $x\in r^E A$ if and only if $r^{-E}x\in A$ and therefore
\begin{equation*}
m(r^E A)=\int_{\mathbb{R}^d}\chi_{r^E A}(x)\,dx=\int_{\mathbb{R}^d}\chi_{A}(r^{-E}x)\,dx
\end{equation*}
where $\chi_{r^EA}$ and $\chi_{A}$ respectively denote the indicator functions of the sets $r^EA$ and $A$. Now, by making the linear change of variables $x\mapsto r^E x$, we have
\begin{equation*}
m(r^E A)=\int_{\mathbb{R}^d}\chi_A(x)|\det(r^E)|\,dx=r^{\mu_P}m(A),
\end{equation*}
because $\det(r^E)=r^{\tr E}=r^{\mu_P}>0$ by virtue of Proposition \ref{prop:ContinuousGroupProperties} and Corollary \ref{cor:TraceisInvariant}.
\end{proof}

\begin{lemma}\label{lem:SpecialRectangle}
Let $F\in\Sigma_E$. If $I\subseteq (0,\infty)$ is open, closed, $G_\delta$, or $F_\sigma$, then $\psi_E(I\times F)\in\mathcal{M}_d$ and
\begin{equation}\label{eq:SpecialRectangle}
m(\psi_E(I\times F))=(\lambda_P\times\sigma_{P,E})(I\times F)=\lambda_P(I)\sigma_{P,E}(F).
\end{equation}
\end{lemma}
\begin{proof}
To simplify notation, we shall write $\lambda=\lambda_P$ and $\sigma=\sigma_{P,E}$ throughout the proof. We fix $F\in\Sigma_E$ and consider several cases for $I$.

\begin{subproof}[Case 1:]\textit{$I=(0,b)$ for $0<b\leq \infty$.} When $b$ is finite, observe that
\begin{equation*}
\psi_E(I\times F)=\{r^E\eta:0<r<b,\eta\in F\}=b^E\{r^E\eta:0<r<1,\eta \in F\}=b^E\widetilde{F_E}.
\end{equation*}
By virtue of Lemma \ref{lemma:Scaling}, it follows that $\psi_E(I\times F)\in\mathcal{M}_d$ and
\begin{eqnarray*}
(\lambda\times\sigma)(I\times F)&=&\lambda(I)\sigma(F)\\
&=&\left(\int_0^b r^{\mu_P-1}\,dr\right)\left(\mu_P\cdot m(\widetilde{F_E})\right)\\
&=&b^{\mu_P}m(\widetilde{F_E})\\
&=&m(b^{E}\widetilde{F_E})\\
&=&m(\psi_E(I\times F)).
\end{eqnarray*}
When $b=\infty$ i.e., $I=(0,\infty)$, we observe that
\begin{equation*}
I=\bigcup_{n=1}^\infty (0,n)=\bigcup_{n=1}^\infty I_n
\end{equation*}
where the open intervals $I_n=(0,n)$ are nested and increasing. In view of the result above (for finite $b=n$), we have
\begin{equation*}\psi_E(I\times F)=\psi_E\left(\bigcup_{n=1}^\infty (I_n\times F)\right)=\bigcup_{n=1}^\infty\psi_E(I_n\times F)\in\mathcal{M}_d.
\end{equation*}
Given that $\psi_E$ is a bijection, $\{\psi_E(I_n\times F)\}$ is necessarily a nested increasing sequence and so, by the continuity of the measures $\lambda\times\sigma$ and $m$,
\begin{equation*}
(\lambda\times\sigma)(I\times F)=\lim_{n\to\infty}(\lambda\times\sigma)(I_n\times F)=\lim_{n\to\infty}m(\psi_E(I_n\times F))= m(\psi_E(I\times F)). 
\end{equation*}
\end{subproof}

\begin{subproof}[Case 2:]\textit{$I=(0,a]$ for $0<a<\infty$.} We have
\begin{equation*}
I=(0,a]=\bigcap_{n=1}^\infty (0,a+1/n)=\bigcap_{n=1}^\infty I_n
\end{equation*}
where the open intervals $I_n=(0,a+1/n)$ are nested and decreasing. By reasoning analogous to that given in Case 1, we have
\begin{equation*}
\psi_E(I\times F)=\bigcap_{n=1}^\infty \psi_E(I_n\times F)\in \mathcal{M}_d
\end{equation*}
and
\begin{equation*}
(\lambda\times\sigma)(I\times F)=\lim_{n\to\infty}(\lambda\times\sigma)(I_n\times F)=\lim_{n\to\infty}m(\psi_E(I_n\times F))=m(\psi_E(I\times F)).
\end{equation*}
In particular, $m(\psi_E(I\times F))=\lambda((0,a])\sigma(F)=a^{\mu_P}\sigma(F)/\mu_P<\infty.$
\end{subproof}
\begin{subproof}[Case 3:]\textit{$I=(a,b)$ for $0<a<b\leq \infty$.} In this case, $I=(0,b)\setminus (0,a]$ and so, in view of Cases 1 and 2, $\psi_E(I\times F)=\psi_E((0,b)\times F)\setminus \psi_E((0,a]\times F)\in\mathcal{M}_d$ and
\begin{eqnarray*}
(\lambda\times\sigma)(I\times F)&=&(\lambda\times\sigma)( (0,b)\times F)-(\lambda\times\sigma)((0,a]\times F)\\
&=&m(\psi_E((0,b)\times F))-m(\psi_E((0,a]\times F))\\
&=&m(\psi_E(I\times F))
\end{eqnarray*}
where we have used the fact that $(\lambda\times\sigma)((0,a]\times F)=m(\psi_E((0,a]\times F))<\infty$.
\end{subproof}
\begin{subproof}[Case 4:]\textit{$I\subseteq (0,\infty)$ is open.} In this case, it is known that $I$ can be expressed as a countable union of disjoint open intervals $\{I_n\}$ and, by virtue of Cases 1 and 3, we have
\begin{equation*}
\psi_E(I\times F)=\bigcup_{n=1}^\infty\psi_E(I_n\times F)\in\mathcal{M}_d,
\end{equation*}
where this union is disjoint, and
\begin{eqnarray*}
\lefteqn{\hspace{-1cm}m(\psi_E(I\times F))=\sum_n m(\psi_E(I_n\times F))=\sum_n (\lambda\times\sigma)(I_n\times F)}\\
&&\hspace{2cm}=\sum_n \lambda(I_n)\sigma(F)=\left(\sum_n \lambda(I_n)\right)\sigma(F)=\lambda(I)\sigma(F)=(\lambda\times\sigma)(I\times F).
\end{eqnarray*}
\end{subproof}
\begin{subproof}[Case 5:]\textit{$I\subseteq (0,\infty)$ is closed.} In this case, we have $I=(0,\infty)\setminus O$ where $O$ is open and so
\begin{equation*}
\psi_E(I\times F)=\psi_E(F\times ((0,\infty)\setminus O))=\psi_E( (0,\infty)\times F)\setminus \psi_E(O\times F)\in\mathcal{M}_d.
\end{equation*}
At this point, we'd like to use the property that 
\begin{equation*}
m(\psi_E((0,\infty)\times F)\setminus \psi_E( O\times F))=m(\psi_E((0,\infty)\times F))-m(\psi_E(O\times F)),
\end{equation*} but this only holds when $m(\psi_E(O\times F))$ is finite. We must therefore proceed differently. For each natural number $n$, define $O_n=O\cap(0,n)$ and $I_n=(0,n)\setminus O_n$. It is straightforward to show that $\{I_n\}$ and $\{\psi_E(I_n\times F)\}$ are nested and increasing with
\begin{equation*}
I=\bigcup_{n=1}^\infty I_n\hspace{1cm}\mbox{and}\hspace{1cm}\psi_E(I\times F)=\bigcup_{n=1}^\infty \psi_E(I_n\times F). 
\end{equation*}
The results of Cases 1 and 4 guarantee that, for each $n$,
\begin{equation*}
m(\psi_E(O_n\times F))=(\lambda\times\sigma)(O_n\times F)\leq (\lambda\times\sigma)((0,n)\times F)<n^{\mu_P}m(\widetilde{F_E})<\infty
\end{equation*}
and therefore
\begin{equation*}
m(\psi_E(I_n\times F))=m(\psi_E((0,n)\times F))-m(\psi_E(O_n\times F))=(\lambda\times\sigma)((0,n)\times F)-(\lambda\times\sigma)(O_n\times F)=(\lambda\times\sigma)(I_n\times F).
\end{equation*}
Then, by virtue of the continuity of measure,
\begin{equation*}
m(\psi_E(I\times F))=\lim_{n\to\infty}m(\psi_E(I_n\times F))=\lim_{n\to\infty}(\lambda\times\sigma)(I_n\times F)=(\lambda\times\sigma)(I\times F). 
\end{equation*}
\end{subproof}
\begin{subproof}[Case 6]\textit{$I\subseteq (0,\infty)$ is $G_\delta$ or $F_\sigma$.} Depending on whether $I$ is $G_\delta$ or $F_\sigma$,  express $I$ as an intersection of nested decreasing open sets or a union of nested increasing closed sets. In both cases, by virtually the same argument given in the previous cases, we find that $\psi_E(I\times F)\in \mathcal{M}_d$,
\begin{equation*}
m(\psi_E(I\times F))=(\lambda\times\sigma)(I\times F).
\end{equation*}
\end{subproof}
\end{proof}

\begin{comment}\textcolor{blue}{\begin{remark}
Huan, the analogous result to the following lemma is in the first paragraph on Page 281 of \cite{Stein2005} and is in the sentence preceding ``So we have established (10) for all measurable rectangles..." Truthfully, I don't follow their argument and, actually, I don't quite believe it. When checking it, you should verify carefully the claims made in the first few sentences.
\end{remark}}
\end{comment}
\begin{lemma}\label{lem:AllMeasurableRectangles} For any $L\in\mathcal{L}$ and $F\in \Sigma_{P,E}$, $\psi_E(L\times F)\in\mathcal{M}_d$ and 
\begin{equation*}
m(\psi_E(L\times F))=(\lambda_P\times\sigma_{P,E})(L\times F).
\end{equation*}
\end{lemma}
\begin{proof}
Fix $L\in\mathcal{L}$ and $F\in\Sigma_E$. It is easy to see that $\lambda_P$ and the Lebesgue measure $dr$ on $(0,\infty)$ are mutually absolutely continuous. It follows that $((0,\infty), \mathcal{L},\lambda_P)$ is a complete measure space and, further, that there exists an $F_\sigma$ set $L_\sigma\subseteq (0,\infty)$ and a $G_\delta$ set $L_\delta\subseteq (0,\infty)$ for which $L_\sigma\subseteq L\subseteq L_\delta$ and $\lambda_P(L_\delta\setminus L_\sigma)=0$. Note that, necessarily, $\lambda_P(L)=\lambda_P(L_\sigma)=\lambda_P(L_\delta)$. We have
\begin{equation}\label{eq:AllMeasurableRectangles1}
\psi_E(L\times F)=\psi_E( L_\sigma\times F)\cup\psi_E((L\setminus L_\sigma)\times F)
\end{equation}
where, by virtue of the preceding lemma, $\psi_E(L_\sigma\times F)\in \mathcal{M}_d$ and
\begin{equation}\label{eq:AllMeasurableRectangles2}
m(\psi_E(L_{\sigma}\times F))=(\lambda_P\times\sigma_{P,E})( L_\sigma\times F)=\lambda_P(L_\sigma)\sigma_{P,E}(F)=\lambda_P(L)\sigma_{P,E}(F)=(\lambda_P\times\sigma_{P,E})(L\times F).
\end{equation}
Observe that
\begin{equation*}
\psi_E((L\setminus L_\sigma)\times F)\subseteq \psi_E((L_{\delta}\setminus L_\sigma)\times F)
\end{equation*}
where, because $L_\delta\setminus L_\sigma$ is an $G_{\delta}$ set, the latter set is a member of $\mathcal{M}_d$ and
\begin{equation*}
m(\psi_E((L_\delta\setminus L_\sigma)\times F))=(\lambda_P\times\sigma_{P,E})((L_\delta\setminus L_\sigma)\times F)=\lambda_P(L_\delta\setminus L_\sigma))\sigma_{P,E}(F)=0
\end{equation*}
by virtue of the preceding lemma. Using the fact that $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d,m)$ is complete, we conclude that $\psi_E((L\setminus L_\sigma)\times F)\in \mathcal{M}_d$ and $m(\psi_E((L\setminus L_\sigma)\times F))=0$. It now follows from \eqref{eq:AllMeasurableRectangles1} and \eqref{eq:AllMeasurableRectangles2} that $\psi_E(L\times F)\in\mathcal{M}_d$ and
\begin{equation*}
m(\psi_E(L\times F))=m(\psi_E(L_\sigma\times F))+m(\psi_E((L\setminus L_\sigma)\times F))=(\lambda_P\times\sigma_{P,E})(L\times F),
\end{equation*}
as desired.
\end{proof}

\begin{comment}\noindent \textcolor{blue}{As it is fairly elementary, I've commented out the lemma showing that $S$, as a compact set of a metric space, necessarily contains a countably dense set. If this appears in your thesis, you should feel free to include the lemma}
\end{comment}
%\begin{lemma}
%Let $S$ be a compact subset of a metric space. Then $S$ contains a countably dense set.
%\end{lemma}
%\begin{proof}
%For each $n\in\mathbb{N}$, consider the open cover
%\begin{equation*}
%\{B_{1/n}(x)\cap S, x\in S\}
%\end{equation*}
%of $S$. Since $S$ is compact, there exists a finite subcover. Let $x_{j,n}$, $j=1,2,\dots N_n$ denote the center of each of the balls, then, we have that $S$ is covered by $\{B_{1/n}(x_{j,n})\cap S,j=1,2,\dots, N_n\}$. Thus, for each $n\in \mathbb{N}$, we have a finite set $\{x_{j,n}\}$ of centers. The countable union of these finite sets, $\bigcup^\infty_{n=1} \{ x_{j,n}\}$, is countable. It is also dense because for every point $x\in S$ and $\epsilon >0$, there is always some $n$ such that $\vert x_{j,n} - x\vert < 1/n < \epsilon$.  
%\end{proof}


\begin{lemma}\label{lem:OpenRectangle}
Every open subset $U\subseteq \mathbb{R}^d\setminus\{0\}$ can be written as a countable union of open sets of the form $\psi_E(\mathcal{U})$ where $\mathcal{U}=I\times\mathcal{O}$ is an open rectangle in $(0,\infty)\times S$.
\end{lemma}


\begin{proof}
Let $\{r_k\}_{k=1}^\infty$ be a countably dense subset of $(0,\infty)$ and, because $S$ is compact, $S$ has a countably dense set $\{\eta_j\}_{j=1}^\infty$.  For each triple of natural numbers $j,l,n\in\mathbb{N}_+$, consider the open set
\begin{equation*}
\mathcal{U}_{j,l,n}=\{ \vert r - r_j \vert < 1/n \}\times \mathcal{O}_{l,n}\subseteq (0,\infty)\times S
\end{equation*}
where
\begin{equation*}
\mathcal{O}_{l,n}=\{\eta\in S: |\eta-\eta_l|<1/n\}.
\end{equation*}
Fix $U\subseteq \mathbb{R}^d\setminus \{0\}$, an open subset of $\mathbb{R}^d\setminus\{0\}$. We will show that
\begin{equation}\label{eq:OpenRectangle}
U=\bigcup_{\substack{j,l,n\\ \psi_E(\mathcal{U}_{j,l,n})\subseteq U}}\psi_E(\mathcal{U}_{j,l,n}),
\end{equation}
where, in view of Proposition \ref{prop:PsiHomeomorphism}, each $\psi_E(\mathcal{U}_{j,l,n})$ is open. It is clear that any element of the union on the right hand side of \eqref{eq:OpenRectangle} belongs to some $\psi_E(\mathcal{U}_{j,l,n}) \subseteq U$ and so the union is a subset of $U$. To prove \eqref{eq:OpenRectangle}, it therefore suffices to prove that, for each $x\in U$, there exists a triple $j,l,n$ with
\begin{equation*}
x\in\psi_E(\mathcal{U}_{j,l,n})\subseteq U.
\end{equation*}
To this end, fix $x\in U$ and let $\delta>0$ be such that $\mathbb{B}_\delta(x)\subseteq U$. Consider $(r_x,\eta_x)=\psi_E^{-1}(x)\in (0,\infty)\times S$ and set $M=\|r_x^E\|>0$ and $C=\|E\|>0$. Observe that 
\begin{equation*}
\|I-\alpha^E\|=\left\|\sum_{k=1}^\infty \frac{(\ln \alpha)^k}{k!} E^k\right\|\leq \sum_{k=1}^\infty \frac{|\ln \alpha|^k}{k!} \|E\|^k=e^{(C|\ln \alpha|)}-1
\end{equation*}
for all $\alpha>0$. Since $\alpha\mapsto e^{(C|\ln \alpha|)}-1$ is continuous and $0$ at $\alpha=1$, we can choose $\delta'>0$ for which
\begin{equation*}
\|I-\alpha ^E\|< \frac{\delta}{2M (  |\eta_x|+2)}
\end{equation*}
whenever $|\alpha-1|<\delta'$. Choose an integer
\begin{equation*}
n>\max \left\{\frac{1}{\delta'r_x}, \frac{4 M }{\delta}\right\}.
\end{equation*}
In view of the density of the collections $\{r_j\}$ and $\{\eta_l\}$, we can find $r_j, \eta_l$ such that
\begin{equation*}
    \vert r_j - r_x \vert < \frac{1}{n},\quad \vert \eta_l - \eta_x \vert < \frac{1}{n}.
\end{equation*}
It follows that the corresponding open set $\mathcal{U}_{j,l,n}$ contains $\psi_E^{-1}(x)$, or, equivalently, $x\in \psi_E(\mathcal{U}_{j,l,n})$. Thus, it remains to show that $\psi_E(\mathcal{U}_{j,l,n}) \subseteq \mathbb{B}_\delta(x)$. To this end, let $y=\psi_E(r_y,\eta_y,)\in\psi_E(\mathcal{U}_{j,l,n})$ and observe that
\begin{eqnarray*}
| x - y | &\leq& \vert \psi_E(r_x,\eta_x,) - \psi_E(r_x,\eta_y) \vert 
    + \vert \psi_E(r_x,\eta_y) - \psi_E(r_y,\eta_y) \vert\\
    &=&  \vert r_x^E (\eta_x - \eta_y) \vert + \vert (r_x^E - r_y^E) \eta_y \vert\\
    &\leq& M\vert \eta_x - \eta_y \vert + \|{r_x^E - r_y^E}\|  \vert \eta_y \vert.
\end{eqnarray*}
Since both $(\eta_x,r_x),(\eta_y,r_y) \in \mathcal{U}_{j,l,n}$, we have
\begin{equation*}
    \vert \eta_x - \eta_y \vert \leq \vert \eta_x - \eta_j \vert + \vert \eta_j - \eta_y \vert < \frac{2}{n}
\end{equation*}
and
\begin{equation*}
    \vert \eta_y \vert \leq \vert \eta_y - \eta_x \vert + \vert \eta_x \vert < \vert \eta_x \vert + \frac{2}{n}.
\end{equation*}
Also, since $|r_x-r_y|<1/n$, it follows that $r_y=\alpha r_x$ where $|1-\alpha|<1/nr_x < \delta'$ by our choice of $n$. Consequently,
\begin{eqnarray*}
    \vert x - y \vert 
    &< & \frac{2}{n} M+ \left( \vert \eta_x \vert + \frac{2}{n} \right) \|{r_x^E -  r_x^E \alpha^E}\|   \\ 
    &<& \frac{2}{n}M + \left( \vert \eta_x \vert + 2 \right)M\| I - \alpha^E\| \\
    &<&  \frac{2}{n}M +  \frac{\delta M \left( \vert \eta_x \vert + 2\right) }{2M (| \eta_x | + 2)}  \\
    &<& \frac{\delta}{2} + \frac{\delta}{2}=\delta 
\end{eqnarray*}
and so we have established \eqref{eq:OpenRectangle}. Finally, upon noting that $\{\mathcal{U}_{j,l,n})\}$ is a countable collection of open rectangles (indexed by $(j,l,n)\in\mathbb{N}_+^3$), the union in \eqref{eq:OpenRectangle} is necessarily countable and we are done with the proof.
\end{proof}

\begin{comment}\noindent \textcolor{blue}{The following is a (graduate level) homework-exercise worthy lemma. You should try to prove it yourself before you read the proof. Though it is somewhat difficult (to state and prove -- for me, at least), it is abstract enough that I suspect it is fairly well-known and we should look for a reference.}
\end{comment}

\noindent In our final lemma preceding the proof of Theorem \ref{thm:MainIntegrationFormula}, we treat a general measure-theoretic statement which gives sufficient conditions concerning two measure spaces to ensure that their completions are isomorphic. Though we suspect that this result is well-known, we present its proof for completeness.

\begin{lemma}\label{lem:PushforwardLemma}
Let $(X_1,\Sigma_1,\nu_1)$ and $(X_2,\Sigma_2,\nu_2)$ be measure spaces, let $\varphi:X_1\to X_2$ be a bijection and denote by $(X_i,\Sigma_i',\nu_i')$ the completion of the measure space $(X_i,\Sigma_i,\nu_i)$ for $i=1,2$. Assume that the following two properties are satisfied:
\begin{enumerate}
\item\label{property:PushforwardLemma1} For each $A_1\in\Sigma_1$, $\varphi(A_1)\in\Sigma_2'$ and $\nu_2'(\varphi(A_1))=\nu_1(A_1).$
\item\label{property:PushforwardLemma2} For each $A_2\in\Sigma_2$, $\varphi^{-1}(A_2)\in \Sigma_1'$ and $\nu_1'(\varphi^{-1}(A_2))=\nu_2(A_2)$.
\end{enumerate}
Then the measure spaces $(X_1,\Sigma_1',\nu_1')$ and $(X_2,\Sigma_2',\nu_2')$ are isomorphic with point isomorphism $\varphi$. Specifically,
\begin{equation}\label{eq:PushforwardLemma1}
\Sigma_2'=\{A_2\subseteq X_2: \varphi^{-1}(A_2)\in\Sigma_1'\}
\end{equation}
and
\begin{equation}\label{eq:PushforwardLemma2}
\nu_2'(A_2)=\nu_1'(\varphi^{-1}(A_2))
\end{equation}
for all $A_2\in\Sigma_2'$.
\end{lemma}
\begin{proof}
Let us first assume that $A_2\in\Sigma_2'$. By definition, $A_2=G_2\cup H_2$ where $G_2\in\Sigma_2$ and $H_2\subseteq G_{2,0}\in \Sigma_2$ with $\nu_2'(A_2)=\nu_2(G_2)$ and $\nu_2'(H_2)=\nu_2(G_{2,0})=0$. Consequently, $\varphi^{-1}(A_2)=\varphi^{-1}(G_2)\cup\varphi^{-1}(H_2)$ and $\varphi^{-1}(H_2)\subseteq \varphi^{-1}(G_{2,0})$. In view of Property \ref{property:PushforwardLemma2}, $\varphi^{-1}(G_2),\varphi^{-1}(G_{2,0})\in \Sigma_1'$ and we have
\begin{equation*}
\nu_1'(\varphi^{-1}(G_2))=\nu_2(G_2)=\nu_2'(A_2)\hspace{1cm}\mbox{and}\hspace{1cm}\nu_1'(\varphi^{-1}(G_{2,0}))=\nu_2(G_{2,0})=0.
\end{equation*}
In view of the fact that $(X_1',\Sigma_1',\nu_1')$ is complete, $\varphi^{-1}(H_2)\in\Sigma_1'$ and $\nu_1'(\varphi^{-1}(H_2))=0$. Consequently, we obtain $\varphi^{-1}(A_2)=\varphi^{-1}(G_2)\cup\varphi^{-1}(H_2)\in\Sigma_1'$ and
\begin{equation*}
\nu_2'(A_2)=\nu_1'(\varphi^{-1}(G_2))\leq\nu_1'(\varphi^{-1}(A_2))\leq\nu_1'(\varphi^{-1}(G_2))+\nu_1'(\varphi^{-1}(H_2))=\nu_2(G_2)+0=\nu_2'(A_2).
\end{equation*}
From this we obtain that $\Sigma_2'\subseteq \{A_2\subseteq X_2:\varphi^{-1}(A_2)\in\Sigma_1'\}$ and, for each $A_2\in\Sigma_2'$, $\nu_2'(A_2)=\nu_1'(\varphi^{-1}(A_2))$. It remains to prove that
\begin{equation*}
\{A_2\subseteq X_2:\varphi^{-1}(A_2)\in\Sigma_1'\}\subseteq \Sigma_2'.
\end{equation*}
To this end, let $A_2$ be a subset of $X_2$ for which $\varphi^{-1}(A_2)\in\Sigma_1'$. By the definition of $\Sigma_1'$, we have $\varphi^{-1}(A_2)=G_1\cup H_1$ where $G_1\in\Sigma_1$, $H_1\subseteq G_{1,0}\in\Sigma_1$ and $\nu_1'(H_1)=\nu_1(G_{1,0})=0$. In view of Property \ref{property:PushforwardLemma1}, $\varphi(G_1)\in\Sigma_2'$, $\varphi(H_1)\subseteq\varphi(G_{1,0})\in\Sigma_2'$ and $\nu_2'(\varphi(G_{1,0}))=\nu_1(G_{1,0})=0$. Because $(X_2',\Sigma_2',\nu_2')$ is complete, we have $\varphi(H_1)\in\Sigma_2'$ and so
\begin{equation*}
A_1=\varphi(\varphi^{-1}(A_2))=\varphi(G_1)\cup\varphi(H_1)\in \Sigma_2',
\end{equation*}
as desired.
\end{proof}

\noindent We are finally in a position to prove Theorem \ref{thm:MainIntegrationFormula}.

\begin{comment}\noindent\textcolor{blue}{Huan, my use of the monotone class lemma below avoids the method in \cite{Stein2005} which relies on Theorem 3.3 (of \cite{Stein2005}) and sweeps some things under the carpet.}
\end{comment}

\begin{proof}[Proof of Theorem \ref{thm:MainIntegrationFormula}]
Denote by $\mathcal{C}$ the collection of sets $G\subseteq (0,\infty)\times S$ for which $\psi_E(G)\in \mathcal{M}_d$ and $m(\psi_E(G))=(\lambda_P\times\sigma_{P,E})(G).$ By virtue of Lemma \ref{lem:AllMeasurableRectangles}, it follows that $\mathcal{C}$ contains all elementary sets, i.e., finite unions of disjoint measurable rectangles. Using the continuity of measure (applied to the measures $m$ and $\lambda_P\times\sigma_{P,E}$) and the fact that $\psi_E$ is a bijection, it is straightforward to verify that $\mathcal{C}$ is a monotone class. By the monotone class lemma (Theorem 8.3 of \cite{Rudin1987}), it immediately follows that $\mathcal{L}\times\Sigma_E\subseteq\mathcal{C}$. In other words, for each $G\in\mathcal{L}\times\Sigma_E$,
\begin{equation}\label{eq:Good1}
\psi_E(G)\in\mathcal{M}_d\hspace{1cm}\mbox{and}\hspace{1cm}m(\psi_E(G))=(\lambda_P\times\sigma_{P,E})(G).
\end{equation}
We claim that, for each Borel subset $A$ of $\mathbb{R}^d\setminus\{0\}$, $\psi_E^{-1}(A)\subseteq \mathcal{L}\times\Sigma_E$. To this end, we write
\begin{equation*}
\psi_E(\mathcal{L}\times\Sigma_E)=\{\psi_E(G):G\in\mathcal{L}\times\Sigma_E\}
\end{equation*}
for the $\sigma$-algebra on $\mathbb{R}^d\setminus\{0\}$ induced by $\psi_E$. In view of Lemma \ref{lem:OpenRectangle}, $\psi_E(\mathcal{L}\times\Sigma_E)$ contains every open subset of $\mathbb{R}^d\setminus\{0\}$ and therefore
\begin{equation*}
\mathcal{B}(\mathbb{R}^d\setminus\{0\})\subseteq\psi_E(\mathcal{L}\times\Sigma_E).
\end{equation*}
where $\mathcal{B}(\mathbb{R}^d\setminus\{0\})$ denotes the $\sigma$-algebra of Borel subsets of $\mathbb{R}^d\setminus\{0\}$ thus proving our claim. 

Together, the results of the two preceding paragraphs show that, for each $A\in\mathcal{B}(\mathbb{R}^d\setminus\{0\})$, $\psi_E^{-1}(A)\subseteq \mathcal{L}\times\Sigma_E$ and $m(A)=(\lambda_P\times\sigma_{P,E})(\psi_E^{-1}(A))$. Upon noting that $\mathcal{L}\times\Sigma_E\subseteq (\mathcal{L}\times\Sigma_E)'$, we immediately obtain the following statement: For each $A\in\mathcal{B}(\mathbb{R}^d\setminus\{0\})$,
\begin{equation}\label{eq:Good2}
\psi_E^{-1}(A)\in (\mathcal{L}\times\Sigma_E)'\hspace{1cm}\mbox{and}\hspace{1cm}m(A)=(\lambda_P\times\sigma_{P,E})(\psi_E^{-1}(A)).
\end{equation}
In comparing \eqref{eq:Good1} and \eqref{eq:Good2} with Properties \ref{property:PushforwardLemma1} and \ref{property:PushforwardLemma2} of Lemma \ref{lem:PushforwardLemma} and, upon noting that $((0,\infty)\times S,(\mathcal{L}\times\Sigma_E)',\lambda_P\times\sigma_{P,E})$ is the completion of $((0,\infty)\times S,\mathcal{L}\times\Sigma_E,\lambda_P\times\sigma_{P,E})$ and $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d,m)$ is the completion of $(\mathbb{R}^d\setminus\{0\},\mathcal{B}(\mathbb{R}^d\setminus\{0\}),m)$, Property \ref{item:MainIntegrationFormula1} of Theorem \ref{thm:MainIntegrationFormula} follows immediately from Lemma \ref{lem:PushforwardLemma}.

It remains to prove Property \ref{item:MainintegrationFormula2}. To this end, let $f:\mathbb{R}^d\to\mathbb{C}$ be Lebesgue measurable. Because $\mathcal{M}_d=\{A\subseteq \mathbb{R}^d\setminus\{0\}:\psi_E^{-1}(A)\in(\mathcal{L}\times\Sigma_E)'\}$, it follows that $f\circ\psi_E$ is $(\mathcal{L}\times\Sigma_E)'$-measurable. In the case that $f\geq 0$, we may approximate $f$ monotonically by simple functions and, by invoking Property \ref{item:MainIntegrationFormula1} and the monotone convergence theorem, we find that
\begin{equation}\label{eq:ChangeofMeasure}
\int_{\mathbb{R}^d}f(x)\,dx=\int_{\mathbb{R}^d\setminus \{0\}}f(x)\,dx=\int_{(0,\infty)\times S}f\circ \psi_E\, d(\lambda_P\times\sigma_{P,E}).
\end{equation}
From this, \eqref{eq:MainIntegrationFormula} follows from Item \ref{item:Fubini1} in Theorem \ref{thm:Fubini}. Finally, by applying the above result to $|f|\geq 0$, we obtain $f\in L^1(\mathbb{R}^d)$ if and only if $f\circ \psi_E\in L^1((0,\infty)\times S,(\mathcal{L}\times\Sigma_E)',\lambda_P\times\sigma_{P,E})$. In this case, by applying \eqref{eq:ChangeofMeasure} to $\Re(f)_+,\Re(f)_-,\Im(f)_+$ and $\Im(f)_-$, we find that \eqref{eq:ChangeofMeasure} holds for our integrable $f$ and, by virtue of Item  \ref{item:Fubini2} of Theorem \ref{thm:Fubini}, the desired result follows.
\end{proof}

\noindent Our next result, Proposition \ref{prop:Regular}, guarantees that, in particular, $\sigma_{P,E}$ is a Radon measure. 

\begin{proposition}\label{prop:Regular}
We have:
\begin{enumerate}
    \item\label{item:Complete} $(S,\Sigma_E,\sigma_{P,E})$ is the completion of the measure space $(S,\mathcal{B}(S),\sigma_{P,E})$. In particular, the $(S,\Sigma_E,\sigma_{P,E})$ is complete and every $F\in \Sigma_E$ is of the form $F=G\cup H$ where $G$ is a Borel set and $H$ is a subset of a Borel set $Z$ with $\sigma_{P,E}(Z)=0$.
\item\label{item:Regular} For each $F\in\Sigma_E$,
\begin{equation}\label{eq:OuterRegular}
\sigma_{P,E}(F)=\inf\{\sigma_{P,E}(\mathcal{O}):F\subseteq\mathcal{O}\subseteq S\mbox{ and $\mathcal{O}$ is open}\}
\end{equation}
and
\begin{equation}
\sigma_{P,E}(F)=\sup\{\sigma_{P,E}(K):K\subseteq F\subseteq S\mbox{ and $K$ is compact}\}.
\end{equation}
\end{enumerate} 
\end{proposition}
\begin{remark}
This proposition can be seen as an application of Proposition \ref{prop:BorelContainment} and Theorem 2.18 of \cite{Rudin1987}. The proof we give here is distinct and, we believe, nicely illustrates the utility of \eqref{eq:MainIntegrationFormula} of Theorem \ref{thm:MainIntegrationFormula}.
\end{remark}
\begin{proof}
Throughout the proof, we shall write $\sigma=\sigma_{P,E}$, $\Sigma=\Sigma_E$ and, for each $F\subseteq S$, $\widetilde{F}=\widetilde{F_E}$. We remark that, by standard arguments using $G_\delta$ and $F_\sigma$ sets, Item \ref{item:Complete} follows immediately from Item \ref{item:Regular}. Also, given that $S$ is compact and $\sigma$ is finite, it suffices to prove \eqref{eq:OuterRegular}, i.e., it suffices to prove the statement: For each $F\in \Sigma$ and $\epsilon>0$, there is an open subset $\mathcal{O}$ of $S$ containing $F$ for which 
\begin{equation*}
\sigma(\mathcal{O}\setminus F)<\epsilon.
\end{equation*}
To this end, let $F\in \Sigma$ and $\epsilon>0$. Given that $\widetilde{F}\in\mathcal{M}_d$ and $m$ is outer regular, there exists an open set $U\subseteq \mathbb{R}^d\setminus\{0\}$ for which $\widetilde{F}\subseteq U$ and $m(U\setminus\widetilde{F})<\epsilon/(2\mu_P)$. Since $\widetilde{F}$ is a subset of the open set $B\setminus\{0\}$, we may assume without loss of generality that $U\subseteq B\setminus\{0\}$ and so $m(\widetilde{F})\leq m(U)<\infty$ and
\begin{equation}\label{eq:LebesgueOuter}
m(U\setminus \widetilde{F})=m(U)-m(\widetilde{F})<\epsilon/(2\mu_P).
\end{equation}
For each $0<r<1$, consider the open set
\begin{equation*}
\mathcal{O}_r=S\cap\left( r^{-E}U\right)
\end{equation*}
in $S$. Observe that, for each $x\in F$, $r^E x\in \widetilde{F}\subseteq U$ and therefore $x\in \mathcal{O}_t$. Hence, for each $0<r<1$, $\mathcal{O}_r$ is an open subset of $S$ containing $F$. 

We claim that there is at least one $r_0\in (0,1)$ for which 
\begin{equation}\label{eq:GoodIneq}
m(\widetilde{\mathcal{O}_{r_0}})< m(U)+\epsilon/(2\mu_P).
\end{equation}
To prove the claim, we shall assume, to reach a contradiction, that 
\begin{equation*}
m(\widetilde{\mathcal{O}_{r}})\geq m(U)+\epsilon/(2\mu_P)
\end{equation*}
for all $0<r<1$. By virtue of \eqref{eq:MainIntegrationFormula} of Theorem \ref{thm:MainIntegrationFormula},
\begin{equation*}
m(U)=\int_{0}^\infty\left(\int_S \chi_{U}(r^E\eta)\,\sigma(d\eta)\right)r^{\mu_P-1}\,dr.
\end{equation*}
Upon noting that $U\subseteq B\setminus\{0\}$, it is easy to see that
\begin{equation*}
U=\bigcup_{0<s<1}s^E\mathcal{O}_s
\hspace{1cm}\mbox{and}\hspace{1cm}
r^E\eta\in \bigcup_{0<s<1}s^E\mathcal{O}_s
\end{equation*}
if and only if $0<r<1$ and $\eta\in \mathcal{O}_r$. Consequently,
\begin{equation*}
m(U)=\int_0^1\left(\int_S\chi_{\mathcal{O}_r}(\eta)\,\sigma(d\eta)\right)\,r^{\mu_P-1}\,dr=\int_0^1\sigma(\mathcal{O}_r)r^{\mu_P-1}\,dr=\int_0^1 \mu_P\cdot m(\widetilde{\mathcal{O}_r})\,r^{\mu_P-1}\,dr.
\end{equation*}
Upon making use of our supposition, we have
\begin{equation*}
\int_0^1\mu_P\cdot m(\widetilde{\mathcal{O}_r})r^{\tr E-1}\,dr\geq \int_0^1\mu_P\cdot (m(U)+\epsilon/(2\mu_P))r^{\mu_P-1}\,dr=m(U)+\epsilon/(2\mu_P)
\end{equation*}
and so
\begin{equation*}
m(U)\geq m(U)+\epsilon/(2\mu_P),
\end{equation*}
which is impossible. Thus, the stated claim is true.

Given any such $r_0$ for which \eqref{eq:GoodIneq} holds, set $\mathcal{O}=\mathcal{O}_{r_0}$. As previously noted, $\mathcal{O}$ is an open subset of $S$ which contains $F$. In view of \eqref{eq:LebesgueOuter} and \eqref{eq:GoodIneq}, we have
\begin{equation*}
m(\widetilde{\mathcal{O}})-m(\widetilde{F})<m(U)-m(\widetilde{F})+\epsilon/(2\mu_P)<\epsilon/(2\mu_P)+\epsilon/(2\mu_P)=\epsilon/\mu_P
\end{equation*}
and therefore
\begin{equation*}
\sigma(\mathcal{O}\setminus F)=\sigma(\mathcal{O})-\sigma(F)=\mu_P(m(\widetilde{\mathcal{O}})-m(\widetilde{F}))<\epsilon,
\end{equation*}
as desired.
\end{proof}


\begin{comment}
\begin{proposition}
The completion of the measure space $(S,\mathcal{B}(S),\sigma_{P,E})$ is $(S,\Sigma_E,\sigma_{P,E})$. In particular, the latter space is complete and every $F\in \Sigma_E$ is of the form $F=G\cup H$ where $G$ is a Borel set and $H$ is a subset of a Borel set $Z$ with $\sigma_{P,E}(Z)=0$.
\end{proposition}


\begin{proof}
For notational simplicity, we shall write $\sigma=\sigma_{P,E}$, $\Sigma=\Sigma_E$ and, for $F\subseteq S$, $\widetilde{F}=\widetilde{F_E}$. Let us denote by $(S,\overline{\mathcal{B}(S)},\overline{\sigma})$ the completion of the measure space $(S,\mathcal{B}(S),\sigma)$. Our job is to show that $\overline{\mathcal{B}(S)}=\Sigma$ and $\overline{\sigma}(F)=\sigma(F)$ for all $F$ in this common $\sigma$-algebra. 

First, let $F\in\overline{\mathcal{B}(S)}$ which is, by definition, a set of the form $F=G\cup H$ where $G\in\mathcal{B}(S)$ with $\overline{\sigma}(F)=\sigma(G)$ and $H\subseteq G_0\in\mathcal{B}(S)$ with $\sigma(G_0)=0$. In view of Proposition \ref{prop:BorelContainment}, $\widetilde{G}\in \mathcal{M}_d$, $\widetilde{H}\subseteq \widetilde{G_0}\in\mathcal{M}_d$ and we have
\begin{equation*}
m(\widetilde{G_0})=\frac{1}{\mu_P}\sigma(G_0)=0
\end{equation*}
Since $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d,m)$ is complete, we conclude that $\widetilde{H}\in\mathcal{M}_d$ with $m(\widetilde{H})=0$ and therefore $H\in\Sigma$ with $\sigma(H)=(\mu_P)m(\widetilde{H})=0$. It follows that $F=G\cup H\in\Sigma$ and
\begin{equation*}
\overline{\sigma}(F)=\sigma(G)\leq \sigma(F)\leq\sigma(G)+\sigma(H)=\sigma(G)+0=\overline{\sigma}(F).
\end{equation*}
It remains only to prove that $\Sigma\subseteq\overline{\mathcal{B}(S)}$. To this end, let $F\in\Sigma$ be arbitrary but fixed. By appealing to Proposition \ref{prop:Regular}, for each integer $n\in\mathbb{N}$, there exists a compact set $F_n\subseteq F$ for which
\begin{equation*}
\sigma(F\setminus F_n)=\sigma(F)-\sigma(F_n)<1/n.
\end{equation*}
Set
\begin{equation*}
G=\bigcup_{n=1}^\infty F_n\subseteq F
\end{equation*}
and $H=F\setminus G$. 
We observe that $G$ is a Borel set (in fact, an $F_\sigma$ set) and
\begin{equation*}
\sigma(H)=\sigma(F)-\sigma(G)=\sigma(F)-\lim_{n\to\infty}\sigma(F_n)=0,
\end{equation*}
by the continuity of measure. We have shown that
\begin{equation*}
F=G\cup H
\end{equation*}
where $G\in\mathcal{B}(S)$ and $H\in\Sigma$ with $\sigma(H)=0$. It remains to find a Borel set $G_0\supseteq H$ for which $\sigma(G_0)=0$. To this end, we again appeal to Proposition \ref{prop:Regular} to form a collection of open sets $\{\mathcal{O}_n\}_{n=1}^\infty$ such that, for each $n\in\mathbb{N}$, $H\subseteq \mathcal{O}_n$ and $\sigma(\mathcal{O}_n)=\sigma(\mathcal{O}_n)-\sigma(H)<1/n$. Finally, consider
\begin{equation*}
G_0=\bigcap_{n=1}^\infty\mathcal{O}_n,
\end{equation*}
which is necessarily a Borel set (in fact, a $G_\delta$-set) containing $H$ and, by the continuity of measure, has $\sigma(G_0)=0$, as desired.
\end{proof}


\textcolor{blue}{Some questions (I think the third is easiest):
\begin{enumerate}
\item To what extent does $\sigma$ depend on $E$? In other words, if $E,E'\in\Exp(P)$ (which necessarily have $\tr E=\tr E'$ in view of Section 2 of \cite{Randles2017}), would our construction have yielded the same measure $\sigma$ had we instead used the dilation $T_t=t^{E'}$ for everything? They should be closely related if not equal. But I'm really curious about this. For a little background reading, see the material near Proposition 2.3 of \cite{Randles2017}. 
\item We discussed the fact that the surface measure on the (usual) sphere $\mathbb{S}^{d-1}$ was the unique Radon measure which was rotationally invariant and satisfied $\sigma_d(\mathbb{S}^{d-1})=d\cdot m(\mathbb{B})$. I suspect that we also have some characterization for our measure $\sigma$ on $S$ -- in fact, this is why I suspect that $\sigma$ might not depend on the choice of $E$. Here are two possible conjectures and I really don't know if they are true:
\begin{conjecture} For any $O\in\Sym(P)$ and $F\in\Sigma_S$,
\begin{equation}\label{eq:Conjec1}
\sigma(O F)=\sigma(F).
\end{equation} 
\end{conjecture}
\begin{conjecture}
If $\sigma$ does not depend on $E$ (hence the construction produces the same measure $\sigma$ regardless of which $E\in\Exp(P)$ is chosen) and \eqref{eq:Conjec1} holds, $\sigma$ is the unique Radon measure on $S$ which satisfies \eqref{eq:Conjec1} and $\sigma(S)=\tr E m(B)$.
\end{conjecture}
\item There are many polynomials (and positive-definite continuous functions) that have $S$ as their ``unital" level set. For example: For any $\alpha>0$, $Q_{\alpha}(\xi):=(P(\xi))^\alpha$ is continuous and has
\begin{equation*}
S=\{\eta\in\mathbb{R}^d:Q_{\alpha}(\xi)=1\}.
\end{equation*}
Further, $Q_\alpha$ is positive-homogeneous\footnote{and is a polynomial precisely when $\alpha=1,2,\dots$.} and has $\Exp(Q_{\alpha})=\Exp(P)/\alpha$ in the senses that $E_\alpha\in \Exp(Q_\alpha)$ if and only if $E_\alpha=E/\alpha$ for $E\in \Exp(P)$. If you use $E_{\alpha}=E/\alpha$ to construct a measure $\sigma_\alpha$ on $S$ via the above construction, how is $\sigma_\alpha$ related to $\sigma$? I think I have an idea about this, but you should try it. Another question: Are there other polynomials (which are not powers of $P$) that have $S$ as their unital level set? 
\end{enumerate}}


\end{comment}


\subsection{The construction is independent of $E\in\Exp(P)$.}\label{subsec:IndependentofE}

\noindent In this subsection, we show that the Radon measure $\sigma_{P,E}$ is independent of the choice of $E\in\Exp(P)$ and complete the proof of Theorem \ref{thm:BestIntegrationFormula}. To set the stage for our first result, let $E_1,E_2\in\Exp(P)$ and consider the associated (respective) measure spaces $(S,\Sigma_{P,E_1},\sigma_{P,E_1})$ and $(S,\Sigma_{P,E_2},\sigma_{P,E_2})$ produced via the construction in Subsection \ref{subsec:ConstructionofSigma}. 

\begin{proposition}\label{prop:Endependence}
These measure spaces are the same, i.e., $\Sigma_{P,E_1}=\Sigma_{P,E_2}$ and $\sigma_{P,E_1}=\sigma_{P,E_2}$.
\end{proposition}
\begin{proof}
Throughout the proof, we will write $\Sigma_i=\Sigma_{P,E_i}$ and $\sigma_i=\sigma_{P,E_i}$ for $i=1,2$. In view of the Proposition \ref{prop:Regular}, it suffices to show that 
\begin{equation*}
\sigma_1(F)=\sigma_2(F)
\end{equation*}
for all $F\in \mathcal{B}(S)\subseteq \Sigma_{1}\cap\Sigma_{2}$. To this end, we let $F\in\mathcal{B}(S)$ be arbitrary but fixed. 

Given $n\in\mathbb{N}$, using the regularity of the measures $\sigma_1$ and $\sigma_2$, select open sets $\mathcal{O}_{n,1},\mathcal{O}_{n,2}$ and compact sets $K_{n,1},K_{n,2}$ for which
\begin{equation*}
K_{n,j}\subseteq F\subseteq \mathcal{O}_{n,j}\hspace{1cm}\mbox{and}\hspace{1cm}\sigma_j(\mathcal{O}_{n,j}\setminus K_{n,j})<1/n
\end{equation*}
for $j=1,2$. Observe that $K_n=K_{n,1}\cup K_{n,2}$ is a compact set, $\mathcal{O}_n=\mathcal{O}_{n,1}\cap\mathcal{O}_{n,2}$ is an open set and $K_n\subseteq F\subseteq \mathcal{O}_n$. Furthemore, 
\begin{equation*}
\sigma_j(\mathcal{O}_n\setminus K_n)\leq \sigma_j(\mathcal{O}_{n,j}\setminus K_{n,j})<1/n
\end{equation*}
for $j=1,2$. Given that $\mathcal{O}_n$ is open in $S$, $\mathcal{O}_n=S\cup U_n$ where $U_n$ is an open subset of $\mathbb{R}^d$ and, because that $S$ is compact, $K_n=K_n\cap S$ is a compact subset of $\mathbb{R}^d$. By virtue of Urysohn's lemma, let $\phi_n:\mathbb{R}^d\to [0,1]$ be a continuous function which is compactly supported in $U_n$ and for which $\phi_n(x)=1$ for all $x\in K_n$. Using this sequence of functions $\{\phi_n\}$, we establish the following useful lemma.

\begin{lemma}\label{lem:IndepProof}
For $j=1,2$ and $n\in\mathbb{N}$, define $g_{n,j}:(0,\infty)\to\mathbb{R}$ by
\begin{equation*}
g_{n,j}(r)=\int_S\phi_n(r^{E_j}\eta)\,\sigma_j(d\eta).
\end{equation*}
for $r>0$. Then $g_{n,j}$ is continuous for each $n\in\mathbb{N}$ and $j=1,2$ and
\begin{equation*}
    \sigma_j(F)=\lim_{n\to\infty}g_{n,j}(1)
\end{equation*}
for $j=1,2$.
\end{lemma}
\begin{subproof}
First, we note that, for each $r\in (0,\infty)$, the above integral makes sense because $\eta\mapsto \phi_n(r^{E_j}\eta)$ is Borel measurable (because it's continuous on $S$) and non-negative. Let $\epsilon>0$ and $r_0\in (0,\infty)$ be arbitrary but fixed. It is clear that the function $(0,\infty)\times S\ni (r,\eta)\mapsto \phi_n(r^{E_j}\eta)$ is continuous on its domain and therefore, in view of the compactness of $S$, we can find a $\delta>0$ for which
\begin{equation*}
|\phi_n(r^{E_j}\eta)-\phi_n(r_0^{E_j}\eta)|\leq\frac{\epsilon}{2\sigma_j(S)}\hspace{1cm}\mbox{whenever}\hspace{1cm}|r-r_0|<\delta
\end{equation*}
for all $\eta\in S$. The triangle inequality guarantees that
\begin{equation*}
|g_{n,j}(r)-g_{n,j}(r_0)|\leq \int_S|\phi_n(r^{E_j}\eta)-\phi_n(r_0^{E_j}\eta)|\,\sigma_j(d \eta)\leq\epsilon/2<\epsilon
\end{equation*}
whenever $|r-r_0|<\delta$. Thus, $g_{n,j}$ is continuous.

We observe that
\begin{equation*}
g_{n,j}(1)=\int_{S}\phi_n(\eta)\,\sigma_j(d\eta)
\end{equation*}
because $1^{E_j}=I$. By construction, we have $\chi_{K_n}(\eta)\leq\phi_{n}(\eta)\leq \chi_{\mathcal{O}_n}(\eta)$ for all $\eta\in S$ and $n\in\mathbb{N}_+$ and therefore
\begin{equation*}
\sigma_j(K_n)\leq g_{n,j}(1)\leq \sigma_{j}(\mathcal{O}_n)
\end{equation*}
by the monotonicity of the integral. Since
\begin{equation*}
\sigma_j(F)=\lim_{n\to\infty}\sigma_j(K_n)=\lim_{n\to\infty}\sigma_j(\mathcal{O}_n)
\end{equation*}
in view of our choice of $\mathcal{O}_n$ and $K_n$, the remaining result follows immediately from the preceding inequality (and the squeeze theorem).
\end{subproof}

\noindent Let us now complete the proof of Proposition \ref{prop:Endependence}. Given any $0<s<1< t$ and $n\in\mathbb{N}$, consider the function $f=f_{n,s,t}:\mathbb{R}^d\to [0,1]$ given by
\begin{equation*}
f(x)=\phi_n(x)\chi_{[s,t]}(P(x))
\end{equation*}
for $x\in\mathbb{R}^d$. It is clear that $f$ is Lebesgue measurable on $\mathbb{R}^d$ and non-negative. By virtue of Theorem \ref{thm:MainIntegrationFormula} (applied to the two measures $\sigma_1$ and $\sigma_2$), we have
\begin{equation}\label{eq:SameMeasure1}
\int_0^\infty \int_Sf(r^{E_1}\eta)\,\sigma_1(d\eta)r^{\mu_P-1}\,dr=\int_{\mathbb{R}^d}f(x)\,dx=\int_0^\infty \int_Sf(r^{E_2}\eta)\,\sigma_2(d\eta)r^{\mu_P-1}\,dr
\end{equation}
Upon noting that
\begin{equation*}
f(r^{E_j}\eta)=\phi_n(r^{E_j}\eta)\chi_{[s,t]}\left((P(r^{E_j}\eta)\right)=\phi_n(r^{E_j}\eta)\chi_{[s,t]}(rP(\eta))=\chi_{[s,t]}(r)\phi_n(r^{E_j}\eta)
\end{equation*}
for $r\in (0,\infty)$, $\eta\in S$, and $j=1,2$, we have
\begin{equation*}
\int_0^\infty\int_S f(r^{E_j}\eta)\,\sigma_j(d\eta)r^{\mu_P-1}\,dr=\int_{[s,t]}\int_S\phi_n(r^{E_j}\eta)\,\sigma_j(d\eta) r^{\mu_P-1}\,dr=\int_{[s,t]}g_{n,j}(r)r^{\mu_P-1}\,dr
\end{equation*}
for $j=1,2$. By virtue of the Lemma \ref{lem:IndepProof}, $r\mapsto g_{n,j}(r)r^{\mu_P-1}$ is continuous and necessarily bounded on $[s,t]$ and so the final integral above can be interpreted as a Riemann integral. In this interpretation, we have
\begin{equation}\label{eq:SameMeasure2}
\int_s^tg_{n,j}(r)r^{\mu_P-1}\,dr=\int_0^\infty \int_S f(r^{E_j}\eta)\,\sigma_j(d\eta)r^{\mu_P-1}\,dr
\end{equation}
for $j=1,2$ and $0<s<1<t$. In view of \eqref{eq:SameMeasure1} and \eqref{eq:SameMeasure2}, we conclude that
\begin{equation*}
\int_s^t g_{n,1}(r)r^{\mu_P-1}\,dr=\int_s^t g_{n,2}(r)r^{\mu_P-1}\,dr
\end{equation*}
for all $0<s<1<t$. In view of continuity of the integrands, an application of the fundamental theorem of calculus now guarantees that $g_{n,1}(1)=g_{n,2}(1)$ for each $n\in\mathbb{N}$. Therefore
\begin{equation*}
\sigma_1(F)=\lim_{n\to\infty}g_{n,1}(1)=\lim_{n\to\infty}g_{n,2}(1)=\sigma_2(F)
\end{equation*}
by virtue of Lemma \ref{lem:IndepProof}.
\end{proof}

\noindent In view of Proposition \ref{prop:Endependence}, we will denote by $\Sigma_P$ and $\sigma_P$ the unique $\sigma$-algebra and measure on $S$ which, respectively, satisfy
\begin{equation*}
    \Sigma_P=\Sigma_E\hspace{1cm}\mbox{and}\hspace{1cm}\sigma_P=\sigma_{P,E}
\end{equation*}
for all $E\in\Exp(P)$. We will henceforth assume this notation. 



\begin{proposition}\label{prop:SymInvariance}
For any $O\in\Sym(P)$ and $F\in\Sigma_P$,
\begin{equation*}
\sigma_P(O F)=\sigma_P(F).
\end{equation*} 
That is, the measure $\sigma_P$ is invariant under the action by $\Sym(P)$. 
\end{proposition}



\begin{proof}
Let $O\in\Sym(P)$, $F\in\Sigma_P$ and, for $E\in \Exp(P)$, define $E'=O^\top EO$. In view of Proposition \ref{prop:ExpP}, we note that $E'\in \Exp(P)$. Observe that
\begin{equation}\label{eq:TildeConjugation}
    \widetilde{(OF)_E}=\bigcup_{0<r<1}r^E (OF)=\bigcup_{0<r<1}O\left(O^\top r^E O F\right)=O\left(\bigcup_{0<r<1} r^{E'}F\right)=O \widetilde{F_{E'}}
\end{equation}
thanks to Proposition \ref{prop:ContinuousGroupProperties}.
In view of Proposition \ref{prop:Endependence}, we have $O\widetilde{F_{E'}}\in \mathcal{M}_d$ because $F\in \Sigma_P=\Sigma_{P,E'}$ and $O$ is linear. Using \eqref{eq:TildeConjugation}, we find that $\widetilde{(OF)_E}\in\mathcal{M}_d$ and therefore  $OF\in\Sigma_{E,P}=\Sigma_P$ by virtue of Proposition \ref{prop:Endependence}. In view of the fact that $O$ is orthogonal,
\begin{equation*}
\sigma_{P,E}(OF)=\mu_P\cdot m\left(\widetilde{(OF)_E}\right)=\mu_P\cdot m\left(O \widetilde{F_{E'}}\right)=\mu_P\cdot m\left(\widetilde{F}_{E'}\right)=\sigma_{P,E'}(F)
\end{equation*}
and therefore, a final appeal to Proposition \ref{prop:Endependence} guarantees that
\begin{equation*}
    \sigma_P(OF)=\sigma_{P,E}(OF)=\sigma_{P,E'}(F)=\sigma_P(F),
\end{equation*}
as desired.
\begin{comment}
Consider the measure spaces constructed from $E$ and $E'$ respectively: $(S, \Sigma_{S,E},\sigma_E)$ and $(S,\Sigma_{S,E'},\sigma_{E'})$. By virtue of Proposition \ref{prop:Endependence}, these measure spaces are the same, i.e., $\Sigma_{S,E} = \Sigma_{S,E'}$ and $\sigma_{E} = \sigma_{E'}$. For convenience, let us call these equivalent measure spaces the triple $(S,\Sigma_S,\sigma)$. 

Let $F\in \Sigma_S$ be given. We will show that $O(F)\in \Sigma_S$. To this end, we first notice that since $O\in \Sym(P) < \OdR$, we have $O O^\top = I$. As a result, we can write
\begin{equation*}
    \widetilde{O(F)} = \bigcup_{0<t<1}t^E O(F) = \bigcup_{0<t<1} O O^\top t^E O(F) = \bigcup_{0<t<1}O t^{O^\top E O} F = O\lp \bigcup_{0<t<1}t^{E'} F\rp.
\end{equation*}
We observe that the set $\bigcup_{0<t<1} t^{E'}F$ is Lebesgue measurable since $F\in \Sigma_S = \Sigma_{S,E'}$. By the orthogonal invariance of the Lebesgue measure, $\widetilde{O(F)}$ is also Lebesgue measurable, with
\begin{equation*}
    m (\widetilde{O(F)} ) = m\lb O \lp \bigcup_{0<t<1}t^{E'}F \rp \rb =  m\lp \bigcup_{0<t<1}t^{E'}F \rp.
\end{equation*}
Therefore, $O(F)\in \Sigma_S$, with which it makes sense to ask for the measure $\sigma$ of $O(F)$:
\begin{equation*}
    \sigma(O(F)) = (\tr E)m(\widetilde{O(F)}).
\end{equation*}
Now, in view of Proposition \ref{prop:Endependence} and the fact that $\tr E = \tr E'$ for $E,E'\in \Exp(P)$, we have that
\begin{equation*}
    m\lp \bigcup_{0<t<1}t^{E'}F \rp = \frac{\sigma_{E'}(F)}{\tr E' }  
    = 
    \frac{\sigma_E(F)}{\tr E'} =  \frac{\sigma_E(F)}{\tr E}   = m\lp \bigcup_{0<t<1} t^E F  \rp.
\end{equation*}
From the last three equations, we conclude that 
\begin{equation*}
    \sigma(O(F)) = \sigma(F).
\end{equation*}
Therefore, the measure $\sigma$ is invariant under symmetry group $\Sym(P)$ of $P$.  
\end{comment}
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:BestIntegrationFormula}]
Together, the results of Propositions \ref{prop:Regular}, \ref{prop:Endependence} and \ref{prop:SymInvariance}, guarantee that $\sigma_P$ is a Radon measure satisfying Properties \ref{property:Completion} and \ref{property:Invariance}. Property \ref{property:DefiningConditionofsigma} follows directly from Proposition \ref{prop:Endependence} and the definition of $\sigma_P$ in terms of $\sigma_{P,E}$ for any $E\in\Exp(P)$. Similarly, Properties \ref{property:BestPointIsomorphism} and \ref{property:BestIntegrationFormula} follow from Theorem \ref{thm:MainIntegrationFormula} by virtue of Proposition \ref{prop:Endependence}. 
\end{proof}


\section{Using a smooth structure on $S$ to compute $\sigma$.}\label{sec:SigmaForSmoothP}

\noindent In this section, we shall study the special case in which a positive-homogeneous function $P$ on $\mathbb{R}^d$ is smooth\footnote{Many of the results in this section remain valid (with appropriate modification) under the weaker assumption that $P\in C^k(\mathbb{R}^d)$ for $k=1,2,\dots$. In this setting, $S$ is easily seen to be a $C^k$ manifold. Because working in the smooth category is sufficient for our purposes, we shall not pursue the greater level of generality but invite the reader to do so.}\footnote{\textcolor{red}{To avoid trivialities, we assume that $d>1$ throughout.}}.
Under this additional assumption, we shall find that $\grad P$ is everywhere non-vanishing on $S$ and so $S$ is a smooth compact embedded hypersurface in $\mathbb{R}^d$.\\

\noindent We first set up some notation: For a smooth manifold $M$, we shall denote by $\mathcal{A}(M)$ its unique maximal atlas. Also on $M$, the collection of smooth vector fields is denoted by $\mathfrak{X}(M)$ and, for each $k=1,2,\dots$, the set of (smooth) differential $k$-forms on $M$ will be denoted by $\Omega^k(M)$.  In this section, we integrate non-smooth differential forms and, for the generality needed here, we shall refer the reader to \cite{Naber2011} for background (Another perspective is given in \cite{Amann2009}). To this end, let us denote the Lebesgue $\sigma$-algebra of measurable sets on $M$ by $\mathcal{L}(M)$. We note that $F\in\mathcal{L}(M)$ if and only if, \begin{equation*}
    \varphi(F\cap \mathcal{U})\in\mathcal{M}_d
\end{equation*}
for every chart $(\varphi,\mathcal{U})\in\mathcal{A}(M)$. An $n$-form $\omega$ on $M$, with $n=\dim(M)$, is said to be (Lebesgue) measurable, if in each coordinate system $(\varphi,\mathcal{U})$, the local representation
\begin{equation*}
    \omega=h_{\varphi}(x)dx^1\wedge dx^2\wedge \cdots\wedge dx^n
\end{equation*}
in the coordinates $\varphi=(x^1,x^2,\dots,x^n)$ has $h_{\varphi}(x)$ a Lebesgue measurable function on $U=\varphi(\mathcal{U})\subseteq\mathbb{R}^n$. The collection of measurable $n$-forms on $M$ is denoted by $\mathcal{L}(\Lambda^d(M))$ and, naturally, $\Omega^{d}(M)\subseteq \mathcal{L}(\Lambda^d(M))$. As standard, we shall use Einstein's summation convention without explicit mention.\\



\noindent We view $\mathbb{R}^d$ as smooth oriented Riemannian manifold with its standard Euclidean metric $\overline{g}$, oriented smooth atlas $\mathcal{A}_+(\mathbb{R}^d)$, and Riemannian volume form $ d\Vol_{\mathbb{R}^d}$. Given any $E\in\Exp(P)$, consider $\mathcal{E}_E\in \mathfrak{X}(\mathbb{R}^d)$ defined, at each $x\in\mathbb{R}^d$, by
\begin{equation*}
    (\mathcal{E}_E)_x(f)=\frac{d}{dt}f(x+t(Ex))\big\vert_{t=0}\hspace{1cm}
\end{equation*}
for $f\in C^\infty(\mathbb{R}^d)$. In the standard (global) chart with coordinates $x=(x^1,x^2,\dots,x^d)$, $(\mathcal{E}_E)_{x}\in T_{x}(\mathbb{R}^d)$ is given by
\begin{equation*}
    (\mathcal{E}_E)_{x}=(Ex)^{\alpha}\partial_{x^\alpha}=E^\alpha_\beta x^{\beta}\partial_{x^\alpha}
\end{equation*}
where $(E_\alpha^\beta)$ is the standard matrix representation for $E$ and  $\partial_{x^{\alpha}}=\partial/\partial x^\alpha$. By an abuse of notation, we shall write $\grad P$ to denote both the function
\begin{equation*}
\mathbb{R}^d\ni x\mapsto \grad P(x)=\left(\frac{\partial P}{\partial x^1},\frac{\partial P}{\partial x^2},\dots,\frac{\partial P}{\partial x^d}\right)^{\top}\in\mathbb{R}^d,
\end{equation*}
where $\frac{\partial P}{\partial x^{\alpha}}=\frac{\partial P}{\partial x^{\alpha}}\vert_{x}$ for $\alpha=1,2\dots,d$, and its canonical identification $\grad P\in \mathfrak{X}(\mathbb{R}^d)$ given by \begin{equation*}
    \grad P_x=\overline{g}^{\alpha\beta}\frac{\partial P}{\partial x^{\alpha}}\partial_{x^{\beta}}=\delta^{\alpha\beta}\frac{\partial P}{\partial x^{\alpha}}\partial_{x^{\beta}}=\sum_{\alpha=1}^d\frac{\partial P}{\partial x^{\alpha}}\partial_{x^\alpha}
\end{equation*}
in standard Euclidean coordinates $x=(x^\alpha)$. Of course, for each $x\in\mathbb{R}^d$, the Riemannian norm $|\grad P_x |_{\overline{g}}$ of $\grad P_x \in T_x (\mathbb{R}^d)$ coincides with the Euclidean norm $| \grad P(x) |$ of $ \grad P(x) \in \mathbb{R}^d$. These equivalent quantities (functions) will be henceforth denoted by $|\grad P|$.

\begin{proposition}\label{prop:InnerProdIsOne}
For each $\eta\in S$, 
\begin{equation*}
    \overline{g}(\grad P,\mathcal{E})_{\eta}=\grad P(\eta)\cdot (E\eta)=1.
\end{equation*}
In particular, $\grad P$ (and $dP$) never vanishes on $S$ and so $S$ is a compact embedded hypersurface in $\mathbb{R}^d$.
\end{proposition}
\begin{proof}
Given that $E\in\Exp(P)$ and $P\in C^\infty(\mathbb{R}^d)$, we differentiate the identity $rP(x)=P(r^Ex)$ to find that
\begin{equation*}
    P(x)=\frac{d}{dr}P(r^Ex)=\grad P(r^Ex)\cdot\left(\left(r^{E-I}E\right)x\right)
\end{equation*}
for $r>0$ and $x\in\mathbb{R}^d$. In particular, when $r=1$ and $x=\eta\in S$, we have
\begin{equation*}
    1=\grad P(\eta)\cdot \left(E\eta\right)=\frac{\partial P}{\partial x^\alpha}(E\eta)^\alpha=\overline{g}_{\alpha \beta}\left(\grad P_\eta\right)^{\alpha}(\mathcal{E}_\eta)^\beta=\overline{g}(\grad P,\mathcal{E})_\eta.
\end{equation*}
Thus, our (necessarily) compact level set $S$ is a smooth embedded hypersurface of $\mathbb{R}^d$ in view of the regular level set theorem.
\end{proof}
\noindent We shall denote by $\iota:  S \hookrightarrow \mathbb{R}^d$ the canonical inclusion map and set $d'=d-1$. As an embedded submanifold of $\mathbb{R}^d$, $S$ is a Riemannian submanifold of $\mathbb{R}^d$ with metric $g^S$ given by
\begin{equation*}
    g^S(X,Y)=\overline{g}(\iota_*(X),\iota_*(Y))
\end{equation*}
for $X,Y\in\mathfrak{X}(S)$; here, for each $\eta\in S$,  $\iota_*:T_\eta(S)\to T_\eta(\mathbb{R}^d)$ is the pushforward of $\iota$.  In view of the preceding proposition, $N:=\grad P/|\grad P|\in \mathfrak{X}(\mathbb{R}^d)$ is a smooth unit normal vector field along $S$ and it determines an orientation on the Riemannian manifold $S$. Equipped with this orientation, $(S,g^S)$ is an oriented Riemannian manifold and we shall denote by $d\Vol_S$ Riemannian volume form and by $\mathcal{A}_+(S)$ its corresponding (maximal) oriented atlas. By virtue of Proposition 15.21 of \cite{lee2013smooth}, $d\Vol_S=(N\iprod d\Vol_{\mathbb{R}^d})\vert_S$, i.e.,
\begin{eqnarray*}
    d\Vol_S(X_1,X_2,\dots,X_{d'})&=&d\Vol_{\mathbb{R}^d}(N,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'}))\\
    &=&\frac{1}{|\grad P|}d\Vol_{\mathbb{R}^d}(\grad P,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'}))
\end{eqnarray*}
for any collection $\{X_1,X_2,\dots,X_{d'}\}\in \mathfrak{X}(S)$. Beyond $d\Vol_S\in \Omega^{d'}(S)$, we consider the following smooth $d'$-form(s): Given $E\in \Exp(P)$, define $d\sigma_{P,E}\in\Omega^{d'}(S)$ by
\begin{equation*}
    d\sigma_{P,E}(X_1,X_2,\dots,X_{d'})=d\Vol_{\mathbb{R}^d}(\mathcal{E}_E,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'}))
\end{equation*}
for $X_1,X_2,\dots,X_{d'}\in\mathfrak{X}(S)$. We have
\begin{proposition}\label{prop:FormRiemannRelation}
For any $E\in\Exp(P)$,
\begin{equation*}
    d\sigma_{P,E}=\frac{1}{|\grad P|}d\Vol_S.
\end{equation*}
In particular, $d\sigma_{P,E}$ is positively oriented and is independent of $E\in\Exp(P)$.
\end{proposition}
\noindent Before proving the proposition, we first treat a lemma of a purely linear algebraic nature. 
\begin{lemma}\label{lem:determinants}
Let $v_1,v_2,\dots,v_{d'}$ be linearly independent vectors in $\mathbb{R}^d$ and suppose that $w\in\mathbb{R}^d \setminus\{0\}$ is such that $w\perp v_i$ for all $i$. Then, for any $z\in\mathbb{R}^d$ for which $z\cdot w=1$,
\begin{equation*}
\det(z, v_1,v_2,\dots,v_{d'})=\frac{1}{|w|}\det(n,v_1,v_2,\dots,v_{d'})=\frac{1}{|w|^2}\det(w,v_1,v_2,\dots,v_{d'}).
\end{equation*}
where $n:=w/|w|$.
\end{lemma}

\begin{proof}
Given $z\in\mathbb{R}^d$ such that $z\cdot w=1$, it follows that 
\begin{equation*}
z=\frac{1}{|w|}n+a_1v_1+a_2v_2+\cdots a_{d'}v_{d'}.
\end{equation*}
By the multilinearity of the determinant map, we have
\begin{eqnarray*}
\det(z,v_1,v_2,\dots,v_{d'}) &=&\det\lp \frac{1}{|w|}n+a_1v_2+a_2v_2+\cdots a_{d'} v_{d'},v_1,v_2,\dots,v_{d'}\rp\\
    &=&\frac{1}{|w|}\det(n,v_1,v_2,\dots,v_{d'})+\det(a_1v_1+\cdots+a_{d'} v_{d'}, v_1,v_2,\dots,v_{d'})\\
&=&\frac{1}{|w|}\det(n, v_1,v_2,\dots,v_{d'})+0
\end{eqnarray*}
where we have used the fact that the columns of the matrix $(a_1v_1+\cdots+a_{d'} v_{d'}, v_1,v_2,\dots,v_{d'})$ are linearly dependent to conclude that the final determinant is zero.
\end{proof}
\begin{proof}[Proof of Proposition \ref{prop:FormRiemannRelation}]
We fix $E\in\Exp(P)$ and note that the assertion at hand is a local one. Thus, it suffices to verify that, for any $\eta\in S$ and $X_1,X_2,\dots,X_{d'}\in T_\eta(S)$, 
\begin{equation*}
    d\sigma_{P,E}(X_1,X_2,\dots,X_{d'})=\frac{1}{|\grad P_{\eta}|}d\Vol_{\mathbb{R}^d}(N_\eta,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'})).
\end{equation*}
Fix $\eta\in S$ and let $(\mathcal{O},\varphi)$ be a coordinate chart centered at $\eta$ with local coordinates $u=(u^{\alpha})$. As usual, denote by $x=(x^{\alpha})$ the Euclidean coordinates on $\mathbb{R}^d$.  For each $i=1,2,\dots,{d'}$, \begin{equation*}
X_i=X_i^\alpha \partial_{u^{\alpha}}\hspace{1cm}\mbox{and}\hspace{1cm}\iota_*(X_i)=v_i^\beta\partial_{x^{\beta}}
\end{equation*}
where
\begin{equation*}
v_i^\beta =X_i^\alpha\frac{\partial x^\beta}{\partial u^\alpha}.
\end{equation*}
For each $i=1,2,\dots,d'$, we set $v_i=(v_i^1,v_i^2,\dots,v_i^{d'})^\top\in\mathbb{R}^d$. Also, let $w=\grad P(\eta)\in\mathbb{R}^d$ with $|w|=|\grad P(\eta)|=|\grad P_\eta|$, set $n=w/|w|\in\mathbb{R}^d$ and note that
\begin{equation*}
    N_\eta=\frac{1}{|\grad P_\eta|}\sum_{k=1}^d\frac{\partial P}{\partial x^{k}}\partial_{x^k}=n^{\mu}\partial_{x^\mu}.
\end{equation*}Given that $\grad P$ is normal to $S$, we have
\begin{equation*}
    v_i\cdot w=\overline{g}_{\mu,\nu}v_i^\mu w^\nu= \overline{g}(\iota_*(X_i),\grad P)_\eta=0
\end{equation*}
and therefore $w\perp v_i$ for each $i=1,2,\dots,{d'}$. Upon recalling that $(\mathcal{E}_E)_\eta=(E\eta)^\alpha\partial_{x^{\alpha}}$, set $z=((E\eta)^1,(E\eta)^2,\dots,(E\eta)^d)^\top\in\mathbb{R}^d$ and observe that $z\cdot w=1$ by virtue of Proposition \ref{prop:InnerProdIsOne}. An appeal to the lemma guarantees that
\begin{eqnarray*}
d\sigma_{P,E}(X_1,X_2,\dots,X_{d'})&=&d\Vol_{\mathbb{R}^d}(\mathcal{E}_E,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'}))\\
&=&\det(z,v_1,v_2,\dots,v_{d'})\\
&=&\frac{1}{|w|}\det(n,v_1,v_2,\dots,v_{d'})\\
&=&\frac{1}{|\grad P_\eta|}d\Vol_{\mathbb{R}^d}(N_\eta,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'}))\\
&=&\frac{1}{|\grad P|}d\Vol_S(X_1,X_2,\dots,X_{d'}).
\end{eqnarray*}
\end{proof}
\noindent By virtue of the preceding proposition, we shall denote by $d\sigma_P$ the unique smooth $d'$-form on $S$ which satisfies
\begin{equation}\label{eq:sigmaForm}
    d\sigma_P=d\sigma_{P,E}=\frac{1}{|\grad P|}d\Vol_S
\end{equation}
for all $E\in\Exp(P)$. In this notation, we have this section's central result.




\begin{theorem}\label{thm:RiemannLebesgue}
Let $P$ be a smooth positive-homogeneous function and let $S=\{\eta\in\mathbb{R}^d:P(\eta)=1\}$. Then $S$ is a compact smooth embedded hypersurface of $\mathbb{R}^d$. Viewing $\mathbb{R}^d$ as an oriented Riemannian manifold with its usual orientation and metric $\overline{g}$, $N=\grad P/|\grad P|$ is a smooth unit normal vector field along $S$. As a submanifold of $\mathbb{R}^d$, $S$ is a oriented Riemannian manifold of dimension $d'=d-1$ with its induced Riemannian metric $g^S$, volume form $d\Vol_S\in\Omega^{d'}(S)$ and orientation determined by $N$. The $\sigma$-algebras $\Sigma_P$ and $\mathcal{L}(S)$ on $S$ coincide and the smooth $d'$-form $d\sigma_P\in\Omega^{d'}(S)$, defined by \eqref{eq:sigmaForm}, coincides with the measure $\sigma_P$ in the sense that
\begin{equation}\label{eq:FormsAndMeasures}
\int_S g(\eta)\,\sigma_P(d\eta)=\int_S g\,d\sigma_P
\end{equation}
for all $g\in L^1(S,\Sigma_P,\sigma_P)$; here, the left hand side represents the Lebesgue integral of $g$ with respect to $\sigma_P$ and the right hand side is the integral of the measurable $d'$-form $g\, d\sigma_P$. Furthermore, the measure $\sigma_P$ and the canonical Riemannian volume measure $\Vol_S$ on $S$ are mutually absolutely continuous.
\end{theorem} 

\begin{lemma}\label{lem:JacobianRelation}
Let $(\mathcal{U},\varphi)\in \mathcal{A}(S)$ and $E\in\Exp(P)$. Set $U=\varphi(\mathcal{U})\subseteq\mathbb{R}^{d'}$, $V=(0,1)\times U$ and define $\rho_{E,\varphi}:V\to \mathbb{R}^d$ and $h_{E,\varphi}:U\to \mathbb{R}$, respectively, by
\begin{equation*}
    \rho_{E,\varphi}(y)=\psi_E(r,\varphi^{-1})=r^E\varphi^{-1}(u)
\end{equation*}
for $y=(r,u)\in V$ and
\begin{equation*}
    h_{E,\varphi}(u)=\det\left.\left(E\varphi^{-1}(u)\right\vert D_u\varphi^{-1}(u)\right)
\end{equation*}
for $u\in U$; here, the vertical bar separates the first column of the (necessarily) $d\times d$ matrix from the rightmost $d\times d'$ submatrix and $D_u$ denotes the Jacobian in the coordinates $u=(u^1,u^2,\dots,u^{d'})\in U$. Then, $\rho_{E,\varphi}$ is a diffeomorphism onto its image $\rho_{E,\varphi}(V)=\widetilde{\mathcal{U}_E}$ and its Jacobian matrix $D\rho_{E,\varphi}$ has
\begin{equation}\label{eq:JacobianRelation1}
    \det(D\rho_{E,\varphi}(y))=r^{\mu_P-1}h_{E,\varphi}(u)
\end{equation}
for all $y=(r,u)\in V$. Furthermore, $h_{E,\varphi}$ is everywhere non-zero, smooth and
%\begin{equation}\label{eq:JacobianRelation2}
%    h_{E,\varphi}(u)=(d\sigma_P)_{\varphi^{-1}(u)}(\partial_{u^1},\partial_{u^2},\dots,\partial_{u^{d'}})
%\end{equation}
\begin{equation}\label{eq:JacobianRelation2}
    d\sigma_P=h_{E,\varphi}(u)\,du^1\wedge du^2\wedge\cdots\wedge du^{d'}
\end{equation}
in the coordinates $u=(u^1,u^2,\dots,u^{d'})\in U$. 
\end{lemma}
\begin{proof}
The map $\rho_{E,\varphi}$ is smooth because $\varphi$ is smooth. By virtually the same argument made in the proof of Proposition \ref{prop:PsiHomeomorphism}, which here uses the fact that $P\in C^\infty(\mathbb{R}^d)$, we conclude that $\rho_{E,\varphi}$ is a diffeomorphism onto 
\begin{equation*}\rho_{E,\varphi}(V)=\bigcup_{0<r<1}r^E\mathcal{U}=\widetilde{\mathcal{U}_E}
\end{equation*}
with inverse $\rho_{E,\varphi}^{-1}(x)=(P(x),\varphi((P(x))^{-E}x))$. For $y=(r,u)\in V$, observe that
\begin{eqnarray*}
D\rho_{E,\varphi}(y)&=&\left.\left(\frac{d}{dr}(r^E\varphi^{-1}(u)) \right\vert D_u\left[r^E\varphi^{-1}(u)\right]\right)\\
&=&\left.\left(r^{E-I}E\varphi^{-1}(u)\right\vert r^E D_u\varphi^{-1}(u)\right)\\
&=&r^E\left.\left(\frac{1}{r}E\varphi^{-1}(u)\right\vert D_u\varphi^{-1}(u)\right).
\end{eqnarray*}
Using properties of the determinant, we have
\begin{eqnarray*}
    \det(D\rho_E(y))&=&\det(r^E)\det\left.\left(\frac{1}{r}E\varphi^{-1}(u)\right\vert D_u\varphi^{-1}(u)\right)\\
    &=&r^{\tr E}r^{-1}\det\left.\left(E\varphi^{-1}(u)\right\vert D_u\varphi^{-1}(u)\right)\\
    &=&r^{\mu_P-1}h_{E,\varphi}(u)
\end{eqnarray*}
for all $y=(r,u)\in V$ thus proving \eqref{eq:JacobianRelation1}. It is clear that $h_{E,\varphi}$ is smooth and, by virtue of the fact that $\rho_{E,\varphi}:(0,1)\times U\to \widetilde{\mathcal{U}_E}$ is a diffeomorphism, \eqref{eq:JacobianRelation1} guarantees that $h_{E,\varphi}$ is everywhere non-vanishing. Finally, 
in view of Proposition \ref{prop:FormRiemannRelation} (and \eqref{eq:sigmaForm}), we find that
\begin{eqnarray*}
    h_{E,\varphi}(u)&=&
    \det\left.\left(E\varphi^{-1}(u)\right\vert D_u\varphi^{-1}(u)\right)\\ \nonumber
    &=&
    (d\Vol_{\mathbb{R}^d})_{\varphi^{-1}(u)}(\mathcal{E}_E,\iota_*(\partial_{u^1}),\iota_*(\partial_{u^2}),\dots,\iota_*(\partial_{u^{d'}}))\\ \nonumber
    &=&\left(d\sigma_P\right)_{\varphi^{-1}(u)}(\partial_{u^1},\partial_{u^2},\dots,\partial_{u^{d'}})\\
\end{eqnarray*}
for $u\in U$ and so \eqref{eq:JacobianRelation2} is satisfied.
\end{proof}

\begin{lemma}\label{lem:LocalIntegralFormula}
Let $g\in L^1(S,\Sigma_P,\sigma_P)$ be supported on the domain of some chart on $S$. Then, for any $(\mathcal{U},\varphi)\in\mathcal{A}^+(S)$ such that $\supp(g)\subseteq\mathcal{U}$, the pushforward $(\varphi^{-1})^*(g)=g\circ\varphi^{-1}$ is Lebesgue measurable on $U=\varphi(\mathcal{U})\subseteq\mathbb{R}^{d'}$ and 
\begin{equation*}
\int_S g(\eta)\sigma_P(d\eta)=\int_{U}(\psi^{-1})^*(g\, d\sigma_P).
\end{equation*}
\end{lemma}
\begin{proof}
Let $(\mathcal{U},\varphi)$ be a chart on $S$ for which $\supp(g)\subseteq \mathcal{U}$ and assume the notation of Lemma \ref{lem:JacobianRelation}. Given $E\in\Exp(P)$, observe that
\begin{equation*}
    f(x)=\mu_P\, \chi_{(0,1)}(P(x))g(P(x)^{-E}x),
\end{equation*}
defined for $x\in\mathbb{R}^d\setminus\{0\}$, is supported on $\widetilde{\mathcal{U}_E}=\rho_{E,\varphi}(V)$. An appeal to Corollary \ref{cor:IntegrateOnS} guarantees that $f$ is absolutely integrable on $\rho_{E,\varphi}(V)$ and
\begin{equation}\label{eq:LocalIntegralFormula1}
\int_S g(\eta)\,\sigma_P(d\eta)=\int_{\rho_{E,\varphi}(V)}f(x)\,dx.
\end{equation}
Given that $\rho_{E,\varphi}$ is a diffeomorphism, an appeal to Theorem 15.11 of \cite{Apostol1974} (see also Theorem 10.46 of \cite{Browder1996}) guarantees that
\begin{equation}\label{eq:LocalIntegralFormula2}
\int_{\rho_{E,\varphi}(V)}f(x)\,dx=\int_V f(\rho_{E,\varphi}(y))|\det(D\rho_{E,\varphi}(y))|\,dy;
\end{equation}
in particular, $V\ni y\mapsto f(\rho_{E,\varphi}(y))|\det(D\rho_{E,\varphi}(y))$ is Lebesgue measurable on $\mathbb{R}^{d}$. Let us now view the Lebesgue measure $dy$ on $\mathbb{R}^d$ as the completion of the product measure $dr\times du$ on the product space $\mathbb{R}\times\mathbb{R}^{d'}$. By virtue of Lemma \ref{lem:JacobianRelation}, we have
\begin{eqnarray}\label{eq:LocalIntegralFormula3}\nonumber
    f(\rho_{E,\varphi}(y))|\det(D\rho_{E,\varphi}(y))|
    &=& f(r^E\varphi^{-1}(u))\,r^{\mu_{P}-1}|h_{E,\varphi}(u)|\\ \nonumber
    &=& \mu_P\,\chi_{(0,1)}(r)g(\varphi^{-1}(u))\, r^{\mu_P-1}|h_{E,\varphi}(u)|\\ 
    &=& \mu_P\,r^{\mu_P-1}g(\varphi^{-1}(u))|h_{E,\varphi}(u)|
\end{eqnarray}
for $y=(r,u)\in V$. By virtue of Fubini's theorem, $dr$-almost every $r\in (0,1)$, the $r$-section 
\begin{equation*}
    U\ni u\mapsto \mu_P r^{\mu_P-1}g(\varphi^{-1}(u))|h_{E,\varphi}(u)|
\end{equation*}
is Lebesgue measurable and,  upon recalling that $h_{E,\varphi}$ is smooth and everywhere nonzero, we conclude that $(\varphi^{-1})^*(g)=g\circ\varphi^{-1}$ is Lebesgue measurable on $U$. In view of \eqref{eq:LocalIntegralFormula3}, Fubini's theorem also guarantees that
\begin{eqnarray}\label{eq:LocalIntegralFormula4}\nonumber
    \int_V f(\rho_{E,\varphi}(y))|\det(D\rho_{E,\varphi}(y))|\,dy
    &=&\int_{(0,1)}\int_U \mu_P\, r^{\mu_P-1}g(\varphi^{-1}(u))|h_{E,\varphi}(u)|\,du\,dr\\\nonumber
    &=&\int_0^1\mu_P\, r^{\mu_P-1}\left(\int_U g(\varphi^{-1}(u))|h_{E,\varphi}(u)|\,du\right)\,dr\\
    &=&\int_U g(\varphi^{-1}(u))|h_{E,\varphi}(u)|\,du
\end{eqnarray}
By combining \eqref{eq:LocalIntegralFormula1}, \eqref{eq:LocalIntegralFormula2} and \eqref{eq:LocalIntegralFormula4}, we have shown that $(\varphi^{-1})^*g=g\circ\varphi^{-1}$ is Lebesgue measurable on $U=\varphi(\mathcal{U})$ and
\begin{equation*}
    \int_S g(\eta)\sigma_P(d\eta)=\int_U g(\varphi^{-1}(u))|h_{E,\varphi}(u)|\,du.
\end{equation*}
Finally, if $(\mathcal{U},\varphi)\in\mathcal{A}_+(S)$, an appeal to Proposition \ref{prop:FormRiemannRelation} and \eqref{eq:JacobianRelation2} of Lemma \ref{lem:JacobianRelation} guarantees that
\begin{equation*}
    |h_{E,\varphi}(u)|=h_{E,\varphi}(u)=(d\sigma_P)_{\varphi^{-1}(u)}(\partial_{u^1},\partial_{u^2},\dots,\partial_{u^{d'}})>0
\end{equation*}
for all $u=(u^1,u^2,\dots,u^{d'})\in U$ and thus
\begin{eqnarray*}
        \int_S g(\eta)\sigma_P(d\eta)&=&\int_U g(\varphi^{-1}(u))h_{E,\varphi}(u)\,du\\
        &=&\int_U g(\varphi^{-1}(u))\,h_{E,\varphi}(u)\,du^1\wedge du^2\wedge\cdots \wedge du^{d'}\\
        &=&\int_U (\varphi^{-1})^*(g\cdot d\sigma_P),
\end{eqnarray*}
as desired. 
\end{proof}
\begin{comment}\textcolor{red}{Just checking a minor notational detail. The notation, as always is confusing me. We will erase this (but Huan, you can put this in thesis): Let's write $\partial_{u^1},\partial_{u^2},\dots,\partial_{u^{d'}}$ for the frame on $S$, i.e., each is a vector field on $S$, and $\frac{\partial}{\partial u^1},\frac{\partial}{\partial u^2},\dots,\frac{\partial}{\partial u^{d'}}$ for the frame on $U\in\mathbb{R}^d$. These are connected via the following relation (which actually defines the former): For $f\in C^\infty(S)$, 
\begin{equation*}
    \partial_{u^\mu}(f)(\eta)=\frac{\partial}{\partial u^{\mu}}\left(f\circ\varphi^{-1}\right)(u)
\end{equation*}
where $u=\varphi(\eta)$. In other words,
\begin{equation*}
    \partial_{u^\mu}=\varphi^{-1}_*\frac{\partial}{\partial u^\mu}.
\end{equation*}
Now, by definition of the pullback $(\varphi^{-1})^*\,d\sigma_P$ is a $d'$-form on the $d'$-dimensional manifold $U$ and every such form is given by $f(u)du^1\wedge du^2\wedge\cdots\wedge du^{d'}$, i.e., there is a smooth function $f:\to\mathbb{R}$ for which
\begin{equation*}
    (\varphi^{-1})^*d\sigma_P=f du^1\wedge du^2\wedge\cdots\wedge du^{d'}
\end{equation*}
Then, by definition, 
\begin{equation*}
    \int_U (\varphi^{-1})^*d(g\cdot d\sigma_P)=\int_U g(\varphi^{-1}(u))f(u)\,du^1,du^2,\dots,du^{d'}
\end{equation*}
(we've erased the wedges to integrate). Thus, we really just need to know $f$. We have
\begin{eqnarray*}
    f(u)&=&f(u)\left(du^1\wedge du^2\wedge\cdots\wedge du^{d'}\right)\left(\frac{\partial}{\partial u^1},\frac{\partial}{\partial u^2},\dots,\frac{\partial}{\partial u^{d'}}\right)\\
    &=&\left((\varphi^{-1})^*\,d\sigma_P\right)\left(\frac{\partial}{\partial u^1},\frac{\partial}{\partial u^2},\dots,\frac{\partial}{\partial u^{d'}}\right)\\
    &=&d\sigma_P\left(\varphi^{-1}_*\left(\frac{\partial}{\partial u^1}\right),\varphi^{-1}_*\left(\frac{\partial}{\partial u^2}\right),\dots,\varphi^{-1}_*\left(\frac{\partial}{\partial u^{d'}}\right)\right)\\
    &=&d\sigma_P(\partial_{u^1},\partial_{u^2},\dots,\partial_{u^{d'}})\\
    &=&h_{E,\varphi}(u).
\end{eqnarray*}
Therefore
\begin{equation*}
    \int_U (\varphi^{-1})^*(g\cdot d\sigma_P)=\int_U g(\varphi^{-1}(u))h_{E,\varphi}(u)\,du.
\end{equation*}}
\end{comment}

\begin{remark}\label{rmk:LocalIntegralFormula}
In studying the proof of Lemma \ref{lem:LocalIntegralFormula}, we deduce the (slightly) more general statement: Given any chart $(\mathcal{U},\varphi)\in\mathcal{A}(S)$ and $g\in L^1(S,\Sigma_P,\sigma_P)$ for which $\supp(g)\in\mathcal{U}$, $(\varphi^{-1})^*g$ is Lebesgue measurable on $U=\varphi(\mathcal{U})$ and 
\begin{equation*}
    \int_S g(\eta)\sigma_P(d\eta)=\begin{cases}
    \displaystyle\int_U(\varphi^{-1})^*(g\,d\sigma_P) &\mbox{ if }(\mathcal{U},\varphi)\in\mathcal{A}_+(S)\\
    &\\
    -\displaystyle\int_U(\varphi^{-1})^*(g\,d\sigma_P)&\mbox{ if }(\mathcal{U},\varphi)\in\mathcal{A}_-(S)\coloneqq\mathcal{A}(S)\setminus\mathcal{A}_+(S).
    \end{cases}
\end{equation*}
\end{remark}
\begin{proof}[Proof of Theorem \ref{thm:RiemannLebesgue}]
In view of Proposition \ref{prop:InnerProdIsOne} and the discussion following its proof, it remains to prove the assertions in the last two sentences in the statement of the theorem. Given any $F\in \Sigma_P$ and chart $(\mathcal{U},\varphi)\subseteq \mathcal{A}(S)$, we have $\chi_{\varphi(F\cap \mathcal{U})}=(\varphi^{-1})^*\left(\chi_{F\cap\mathcal{U}}\right)$ is Lebesgue measurable on $U=\varphi(\mathcal{U})$ and so it follows (Exercise 4.6.2 of \cite{Naber2011}) that $F\in\mathcal{L}(S)$. Consequently, $\mathcal{B}(S)\subseteq\Sigma_P\subseteq\mathcal{L}(S)$.

Let $g\in L^1(S,\Sigma_P,\sigma_P)$, which is necessarily Lebesgue measurable on $S$ in view of the results of the previous paragraph. Now, let  $\{(\mathcal{U}_j,\varphi_j)\}\subseteq\mathcal{A}_+(S)$ be a countable atlas on $S$ and let $\{\kappa_j\}$ be a smooth partition of unity subordinate to the cover $\{\mathcal{U}_j\}$. For each $j\in\mathbb{N}$, observe that $\kappa_j g\in L^1(S,\Sigma_P,\sigma_P)$ and has $\supp(\kappa_j g)\subseteq \mathcal{U}_j$. By virtue of Lemma \ref{lem:LocalIntegralFormula}, we have $(\varphi_j^{-1})^*(\kappa_j g\,d\sigma_P)$ is integrable on $U_j=\varphi(\mathcal{U}_j)$ and
\begin{equation}\label{eq:LebesgueRiemann1}
\int_S \kappa_j(\eta)g(\eta)\sigma_P(d\eta)=\int_{U_j}(\varphi_j^{-1})^*(\kappa_j g\,d\sigma_P)
\end{equation}
for each $j\in\mathbb{N}$. With the help of Proposition \ref{prop:FormRiemannRelation}, it is easy to see that $g\,d\sigma_P$ and $\kappa_j g\,d\sigma_P$ (for $j\in\mathbb{N}$) are Lebesgue measurable $d'$-forms on $S$. In view of (4.4.6) of \cite{Naber2011}, \eqref{eq:LebesgueRiemann1} ensures that, for each $j\in\mathbb{N}$, $\kappa_j g\,d\sigma_P$ is integrable (in the sense of forms) on $S$ and
\begin{equation*}
\int_S \kappa_j(\eta)g(\eta)\sigma_P(d\eta)=\int_S \kappa_j g\,d\sigma_P.
\end{equation*}
By the monotone convergence theorem, it follows that
\begin{equation*}
\sum_{j=1}^\infty\left| \int_S \kappa_j g\,d\sigma_P\right|=\sum_{j=1}^\infty \left|\int_S \kappa_j(\eta)g(\eta)\sigma(d\eta)\right|\leq \sum_{j=1}^\infty\int_S \kappa_j(\eta)|g(\eta)|\sigma_P(d\eta)=\|g\|_{L^1(S,\Sigma_P,\sigma_P)}<\infty.
\end{equation*}
Therefore, in view of the construction on p. 242 of \cite{Naber2011}, we conclude that the $d'$-form $g\,d\sigma_P$ is integrable and
\begin{equation*}
\int_S g(\eta)\sigma_P(d\eta)=\int_S \kappa_j(\eta)g(\eta)\sigma_P(d\eta)=\sum_{j=1}^\infty \int_{S} \kappa_j g\,d\sigma_P=\int_S g\,d\sigma_P
\end{equation*}
by virtue of the dominated convergence theorem; this is \eqref{eq:FormsAndMeasures}.

Finally, given that $\abs{\grad P}$ is continuous and non-vanishing on the compact set $S$,
\begin{equation*}
    C_1 := \inf_S\frac{1}{|\grad P|}\quad\mbox{and}\quad C_2 := \sup_{S}\frac{1}{\abs{\grad P }}
\end{equation*}
are both positive real numbers. For each $F\in \Sigma_P\subseteq\mathcal{L}(S)$, \eqref{eq:FormsAndMeasures} guarantees that
\begin{equation*}
    \sigma_P(F)=\int_S\chi_F(\eta)\sigma_P(d\eta)=\int_S \chi_Fd\sigma_P
\end{equation*}
By virtue of Proposition \ref{prop:FormRiemannRelation}, it follows that
\begin{equation*}
C_1\Vol_S(F)=C_1\int_S \chi_F\,d\Vol_S\leq \int_S \frac{\chi_F}{|\grad P|}d\Vol_S=\int_S \chi_F\,d\sigma_P=\sigma_P(F)
\end{equation*}
and
\begin{equation*}
    \sigma_P(F)=\int_S\chi_F d\sigma_P=\int_S\frac{\chi_F}{|\grad P|}\,d\Vol_S\leq C_2\int_S\chi_F\,d\Vol_S=C_2\Vol_S(F)
\end{equation*}
where we have used the definition of the Riemannian volume measure on $S$, c.f., \cite{Amann2009}. In short, there are positive constants $C_1$ and $C_2$ for which
\begin{equation}\label{eq:FormsAndMeasures2}
    C_1\Vol_S(F)\leq\sigma_P(F)\leq C_2\Vol_S(F)
\end{equation}
for all $F\in\Sigma_P$. In particular, \eqref{eq:FormsAndMeasures} holds for all $F\in\mathcal{B}(S)$ and so it follows that the completions of the $\sigma$-algebra $\mathcal{B}(S)$ with respect to $\sigma_P$ and $\Vol_S$ coincide. We know, however, that $\Vol_S$, which is defined on $\mathcal{L}(S)$, is a Radon measure ((Proposition 1.5 \cite[Chapter XII]{Amann2009})) and, by virtue of Proposition \ref{prop:Regular}, it follows that $\Sigma_P=\mathcal{L}(S)$ and \eqref{eq:FormsAndMeasures2} holds for all $F$ in this common $\sigma$-algebra. Thus $\sigma_P$ and $\Vol_S$ are mutually absolutely continuous and the theorem is proved.
\end{proof}

\noindent We immediately obtain the following corollary which allows us to compute the Lebesgue integral with respect to $\sigma_P$ in coordinates.
\begin{corollary}\label{cor:IntegralFormula}
Let $g\in L^1(S,\mathcal{L}(S),\sigma_P)$. Then, given any  countable (or finite) atlas $\{(\mathcal{U}_j,\varphi_j)\}\subseteq\mathcal{A}_+(S)$,  smooth partition of unity $\{\kappa_j\}$ subordinate to $\{\mathcal{U}_j\}$, and $E\in\Exp(P)$,
\begin{equation*}
\int_S g(\eta)\sigma_P(d\eta)=\sum_{j}\int_S \kappa_jg\,d\sigma_P=\sum_j\int_{U_j}\kappa_j(\varphi^{-1}(u))g(\varphi^{-1}(u))h_{E,\varphi_j}(u)\,du
\end{equation*}
where, for each $j$, $U_j=\varphi_j(\mathcal{U}_j)\subseteq\mathbb{R}^{d'}$ and
\begin{equation*}
    h_{E,\varphi_j}(u)=\det(E\varphi^{-1}(u)\vert D_u\varphi^{-1})
\end{equation*}
for $u=(u^1,u^2,\dots,u^{d'})\in U_j$. 
\end{corollary}








\appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Appendix}\label{sec:Appendix}
\subsection{Continuous one-parameter subgroups of $\Gl(\mathbb{R}^d)$.}\label{subsec:OneParameterGroups}

\begin{proposition}[See Section 8 of \cite{Randles2017}]\label{prop:ContinuousGroupProperties}
Let $E,G\in\End(\mathbb{R}^d)$ and $A\in\Gl(\mathbb{R}^d)$. Also, let $E^*$ denote the adjoint of $E$. Then, for all $t,s>0$, the following statements hold:

\vspace{.3cm}
\begin{tabular}{lllll}
$\bullet$ $1^E=I$ &  $\bullet$ $t^{E^*}=(t^E)^*$ & $\bullet$ $(t^E)^{-1}=t^{-E}$ &   $\bullet$ If $EG=GE$, then $t^Et^G=t^{E+G}$\\
\vspace{.1cm}\\
$\bullet$ $(st)^E=s^Et^E$ & $\bullet$ $At^EA^{-1}=t^{AEA^{-1}}$&  $\bullet$ $\det\left(t^E\right)=t^{\tr E}$\\

\end{tabular}
\end{proposition}

\begin{definition} A continuous one-parameter group $T_t=t^E$ is said to be \textit{contracting} if
\begin{equation*}
\lim_{t\to 0}\|T_t\|=0. 
\end{equation*}
\end{definition}
\noindent By virtue of the Banach-Steinhaus theorem, we have the following useful characterization.
\begin{proposition}\label{prop:ContractingCharacterization}
Let $\{T_t\}$ be a continuous one-parameter group. Then $\{T_t\}$ is contracting if and only if
\begin{equation}\label{eq:ContractingSufficient}
\lim_{t\to 0}|T_tx|=0
\end{equation}
for all $x\in\mathbb{R}^d$.
\end{proposition}

\begin{proof}It is clear that \eqref{eq:ContractingSufficient} is a necessary condition for $\{T_t\}$ to be contracting. We must therefore prove \eqref{eq:ContractingSufficient} also sufficient. To this end, we assume that the continuous one-parameter group $\{T_t\}$ satisfies \eqref{eq:ContractingSufficient}. By virtue of the continuity of $\{T_t\}$ and \eqref{eq:ContractingSufficient}, we have
\begin{equation*}
\sup_{0<t\leq 1}|T_t x|<\infty
 \end{equation*}
for each $x\in\mathbb{R}^d$. From the Banach-Steinhaus theorem, it follows that $\|T_t\|\leq C$ for all $0<t\leq 1$. Now, suppose that $\{T_t\}$ is not contracting. In this case, one can find a sequence $\{\eta_n\}\subseteq\mathbb{S}$ and a sequence $t_n\rightarrow 0$ for which $\lim_n|T_{t_n}\eta_n|>0$. But because the unit sphere is compact, $\{\eta_n\}$ has a convergence subsequence $\eta_{n_k}\rightarrow \eta$ with $|\eta|=1$ . Observe that, for all $n$,
 \begin{equation*}
 |T_{t_n}(\eta-\eta_n)|\leq C|\eta-\eta_n|
 \end{equation*}
 and so it follows that
 \begin{equation*}
 \lim_{k\rightarrow\infty}|T_{t_{n_k}}\eta|=\lim_{k\rightarrow\infty}|T_{t_{n_k}}\eta_{n_k}|>0,
 \end{equation*}
 a contradiction.
 \end{proof}




\begin{lemma}\label{lem:OperatorBoundsforContractingGroup}
Let $\{T_t\}\subseteq\GldR$ be a continuous one-parameter group and let $E\in\End(\mathbb{R}^d)$ be its generator, i.e., $T_t=t^E$ for all $t>0$.
If $\{T_t\}$ is contracting, then $E\in\Gl(\mathbb{R}^d)$ and there is a positive constant $C$ for which
\begin{equation*}
\|T_t\|\leq C+t^{\|E\|}
\end{equation*}
for all $t>0$.
\end{lemma}
\begin{proof}
If for some non-zero vector $\eta$, $E\eta=0$, then $t^E\eta=\eta$ for all $t>0$ and this would contradict our assumption that $\{T_t\}$ is contracting. Hence $E\in\Gl(\mathbb{R}^d)$ and, in particular, $\|E\|>0$. From the representation $T_t=t^E$, it follows immediately that $\|T_t\|\leq t^{\|E\|}$ for all $t\geq 1$ and so it remains to estimate $\|T_t\|$ for $t<1$. Given that $\{T_t\}$ is continuous and contracting, the map $t\mapsto \|T_t\|$ is continuous and approaches $0$ as $t\rightarrow 0$ and so it is necessarily bounded for $0<t\leq 1$.
\end{proof}




\begin{proposition}\label{prop:ContractingLimits}
Let $\{T_t\}_{t>0}\subseteq\Gl(\mathbb{R}^d)$ be a continuous one-parameter contracting group.  Then, for all non-zero $x\in\mathbb{R}^d$,
\begin{equation*}
\lim_{t\rightarrow 0}|T_t x|=0\hspace{.5cm}\mbox{ and }\hspace{.5cm}\lim_{t\rightarrow\infty}|T_t x|=\infty.
\end{equation*}
\end{proposition}
\begin{proof}
The validity of the first limit is clear. Upon noting that $|x|=|T_{1/t}T_tx|\leq \|T_{1/t}\||T_t x|$ for all $t>0$, the second limit follows at once.
\end{proof}
\begin{proposition}\label{prop:ScaleFromSphere}
Let $\{T_t\}_{t>0}$ be a continuous one-parameter contracting group. There holds the following:
\begin{enumerate}[label=(\alph*), ref=(\alph*)]
\item\label{item:ScaleFromSphere_1} For each non-zero $x\in \mathbb{R}^d$, there exists $t>0$ and $\eta\in \mathbb{S}$ for which $T_t\eta=x$. Equivalently,
\begin{equation*}
\mathbb{R}^d\setminus\{0\}=\{T_t\eta:t>0\mbox{ and }\eta\in \mathbb{S}\}.
\end{equation*}
\item\label{item:ScaleFromSphere_2} For each sequence $\{x_n\}\subseteq\mathbb{R}^d$ such that $\lim_n|x_n|=\infty$, $x_n=T_{t_n}\eta_n$ for each $n$, where $\{\eta_n\}\subseteq \mathbb{S}$ and $t_n\rightarrow\infty$ as $n\rightarrow\infty$.
\item\label{item:ScaleFromSphere_3} For each sequence $\{x_n\}\subseteq\mathbb{R}^d$ such that $\lim_n|x_n|=0$, $x_n=T_{t_n}\eta_n$ for each $n$, where $\{\eta_n\}\subseteq \mathbb{S}$ and $t_n\rightarrow 0$ as $n\rightarrow\infty$.
\end{enumerate}
\end{proposition}
\begin{proof}
In view of Proposition \ref{prop:ContractingLimits}, the assertion \ref{item:ScaleFromSphere_1} is a straightforward application of the intermediate value theorem. For \ref{item:ScaleFromSphere_2}, suppose that $\{x_n\}\subseteq\mathbb{R}^d$ is such that $|x_n|\rightarrow \infty$ as $n\rightarrow\infty$. In view of \ref{item:ScaleFromSphere_1}, take $\{\eta_n\}\subseteq S$ and $\{t_n\}\subseteq (0,\infty)$ for which $x_n=T_{t_n}\eta_n$ for each $n$. In view of Lemma \ref{lem:OperatorBoundsforContractingGroup},
\begin{equation*}
\infty=\liminf_n |x_n|\leq\liminf_n \left(C+t_n^M\right)|\eta_n|\leq C+\liminf_nt_n^M,
\end{equation*}
where $C,M>0$ and therefore $t_n\rightarrow\infty$. If instead $\lim_n x_n=0$,
\begin{equation*}
\infty=\lim_{n\rightarrow\infty}\frac{|\eta_n|}{|x_n|}=\lim_{n\rightarrow\infty}\frac{|T_{1/t_n}x_n|}{|x_n|}\leq\limsup_n\|T_{1/t_n}\|\leq\limsup_n(C+(1/t_n)^M)
\end{equation*}
from which we see that $t_n\rightarrow 0$, thus proving \ref{item:ScaleFromSphere_3}.
\end{proof}


\begin{proposition}\label{prop:ContractingCapturesCompact}
Let $\{T_t\}$ be a continuous contracting one-parameter group. Then for any open neighborhood $\mathcal{O}\subseteq\mathbb{R}^d$ of the origin and any compact set $K\subseteq\mathbb{R}^d$, $K\subseteq T_t(\mathcal{O})$ for sufficiently large $t$.
\end{proposition}
\begin{proof}
Assume, to reach a contradiction, that there are sequences $\{x_n\}\subseteq K$ and $t_n\rightarrow\infty$ for which $x_n\notin T_{t_n}(\mathcal{O})$ for all $n$. Because $K$ is compact, $\{x_n\}$ has a subsequential limit and so by relabeling, let us take sequences $\{\zeta_k\}\subseteq K$ and $\{r_k\}\subseteq (0,\infty)$ for which $\zeta_k\rightarrow \zeta$, $r_k\rightarrow\infty$ and $\zeta_k\notin T_{r_k}(\mathcal{O})$ for all $k$. Setting $s_k=1/r_k$ and using the fact that $\{T_t\}$ is a one-parameter group, we have $T_{s_k}\zeta_k\notin\mathcal{O}$ for all $k$ and so $\liminf_{k}|T_{s_k}\zeta_k|>0$, where $s_k\rightarrow 0$. This is however impossible because $\{T_t\}$ is contracting and so
\begin{equation*}
\lim_{k\rightarrow\infty}|T_{s_k}\zeta_k|\leq\lim_{k\rightarrow \infty}|T_{s_k}(\zeta_k-\zeta)|+\lim_{k\rightarrow\infty}|T_{s_k}\zeta|\leq C\lim_{k\rightarrow\infty}|\zeta_k-\zeta|+0=0
\end{equation*}
in view of Lemma \ref{lem:OperatorBoundsforContractingGroup}.
\end{proof}


\subsection{Results on Positive-homogeneous and subhomogeneous functions}


\begin{proof}[Proof of Proposition \ref{prop:PositiveHomogeneousCharacterization}]
In the case that $d=1$, it is easy to see that every function satisfying the hypotheses is of the form
\begin{equation*}
P(x)=\begin{cases}
P(1)x^\alpha \\
P(-1)(-x)^\alpha
\end{cases}
\end{equation*}
for some $\alpha>0$ where $P(1),P(-1)>0$ and $\Exp(P)$ consists only of the linear function $x\mapsto x/\alpha$. In this setting, it is easy to see that Conditions \ref{cond:SisCompact}--\ref{cond:InfiniteLimit} are satisfied (always and) simultaneously. We shall therefore assume that $d>1$ for the remainder of the proof.

\begin{subproof}[$\ref{cond:SisCompact}\Rightarrow\ref{cond:PisAboveOne}$]
Given that $S$ is compact, it is bounded and so we have a positive number $M$ for which $P(x)\neq 1$ for all $|x|\geq M$. Observe that, if for two points $x_1,x_2\in \mathbb{R}^d\setminus\mathbb{B}_M(0)$, $P(x_1)<1<P(x_2)$ or $P(x_2)<1<P(x_1)$, then by virtue of the path connectedness of $\mathbb{R}^d\setminus\mathbb{B}_M(0)$ and the intermediate value theorem, we would be able to find  $x_0\in\mathbb{R}^d\setminus\mathbb{B}_M(0)$ for which $P(x_0)=1$, an impossibility. Therefore, to show that Condition \ref{cond:PisAboveOne} holds, we must simply rule out the case in which $P(x)<1$ for all $|x|\geq M$. Let us therefore assume, to reach a contradiction, that this alternate condition holds. In this case, we take $E\in\Exp(P)$ and $y\in\mathbb{R}^d\setminus \{0\}$ and observe that
\begin{equation*}
\lim_{r\to\infty}P(r^Ey)=\lim_{r\to\infty}rP(y)=\infty.
\end{equation*}
By virtue of our supposition, we find that $|r^Ey|<M\leq M$ for all sufficiently large $r$. In particular, there exists a sequence $r_k\to\infty$ for which $|r_k^Ey|\leq M$ for all $k$ and 
\begin{equation*}
\lim_{k\to\infty}P(r_k^Ey)=\infty.
\end{equation*}
Because $\overline{\mathbb{B}_M(0)}$, the closure of $\mathbb{B}_M(0)$, is compact, $\{r_k^Ey\}$ has a convergent subsequence which we also denote by $\{r_k^Ey\}$ by a slight abuse of notation. In view of the continuity of $P$ at $\eta=\lim_{k\to\infty}r_k^Ey$, we have
\begin{equation*}
P(\eta)=\lim_{k\to\infty}P(r_k^Ey)=\lim_{k\to\infty}r_kP(y)=\infty,
\end{equation*}
which is impossible. Thus Condition \ref{cond:PisAboveOne} holds.
\end{subproof}
\begin{subproof}[$\ref{cond:PisAboveOne}\Rightarrow\ref{cond:Contracting}$]
We shall prove the contrapositive statement. Suppose that, for $E\in\Exp(P)$, $\{r^E\}$ is not contracting. In this case, by virtue of Proposition \ref{prop:ContractingCharacterization}, there exists $x\in\mathbb{R}^d\setminus\{0\}$ and a sequence $r_k\to 0$ for which $r_k^Ex$ does not converge to zero in $\mathbb{R}^d$. If our sequence $\{r_k^Ex\}$ is bounded, then it must have a convergent subsequence $\{r_{k_m}^Ex\}$ with non-zero subsequential limit $\eta=\lim_{m\to\infty}r_{k_m}^Ex$. By the continuity of $P$, we have
\begin{equation*}
P(\eta)=\lim_{m\to\infty}P(r_{k_m}^Ex)=\lim_{k\to\infty}r_{k_m}P(x)=0
\end{equation*}
which cannot be true for it would violate the positive-definiteness of $P$. We must therefore consider the other possibility: The sequence $\{r_k^Ex\}$ is unbounded. In particular, there must be some $k_0$ for which $r_{k_0}<1/P(x)$ and $|r_{k_0}^Ex|>M$. Upon putting $y=r_{k_0}^Ex$, we have $|y|>M$ and  $P(y)=P(r_{k_0}^Ex)=r_{k_0}P(x)<1$ which shows that Condition \ref{cond:PisAboveOne} cannot hold.
\end{subproof}
\begin{subproof}[$\ref{cond:Contracting}\Rightarrow\ref{cond:ThereExistsContracting}$] This is immediate.
\end{subproof}
\begin{subproof}[$\ref{cond:ThereExistsContracting}\Rightarrow\ref{cond:InfiniteLimit}$]
Let $E\in\Exp(P)$ be such that $\{r^E\}$ is contracting and let $\{x_k\}\subseteq\mathbb{R}^d$ be such that $\lim_{k\to\infty}|x_k|=\infty$. By virtue of Proposition \ref{prop:ScaleFromSphere}, there exist sequences $\{r_k\}\subseteq (0,\infty)$ and $\{\eta_k\}\in\mathbb{S}$ for which $r_k^E\eta_k=x_k$ for all $k$ and $\lim_{k\to\infty}r_k=\infty$. Given that $P$ is continuous and strictly positive on the compact set $\mathbb{S}$, we have $\inf_{\eta\in\mathbb{S}}P(\eta)>0$ and therefore
\begin{equation*}
\liminf_k P(x_k)=\liminf_k r_kP(\eta_k)\geq \liminf_k r_k\left(\inf_{\eta\in\mathbb{S}}P(\eta)\right)=\infty
\end{equation*}
showing that $\lim_{k\to\infty} P(x_k)=\infty$, as desired.
\end{subproof}
\begin{subproof}[$\ref{cond:InfiniteLimit}\Rightarrow\ref{cond:SisCompact}$]
Because $S$ is the preimage of the closed singleton $\{1\}$ under the continuous function $P$, it is closed. By virtue of Condition \ref{cond:InfiniteLimit}, $S$ is also be bounded and thus compact in view of the Heine-Borel theorem.
\end{subproof}
\end{proof}

\noindent For a continuous, positive definite function $P$ for which $\Exp(P)$ is non-empty, the following proposition gives a sufficient condition for $P$ to be positive-homogeneous. As discussed in Example \ref{exp:Weierstrass} above, it is this condition that was used to define ``positive-homogeneous polynomial" in \cite{Randles2017}. \textcolor{red}{We still do not know if this condition is also necessary. See Theorem 1 Part c on Page 178 of \cite{Braun1993}.}



\begin{proposition}\label{prop:PosHomSufficientCondition}
If $P$ is continuous, positive definite and $\Exp(P)$ contains an $E\in\End(\mathbb{R}^d)$ with real spectrum, then $\{r^E\}$ is contracting and hence all of the above conditions are (simultaneously) met. 
\end{proposition}
\begin{proof}
Since $\Spec(E)$ is real, the characteristic polynomial of $E$ factors completely over $\R$ and so we may apply the Jordan-Chevalley decomposition to write $E=S+N$ where $S$ is diagonalizable, $N$ is nilpotent, and $SN=NS$. Let $v_1,v_2,\dots,v_d \in \R^d$ be an eigenbasis of $S$ whose corresponding eigenvalues $\lambda_1,\lambda_2,\dots,\lambda_d$ satisfy $\lambda_k\leq \lambda_{k+1}$ for all $k=1,2\dots,d-1$.

Let us assume, to reach a contradiction, 
that $\{ r^E \}$ is not contracting. Repeating the same argument given in $\ref{cond:PisAboveOne}\Rightarrow\ref{cond:Contracting}$ in the proof of Proposition \ref{prop:PositiveHomogeneousCharacterization}, leaves us with only one possibility: There is a non-zero $x = \sum^d_{i=1}\alpha_i v_i \in\mathbb{R}^d$, and a sequence $r_k\to 0$ for which $|r_k^E x|\to\infty$. Let $n+1$ denote the index of $N$, then we have
\begin{equation*}
r^E_k x = r_k^{N+S} x 
= r_k^N r_k^S x 
= \sum_{j=0}^n\sum_{i=1}^d \f{r_k^{\lambda_i}(\log r_k)^j}{j!}   \alpha_iN^j v_i
\end{equation*}
for all $k$. Since $\abs{r_k^E x} \to \infty$ and $r_k \to 0$, at least one eigenvalue of $S$ must be non-positive. To see this, suppose $\lambda_i > 0$ for all $i = 1,2,\dots,d$, then in view of L'H\^{o}pital's rule we have
\begin{equation*}
    \lim_{r_k \to 0}(\log r_k)^j r_k^{\lambda_i} = 0  
\end{equation*}
for any $j =0, 1,2,\dots,n$ and $i =1,2,\dots,d$, which implies that $\abs{r^E_k x} \not\to \infty$ as $r_k \to 0$, contradicting our assumption. Thus, $\lambda_1 = \min\{ \Spec(S)\} \leq 0$. Let $k$ be such that $N^k v_1 \neq 0$ but $N^{k+1} v_1 = 0$, then
\begin{equation*}
    r^E N^k v_1 = r^S r^N N^k v_1 = r^S \sum_{j=0}^\infty \f{(\log r)^j}{j!}N^j N^k v_1 = r^S N^k v_1 = N^k r^S  v_1 =  r^{\lambda_{1}} N^k  v_1
\end{equation*}
where we have used the fact that $SN = NS$. If $\lambda_1= 0$, then 
\begin{equation*}
    \infty =  \lim_{r\to \infty} rP(N^k v_1)  = \lim_{r\to \infty} P( r^S r^N N^k v_1) =  \lim_{r\to \infty}P(r^{0} N^k v_1)= \lim_{r\to \infty}P( N^k v_1) = P(N^k v_1)
\end{equation*}
which is impossible since $P$ is continuous at $N^k v_1$. On the other hand, if $\lambda_1 < 0$, then
\begin{equation*}
    \infty = \lim_{r\to \infty} rP(N^k v_1) = \lim_{r\to \infty} P(r^S r^N N^k v_1) = \lim_{r\to \infty}P(r^{\lambda_1} N^k v_1) = P(0) = 0
\end{equation*}
which is also impossible. 
\end{proof}

\noindent We end this section by addressing a useful proposition which connects $\Exp(P)$ and $\Sym(P)$. Given $O\in\Sym(P)$, we write
\begin{equation*}
    OF=\{O\eta:\eta\in F\}.
\end{equation*}

\begin{proposition}\label{prop:ExpP}
For any  $O \in \Sym{(P)} $
\begin{equation*}
    \Exp(P) = O^\top \Exp(P) O.
\end{equation*}
In other words, the set $\Exp(P)$ is invariant under conjugation by $\Sym(P)$.
\end{proposition}

\begin{proof}
Since $\Sym(P)$ is a subgroup of the orthogonal group $O(\mathbb{R}^d)$, $O^\top = O^{-1} \in \Sym{P}$ whenever $O\in\Sym(P)$. For a fixed $O\in\Sym(P)$, it is easy to see that the map $\Exp(P)\ni E\mapsto  O^\top E O\in\Exp(P)$ is a bijection and hence $\Exp(P)=O^\top \Exp(P) O$. 
% Observe that, if $O^\top E_1 O=O^\top E_2 O$, then by left multiplying by $O$ and right multiplying by $O^T=O^{-1}$ we find that $E_1=E_2$ whence $\mbox{Conj}$ is injective.
% Now, if $E_i, E_j\in \Exp(P)$ and $E_i\neq E_j$, then $O^\top E_i O \neq O^\top E_j O$ since $O,O^\top\in \OdR{}$. Thus the conjugation map induced by $O$, $\varphi_O: \Exp{P}\to \Exp{P}$ defined by 
% \begin{equation*}
%     \varphi_O (E) = O^\top E O
% \end{equation*}
% is one-to-one. Further, for any $E\in \Exp(P)$, a similar argument as \eqref{eq:OOO} shows that $OEO^\top \in \Exp(P)$ and satisfies
% \begin{equation*}
%     \varphi_O(OEO^\top) = O^\top (OEO^\top) O = E\in \Exp{(P)}.
% \end{equation*}
% So, $\varphi_O$ is bijective, which means 
% \begin{equation*}
%     \Exp(P) = O^\top \Exp(P) O = O \Exp{(P)} O^\top, \quad \text{for all } O\in \Sym{(P)}.
% \end{equation*}
\end{proof}

\begin{proposition}\label{prop:supersub_implies_sub}
Let $Q$ be differentiable on an open neighborhood of $0$ in $\mathbb{R}^d$ and let $E\in\End(\mathbb{R}^d)$ be such that $\{r^E\}$ is a contracting group. If $Q$ is strongly subhomogeneous with respect to $E$ and $Q(0)=0$, then $Q$ is subhomogeneous with respect to $E$.
\end{proposition}
\begin{proof}
Let $\epsilon>0$ and $K$ be a compact set.  In view of our supposition that $Q$ is strongly subhomogeneous with respect to $E$, let $\delta>0$ be given so that $\abs{\partial_r Q(r^E\xi)}\leq \epsilon$ for all $\xi\in K$ and $0<r< \delta$. Given that $r^E$ is a contracting group and $Q(0)=0$, it follows that, for each $\xi\in K$, $f_{\xi}:[0,\delta)\to\mathbb{C}$ defined by
\begin{equation*}
f_{\xi}(r)=\begin{cases}
Q(r^E\xi) & 0<r<\delta\\
0 & r=0
\end{cases}
\end{equation*}
is differentiable on $(0,\delta)$ and continuous on $[0,\delta)$, for each $\xi\in K$. Consequently, for every $0<r<\delta$ and $\xi\in K$, the mean value theorem guarantees a $c=c_{\xi,r}\in (0,r)$ for which 
\begin{equation*}
\abs{f_{\xi}(r)-f_{\xi}(0)}\leq r\abs{f_{\xi}'(c)}=r\abs{\partial_r Q(c^E\xi)}\leq r\epsilon.
\end{equation*}
Consequently, for all $0<r<\delta$ and $\xi\in K$,
\begin{equation*}
\abs{Q(r^E\xi)}=\abs{f_{\xi}(r)-f_{\xi}(0)}\leq r\epsilon.
\end{equation*}
\end{proof}



\begin{proposition}\label{prop:Subhomequivtolittleoh}
Let $P$ be positive-homogeneous and $\widetilde{P}$ be complex-valued and continuous on a neighborhood of $0$ in $\mathbb{R}^d$. The following are equivalent:
\begin{enumerate}[label=(\alph*), ref=(\alph*)]
    \item\label{item:Subhomequivtolittleoh1} $\widetilde{P}(\xi)=o(P(\xi))$ as $\xi\to 0$.
    \item\label{item:Subhomequivtolittleoh2} For every $E\in\Exp(P)$, $\widetilde{P}$ is subhomogeneous with respect to $E$.
    \item\label{item:Subhomequivtolittleoh3} There exists $E\in\Exp(P)$ for which $\widetilde{P}$ is subhomogeneous with respect to $E$.
\end{enumerate}
\end{proposition}
\begin{proof}
\begin{subproof}[\ref{item:Subhomequivtolittleoh1} $\Rightarrow$ \ref{item:Subhomequivtolittleoh2}] Let $\epsilon>0$, $K$ be a compact set and choose $E\in \Exp(P)$. Given our supposition that $\widetilde{P}(\xi)=o(P)(\xi)$ as $\xi\to 0$, we can find an open neighborhood $\mathcal{O}$ of $0$ for which 
\begin{equation*}
\abs{\widetilde{P}(\xi)}\leq \frac{\epsilon}{1+\sup_{\eta\in K}P(\eta)}P(\xi)
\end{equation*}
for all $\xi\in \mathcal{O}$. Now, because $r^E$ is contracting in view of Proposition \ref{prop:PositiveHomogeneousCharacterization}, we can find a $\delta>0$ for which $r^E\xi\in \mathcal{O}$ for all $0<r<\delta$ and $\xi\in K$ by virtue of Proposition \ref{prop:ContractingCapturesCompact}. Consequently, for all $0<r<\delta$ and $\xi\in K$,
\begin{equation*}
\abs{\widetilde{P}(r^E\xi)}\leq \frac{\epsilon}{1+\sup_{\eta\in K}P(\eta)}P(r^E\xi)=\epsilon r\frac{P(\xi)}{1+\sup_{\eta\in K}P(\eta)}\leq r\epsilon.
\end{equation*}
\end{subproof}

\begin{subproof} [\ref{item:Subhomequivtolittleoh2} $\Rightarrow$ \ref{item:Subhomequivtolittleoh3}] This implication is trivial.
\end{subproof}
 
 \begin{subproof}[\ref{item:Subhomequivtolittleoh3} $\Rightarrow$ \ref{item:Subhomequivtolittleoh1}]  Let $\epsilon>0$. Choose $E\in \Exp(P)$ and let $S=\{\eta\in\mathbb{R}^d:P(\eta)=1\}$. Using the supposition that $\widetilde{P}$ is subhomogeneous with respect to $E$, we may choose $\delta>0$ for which
\begin{equation*}
\abs{\widetilde{P}(r^E\eta)}\leq \epsilon r 
\end{equation*}
 for all $0<r<\delta$ and $\eta\in S$. We remark that, in view of the continuity of $\widetilde{P}$ and the fact that $r^E$ is contracting, this inequality ensures that $\widetilde{P}(0)=0$. We set $\mathcal{O}=\{0\}\cup \psi_E((0,\delta)\times S)$, which is necessarily an open set by virtue of Proposition \ref{prop:PsiHomeomorphism}. Then, for every $\xi=r^E\eta \in\mathcal{O}\setminus\{0\}$, 
\begin{equation*}
\abs{\widetilde{P}(\xi)}=\abs{\widetilde{P}(r^E\eta)}\leq r\epsilon=\epsilon rP(\eta)=\epsilon P(r^E\eta)=\epsilon P(\xi)
\end{equation*}
If $\xi=0$, obviously, $\abs{\widetilde{P}(\xi)}=0=\epsilon P(0)=\epsilon P(\xi)$. Thus, for all $\xi\in\mathcal{O}$,
\begin{equation*}
\abs{\widetilde{P}(\xi)}\leq\epsilon P(\xi),
\end{equation*}
as desired.
\end{subproof}
\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\begin{thebibliography}{99}

% \bibitem{absil2009optimization}
% Absil, P-A and Mahony, Robert and Sepulchre, Rodolphe.
% \newblock{\em Optimization algorithms on matrix manifolds}.
% \newblock{\em Princeton University Press, 2009}


\bibitem{Amann2009}
H. Amann and J. Escher
\newblock {\em {Analysis III} }
\newblock {Birkh\"{a}user Basel, 2009}

\bibitem{Apostol1974} 
T.M. Apostol
\newblock {\em {Mathematical Analysis} 2nd Edition}
\newblock {Addison-Wesley, 1974}

\bibitem{Baker1997} 
John A. Baker
\newblock {\em {Integration over spheres and the divergence theorem for balls.}}
\newblock {\textit{The American Mathematical Monthly}, 104(1):36-47, 1997.}

\bibitem{Browder1996} 
A. Browder
\newblock {\em {Mathematical Analysis: An Introduction} \newblock {Springer-Verlag, New York, Berlin, 1996}}

\bibitem{Bogachev2007}
V. I. Bogachev.
\newblock {\em {Measure Theory} Vol. 1}.
\newblock Springer-Verlag, 2007.

\bibitem{Braun1993}
M. Braun
\newblock {\em {Differential Equations and Their Applications} Fourth Ed.}
\newblock Springer-Verlag, 1993.

\bibitem{DSC2014}  
Persi Diaconis and Laurent Saloff-Coste. 
\newblock { Convolution powers of complex functions on Z.}
\newblock {\textit{Math. Nachrichten}, 287(10):1106–1130, 2014.}

\bibitem{Engel2005}
Klaus-Jochen Engel and Rainer Nagel
\newblock {\em {A Short Course on Operator Semigroups}}.
\newblock Springer-Verlag, 2005

\bibitem{Engel2000}
K.-J. Engle and R. Nagel
\newblock {\em {One-Parameter Semigroups for Linear Evolution Equations}}, {\em Graduate Texts in Mathematics., Vol. 194,}
\newblock Springer-Verlag, 2000. 

\bibitem{Folland1984}
Gerald Folland.
\newblock {\em {Real Analysis: Modern Techniques and Their Applications}}, {\em Pure \& Applied Mathematics}.
\newblock Wiley-Interscience, 1984

\bibitem{Folland2001}
Gerald Folland.
\newblock {\em{How to Integrate a Polynomial over a Sphere.}}
\newblock {\em{The American Mathematical Monthly.} 108(5):446-448, 2001} 

\bibitem{Hormander1983}
Lars H{\"{o}}rmander.
\newblock {\em {The Analysis of Linear Partial Differential Operators II}}.
\newblock Springer-Verlag Berlin Heidelberg, Berlin, 1983.

\bibitem{lee2013smooth}
Lee, John M.
\newblock{{\em Introduction to Smooth Manifolds,} Second Ed.}
\newblock{\em Springer, 2013}


\bibitem{Naber2011}
Naber, Gregory L.
\newblock{{\em Topology, Geometry
and Gauge fields,} Second Ed.}
\newblock{\em Springer, 2011}

\bibitem{Randles2015}
Evan Randles and Laurent Saloff-Coste.
\newblock {\em {``On the Convolution Powers of Complex Functions on $\mathbb{Z}$''}}.
\newblock {\em J. Fourier Anal. Appl.}, 21(4):754--798, 2015.

\bibitem{Randles2017}
Evan Randles and Laurent Saloff-Coste. 
\newblock {\em {``Convolution powers of complex functions on $\mathbb{Z}^d$.''}
\newblock Revista Matem\'{a}tica Iberoamericana, vol. 33, no. 3, 2017, pp. 1045-1121.}

\bibitem{Randles2017a}
Evan Randles and Laurent Saloff-Coste.
\newblock {\em {``Positive-homogeneous operators, heat kernel estimates and the Legendre-Fenchel transform.''}}
\newblock {Stochastic Analysis and Related Topics: A Festschrift in Honor of Rodrigo Ba\~{n}uelos. Progress in Probability, Book 72 (2017).}


\bibitem{Rudin1987}
Walter Rudin.
\newblock {\em {Real and Complex Analysis}}, {\em McGraw-Hill Series in Higher Mathematics}.
\newblock WCB/McGraw-Hill, 1987.

\bibitem{Stein2005}
Elias Stein and Rami Shakarchi.
\newblock {\em {Real Analysis} Measure Theorem, Integration, \& Hilbert Spaces}, {\em Princeton Lectures in Analysis III}.
\newblock Princeton University Press, 2005.

\bibitem{SteinHarmonicAnalysis}
Elias Stein.
\newblock {\em Harmonic Analysis: Real-Variable Methods, Orthogonality, and Oscillatory Integrals}, 1st Edition.
\newblock Princeton University Press, 1993.

\bibitem{Thomee1965}
Vidar Thom{\'{e}}e.
\newblock {Stability of difference schemes in the maximum-norm}.
\newblock {\em J. Differ. Equ.}, 1(3):273--292, jul 1965.

\bibitem{YoshidaFunctionalAnalysis}
Yoshida, K\^{o}saku.
\newblock {\em Functional Analysis}, 6th Edition.
\newblock Springer-Verlag, 1980.

\end{thebibliography}




\end{document}