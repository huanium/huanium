\documentclass[11pt, letter]{book}
%\usepackage[margin=1in, bindingoffset= 0.25 in]{geometry}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage[margin=0.5in]{caption}
\usepackage{comment}
\usepackage{palatino}
\usepackage{amsmath, amsthm, latexsym, amssymb, color,cite,enumerate, physics, framed}
\usepackage{lipsum}
\usepackage{caption,subcaption,verbatim, empheq, cancel}
\usepackage[inline]{enumitem}
\usepackage{mathtools}
\usepackage{soul} %For \st (a new form of \sout)
\pagenumbering{arabic}
%\theoremstyle{theorem}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{convention}[theorem]{Convention}
\newtheorem{conjecture}[theorem]{Conjecture}
%\theoremstyle{remark}
\newtheorem{remark}{Remark}
\newtheorem{examplex}{Example}
\newenvironment{example}
  {\pushQED{\qed}\renewcommand{\qedsymbol}{$\triangle$}\examplex}
  {\popQED\endexamplex}
\newcommand*{\myproofname}{Proof}
\newenvironment{subproof}[1][\myproofname]{\begin{proof}[#1]\renewcommand*{\qedsymbol}{$\mathbin{/\mkern-6mu/}$}}{\end{proof}}
\renewcommand\Re{\operatorname{Re}}%%redefined Re and Im
\renewcommand\Im{\operatorname{Im}}
\newcommand\MdR{\mbox{M}_d(\mathbb{R})} %dxd matrices
\newcommand\End{\operatorname{End}} %Prefix linear transformations
\newcommand\GldR{\mbox{Gl}_d(\mathbb{R})}%dxd invertible matrices
\newcommand\Gl{\operatorname{Gl}} %Prefix for general linear group
\newcommand\OdR{\mbox{O}_d(\mathbb{R})} %Orthogonal matrices
\newcommand\Sym{\operatorname{Sym}}
\newcommand\Exp{\operatorname{Exp}}
%\newcommand\tr{\operatorname{tr}}
\newcommand\diag{\operatorname{diag}}
\newcommand\supp{\operatorname{Supp}}
\newcommand\Spec{\operatorname{Spec}}
\renewcommand\det{\operatorname{det}}
\newcommand\Ker{\operatorname{Ker}}
\newcommand\Interior{\operatorname{Int}}
\newcommand\R{\mathbb{R}}
\newcommand{\lp}{\left(}
\newcommand{\rp}{\right)}
\newcommand{\lb}{\left[}
\newcommand{\rb}{\right]}
\newcommand{\lc}{\left\{}
\newcommand{\rc}{\right\}}
\newcommand{\lag}{\mathcal{L}}
\newcommand{\p}{\partial}
\newcommand{\f}[2]{\frac{#1}{#2}}
\newcommand{\Vol}{\operatorname{Vol}}
\newcommand{\iprod}{\mathbin{\lrcorner}}
\newcommand{\al}{\alpha}
\newcommand{\be}{\beta}
\newcommand{\FT}{\mathcal{F}}
\newcommand{\LT}{\mathcal{L}}
\usepackage{hyperref}
\usepackage{tensor}
\usepackage{xcolor}
\hypersetup{
	colorlinks,
	linkcolor={black!50!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black}
}
\newcommand{\slantedslash}{\mathbin{\rotatebox[origin=c]{23}{$-$}}}
\newcommand{\rint}{\mathop{\mathpalette\docircint\relax}\!\int}
\newcommand{\docircint}[2]{%
  \ifx#1\displaystyle
    \displayrint
  \else
    \normalrint{#1}%
  \fi
}
\newcommand{\displayrint}{\displaystyle \slantedslash \mkern-18mu}
\newcommand{\normalrint}[1]{%
  \smallerc{#1}\ifx#1\textstyle\mkern-9mu\else\mkern-8.2mu\fi
}
\newcommand{\smallerc}[1]{%
  \vcenter{\hbox{$\ifx#1\textstyle\scriptstyle\else\scriptscriptstyle\fi \slantedslash $}}%
}


% 3j symbol
\newcommand{\tj}[6]{ \begin{pmatrix}
		#1 & #2 & #3 \\
		#4 & #5 & #6 
\end{pmatrix}}
% 6j symbol
\newcommand{\Gj}[6]{ \begin{Bmatrix}
		#1 & #2 & #3 \\
		#4 & #5 & #6 
\end{Bmatrix}}


\begin{document}

%%%%%%%%%%%%%%%% Title Page %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\thispagestyle{empty}
\begin{center}
{\Large{\textbf{
A generalized polar-coordinate integration formula, \\
oscillatory integral techniques, and applications to convolution powers of complex-valued functions on $\mathbb{Z}^d$
}}}\\
\vspace{1cm}
{\large{Huan Q. Bui}}\\
\vspace{7cm}
A thesis presented to the faculty of the\\
Department of Mathematics and Statistics at\\
Colby College\\
\vspace{7cm}
Department of Mathematics and Statistics\\
Colby College\\
Waterville, ME\\
May, 2021
\end{center}


%%%%%%%%%%%%%%%% Abstract %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section*{Abstract} 


In this article, we consider a class of function on $\mathbb{R}^d$, called positive homogeneous functions, which interact well with certain continuous one-parameter groups of (generally anisotropic) dilations. Generalizing the Euclidean norm, positive homogeneous functions appear naturally in the study of convolution powers of complex-valued functions on $\mathbb{Z}^d$. As the spherical measure is a Radon measure on the unit sphere which is invariant under the symmetry group of the Euclidean norm, to each positive homogeneous function $P$, we construct a Radon measure $\sigma_P$ on $S=\{\eta \in \mathbb{R}^d:P(\eta)=1\}$ which is invariant under the symmetry group of $P$. With this measure, we prove a generalization of the classical polar-coordinate integration formula and deduce a number of corollaries in this setting. We then turn to the study of convolution powers of complex functions on $\mathbb{Z}^d$ and certain oscillatory integrals which arise naturally in that context. Armed with our integration formula and the Van der Corput lemma, we establish sup-norm-type estimates for convolution powers; this result is new and partially extends results of \cite{randles_convolution_2015} and \cite{randles_convolution_2017}.

%%%%%%%%%%%%%%%% Acknowledgments %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section*{Acknowledgments} 



%%%%%%%%%%%%%%%% Table of Contents %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\tableofcontents

%%%%%%%%%%%%%%%% List of Figures and Tables %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\listoffigures
%\listoftables




%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introduction}\label{chap:intro}


In this thesis, we make two distinct studies, a generalized polar coordinate integration formula and convolution powers of finitely-supported complex-valued functions on $\mathbb{Z}^d$. Though these topics appear unrelated, we will utilize the former (Theorem \ref{thm:BestIntegrationFormula}) as a tool to deduce certain estimates for oscillatory integrals, which are subsequently used to prove a new result related to the latter  (Theorem \ref{thm:ConvolutionPowerEstimate}).



\section{A generalized polar-coordinate integration formula}







\noindent In vector calculus, one often evaluates integrals of the form
\begin{equation*}
    \int_{\mathbb{R}^d} f(x)\,dx
\end{equation*}
using polar coordinates whenever the function $f$ has a radial symmetry. In $\mathbb{R}^3$, for example, we may have 
\begin{equation*}
    \int_{\mathbb{R}^3} f(x)\,dx = \int_{0}^\infty \int_{0}^{2\pi} \int_0^{\pi} f(r\eta(\theta,\phi)) r^2 \sin\theta \,d\theta\, d\phi \, dr,
\end{equation*}
where the scaling factor $r^2 \sin\theta$ comes from the determinant of the Jacobian associated with the change of variables. By recognizing that every non-zero $x\in\mathbb{R}^3$ can be written as $x=r\eta(\theta,\phi)$ where $r=|x|$ and $\eta(\theta,\phi)=(\sin\theta\cos\phi,\sin\theta\sin\phi,\cos\theta)$ is a point on the unit sphere, the formula above breaks the computation into integration over a radial part (integration over $r$) and a angular part (integration over the polar and azimuthal angles). In $d$ dimensions, we may generalize this approach by introducing the spherical measure for the angular part.  To introduce this generalization, we let $m$ be the Lebesgue measure on $\mathbb{R}^d$, and write $dx=m(dx)=dm(x)$. Let $\mathbb{S}$ denote the standard unit sphere in $\mathbb{R}^d$. The spherical measure is the canonical Radon measure on $\mathbb{S}$ for which $\Theta(\mathbb{S})=d\cdot m(\mathbb{B})$ and $\Theta(OF)=\Theta(F)$ for every orthogonal transformation $O$ and Borel set $F\subseteq\mathbb{S}$. With this measure, we state the classical polar coordinate integration formula as follows: For every $f\in L^1(\mathbb{R}^d)$ (or non-negative measurable $f$),
\begin{equation}\label{eq:StandardPolarIntegrationFormula}
\int_{\mathbb{R}^d}f(x)\,dx=\int_{\mathbb{S}}\left(\int_0^\infty f(r\eta)r^{d-1}\,dr\right)\,\Theta(d\eta)=\int_0^\infty\left(\int_\mathbb{S}f(r\eta)\Theta(d\eta)\right)r^{d-1}\,dr.
\end{equation}
Precise formulation of this classical result can be found in \cite{stein_real_2009} and \cite{folland_real_2013}. For two interesting applications which provide some useful context, we encourage the reader to see \cite{baker_integration_1997} and \cite{folland_how_2001}.\\




\noindent In this thesis, we generalize the polar-coordinate integration formula \eqref{eq:StandardPolarIntegrationFormula} and its corresponding measure $\Theta$ in a way that is well-aligned to the analysis of certain oscillatory integrals which appear in the study of convolution powers of complex-valued functions on $\mathbb{Z}^d$. Inspired by the classical integration formula, our generalized integration formula also breaks the integration over $\mathbb{R}^d$ into a radial integration and an angular integration. However, the spherical measure in the classical formula is replaced by a more general surface-carried measure which arises naturally from the (Fourier) analysis of convolution powers. Our generalized formula will prove to be a useful tool in the analysis of such oscillatory integrals, leading to the advertised sup-norm-type estimate (Theorem \ref{thm:ConvolutionPowerEstimate}) for convolution powers of complex-valued functions and, in a forthcoming article, a theory of local limit theorems.\\ 

\noindent To describe the generalized polar coordinate integration formula treated in this article, we must first introduce a class of functions on $\mathbb{R}^d$ which share several desirable properties with the Euclidean norm. This gives rise to the notion of positive homogeneous functions, which we will define and study in Chapter \ref{chap:pos-hom-fns}.








\section{Beyond the Classical Local (Central) Limit Theorem}




\noindent In random walk theory and probability theory, convolution powers of a distribution of independent and identically distributed (i.i.d.) random vectors are of central importance. Given a sequence $X_1, X_2, \dots, X_n \in \mathbb{Z}^d$ of i.i.d. random vectors from a probability distribution $\phi$, i.e., for each $k=1,2,\dots$,
\begin{equation*}
    \phi(x)=\mathbb{P}(X_k=x)
\end{equation*}
for all $x\in\mathbb{Z}^d$, we consider the sequence of random vectors $S_1,S_2,\dots$ where $S_n=X_1+X_2 +\dots+X_n$ for each $n\in\mathbb{N}_+$. This sequence $\{S_n\}$, called the random walk driven by $\phi$, represents the position of the random walker after $n$ steps where each step is taken according to $\phi$, independently of the last step.\\

\noindent Using the fact that the random vectors $X_1,X_2,\dots$ are i.i.d, we may compute the distribution of $S_n$ as follows. Since $S_1 = X_1$, the distribution of $S_1$ is simply $\phi$. To compute the distribution of $S_2$, for each $x\in\mathbb{Z}^d$, we have
\begin{eqnarray*}
    \mathbb{P}(S_2=x)
    &=&\mathbb{P}(X_1+X_2=x)\\
    &=&\mathbb{P}(X_2=x-X_1)\\
    &=& \sum_{y\in\mathbb{Z}^d} \mathbb{P}(X_2 = x-y|X_1=y)\\
    &=& \sum_{y\in\mathbb{Z}^d} \mathbb{P}(X_2 = x-y)\mathbb{P}(X_1 = y)\\
    &=&\sum_{y\in\mathbb{Z}^d}\phi(x-y)\phi(y)
\end{eqnarray*}
where the penultimate equality follows from the independence of $X_1$ and $X_2$. In other words, the distribution of $S_2$ is given by the \textbf{convolution} of $\phi$ with itself:
\begin{align*}
    (\phi \ast \phi)(x) = \sum_{y\in \mathbb{Z}^d} \phi(y-x) \phi(y).
\end{align*}
By induction, the distribution of $S_n$ is the $n$th-convolution power of $\phi$ and is defined iteratively by
\begin{equation*}
    \phi^{(n)}(x)=\sum_{y\in\mathbb{Z}^d}\phi^{(n-1)}(x-y)\phi(y) = \phi^{(n-1)}\ast \phi^{(1)}
\end{equation*}
for $n=2,\dots$, $x\in\mathbb{Z}^d$, where $\phi^{(1)} = \phi$. 


\begin{example}\normalfont
Consider the following simple random walk driven by $\phi: \mathbb{Z}^d \to \mathbb{R}$, which is given by 
\begin{align*}
    \phi(x) = 
    \begin{cases}
    1/2d, &\quad x = \pm e_j\\
    0, &\quad \text{otherwise}
    \end{cases}
\end{align*}
for $j = 1,2,\dots, d$, where $e_j$ denotes the unit vector pointing in the $j$th direction. Here, $S_n$ represents the position of the random walker after $n$ steps where each step is taken uniformly in any direction on the lattice according to $\phi$, independently of the last step. For $d=2$, 
\begin{align*}
    (\phi\ast\phi) (x) = 
    \begin{cases}
    1/4, &\quad x = (0,0)\\ 
    1/8, &\quad x = (\pm 1, \pm 1)\\
    1/16, &\quad x = (\pm 2, 0) \mbox{ or } (0,\pm 2)\\
    0, &\quad \mbox{otherwise} 
    \end{cases}.
\end{align*}
\end{example}


\noindent Two interesting concepts related to random walk theory are \textbf{recurrence} and \textbf{transience}. A random walk is recurrent
if it visits its starting position infinitely often with probability one and transient if it visits its starting position finitely often with probability one

\begin{framed}
\begin{definition}
Let $\phi(x)$ be the distribution of a  $\mathbb{Z}^d$-valued r.v. with finite variance and zero mean. The random walk driven by $\phi$ is called \textbf{recurrent} if
\begin{equation*}
    \mathbb{P}(S_n = 0 \text{ for infinitely many } n ) = 1.
\end{equation*}
It is called \textbf{transient} if
\begin{equation*}
    \mathbb{P}(S_n = 0 \text{ for infinitely many } n ) = 0.
\end{equation*}
\end{definition}
\end{framed}
\noindent What's amazing is that the two possibilities of recurrence and transience for a random walk are collectively exhaustive: A random walk is either recurrent or it is transient. This is a consequence of the first and second Borel-Cantelli Lemma. The following theorem gives a characterization of recurrence and transience in terms of the convolution powers of the distribution $\phi$.

\begin{framed}
\begin{theorem}
The random walk driven by $\phi$ is recurrent if and only if $\sum_{n=1}^\infty \phi^{(n)}(0) = \infty$.
\end{theorem}
\end{framed}



\noindent It can be shown that a simple symmetric random walk on $\mathbb{Z}^d$ is recurrent in dimensions $d = 1, 2$ and transient in dimensions $d \geq 3$. A famous quote summarizes this result as follows: ``A drunken man will
always find his way home but a drunken bird may get lost forever.'' Here, we are of course assuming that the motion of both biological entities can be described as simple random walks. For a more thorough description of random walk theory, the reader may refer to \cite{spitzer_principles_1964}.\\



\noindent Fourier analysis allows one to learn about the asymptotic behavior of $\phi^{(n)}$ as $n\to\infty$. For example, when $\phi$ is associated with a random walk that is symmetric, aperiodic, irreducible, or of finite range (The reader may again refer to \cite{spitzer_principles_1964} for more details regarding these terminologies), one may establish the following theorem (Theorem \ref{thm:localglobal}). The first statement concerns the sup-norm behavior of $\phi^{(n)}$ and helps one determine if the random walk is recurrent or transient. The second is the celebrated local limit theorem (originally stated by Abraham de Moivre for independent Bernoulli trials and proved by Pierre-Simon Laplace \cite{mcdonald2005local}). The third is a so-called Gaussian-type estimate.


\begin{framed}
\begin{theorem}\label{thm:localglobal}
Let $\phi$ be a symmetric, aperiodic and irreducible probability distribution on $\mathbb{Z}^d$ with finite variance.
\begin{enumerate}
    \item The (global) decay of $\| \phi^{(n)} \|_\infty = \sup_{x\in \mathbb{Z}^d} \abs{\phi^{(n)}(x)}$: There are positive constants $C_1, C_2$ for which \begin{equation*}
        \f{C_1}{n^{d/2}} \leq \| \phi^{(n)} \|_\infty \leq \f{C_2}{n^{d/2}}
    \end{equation*}
    for all $n\in \mathbb{N}_+$.
    
    \item There exists a simple point-wise description of $\phi^{(n)}$ in the large $n$ limit: The classical local limit theorem states that
    \begin{equation*}
        \phi^{(n)}(x) = \f{1}{n^{d/2}} \Phi_\phi \lp \f{x}{n^{d/2}} \rp + o\lp \f{1}{n^{d/2}} \rp
    \end{equation*}
    uniformly for $x\in \mathbb{Z}^d$, where $\Phi_\phi$ is the generalized Gaussian density:
    \begin{equation*}
        \Phi_\phi(x) = \f{1}{(2\pi)^d} \int_{\mathbb{R}^d} \exp\lp -\xi \cdot C_\phi \xi \rp e^{-ix\cdot \xi}\,d\xi = \f{1}{(2\pi)^{d/2} \sqrt{\det C_\phi} }\exp \lp -\f{x\cdot C_\phi^{-1} x }{2} \rp,
    \end{equation*}
    with $C_\phi$ the positive definite covariance matrix associated to $\phi$. 
    
    \item A global point-wise estimate for $\phi^{(n)}$ is the so-called Gaussian estimate: For positive constants $C$ and $M$, we have
    \begin{equation*}
        \phi^{(n)}(x) \leq \f{C}{n^{d/2}} \exp \lp -\f{M\abs{x}^2}{n} \rp
    \end{equation*}
    for all $x\in \mathbb{Z}^d$ and $n\in \mathbb{N}_+$, where $|\cdot|$ denotes the Euclidean norm. 
\end{enumerate}
\end{theorem}
\end{framed}






\noindent When $\phi$ is not necessarily a probability distribution, the question of whether one can still obtain global and local/point-wise decay estimates and descriptions of its convolution powers $\phi^{(n)}$ in the large $n$ limit remains valid despite the lack of an underlying stochastic (probabilistic) process \footnote{There is a related generalized notion of ``pseudo-process'' whose steps are driven by ``pseudo random variables" whose distributions are signed (See \cite{lachal2008first}).}.
In the works of Persi Diaconis, Evan Randles, and Laurent Saloff-Coste (see, for example, \cite{randles_convolution_2015}, \cite{randles_convolution_2017}, \cite{diaconis_convolution_2014}), one drops the positivity and real-valuedness of $\phi$, and considers the collection of complex-valued functions $\phi$ defined on the $d$-dimensional integer lattice $\mathbb{Z}^d$ for which $\phi$ is absolutely summable, i.e.,
\begin{equation*}
    \| \phi \|_1 = \sum_{x\in \mathbb{Z}^d} \abs{\phi(x)} < \infty.
\end{equation*}
The collection of such functions is denoted by $\ell^1(\mathbb{Z}^d)$ and contains all finitely supported functions on $\mathbb{Z}^d$. For each such $\phi\in\ell^1(\mathbb{Z}^d)$, one can compute its convolution powers $\phi^{(n)}$ (as done in the probabilistic setting) and study the asymptotic behavior of $\phi^{(n)}$. As illustrated in Example \ref{exp:firstExample}, one still finds rich limiting behaviors of $\phi^{(n)}$, many of which have never appeared in the probabilistic setting.


%Example \ref{exp:firstExample} shows the real part of the convolution powers of such a $\phi$ defined on $\mathbb{Z}^2$. 

\begin{example}\label{exp:firstExample}\normalfont
Consider the function $\phi : \mathbb{Z}^2 \to \mathbb{C}$ defined below. Figure \ref{fig:conv_1} shows the real part of $\phi^{(n)}$ for $n=300$ and $n=600$. 
\begin{equation*}
    \phi(x,y) = 
    \f{1}{768}\times
    \begin{cases}
    602 - 112i &(x,y) = (0,0)\\
    56 + 32i   &(x,y) = (-1,0)\\
    72 + 32i   &(x,y) = (1,0)\\
    -16        &(x,y) = (\pm 2,0)\\
    56 + 32i   &(x,y) = (0,\pm 1)\\
    -28 - 8i   &(x,y) = (0,\pm 2)\\
    56         &(x,y) = (0,\pm 3)\\
    -1         &(x,y) = (0,\pm 4)\\
    4          &(x,y) = (-1,\pm 1)\\
    -4         &(x,y) = (1,\pm 1)\\
    0          &\text{otherwise}.
    \end{cases}
\end{equation*}


\begin{figure}[!htb]
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.54]{conv_ex0.eps}
    \caption{$n = 300$.}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.54]{conv_ex1.eps}
    \caption{$n = 600$.}
    \end{subfigure}
    \caption{The real part of $\phi^{(n)}$ for (a) $n=300$ and (b) $n=600$}
    \label{fig:conv_1}
\end{figure}
\end{example}


\noindent  To capture the asymptotic behaviors of $\phi^{(n)}$ thus calls for new theories beyond the classical local (central) limit theorem. This is the main objective of the recent papers \cite{randles_convolution_2015}, \cite{randles_convolution_2017}, \cite{diaconis_convolution_2014}, in which great strides have been made towards proving a new local limit theorem for a large class of sufficiently nice functions $\phi$. In \cite{randles_convolution_2015}, the theory is completely known for the case where $\phi$ is defined on $\mathbb{Z}$. Extending earlier works by Thom\'{e}e, de Forest, Schoenberg\footnote{Mathematician Isaac Jacob Schoenberg (1903-1990) was a Romanian-American Assistant Professor of Mathematics at Colby College from 1936 to 1941. He is most well-know for his discovery of mathematical splines --  special functions defined piecewise by polynomials.}, and Greville and using techniques of Fourier analysis, \cite{randles_convolution_2015} not only established asymptotic bounds for the sup-norm of the convolution powers of finitely-supported complex-valued functions on $\mathbb{Z}$ but also proved extended local limit theorems pertaining to this entire class. In \cite{randles_convolution_2017}, a local limit theorem is attained for the case concerning the $d$-dimensional integer lattice; however, it is only applicable to special subset of $\phi$'s. The natural next step is therefore to generalize the result of \cite{randles_convolution_2017} to all admissible $\phi$ on $\mathbb{Z}^d$.\\



\noindent In this thesis, we will mainly be concerned with the question of how the sup-norm of $\phi^{(n)}$ decays in $n$, which is paralleled by item 1 in Theorem \ref{thm:localglobal}, and our goal is to obtain a global estimate for $\abs{\phi^{(n)}}$. The following theorem (Theorem 1.1 of \cite{randles_convolution_2015}) provides a complete answer for finitely supported functions in $\mathbb{Z}^d$ where $d=1$. 


\begin{framed}
\begin{theorem}[Theorem 1.1 of \cite{randles_convolution_2015}]
Let $\phi : \mathbb{Z} \to \mathbb{C}$ be finitely supported and whose support contains more than one point. Then there is a natural number $m \geq 2$, and positive constants, $A$, $C$, and $C'$ such that 
\begin{equation*}
    Cn^{-1/m} \leq A^{-n}\| \phi^{(n)} \|_\infty \leq C' n^{-1/m}
\end{equation*}
for all natural numbers $n$. Here, $A=\sup|\widehat{\phi}(\xi)|$ where $\widehat{\phi}$ is $\phi$'s Fourier transform, introduced in Chapter \ref{chap:Estimate-ConvPwr}.
\end{theorem}
\end{framed}

\noindent Theorem 1.4 of \cite{randles_convolution_2017} (Theorem \ref{thm:d} below) treats the $d\geq 1$ case and considers ``sufficiently nice'' but not an all encompassing class of functions. Its hypotheses will be defined in Chapter \ref{chap:Estimate-ConvPwr}; the objects $\mathcal{S}_d$, $\mu_\phi$, $\Omega(\phi)$ and the notion of positive homogeneous type are due to \cite{randles_convolution_2017} and will be made more precise in the following chapters. The reader may refer to \cite{randles_convolution_2017} for their definitions; however, knowing these definitions is not a prerequisite for what to come in this paper.

\begin{framed}
\begin{theorem}[Theorem 1.4 of \cite{randles_convolution_2017}]\label{thm:d}
Let $\phi \in \mathcal{S}_d$ be such that $\abs{\widehat{\phi}(\xi)} = 1$ and suppose that each $\xi \in \Omega(\phi)$ is of positive homogeneous type for $\widehat{\phi}$. Then there are positive constants $\mu_\phi$, $C$, and $C'$ for which 
\begin{equation*}
    C'n^{-\mu_\phi} \leq \| \phi^{(n)} \|_\infty \leq C n^{-\mu_\phi}
\end{equation*}
for all $n\in \mathbb{N}$.
\end{theorem}
\end{framed}

\noindent The main idea of the above result is that, similar to the results of \cite{randles_convolution_2015}, one can obtain a uniform sup-norm bound for the convolution powers of $\phi$ when $d>1$, but under the positive homogeneous condition. One main objective of this thesis is thus to relax this condition and partially extend the above theorem. This requires the generalized polar-coordinate integration formula, which we will formally construct in Chapter \ref{chap:formula}. 







\section{Some notational conventions}
In addition to some conventions outlined in the previous sections, we shall denote by $\mathbb{N}$, and $\mathbb{N}_+$ the set of (non-negative) natural numbers and positive natural numbers, respectively; the $d$-tuples formed by elements of these sets will be denoted by $\mathbb{Z}^d$, $\mathbb{N}^d$, and $\mathbb{N}_+^d$. 
Our setting is $d$-dimensional Euclidean space $\mathbb{R}^d$ with coordinates $(x^1,x^2,\dots,x^d)$ equipped with the dot product and associated Euclidean norm. We take $\mathbb{R}^d$ to be equipped with its usual topology and (oriented) smooth structure. Given $x\in\mathbb{R}^d$ and $R>0$, the open ball with center $x$ and radius $R$ is denoted by $\mathbb{B}_R(x)$ and its corresponding sphere is denoted by $\mathbb{S}_R(x)$. We write $\mathbb{B}=\mathbb{B}_1(0)$ to denote the standard unit ball in $\mathbb{R}^d$. For a subset $A$ of a topological space, we denote by $\Interior{(A)}$, $\overline{A}$, and $\partial A$ its interior, closure and boundary, respectively. We shall denote by $\End(\mathbb{R}^d)$ the collection of linear transformations on $\mathbb{R}^d$ and by $\MdR$ the corresponding set of $d\times d$ real matrices. We denote by $\Gl(\mathbb{R}^d)$ the general linear group and by $\GldR$ the corresponding group of $d\times d$ invertible real matrices. For $E\in \End(\mathbb{R}^d)$ (or $E\in\MdR$), $\|E\|$ will denote the so-called operator norm.







%%%%%%%%%%%%%%%% Pos-Hom Functions %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Positive Homogeneous Functions}\label{chap:pos-hom-fns}

In this chapter, we make precise and extend the definition of positive homogeneous polynomials as appeared in \cite{randles_convolution_2017}. We also introduce the notions of \textbf{subhomogeneous functions} and \textbf{strongly subhomogeneous functions}, which appear alongside positive homogeneous polynomials/functions in a certain Taylor expansion related to the Fourier transform of $\phi$. These classes of functions are key ingredients for estimating the convolution powers of $\phi$ via the Van der Corput lemma, particularly in the cases where oscillatory integrals are involved. This chapter is essentially Section 2 of \cite{bui2021generalized}.\\

\noindent To start, we shall review the notion of continuous one-parameter groups defined in Definition \ref{def:cont_one_param_group}. Continuous one-parameter groups appear naturally when one characterizes the radial scaling in a general quasi-polar parameterization. For instance, in the usual polar coordinates we have \textbf{isotropic} scaling in the radial variable $r$ and can choose our continuous one-parameter group to be $\{T_r \}_{r>0} = r^E$ where $E$ is a linear transformation with standard matrix representation $\diag(1/2, 1/2)$. It is clear that $\{T_r \}_{r>0}$ is a group, and that any point $v\in \mathbb{R}^d \setminus \{0\}$ can be written uniquely as $r^E \eta$ where $\eta\in \mathbb{S}$. In general, $E$ needs not be a multiple of the identity transformation $\mathbb{I}$ (whose standard representation is of course $\diag(1,1)$). In such cases, we have \textbf{anisotropic} scaling. For example, let $E'$ be $\diag(1/2, 1/4)$ in the standard basis. Any point $v\in \mathbb{R}^2\setminus\{0\}$ can also be written uniquely as $r^{E'}\eta'$ where $\eta' \in \{ (\eta'_1,\eta'_2) \in \mathbb{R}^2 : {\eta'}_1^{2} + {\eta'}_2^{4} = 1  \}$ and $r> 0$. 

% Continuous one-parameter group
\begin{framed}
\begin{definition}\label{def:cont_one_param_group}
$\{T_r \}_{r>0} \subseteq \Gl{(\mathbb{R}^d)}$ is said to be a \textbf{continuous one-parameter group} if
\begin{enumerate}
    \item $T_r : \mathbb{R}^d \to \mathbb{R}^d$ is a linear operator for each $r>0$;
    \item $T_r$ is continuous in $r$ (in the usual topology in $\Gl{\mathbb{R}^d}$);    
    \item $T_0 = \mathbb{I}_d$, where $\mathbb{I}_d$ denotes the identity on $\Gl{(\mathbb{R}^d)}$;
    \item $T_{uv} = T_u T_v$ for all $u,v >0$. 
\end{enumerate}
\end{definition}
\end{framed}
\noindent It is well-known (c.f., \cite{randles_convolution_2017,engel_one-parameter_2000,engel_short_2006}) that every continuous one-parameter group $\{T_r\}$ has the unique representation
\begin{equation*}
T_r=r^E=\exp((\ln r) E)=\sum_{k=0}^\infty \frac{(\ln r)^k}{k!}E^k
\end{equation*}
for some $E\in\End(\mathbb{R}^d)$. $E$ is called (infinitesimal) generator of $\{T_r\}$, and $\{T_r\}$ is said to be generated by $E$. For simplicity, we shall use this representation throughout the paper, i.e., any element of $\{T_r \}_{r>0}$ has the form $r^E$. We write $T_r= r^E$ to be explicit about $E$.\\

\noindent An important aspect of the continuous one-parameter groups $\{T_r \}_{r>0}$ is the \textbf{contracting} property. Intuitively, this means that the radial scaling becomes vanishingly small as the parameter $r$ approaches $0$. This property will become useful in our construction of the measure on $S$ where it is used to contract sufficiently nice sets $F\subseteq S$ into the unit ball.
% Contracting group
\begin{framed}
\begin{definition} \label{def:contracting_group} A continuous one-parameter group $\{T_r\}$ is said to be \textbf{contracting} if
\begin{equation*}
\lim_{r\to 0}\|T_r\|=0. 
\end{equation*}
\end{definition}
\end{framed}

\noindent The next two results follow immediately from this definition. The first result is by virtue of continuity and the Banach-Steinhaus theorem (or, the uniform boundedness principle), while the second by the continuity of the determinant and the operator-norm topology on $\End{\mathbb{R}^d}$. The proof of Proposition \ref{prop:ContractingCharacterization} is presented in Appendix \ref{sec:OneParameterGroups}.
\begin{framed}
\begin{proposition}\label{prop:ContractingCharacterization}
Let $\{T_r\}$ be a continuous one-parameter group. Then $\{T_r\}$ is contracting if and only if for all $x\in\mathbb{R}^d$,
\begin{equation}
\lim_{t\to 0}|T_r x|=0.
\end{equation}
\end{proposition}
\end{framed}

% Contracting group has trE > 0
\begin{framed}
\begin{proposition}\label{prop:ContractingTrace}
Let $\{T_r\}\subseteq \Gl(\mathbb{R}^d)$ be a continuous one-parameter group with generator $E$. If $\{T_r\}$ is  contracting, then $\tr E>0$.
\end{proposition}
\end{framed}
\begin{proof}
The supposition that $\{T_r\}$ is a contracting group implies that $r^E\to \mathbf{0}$ as $r\to 0$ in the operator-norm topology on $\End(\mathbb{R}^d)$; here $\mathbf{0}$ is zero transformation. Because the determinant is a continuous function from $\End(\mathbb{R}^d)$, equipped with operator-norm topology, into $\mathbb{R}$, we have
\begin{equation*}
0=\det(\mathbf{0})=\det\left(\lim_{r\to 0}r^E\right)=\lim_{r\to 0}\det\left(r^E\right)=\lim_{r\to 0}r^{\tr E}
\end{equation*}
in view of the preceding proposition. Therefore, $\tr E>0$.
\end{proof}


%% Positive Homogeneous Functions (properties)

\noindent Now we are ready to define the notion of ``positive homogeneous functions.'' Recall the previous example of anisotropic scaling in which any point $v\in \mathbb{R}^2$ can be written as $r^{E}\eta$ where $E$ has standard matrix representation $\diag(1/2,1/4)$ and $\eta \in \{ (\eta_1,\eta_2) \in \mathbb{R}^2 : P(\eta_1, \eta_2) ={\eta}_1^{2} + {\eta}_2^{4} = 1  \}$. We observe that the function $P$ is ``homogeneous'' with respect to the matrix $E$ in the sense that 
\begin{equation*}
    P(r^{E}x) =  \lp r^{1/2}{x}_1\rp ^{2} + \lp r^{1/4}{x}_2\rp ^{4} = r P(x)
\end{equation*}
for all $x\in \mathbb{R}^d$ and $r>0$. Because such functions (which are not necessarily polynomials, as we will see) often show up in estimating convolution powers and their attractors, we will generalize and make precise this notion of homogeneity. In what follows, for a function $P:\mathbb{R}^d\to\mathbb{R}$, we shall call
\begin{equation*}
    S=\{\eta\in\mathbb{R}^d:P(\eta)=1\}
\end{equation*}
\textbf{the unital level set of $P$}. We say that $P$ is \textbf{positive definite} if $P$ is non-negative and $P(x)=0$ only when $x=0$. Given a continuous one-parameter group $\{T_r\}$, we say that $P$ is \textbf{homogeneous with respect to $\{T_r\}$} if
\begin{equation}\label{eq:IntroductionHomogeneous}
    rP(x)=P(T_r x)=P(r^Ex)
\end{equation}
for all $r>0$ and $x\in\mathbb{R}^d$. For a given map $P:\mathbb{R}^d\to\mathbb{R}$, the set of all $E$ for which \eqref{eq:IntroductionHomogeneous} is satisfied is called the \textbf{exponent set of $P$} and shall be denoted by $\Exp(P)$. We note that even though $P$ often appears as a polynomial in the convolution powers setting, we only require that it be a continuous function. \\



The forthcoming relates the unital level set $S$ to the contracting group $\{r^E\}$ for a positive-definite $P$ and lists the (equivalent) defining characteristics of a \textbf{positive-homogeneous function}. This characterization highlights an interplay between positive definite functions, contracting groups, and unital level sets and sets the stage for our definition of positive homogeneous functions\\


Just before we state and prove this proposition, however, it is helpful to fix some notation and introduce some basic topological objects connected to positive homogeneous functions.  Given a positive homogeneous function $P$, we define
\begin{equation*}
B_r=\{\xi\in\mathbb{R}^d:P(\xi)<r\}\hspace{1cm}\mbox{and}\hspace{1cm}A_s^r=\{\xi\in\mathbb{R}^d:s\leq P(\xi)<r\}
\end{equation*}
for $r>0$ and $0\leq s<r$; these are $P$-adapted analogues of the Euclidean ball, $\mathbb{B}_r$, and the annulus of inner radius $s$ and outer radius $r$, respectively. In view of of Proposition \ref{prop:PositiveHomogeneousCharacterization} and the continuity of $P$, we see that, for each $r>0$, $B_r$ is open and $\overline{B_r}$ is compact. Further, by setting $B=B_1$, it is a straightforward exercise to see that $\overline{B}=B\cup S$ where $\partial B=S$ is the unital level set associated to $P$. 

%% Some properties.
\begin{framed}
\begin{proposition}\label{prop:PositiveHomogeneousCharacterization}
Let $P:\mathbb{R}^d\to\mathbb{R}$ be continuous, positive definite, and have $\Exp(P)\neq \varnothing$. The following are equivalent:
\begin{enumerate}[label=(\alph*), ref=(\alph*)]
\item\label{cond:SisCompact} $S$ is compact.
\item\label{cond:PisAboveOne} There is a positive number $M$ for which
\begin{equation*}
P(x)>1
\end{equation*}
for all $|x|\geq M$. 
\item\label{cond:Contracting} For each $E\in\Exp(P)$, $T_r=r^E$ is contracting.
\item\label{cond:ThereExistsContracting} There exists $E\in\Exp(P)$ for which $T_r=r^E$ is contracting.
\item\label{cond:InfiniteLimit} We have
\begin{equation*}
\lim_{x\to\infty}P(x)=\infty.
\end{equation*}
\end{enumerate}
\end{proposition}
\end{framed}
\begin{proof}
In the case that $d=1$, it is easy to see that every function satisfying the hypotheses is of the form
\begin{equation*}
P(x)=\begin{cases}
P(1)x^\alpha & \mbox{ for }x\geq 0 \\
P(-1)(-x)^\alpha &\mbox{ for }x<0
\end{cases}
\end{equation*}
for some $\alpha>0$ where $P(1),P(-1)>0$ and $\Exp(P)$ consists only of the linear function $x\mapsto x/\alpha$. In this setting, it is easy to see that Conditions \ref{cond:SisCompact}--\ref{cond:InfiniteLimit} are satisfied (always and) simultaneously. We shall therefore assume that $d>1$ for the remainder of the proof.

\begin{subproof}[$\ref{cond:SisCompact}\Rightarrow\ref{cond:PisAboveOne}$]
Given that $S$ is compact, it is bounded and so we have a positive number $M$ for which $P(x)\neq 1$ for all $|x|\geq M$. Observe that, if for two points $x_1,x_2\in \mathbb{R}^d\setminus\mathbb{B}_M$, $P(x_1)<1<P(x_2)$ or $P(x_2)<1<P(x_1)$, then by virtue of the path connectedness of $\mathbb{R}^d\setminus\mathbb{B}_M$ and the intermediate value theorem, we would be able to find  $x_0\in\mathbb{R}^d\setminus\mathbb{B}_M$ for which $P(x_0)=1$, an impossibility. Therefore, to show that Condition \ref{cond:PisAboveOne} holds, we must simply rule out the case in which $P(x)<1$ for all $|x|\geq M$. Let us therefore assume, to reach a contradiction, that this alternate condition holds. In this case, we take $E\in\Exp(P)$ and $y\in\mathbb{R}^d\setminus \{0\}$ and observe that
\begin{equation*}
\lim_{r\to\infty}P(r^Ey)=\lim_{r\to\infty}rP(y)=\infty.
\end{equation*}
By virtue of our supposition, we find that $|r^Ey|<M$ for all sufficiently large $r$. In particular, there exists a sequence $r_k\to\infty$ for which $|r_k^Ey|\leq M$ for all $k$ and 
\begin{equation*}
\lim_{k\to\infty}P(r_k^Ey)=\infty.
\end{equation*}
Because $\overline{\mathbb{B}_M}$, the closure of $\mathbb{B}_M$, is compact, $\{r_k^Ey\}$ has a convergent subsequence which we also denote by $\{r_k^Ey\}$ by a slight abuse of notation. In view of the continuity of $P$ at $\eta=\lim_{k\to\infty}r_k^Ey$, we have
\begin{equation*}
P(\eta)=\lim_{k\to\infty}P(r_k^Ey)=\lim_{k\to\infty}r_kP(y)=\infty,
\end{equation*}
which is impossible. Thus Condition \ref{cond:PisAboveOne} holds.
\end{subproof}
\begin{subproof}[$\ref{cond:PisAboveOne}\Rightarrow\ref{cond:Contracting}$]
We shall prove the contrapositive statement. Suppose that, for $E\in\Exp(P)$, $\{r^E\}$ is not contracting. In this case, by virtue of Proposition \ref{prop:ContractingCharacterization}, there exists $x\in\mathbb{R}^d\setminus\{0\}$ and a sequence $r_k\to 0$ for which $r_k^Ex$ does not converge to zero in $\mathbb{R}^d$. If our sequence $\{r_k^Ex\}$ is bounded, then it must have a convergent subsequence $\{r_{k_m}^Ex\}$ with non-zero subsequential limit $\eta=\lim_{m\to\infty}r_{k_m}^Ex$. By the continuity of $P$, we have
\begin{equation*}
P(\eta)=\lim_{m\to\infty}P(r_{k_m}^Ex)=\lim_{k\to\infty}r_{k_m}P(x)=0
\end{equation*}
which cannot be true for it would violate the positive definiteness of $P$. We must therefore consider the other possibility: The sequence $\{r_k^Ex\}$ is unbounded. In particular, there must be some $k_0$ for which $r_{k_0}<1/P(x)$ and $|r_{k_0}^Ex|>M$. Upon putting $y=r_{k_0}^Ex$, we have $|y|>M$ and  $P(y)=P(r_{k_0}^Ex)=r_{k_0}P(x)<1$ which shows that Condition \ref{cond:PisAboveOne} cannot hold.
\end{subproof}
\begin{subproof}[$\ref{cond:Contracting}\Rightarrow\ref{cond:ThereExistsContracting}$] This is immediate.
\end{subproof}
\begin{subproof}[$\ref{cond:ThereExistsContracting}\Rightarrow\ref{cond:InfiniteLimit}$]
Let $E\in\Exp(P)$ be such that the one-parameter group $\{r^E\}$ is contracting and let $\{x_k\}\subseteq\mathbb{R}^d$ be such that $\lim_{k\to\infty}|x_k|=\infty$. By virtue of Proposition \ref{prop:ScaleFromSphere}, there exist sequences $\{r_k\}\subseteq (0,\infty)$ and $\{\eta_k\}\in\mathbb{S}$ for which $r_k^E\eta_k=x_k$ for all $k$ and $\lim_{k\to\infty}r_k=\infty$. Given that $P$ is continuous and strictly positive on the compact set $\mathbb{S}$, we have $\inf_{\eta\in\mathbb{S}}P(\eta)>0$ and therefore
\begin{equation*}
\liminf_k P(x_k)=\liminf_k r_kP(\eta_k)\geq \liminf_k r_k\left(\inf_{\eta\in\mathbb{S}}P(\eta)\right)=\infty
\end{equation*}
showing that $\lim_{k\to\infty} P(x_k)=\infty$, as desired.
\end{subproof}
\begin{subproof}[$\ref{cond:InfiniteLimit}\Rightarrow\ref{cond:SisCompact}$]
Because $S$ is the preimage of the closed singleton $\{1\}$ under the continuous function $P$, it is closed. By virtue of Condition \ref{cond:InfiniteLimit}, $S$ is also be bounded and thus compact in view of the Heine-Borel theorem.
\end{subproof}
\end{proof}



%% Positive Homogeneous Functions (DEFINITION)
\noindent The characterizing Proposition \ref{prop:PositiveHomogeneousCharacterization} gives us the following definition. 
\begin{framed}
\begin{definition}\label{def:pos-hom-fns}
Let $P:\mathbb{R}^d\to\mathbb{R}$ be continuous, positive definite and have $\Exp(P)\neq \varnothing$. If any one (and hence all) of the equivalent conditions in Proposition \ref{prop:PositiveHomogeneousCharacterization} are fulfilled, we say that $P$ is positive homogeneous.
\end{definition}
\end{framed}




%% EXAMPLES
\begin{example}\label{exp:EuclideanNorm}\normalfont
For any $\alpha>0$, the $\alpha$th-power of the Euclidean norm $x\mapsto |x|^\alpha$ is positive homogeneous.  In this case, the unital level set $S$ is the standard unit sphere $\mathbb{S}=\mathbb{S}_1$, $B=\mathbb{B}=\mathbb{B}_1$, and
\begin{equation*}
    \Exp(|\cdot|^\alpha)=\frac{1}{\alpha}I+\mathfrak{o}(d)
\end{equation*}
where $I$ is the identity and $\mathfrak{o}(d)$ is the Lie algebra of the orthogonal group $\OdR$ and is characterized by the set of skew-symmetric matrices. 
\end{example}

\begin{example}\label{exp:Polynomial}\normalfont
In the language of L. H\"{o}rmander \cite{hormander_analysis_1983}, consider semi-elliptic polynomial of the form
\begin{equation}\label{eq:SemiEllipticIntro}
    P(x)=\sum_{|\alpha:\mathbf{n}|=1}a_\alpha x^\alpha,
\end{equation}
where $\mathbf{n}=(n_1,n_2,\dots,n_d)$ is a $d$-tuple of positive even natural numbers\footnote{In Section \ref{sec:Examples}, we will write this as $\mathbf{n}=2\mathbf{m}$ for $\mathbf{m}\in\mathbb{N}_+^d$.}, and, for each multi-index $\alpha =(\alpha_1,\alpha_2,\dots,\alpha_d)\in\mathbb{N}^d$,
\begin{equation*}
    |\alpha:\mathbf{n}|:=\sum_{k=1}^d\frac{\alpha_k}{n_k},
\end{equation*}
and
\begin{equation*}
    x^\alpha=\left(x^1\right)^{\alpha_1}\left(x^2\right)^{\alpha_2}\cdots\left(x^d\right)^{\alpha_d}
\end{equation*}
for $x=\left(x^1,x^2,\dots,x^d\right)\in\mathbb{R}^d$. If we consider $E\in\End(\mathbb{R}^d)$ whose standard matrix representation is $\diag(1/n_1,1/n_2,\dots,1/n_d)$, we have
\begin{equation*}
    P\left(r^Ex\right)=\sum_{|\alpha:\mathbf{n}|=1}a_{\alpha}\left(r^{1/n_1}x^1\right)^{\alpha_1}\left(r^{1/n_2}x^2\right)^{\alpha_2}\cdots\left(r^{1/n_d}x^d\right)^{\alpha_d}=\sum_{|\alpha:\mathbf{n}|=1}a_\alpha r^{|\alpha:\mathbf{n}|}x^\alpha=rP(x)
\end{equation*}
for all $x\in\mathbb{R}^d$ and $r>0$ and therefore $E\in\Exp(P)$. It is easy to see that $T_r=r^E$ is a contracting group and so we have the following statement by virtue of Proposition \ref{prop:PositiveHomogeneousCharacterization}: \begin{center}\textit{If a semi-elliptic polynomial $P(x)$ of the form \eqref{eq:SemiEllipticIntro} is positive definite, then it is positive homogeneous.}
\end{center}

\noindent For two concrete examples, consider the polynomials $P_1$ and $P_2$ on $\mathbb{R}^2$ defined by
\begin{equation*}
    P_1(x,y)=x^2+y^4\hspace{1cm}\mbox{and}\hspace{1cm}P_2(x,y)=x^2+\frac{3}{2}xy^2+y^4
\end{equation*}
defined for $(x,y)\in\mathbb{R}^2$. It is straightforward to see that $P_1$ and $P_2$ are both positive definite and semi-elliptic of the form \eqref{eq:SemiEllipticIntro} with $\mathbf{n}=(2,4)$. Figure \ref{fig:PoneAndtwo} illustrates $P_1$ and $P_2$ along with their associated unital level sets $S_1$ and $S_2$ and corresponding sets $B_1=\{(x,y)\in\mathbb{R}^2:P_1(x,y)<1\}$ and $B_2=\{(x,y)\in\mathbb{R}^2:P_2(x,y)<1\}$ written with a slight abuse of notation.
\begin{figure}[!htb]
    \centering
    \hspace{10pt}
    \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.6]{Fig1a.eps}
    \vspace{-10pt}
    \includegraphics[scale=0.6]{Fig1b.eps}
    %\caption{}
    %\label{fig:convex_SP}
    \end{subfigure}%
    \hspace{-20pt}
    \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.6]{Fig1c.eps}
    \vspace{-10pt}
    \includegraphics[scale=0.6]{Fig1d.eps}
    %\caption{}
    %\label{fig:non_convex_SQ}
    \end{subfigure}
    \caption{The left column illustrates the graph of $P_1$ with its associated $S_1$ and convex $B_1$. The right column illustrates the graph of $P_2$ with its associated $S_2$ and non-convex $B_2$.}
    \label{fig:PoneAndtwo}
\end{figure}
\begin{remark}\label{rmk:PositiveHomogeneousPolynomialsVSFunctions}
In \cite{randles_convolution_2017}, a positive homogeneous polynomial $P$ is, by definition, a complex-valued multivariate polynomial on $\mathbb{R}^d$ for which $\Exp(P)$ contains an element of $\End(\mathbb{R}^d)$ whose spectrum is purely real and for which $R=\Re P$ is positive definite (see Proposition \ref{prop:PosHomSufficientCondition} below). By virtue of Proposition 2.2 of \cite{randles_convolution_2017}, for each such polynomial $P$ and $E\in\Exp(P)$ with real spectrum, there exists $A\in\Gl(\mathbb{R}^d)$ (representing a change of basis of $\mathbb{R}^d$) and a $d$-tuple of even positive natural numbers $\mathbf{n}=(n_1,n_2,\dots,n_d)\in\mathbb{N}_+^d$ for which $A^{-1}EA$ has standard matrix representation $\diag(1/n_1,1/n_2,\dots,1/n_d)$ and $(P\circ A)(x)$ is semi-elliptic of the form \eqref{eq:SemiEllipticIntro} with, in this case, complex coefficients. It follows that every real-valued positive homogeneous polynomial (in the sense of \cite{randles_convolution_2017}) is a positive homogeneous function in the sense of the present article. Of course, the semi-elliptic polynomials discussed above are positive homogeneous polynomials in the sense of \cite{randles_convolution_2017} where $A=I$. We refer the reader to Section 7.3 of \cite{randles_convolution_2017} which presents a real-valued positive homogeneous polynomial which is not semi-elliptic (and so $A\neq I$).
\end{remark}
\end{example}

\begin{example}\label{exp:Weierstrass}\normalfont
Let $Q$ be a positive homogeneous function with exponent set $\Exp(Q)$ and compact level set $S_Q=\{\eta:Q(\eta)=1\}$. Given any $f\in C^0(S_Q)$ for which $f(\eta)>0$ for all $\eta\in S_Q$ and $E\in \Exp(Q)$, define $P=P_{f,E,Q}:\mathbb{R}^d\to\mathbb{R}$ by
\begin{equation*}
P(x)=\begin{cases}
Q(x)f\left((Q(x))^{-E}x\right) & x\neq 0\\
0 & x=0
\end{cases}
\end{equation*}
for $x\in\mathbb{R}^d$. We claim that $P$ is positive homogeneous and $E\in\Exp(P)$.

\begin{subproof}To see this, we first observe that, for any $x\in\mathbb{R}^d\setminus \{0\}$, $Q((Q(x))^{-E}x)=Q(x)/Q(x)=1$ and hence $Q(x)^{-E}x\in S_Q$ and so the above formula makes sense and ensures that $P$ is continuous on $\mathbb{R}^d\setminus\{0\}$. Furthermore, because $f$ is continuous and positive on the compact set $S_Q$, we have $0<\min f\leq \max f<\infty$. From this it follows that $P$ is positive definite and, by virtue of the squeeze theorem, continuous at $x=0$. For any $r>0$ and $x\in\mathbb{R}^d$, we have
\begin{equation*}
P(r^Ex)=Q(r^Ex)f(Q(r^Ex)^{-E}r^Ex)=rQ(x)f(Q(x)^{-E}x)=rP(x)
\end{equation*}
and therefore $E\in\Exp(P)$. Upon noting that $\{r^E\}$ is contracting by virtue of Proposition \ref{prop:PositiveHomogeneousCharacterization}, we conclude that $P$ is positive homogeneous.
\end{subproof}
\noindent The utility of this construction allows us to see that ``most'' positive homogeneous functions are not smooth. To see this, we fix a positive homogeneous function $Q\in C^{\infty}(\mathbb{R}^d)$ and remark that $S_Q$ is necessarily a compact smooth embedded hypersurface of $\mathbb{R}^d$ (see Proposition \ref{prop:InnerProdIsOne}). If $P=P_{f,Q}$ is $C^\infty(\mathbb{R}^d)$, $P\vert_{S_Q}=f$ is necessarily $C^\infty(S_Q)$. It follows that $P\notin C^\infty(\mathbb{R}^d)$ whenever $f$ is chosen from $C^0(S_Q)\setminus C^\infty(S_Q)$. By precisely the same argument, we see that $P\in C^0(\mathbb{R}^d)\setminus C^k(\mathbb{R}^d)$ whenever $f\in C^0(S_Q)\setminus C^k(S_Q)$ for each $k\in\mathbb{N}_+$.\\

\noindent  As a straightforward example, consider $Q(x,y)=|(x,y)|=\sqrt{x^2+y^2}$ on $\mathbb{R}^2$ with $S_Q=\mathbb{S}$ and define
\begin{equation*}
f(x,y)=w(\mbox{Arg}(x,y))+3
\end{equation*}
where $w:\mathbb{R}\to\mathbb{R}$ is defined by
\begin{equation*}
    w(t) = \sum_{n=0}^\infty 2^{-n} \cos\lp 3^n t \rp
\end{equation*}
for $t\in\mathbb{R}$; $w$ is a continuous $2\pi$-periodic version of the Weierstrass function. The resulting positive homogeneous function $P$ is continuous but nowhere differentiable. Figure \ref{fig:Weierstrass} illustrates this function $P$ alongside $Q$ and together with their associated unital level sets. We note that $S_P\neq S_Q$ and this is generally the case unless $f\equiv 1$.

\begin{figure}[!htb]
    \centering
    \hspace{10pt}
    \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.6]{Fig2a.eps}
    \vspace{-10pt}
    \includegraphics[scale=0.6]{Fig2b.eps}
    %\caption{}
    %\label{fig:WeierstrassP_levelsets}
    \end{subfigure}%
    \hspace{-20pt}
    \begin{subfigure}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.6]{Fig2c.eps}
    \vspace{-10pt}
    \includegraphics[scale=0.6]{Fig2d.eps}
    %\caption{}
    %\label{fig:Q_levelsets}
    \end{subfigure}
    \caption{The left column illustrates $P$'s graph and associated level set $S_P$ containing $B_P$. The right column illustrates $Q$'s graph and associated level set $S_Q$ containing $B_Q$.}
    \label{fig:Weierstrass}
\end{figure}
\end{example}

% ANOTHER PROPERTY OF POS-HOM FN:

\noindent In most situations in estimating convolution powers, we are provided with a continuous, positive-definite $P$ with some $E\in \Exp(P)$. To see if $P$ is a positive-homogeneous function, we can check if the spectrum of $E$ is real. The following proposition captures this result. 

\begin{framed}
\begin{proposition}\label{prop:PosHomSufficientCondition}
If $P$ is continuous, positive definite and $\Exp(P)$ contains an $E\in\End(\mathbb{R}^d)$ with real spectrum, then $\{r^E\}$ is contracting and hence all of the above conditions are (simultaneously) met. 
\end{proposition}
\end{framed}
\begin{proof}
Since $\Spec(E)$ is real, the characteristic polynomial of $E$ factors completely over $\R$ and so we may apply the Jordan-Chevalley decomposition to write $E=D+N$ where $D$ is diagonalizable, $N$ is nilpotent, and $DN=ND$. Let $v_1,v_2,\dots,v_d \in \R^d$ be an eigenbasis of $D$ whose corresponding eigenvalues $\lambda_1,\lambda_2,\dots,\lambda_d$ satisfy $\lambda_k\leq \lambda_{k+1}$ for all $k=1,2\dots,d-1$.

Let us assume, to reach a contradiction, 
that $\{ r^E \}$ is not contracting. Repeating the same argument given in $\ref{cond:PisAboveOne}\Rightarrow\ref{cond:Contracting}$ in the proof of Proposition \ref{prop:PositiveHomogeneousCharacterization}, leaves us with only one possibility: There is a non-zero $x = \sum^d_{i=1}\alpha_i v_i \in\mathbb{R}^d$, and a sequence $r_k\to 0$ for which $|r_k^E x|\to\infty$. Let $n+1$ denote the index of $N$, then we have
\begin{equation*}
r^E_k x = r_k^{N+D} x 
= r_k^N r_k^D x 
= \sum_{j=0}^n\sum_{i=1}^d \f{r_k^{\lambda_i}(\log r_k)^j}{j!}   \alpha_iN^j v_i
\end{equation*}
for all $k$. Since $\abs{r_k^E x} \to \infty$ and $r_k \to 0$, at least one eigenvalue of $D$ must be non-positive. To see this, suppose $\lambda_i > 0$ for all $i = 1,2,\dots,d$, then in view of L'H\^{o}pital's rule we have
\begin{equation*}
    \lim_{r_k \to 0}(\log r_k)^j r_k^{\lambda_i} = 0  
\end{equation*}
for any $j =0, 1,2,\dots,n$ and $i =1,2,\dots,d$, which implies that $\abs{r^E_k x} \not\to \infty$ as $r_k \to 0$, contradicting our assumption. Thus, $\lambda_1 = \min\{ \Spec(D)\} \leq 0$. Let $k$ be such that $N^k v_1 \neq 0$ but $N^{k+1} v_1 = 0$, then
\begin{equation*}
    r^E N^k v_1 = r^D r^N N^k v_1 = r^D \sum_{j=0}^\infty \f{(\log r)^j}{j!}N^j N^k v_1 = r^D N^k v_1 = N^k r^D  v_1 =  r^{\lambda_{1}} N^k  v_1
\end{equation*}
where we have used the fact that $DN = ND$. If $\lambda_1= 0$, then 
\begin{equation*}
    \infty =  \lim_{r\to \infty} rP(N^k v_1)  = \lim_{r\to \infty} P( r^D r^N N^k v_1) =  \lim_{r\to \infty}P(r^{0} N^k v_1)= \lim_{r\to \infty}P( N^k v_1) = P(N^k v_1)
\end{equation*}
which is impossible since $P$ is continuous at $N^k v_1$. On the other hand, if $\lambda_1 < 0$, then
\begin{equation*}
    \infty = \lim_{r\to \infty} rP(N^k v_1) = \lim_{r\to \infty} P(r^D r^N N^k v_1) = \lim_{r\to \infty}P(r^{\lambda_1} N^k v_1) = P(0) = 0
\end{equation*}
which is also impossible. 
\end{proof}





\begin{example}\normalfont
In Example \ref{exp:EuclideanNorm}, $\Sym(|\cdot|^\alpha)$ is precisely the orthogonal group $\OdR$ and $\mu_{|\cdot|^\alpha}=d/\alpha$. In Example \ref{exp:Polynomial}, the symmetric set of a semi-elliptic polynomial $P$ of the form \eqref{eq:SemiEllipticIntro} depends on the specific nature of the polynomial in question. Concerning the polynomials $P_1$ and $P_2$ in that example, it is easily shown that $\Sym(P_1)$ is the four-element dihedral group $D_2$ and $\Sym(P_2)$ is the two-element group consisting of the identity and the transformation $(x,y)\mapsto (x,-y)$. For a semi-elliptic polynomial $P$ of the form \eqref{eq:SemiEllipticIntro}, 
\begin{equation*}
    \mu_P=|\mathbf{1}:\mathbf{n}|=\frac{1}{n_1}+\frac{1}{n_2}+\cdots+\frac{1}{n_d}
\end{equation*}
and, in particular, $\mu_{P_1}=\mu_{P_2}=1/2+1/4=3/4.$
\end{example}

\noindent Given a positive-homogeneous function $P$, let $\Sym(P)$ be the set of $O\in\End(\mathbb{R}^d)$ for which
\begin{equation*}
P(Ox)=P(x)
\end{equation*}
for all $x\in\mathbb{R}^d$. By virtue of the positive-definiteness of $P$, it is easy to see that $\Sym(P)$ is a subgroup of $\Gl(\mathbb{R}^d)$. For this reason, $\Sym(P)$ is said to be the \textbf{symmetry group associated to $P$}. It turns out that $\Sym{(P)}$ is a subgroup of the orthogonal group. Later, we will show later that measures of sufficiently nice sets on $S$ are invariant under transformation by any element of $\Sym(P)$, as expected.  

\begin{framed}
\begin{proposition}\label{prop:SymCompact}
For each positive-homogeneous function $P$, $\Sym(P)$ is a compact subgroup of $\Gl(\mathbb{R}^d)$. In particular, it is a subgroup of the orthogonal group $O(\mathbb{R}^d)$.
\end{proposition}
\end{framed}
\begin{proof}
By virtue of the Heine-Borel theorem (and the fact that $\Gl(\mathbb{R}^d)$ is finite dimensional), we prove that $\Sym(P)$ is closed and bounded. To this end, let $\{O_n\}\subseteq\Sym(P)$ be a sequence converging to $O\in \Gl(\mathbb{R}^d)$. For each $x\in\mathbb{R}^d$, the continuity of $P$ guarantees that
\begin{equation*}
P(Ox)=P\left(\lim_{n\to\infty}O_nx\right)=\lim_{n\to\infty}P(O_nx)=\lim_{n\to\infty}P(x)=P(x).
\end{equation*}
Hence, $O\in\Sym(P)$ and so $\Sym(P)$ is closed.

We assume, to reach a contradiction, that $\Sym(P)$ is not bounded. In this case, there is a sequence $\{\eta_n\}\subseteq \mathbb{S}$ for which $\lim_{n\to\infty}|O_n\eta_n|=\infty$. Given that $\mathbb{S}$ is compact, by passing to a subsequence if needed, we may assume without loss in generality that $\lim_{n\to\infty}\eta_n=\eta\in\mathbb{S}$. By virtue of Proposition \ref{prop:PositiveHomogeneousCharacterization} and the continuity of $P$,
\begin{equation*}
P(\eta)=\lim_{n\to\infty}P(\eta_n)=\lim_{n\to\infty}P(O_n\eta_n)=\infty
\end{equation*}
which is impossible. Hence $\Sym(P)$ is bounded.
\end{proof}


\begin{framed}
\begin{corollary}\label{cor:TraceisInvariant}
Let $P$ be a positive-homogeneous function, then for all $E,E'\in\Exp(P)$,
\begin{equation*}
\tr E=\tr E'>0.
\end{equation*}
\end{corollary}
\end{framed}
\begin{proof}
By virtue of Propositions \ref{prop:ContractingTrace} and \ref{prop:PositiveHomogeneousCharacterization}, $\tr E>0$ for all $E\in\Exp(P)$. It remains to show that the trace map is constant on $\Exp(P)$. To this end, let $E,E'\in\Exp(P)$. Then, for all $r>0$ and $x\in\mathbb{R}^d$,
\begin{equation*}
P(x)=r(1/r)P(x)=rP((1/r)^{E'}x)=P(r^E(1/r)^{E'}x)=P(r^{E}r^{-E'}x).
\end{equation*}
Thus $O_r=r^{E}r^{-E'}\in\Sym(P)$ for each $r>0$. In view of the Propositions \ref{prop:ContinuousGroupProperties} and \ref{prop:SymCompact} and the homomorphism property of the determinant,
\begin{equation*}
1=\det(O_r)=\det(r^{E}r^{E'})=\det(r^{E})\det(r^{-E'})=r^{\tr E}r^{\tr E}=r^{\tr E-\tr E'}
\end{equation*}
for all $r>0$ and therefore $\tr E=\tr E'$.
\end{proof}

\noindent In view of the preceding corollary, to each positive-homogeneous function $P$, we define the \textit{homogeneous order of $P$} to be the unique positive number $\mu_P$ for which
\begin{equation*}
\mu_P=\tr E
\end{equation*}
for all $E\in\Exp(P)$. \\



\noindent We end this section by addressing a useful proposition which connects $\Exp(P)$ and $\Sym(P)$. Given $O\in\Sym(P)$, we write
\begin{equation*}
    OF=\{O\eta:\eta\in F\}.
\end{equation*}
While a small result, the following proposition will be useful when we show that the measure on $S$ (which we will construct from some $E\in \Exp(P)$) is in fact independent of the choice of $E\in \Exp(P)$. In other words, we will show that the measure is intrinsic to $P$. 

\begin{framed}
\begin{proposition}\label{prop:ExpP}
For any  $O \in \Sym{(P)} $
\begin{equation*}
    \Exp(P) = O^* \Exp(P) O.
\end{equation*}
In other words, the set $\Exp(P)$ is invariant under conjugation by $\Sym(P)$.
\end{proposition}
\end{framed}

\begin{proof}
Since $\Sym(P)$ is a subgroup of the orthogonal group $O(\mathbb{R}^d)$, $O^* = O^{-1} \in \Sym{P}$ whenever $O\in\Sym(P)$. For a fixed $O\in\Sym(P)$, it is easy to see that the map $\Exp(P)\ni E\mapsto  O^* E O\in\Exp(P)$ is a bijection and hence $\Exp(P)=O^* \Exp(P) O$. 
\end{proof}







% SUBHOMOGENEOUS FUNCTIONS
\section{Subhomogeneous Functions}
In this section, we introduce the notions of subhomogeneous functions and strongly subhomogeneous functions with respect to a given endomorphism $E\in\End(\mathbb{R}^d)$. As briefly discussed in the beginning of this chapter, these functions show up in the Taylor expansion of $\Gamma$ and play an important role in estimating $\abs{\phi^{(n)}}$ using the Van der Corput lemma. Roughly speaking, for some $E\in \End{(\mathbb{R}^d)}$, a sufficiently nice function $Q: \mathbb{R}^d \to \mathbb{C}$ is said to be subhomogeneous with respect to $E$ if $Q(r^E \xi) = o(r)$ as $r\to 0$. If $\abs{\p_r Q(r^E \xi)} = o(1)$ as $r\to 0$, then $Q$ is said to be strongly subhomogeneous with respect to $E$. It is then straightforward to use the mean value theorem to show that strong subhomogeneity implies subhomogeneity. The following definition and proposition make precise these ideas. 

\begin{framed}
\begin{definition}\label{def:homogeneous_types}
Let $Q$ be a continuous and complex-valued function defined on an open neighborhood $\mathcal{O}$ of $0$ in $\mathbb{R}^d$ and let $E\in\End(\mathbb{R}^d)$ be such that $\{r^E\}$ is a contracting group.
\begin{enumerate}
\item We say that $Q$ is \textbf{subhomogeneous with respect to $E$} if, for each $\epsilon>0$ and compact set $K\subseteq\mathbb{R}^d$, there is a $\delta>0$ for which
\begin{equation*}
\abs{Q(r^E\xi)}\leq \epsilon r
\end{equation*}
for all $0<r<\delta$ and $\xi\in K$.
\item Given $k\geq 1$, we say that $Q$ is \textbf{strongly subhomogeneous with respect to $E$ of order $k$} if $Q\in C^k(\mathcal{O})$ and, for each $\epsilon>0$ and compact set $K\subseteq\mathbb{R}^d$, there is a $\delta>0$ for which
\begin{equation*}
    \abs{r^j\partial_r^j Q(r^E\xi)}\leq \epsilon r
\end{equation*}
for all $j=1,2,\dots,k$, $0<r<\delta$ and $\xi\in K$.
\end{enumerate}
When the endomorphism $E$ is understood (and fixed), we will say that $Q$ is subhomogeneous if it is subhomogeneous with respect to $E$. Also, we will say that $Q$ is $k$-strongly subhomogeneous if it is strongly subhomogeneous with respect to $E$ of order $k$.
\end{definition}
\end{framed}
\noindent The following proposition, in particular, justifies our choice of vocabulary and give credence to the interpretation that $0$-strongly subhomogeneous is synonymous with subhomogeneous.


\begin{framed}
\begin{proposition}\label{prop:supersub_implies_sub}
Let $Q$ be differentiable on an open neighborhood of $0$ in $\mathbb{R}^d$ and let $E\in\End(\mathbb{R}^d)$ be such that $\{r^E\}$ is a contracting group. If, for some $k\geq 1$, $Q$ is strongly subhomogeneous with respect to $E$ of order $k$ and $Q(0)=0$, then $Q$ is subhomogeneous with respect to $E$.
\end{proposition}
\end{framed}
\begin{proof}
Let $\epsilon>0$ and $K$ be a compact set.  In view of our supposition that $Q$ is strongly subhomogeneous with respect to $E$ or order $k$, let $\delta>0$ be given so that $\abs{r\partial_r Q(r^E\xi)}\leq \epsilon r$ for all $\xi\in K$ and $0<r< \delta$. Given that $r^E$ is a contracting group and $Q(0)=0$, it follows that, for each $\xi\in K$, $f_{\xi}:[0,\delta)\to\mathbb{C}$ defined by
\begin{equation*}
f_{\xi}(r)=\begin{cases}
Q(r^E\xi) & 0<r<\delta\\
0 & r=0
\end{cases}
\end{equation*}
is differentiable on $(0,\delta)$ and continuous on $[0,\delta)$, for each $\xi\in K$. Consequently, for every $0<r<\delta$ and $\xi\in K$, the mean value theorem guarantees a $c=c_{\xi,r}\in (0,r)$ for which 
\begin{equation*}
\abs{f_{\xi}(r)-f_{\xi}(0)}\leq r\abs{f_{\xi}'(c)}=r\abs{\partial_r Q(r^E\xi)\Big\vert_{r=c}}\leq r\epsilon.
\end{equation*}
Consequently, for all $0<r<\delta$ and $\xi\in K$,
\begin{equation*}
\abs{Q(r^E\xi)}=\abs{f_{\xi}(r)-f_{\xi}(0)}\leq r\epsilon.
\end{equation*}
\end{proof}


\noindent  When estimating convolution powers, we are often presented with a $Q$ that is (strongly) subhomogeneous with respect to some $G = E/k \in \End{(\mathbb{R}^d)}$ where $k>0$ and $E$ belongs to the exponent of some positive-homogeneous or imaginary-homogeneous function $P$. It is then useful to characterize how the notions of subhomogeneity and strong homogeneity with respect to $E/k$ depend on $k$.






\begin{framed}
\begin{proposition}\label{prop:Subhomequivtolittleoh}
Let $P$ be positive homogeneous and $\widetilde{P}$ be complex-valued and continuous on a neighborhood of $0$ in $\mathbb{R}^d$. The following are equivalent:
\begin{enumerate}[label=(\alph*), ref=(\alph*)]
    \item\label{item:Subhomequivtolittleoh1} $\widetilde{P}(\xi)=o(P(\xi))$ as $\xi\to 0$.
    \item\label{item:Subhomequivtolittleoh2} For every $E\in\Exp(P)$, $\widetilde{P}$ is subhomogeneous with respect to $E$.
    \item\label{item:Subhomequivtolittleoh3} There exists $E\in\Exp(P)$ for which $\widetilde{P}$ is subhomogeneous with respect to $E$.
\end{enumerate}
\end{proposition}
\end{framed}
\begin{proof}
\begin{subproof}[\ref{item:Subhomequivtolittleoh1} $\Rightarrow$ \ref{item:Subhomequivtolittleoh2}] Let $\epsilon>0$, $K$ be a compact set and choose $E\in \Exp(P)$. Given our supposition that $\widetilde{P}(\xi)=o(P(\xi))$ as $\xi\to 0$, we can find an open neighborhood $\mathcal{O}$ of $0$ for which 
\begin{equation*}
\abs{\widetilde{P}(\xi)}\leq \frac{\epsilon}{1+\sup_{\eta\in K}P(\eta)}P(\xi)
\end{equation*}
for all $\xi\in \mathcal{O}$. Now, because $r^E$ is contracting in view of Proposition \ref{prop:PositiveHomogeneousCharacterization}, we can find a $\delta>0$ for which $r^E\xi\in \mathcal{O}$ for all $0<r<\delta$ and $\xi\in K$ by virtue of Proposition \ref{prop:ContractingCapturesCompact}. Consequently, for all $0<r<\delta$ and $\xi\in K$,
\begin{equation*}
\abs{\widetilde{P}(r^E\xi)}\leq \frac{\epsilon}{1+\sup_{\eta\in K}P(\eta)}P(r^E\xi)=\epsilon r\frac{P(\xi)}{1+\sup_{\eta\in K}P(\eta)}\leq r\epsilon.
\end{equation*}
\end{subproof}

\begin{subproof} [\ref{item:Subhomequivtolittleoh2} $\Rightarrow$ \ref{item:Subhomequivtolittleoh3}] This implication is trivial.
\end{subproof}
 
\begin{subproof}[\ref{item:Subhomequivtolittleoh3} $\Rightarrow$ \ref{item:Subhomequivtolittleoh1}]  Let $\epsilon>0$. Choose $E\in \Exp(P)$ and let $S=\{\eta\in\mathbb{R}^d:P(\eta)=1\}$. Using the supposition that $\widetilde{P}$ is subhomogeneous with respect to $E$, we may choose $\delta>0$ for which
\begin{equation*}
\abs{\widetilde{P}(r^E\eta)}\leq \epsilon r 
\end{equation*}
for all $0<r<\delta$ and $\eta\in S$. We remark that, in view of the continuity of $\widetilde{P}$ and the fact that $r^E$ is contracting, this inequality ensures that $\widetilde{P}(0)=0$. We fix $\mathcal{O}$ to be the open set $B_\delta=\{\xi\in\mathbb{R}^d:P(\xi)<\delta\}$. For each non-zero $\xi\in\mathcal{O}$, we observe that $\xi=r^E\eta$ where $0<r=P(\xi)<\delta$ and $\eta=P(\xi)^{-E}\xi\in S$ and therefore
\begin{equation*}
\abs{\widetilde{P}(\xi)}=\abs{\widetilde{P}(r^E\eta)}\leq r\epsilon=\epsilon  P(\xi)
\end{equation*}
If $\xi=0$, obviously, $\abs{\widetilde{P}(\xi)}=0=\epsilon P(0)=\epsilon P(\xi)$. Thus, for all $\xi\in\mathcal{O}$,
\begin{equation*}
\abs{\widetilde{P}(\xi)}\leq\epsilon P(\xi),
\end{equation*}
as desired.
\end{subproof}
\end{proof}

\begin{framed}
\begin{proposition}\label{prop:2StronglySubhomogeneous}
Let $E\in\End(\mathbb{R}^d)$ be for which $\{r^E\}$ is contracting and suppose that $Q$ is strongly subhomogeneous with respect to $E$ of order $2$. Given $\alpha>0$, set $F=\alpha E$. Then, for any $\epsilon>0$ and compact set $K$,
\begin{equation*}
    \abs{\theta\partial_\theta Q(\theta^F\eta)}\leq \epsilon \theta^\alpha
\end{equation*}
and
\begin{equation*}
    \abs{\theta^2\partial_\theta^2 Q(\theta^F\eta)}\leq \epsilon \theta^\alpha
\end{equation*}
for all $0<\theta\leq \delta^{1/\alpha}$ and $\eta\in K$.
\end{proposition}
\end{framed}
\begin{proof}
Let $\epsilon>0$ and $K\subseteq\mathbb{R}^d$ be a compact set. By virtue of the strong subhomogeneity of $Q$, let $\delta>0$ be such that
\begin{equation*}
    \abs{r\partial_r Q(r^E\eta)}\leq \epsilon' r\hspace{1cm}\mbox{and}\hspace{1cm}\abs{r^2\partial_r^2Q(r^E\eta)}\leq \epsilon' r
\end{equation*}
for $0<r<\delta$ and $\eta\in K$ where $\epsilon'=\epsilon/(2\alpha^2+\alpha)$. We set $r=\theta^\alpha$ so that $r^E=\theta^F$ and observe that
\begin{equation*}
    \abs{\theta\partial_\theta Q(\theta^F\eta)}=\abs{\theta\partial_rQ(r^E\eta)\frac{\partial r}{\partial\theta}}= \abs{\theta\partial_rQ(r^E\eta)\alpha \theta^{\alpha-1}}=\alpha r\abs{\partial_rQ(r^E\eta)}\leq \alpha\epsilon' r<\epsilon \theta^\alpha
\end{equation*}
for all $0<\theta\leq \delta^{1/\alpha}$ and $\eta\in K$. Further, we have
\begin{eqnarray*}
    \abs{\theta^2\partial_\theta^2Q(\theta^F\eta)}&=&\theta^2\abs{\partial_r^2Q(r^E\eta)\left(\frac{\partial r}{\partial\theta}\right)^2+\partial_r Q(r^E\eta)\frac{\partial^2 r}{\partial \theta^2}}\\
    &=&\theta^2\abs{\partial_r^2 Q(r^E\eta) \alpha^2\theta^{2\alpha-2}+\partial_r Q(r^E\eta)\alpha(\alpha-1)\theta^{\alpha-2}}\\
    &\leq &\alpha^2\abs{r^2Q(r^E\eta)}+\abs{\alpha(\alpha-1)}\abs{r\partial_r Q(r^E\eta)}\\
    &< &\alpha^2 \epsilon' r+\abs{\alpha^2-\alpha}\epsilon' r\\
    &<&\epsilon\theta^\alpha
\end{eqnarray*}
for all $0<\theta<\delta^{1/\alpha}$ and $\eta\in K$.
\end{proof}



%%%%%%%%%%%%%%%% Generalized %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{A generalized polar integration formula}\label{chap:formula}

In this chapter, we obtain our generalized polar integration formula from two perspectives: measure theory and smooth-manifold theory. In Subsection \ref{subsec:ConstructionofSigma}, we construct a measure on the unital level set of a positive homogeneous function. Our construction only uses results from point-set topology and measure theory and this measure will appear later as the surface measure which appears in our generalization of the polar coordinate integration formula. In a later section (Section \ref{sec:smooth_manifold}), we will consider the case in which the positive homogeneous function is smooth and, in this case, we will find that its unital level set is a smooth hypersurface of $\mathbb{R}^d$ and the measure constructed in Subsection \ref{subsec:ConstructionofSigma} is characterized by a smooth $d-1$ form which related to the canonical Riemann volume form. This chapter is essentially Section 4 of \cite{bui2021generalized}.\\

\noindent To start, we let a positive-homogeneous function $P$ on $\mathbb{R}^d$ be fixed with homogeneous order $\mu_P$, exponent set $\Exp(P)$, and symmetry group $\Sym{(P)}$. Let $\mathcal{M}_d$ denote the Lebesgue $\sigma$-algebra on $\mathbb{R}^d\setminus\{ 0 \}$ and $m$ the Lebesgue measure. We take the unital level set $S = \{ \eta\in \mathbb{R}^d : P(\eta) = 1 \}$ to be equipped with the relative topology inherited from $\mathbb{R}^d$ and $(0,\infty)\times S$ with the product topology, where $(0,\infty)$ carries the usual topology on $\mathbb{R}$. Let $\mathcal{B}(S)$ denote the $\sigma$-algebra on $S$. We denote by $\mathcal{L}=\mathcal{L}(0,1)$ the $\sigma$-algebra of Lebesgue measurable sets on $(0,\infty)$ and let $\lambda_P$ be the $\sigma$-finite measure on $((0,\infty),\mathcal{L})$ with $\lambda_P(dr)=r^{\mu_P-1}\,dr$. For basic notions of measure theory, the reader is encouraged to refer to \cite{bogachev_measure_2007}, \cite{stein_real_2009}. For selected definitions and theorems from measure theory, see Appendix \ref{sec:measure_theory}.

%%%%%%%%%%%%%%%%%

\section{A surface measure on $S$}
Our main result of this section is as follows. 
\begin{framed}
\begin{theorem}\label{thm:BestIntegrationFormula}
There exists a $\sigma$-algebra $\Sigma$ on $S$ containing $\mathcal{B}(S)$ and a finite Radon measure $\sigma_P$ on $(S,\Sigma)$ which satisfies the following properties:
\begin{enumerate}
\item\label{property:Completion} $(S,\Sigma,\sigma_P)$ is the completion of $(S,\mathcal{B}(S),\sigma_P)$. In particular, $(S,\Sigma,\sigma_P)$ is a complete measure space.
\item\label{property:Invariance} For any $F\in\Sigma_P$ and $O\in\Sym(P)$, $OF\in\Sigma_P$ and $\sigma_P(OF)=\sigma_P(F)$.
\item\label{property:DefiningConditionofsigma} For any $F\in\Sigma$ and $E\in\Exp(P)$, 
\begin{equation*}
\widetilde{F_E}:=\bigcup_{0<r<1}\left(r^E F\right)=\left\{r^E\eta\in\mathbb{R}^d\setminus\{0\}:0<r<1,\eta\in F\right\}
\end{equation*}
is a Lebesgue measurable subset of $\mathbb{R}^d\setminus \{0\}$, i.e., $\widetilde{F_E}\in\mathcal{M}_d$, and
\begin{equation*}
\sigma_P(F)=\mu_P\cdot m\left(\widetilde{F_E}\right)
\end{equation*}
where $m$ denotes the Lebesgue measure on $\mathbb{R}^d$.
\end{enumerate}
Further, denote by $\left((0,\infty)\times S,(\mathcal{L}\times\Sigma)',\lambda_P\times\sigma_P\right)$ the completion of the product measure space $((0,\infty) \times S,\mathcal{L}\times\Sigma,\lambda_P\times\sigma_P)$. We have
\begin{enumerate}
\item\label{property:BestPointIsomorphism} Given any $E\in \Exp(P)$, the map $\psi_E:(0,\infty)\times S\to\mathbb{R}^d\setminus\{0\}$, defined by $\psi_E(r,\eta)=r^E\eta$ for $r>0$ and $\eta\in S$, is a point isomorphism of the measure spaces $\left((0,\infty)\times S,(\mathcal{L}\times\Sigma)',\lambda_P\times\sigma_P\right)$ and $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d,m)$. That is
\begin{equation*}
\mathcal{M}_d=\left\{A\subseteq \mathbb{R}^d\setminus\{0\}:\psi_E^{-1}(A)\in (\mathcal{L}\times\Sigma)'\right\}
\end{equation*}
and, for each $A\in\mathcal{M}_d$,
\begin{equation*}
m(A)=(\lambda_P\times\sigma_P)(\psi_E^{-1}(A)).
\end{equation*}
\item\label{property:BestIntegrationFormula} Given any Lebesgue measurable function $f:\mathbb{R}^d\to\mathbb{C}$ and $E\in \Exp(P)$, $f\circ \psi_E$ is $(\mathcal{L}\times\Sigma)'$-measurable and the following statements hold:
\begin{enumerate}
\item If $f\geq 0$, then
\begin{eqnarray}\label{eq:BestIntegrationFormula}
\int_{\mathbb{R}^d}f(x)\,dx
&=&\int_0^\infty\left(\int_S f(r^E\eta)\,\sigma_P(d\eta)\right)r^{\mu_P-1}\,dr\nonumber \\
&=&\int_S\left(\int_0^\infty f(r^E\eta)r^{\mu_P-1}\,dr\right)\sigma_P(d\eta).
\end{eqnarray}
\item When $f$ is complex-valued, we have 
\begin{equation*}f\in L^1(\mathbb{R}^d)\hspace{.5cm}\mbox{ if and only if}\hspace{.5cm}f\circ\psi_E\in L^1\left((0,\infty)\times S,(\mathcal{L}\times\Sigma)',\lambda_P\times\sigma_P\right)
\end{equation*} 
and, in this case, \eqref{eq:BestIntegrationFormula} holds.
\end{enumerate}
\end{enumerate}
\end{theorem}
\end{framed}

\noindent From this theorem we have a useful corollary.

\begin{framed}
\begin{corollary}\label{cor:IntegrateOnS}
Given $g:S\to\mathbb{C}$ and $E\in\Exp(P)$, define $f:\mathbb{R}^d\to\mathbb{C}$ by
\begin{equation*}
f(x)=\begin{cases}
\mu_P\cdot \chi_{(0,1)}(P(x))g(P(x)^{-E}x) & \mbox{ for }x\neq 0\\
0 & \mbox{ for }x=0
\end{cases}
\end{equation*}
for $x\in\mathbb{R}^d$ where $\chi_{(0,1)}(\cdot)$ is the indicator function of the interval $(0,1)$. Then $g\in L^1(S,\Sigma_P,\sigma_P)$ if and only if $f\in L^1(\mathbb{R}^d)$ and, in this case, 
\begin{equation}\label{eq:ACharacterizationofsigma}
    \int_{\mathbb{R}^d}f(x)\,dx=\int_Sg(\eta)\sigma_P(d\eta).
\end{equation}
\end{corollary}
\end{framed}
\begin{proof}
Observe that, for the $(\mathcal{L}\times\Sigma_P)'$-measurable function $k(r,\eta)=\chi_{(0,1)}(r)g(\eta)$,
\begin{equation*}
    k\circ\psi_E^{-1}(x)=k(P(x),P(x)^{-E}x)=f(x)
\end{equation*}
for $x\in\mathbb{R}^d\setminus \{0\}$. By virtue of Theorem \ref{thm:BestIntegrationFormula}, it follows that $f$ is Lebesgue measurable and 
\begin{eqnarray*}
   \int_{\mathbb{R}^d}|f(x)|\,dx&=&\int_{S}\left(\int_{(0,\infty)}|k(r,\eta)|r^{\mu_P-1}\,dr\right)\sigma_P(d\eta)\\
    &=&\left(\int_S|g(\eta)|\sigma_P(d\eta)\right)\left(\int_0^1 \mu_Pr^{\mu_P-1}\,dr\right)\\
    &=&\int_S\abs{g(\eta)}\sigma_P(d\eta)
\end{eqnarray*}
and therefore $f\in L^1(\mathbb{R}^d)$ if and only if $g\in L^1(S,\Sigma_P,\sigma_P)$ and $\|f\|_{L^1(\mathbb{R}^d)}=\|g\|_{L^1(S)}$. By an analogous computation (for $f$ instead of $|f|$), we have
\begin{equation*}
    \int_{\mathbb{R}^d}f(x)\,dx=\int_S g(\eta)\sigma_P(d\eta),
\end{equation*}
by virtue of Property \ref{property:BestIntegrationFormula} of Theorem \ref{thm:BestIntegrationFormula}. 
\end{proof}


\noindent Our construction of $\sigma_P$ is as follows. In Subsection \ref{subsec:ConstructionofSigma}, we fix $E\in\Exp(P)$ and consider the one-parameter contracting group $\{r^E\}$. As the standard isotropic one-parameter group $r\mapsto rI=r^I$ is well-fitted to the unit sphere $\mathbb{S}$ and allows every non-zero $x\in\mathbb{R}^d$ to be written uniquely as $x=r\eta$ for $r\in (0,\infty)$ and $\eta\in \mathbb{S}$, $\{r^E\}$ is well-fitted to $S$ and has the property that every non-zero $x\in\mathbb{R}^d$ can be written uniquely as $x=r^E\eta$ where $r\in(0,\infty)$ and $\eta\in S$. With this one-parameter group as a tool, we define a surface-carried measure $\sigma_{P,E}$ on $S$ by taking sufficiently nice sets $F\subseteq S$, stretching them into a quasi-conical region of the associated ``ball" $B$ with the contracting group $\{r^E\}$, and computing the Lebesgue measure of the result. Figure \ref{fig:level_set_F} illustrates the action of $r^E$ for $r\in (0,1)$ on a set $F$ (red) in $S$ (blue) to create the set $\widetilde{F}$. Here, we choose $P(x,y) = x^2 + 3xy^2/2 + y^4$ and $E= \diag(1/2, 1/4)$. Figure \ref{fig:level_set_F_3D} illustrates a different example with $P(x,y,z) = x^2 + xy^2 + y^4 + z^4$.

\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.7, trim={1cm 1cm 1cm 0.5cm},clip]{Fig3.eps}
    \caption{Quasi-conical region $\widetilde{F}=\widetilde{F}_E$ (in red) for $F\subseteq S$. Here, $S$ is the unital level set of $P=P_2$ from Example \ref{exp:Polynomial} and $E\in\Exp(P_2)$ has the standard representation $\diag(1/2,1/4)$.}
    \label{fig:level_set_F}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.7, trim={1cm 3cm 1cm 2cm},clip]{Fig4.eps}
    \caption{Quasi-conical region $\widetilde{F}=\widetilde{F}_E$ (in red) for $F\subseteq S$. Here, $S$ is the unital level set of $P(x,y,z) = x^2 + xy^2 + y^4 + z^4$ and $E\in\Exp(P)$ has standard representation $\diag(1/2,1/4,1/4)$. }
    \label{fig:level_set_F_3D}
\end{figure}


In Subsection \ref{subsec:ProductMeasure}, we turn our focus to an associated product measure $\lambda_P\times\sigma_{P,E}$ on $(0,\infty)\times S$ with which we are able to formulate and prove a generalization of \eqref{eq:StandardPolarIntegrationFormula}; this is Theorem \ref{thm:MainIntegrationFormula}. We then derive a number of corollaries of Theorem \ref{thm:MainIntegrationFormula}, including the result that $\sigma_{P,E}$ is a Radon measure on $S$. In Subsection \ref{subsec:IndependentofE}, we prove that even though Subsections \ref{subsec:ConstructionofSigma} and \ref{subsec:ProductMeasure} require a choice of $E\in \Exp(P)$, $\sigma_{P,E}$ is independent of the choice of $E\in \Exp(P)$, and so we write $\sigma_P=\sigma_{P,E}$ and this quickly yields a stronger version of Theorem \ref{thm:MainIntegrationFormula}, which is Theorem \ref{thm:BestIntegrationFormula}.  






\subsection{Construction of $\sigma_{P,E}$}\label{subsec:ConstructionofSigma}

Let $E\in\Exp(P)$. Define $\psi_E:(0,\infty)\times S\to\mathbb{R}^d\setminus\{0\}$ by
\begin{equation}\label{eq:Homeomorphism}
\psi_E(r,\eta)=r^E\eta
\end{equation}
for $r>0$ and $\eta\in S$. As $\psi_E$ is the restriction of the continuous function $(0,\infty)\times \mathbb{R}^d\ni (r,x)\mapsto r^E x\in\mathbb{R}^d$ to $(0,\infty)\times S$, it is necessarily continuous. We now show that $\psi_E$ is a homeomorphism. This will be particularly useful later on when we are required to regularly ``move'' back and forth between $\mathbb{R}^d\setminus \{ 0\}$ and $(0,\infty)\times S$. 

\begin{framed}
\begin{proposition}\label{prop:PsiHomeomorphism}
The map $\psi_E:(0,\infty)\times S\to\mathbb{R}^d\setminus\{0\}$ is a homeomorphism with continuous inverse $\psi_E^{-1}:\mathbb{R}^d\setminus\{0\}\to (0,\infty)\times S$ given by
\begin{equation*}
\psi_E^{-1}(x)=(P(x),(P(x))^{-E}x)
\end{equation*}
for $x\in\mathbb{R}^d\setminus\{0\}$.
\end{proposition}
\end{framed}
\begin{proof}
Given that $P$ is continuous and positive definite, $P(x)>0$ for each $x\in \mathbb{R}^d\setminus\{0\}$ and the map $\mathbb{R}^d\setminus\{0\}\ni x \mapsto (P(x))^{-E}x\in \mathbb{R}^d$ is continuous. Further, in view of the homogeneity of $P$,
\begin{equation*}
P\left((P(x))^{-E} x \right)=P(x)^{-1}P(x)=1
\end{equation*}
for all $x\in\mathbb{R}^d\setminus\{0\}$. It follows from these two observations that
\begin{equation*}
\rho(x)=(P(x),(P(x))^{-E}x),
\end{equation*}
defined for $x\in\mathbb{R}^d\setminus\{0\}$, is a continuous function taking $\mathbb{R}^d\setminus\{0\}$ into $(0,\infty)\times S$. We have
\begin{equation*}
(\psi_E\circ \rho)(x)=\psi_E(P(x),(P(x))^{-E}x)=(P(x))^{E}(P(x))^{-E}x=x
\end{equation*}
for every $x\in \mathbb{R}^d\setminus \{0\}$ and
\begin{equation*}
(\rho\circ\psi_E)(r,\eta)=\rho(r^E\eta)=(P(r^{E}\eta),(P(r^{E}\eta))^{-E}(r^E\eta))=(rP(\eta),(rP(\eta))^{-E}(r^{E}\eta))=(r,\eta)
\end{equation*}
for every $(r,\eta)\in (0,\infty)\times S$. Thus $\rho$ is a (continuous) inverse for $\psi_E$ and so it follows that $\psi_E$ is a homeomorphism and $\rho=\psi_E^{-1}$.
\end{proof}



\noindent As in the statement of Theorem \ref{thm:BestIntegrationFormula}, for each $F\subseteq S$, define
\begin{equation*}
\widetilde{F_E}=\bigcup_{0<r<1}\left(r^E F\right)=\{r^E\eta:0<r<1,\eta\in F\},
\end{equation*}
which we can identify as a quasi-conical region discussed in the previous chapter. Next, we let $\Sigma_{P,E}$ be the collection of subsets $F$ of $S$ for which $\widetilde{F_E}\in\mathcal{M}_d$, i.e.,  
\begin{equation*}
\Sigma_{P,E}=\{F\subseteq S:\widetilde{F_E}\in\mathcal{M}_d\}.
\end{equation*}
We now show that this is a $\sigma$-algebra $\Sigma_{P,E}$ on $S$. 

\begin{framed}
\begin{proposition}\label{prop:BorelContainment}
$\Sigma_{P,E}$ is a $\sigma$-algebra on $S$ containing the Borel $\sigma$-algebra on $S$, $\mathcal{B}(S)$.
\end{proposition}
\end{framed}

\begin{proof}
Throughout the proof, we write $\Sigma=\Sigma_{P,E}$ and $\widetilde{F}=\widetilde{F_E}$ for each $F\subseteq S$.
We first show that $\Sigma$ is a $\sigma$-algebra. Since $\widetilde S=B\setminus\{0\}$, it is open in $\mathbb{R}^d\setminus\{0\}$ and therefore Lebesgue measurable. Hence $S\in \Sigma$. Let $G, F\in \Sigma$ be such that $G\subseteq F$. Then,
\begin{equation*}
\widetilde{F\setminus G}=\bigcup_{0<r<1}r^E\left(F\setminus G\right)=\bigcup_{0<r<1}\left(r^EF\setminus r^E G\right)=\left(\bigcup_{0<r<1}r^E F\right)\setminus\left(\bigcup_{0<r<1}r^E G\right)=\widetilde F\setminus \widetilde G
\end{equation*}
where we have used the fact that the collection $\{r^E F\}_{0<r<1}$ is mutually disjoint to pass the union through the set difference. Consequently $\widetilde F\setminus \widetilde{G}$ is Lebesgue measurable and therefore $F\setminus G\in \Sigma$.  Now, given a countable collection $\{F_n\}\subseteq \Sigma$, observe that
\begin{equation*}
    \widetilde{\bigcup_{n=1}^\infty F_n}= \bigcup_{0<r<1}r^E \left(\bigcup_{n=1}^\infty F_n\right)= \bigcup_{0 <r< 1}  \bigcup_{n=1}^\infty  r^E F_n =\bigcup_{n=1}^\infty \bigcup_{0 <r < 1}  r^E F_n =\bigcup_{n=1}^\infty \widetilde{F_n} \in \mathcal{M}_d
\end{equation*}
whence $\cup_n F_n\in \Sigma$. Thus $\Sigma$ is a $\sigma$-algebra. 

Finally, we show that
\begin{equation*}
\mathcal{B}(S)\subseteq\Sigma.
\end{equation*}
As the Borel $\sigma$-algebra is the smallest $\sigma$-algebra containing the open subsets of $S$, it suffices to show that $\mathcal{O}\in \Sigma$ whenever $\mathcal{O}$ is open in $S$. Armed with Proposition \ref{prop:PsiHomeomorphism}, this is an easy task: Given an open set $\mathcal{O}\subseteq S$, observe that
\begin{equation*}
\widetilde{\mathcal{O}}=\{r^E\eta:0<r<1,\eta\in\mathcal{O}\}=\psi_E((0,1)\times\mathcal{O}).
\end{equation*}
Upon noting that $(0,1)\times\mathcal{O}$ is an open subset of $(0,\infty)\times S$, Proposition \ref{prop:PsiHomeomorphism} guarantees that $\widetilde{\mathcal{O}}=\psi_E((0,1)\times\mathcal{O})\subseteq\mathbb{R}^d\setminus\{0\}$ is open and therefore $\widetilde{\mathcal{O}} \in \mathcal{M}_d$. Thus, $\mathcal{O}\in \Sigma$.
\end{proof}

\noindent With the $\sigma$-algebra $\Sigma_{P,E}$, we now specify a measure on the measurable space $(S,\Sigma_{P,E})$. For each $F\in \Sigma_{P,E}$, define $\sigma_{P,E}: \Sigma_{P,E} \to [0,\infty)$ by 
\begin{equation*}
\sigma_{P,E}(F)=\mu_P\cdot m(\widetilde{F_E})
\end{equation*}
where $m$ is the Lebesgue measure on $\mathbb{R}^d$ and $\mu_P=\tr E>0$ is the homogeneous order associated to $P$. 
\begin{framed}
\begin{proposition}\label{prop:sigmaisameaure}
$\sigma_{P,E}$ is a finite measure on $(S,\Sigma_{P,E})$.
\end{proposition}
\end{framed}
\begin{proof}
\noindent Throughout the proof, we will write $\sigma=\sigma_{P,E}$, $\Sigma=\Sigma_{P,E}$, and, $\widetilde{F}=\widetilde{F_E}$ for each $F\subseteq S$. It is clear that $\sigma$ is non-negative and $\sigma(\varnothing)=0$. Let $\{ F_n  \}^\infty_{n=1} \subseteq \Sigma $ be a mutually disjoint collection. We claim that $\{ \widetilde{F_n} \}_{n=1}^\infty\subseteq\mathcal{M}_d$ is also a mutually disjoint collection. To see this, suppose that $x = r_n^E \eta_n = r_m^E \eta_m\in \widetilde{F_n}\cap\widetilde{F_m}$, where $r_n,r_m \in (0,1)$, $\eta_n \in F_n$, and $\eta_m \in F_m $. Then
\begin{equation*}
    r_n = P(r_n^E \eta_n) = P(x) = P(r_m^E \eta_m) = r_m,
\end{equation*}
implying that $\eta_n = \eta_m\in F_n\cap F_m$. Because $\{F_n\}_{n=1}^\infty$ is mutually disjoint, we must have $n=m$ which verifies our claim. By virtue of the countable additivity of Lebesgue measure, we therefore have
\begin{equation*}
\sigma\left(\bigcup_{n=1}^\infty F_n\right)
    = \mu_P\cdot m\left( \widetilde{\bigcup^\infty_{n=1} F_n } \right)=\mu_P\cdot m\left( \bigcup^\infty_{n=1}\widetilde{F_n} \right)
    = \mu_P\sum^\infty_{n=1} m(\widetilde{F_n})
    = \sum^\infty_{n=1}\sigma(F_n).
\end{equation*}
Therefore $\sigma$ is a measure on $(S,\Sigma)$. In view of Condition \ref{cond:PisAboveOne} of Proposition \ref{prop:PositiveHomogeneousCharacterization}, $\widetilde{S}=B\setminus\{0\}$ is a bounded subset of $\mathbb{R}^d\setminus\{0\}$ and hence $\sigma(S)=\mu_P\cdot m(B\setminus\{0\})<\infty$ showing that $\sigma$ is finite.
\end{proof}



\begin{framed}
\begin{corollary}
By virtue of the two preceding propositions, $\sigma_{P,E}$ is a finite Borel measure on $S$.
\end{corollary}
\end{framed}




\subsection{Product Measure and Point Isomorphism}\label{subsec:ProductMeasure}
So far, we have only worked with a surface-carried measure $\sigma_{P,E}$ on $S$. To obtain the full polar-coordinate integration formula in \ref{thm:BestIntegrationFormula}, we need to construct a \textbf{product measure} that combines the surface measure $\sigma_{P,E}$ on the unital level set $S$ and the radial measure $\lambda_P$ on $\mathbb{R}$ to obtain a ``volume'' measure. Once we have the product measure, we shall use Fubini's theorem, stated below for complete (product) measure spaces, to obtain our main result for this section. \\

\noindent To start, let $(S,\Sigma_{P,E},\sigma_{P,E})$ denote the finite measure space of Proposition \ref{prop:sigmaisameaure}. Recall that $\mathcal{L}$ denotes the $\sigma$-algebra of Lebesgue measurable subsets of $(0,\infty)$ and  $\lambda_P$ denotes the measure on $(0,\infty)$ with $\lambda_P(dr)=r^{\mu_P-1}\,dr$, i.e., for each $L\in\mathcal{L}$,
\begin{equation*}
\lambda_P(L)=\int_0^\infty \chi_L(r)r^{\mu_P-1}\,dr.
\end{equation*}
It is easy to see that $\lambda_P$ is $\sigma$-finite and so, in view of the finiteness of the measure $\sigma_{P,E}$, there exists a unique product measure $\lambda_P\times\sigma_{P,E}$ on $(0,\infty)\times S$ equipped with the product $\sigma$-algebra $\mathcal{L}\times\Sigma_{P,E}$ which satisfies
\begin{equation*}
    (\lambda_P\times\sigma_{P,E})(L\times F)=\lambda_P(L)\sigma_{P,E}(F)
\end{equation*}
for all $L\in\mathcal{L}$ and $F\in\Sigma_{P,E}$ (see Theorem \ref{thm:ProdMeasure} in the Appendix). We shall denote by $((0,\infty)\times S,(\mathcal{L}\times\Sigma_{P,E})', \lambda_P\times\sigma_{P,E})$ the completion of the measure space $((0,\infty)\times S,\mathcal{L}\times\Sigma_{P,E},\lambda_P \times\sigma_P)$. With this, we state (without proving) the following Fubini-Tonelli theorem associated to $\lambda_P\times \sigma_{P,E}$, which combines the results of Theorem \ref{thm:Fubini-Tonelli-OG} and the ``measureable slice'' theorem in Appendix \ref{sec:measure_theory}. This allows us to exchange the order of integration, which is crucial for future applications.
\begin{framed}


\begin{theorem}[Analogous to Theorem 8.12 of \cite{rudin_real_1987}]\label{thm:Fubini}
Let $g:(0,\infty)\times S\to\mathbb{C}$ be $(\mathcal{L}\times\Sigma_{P,E})'$-measurable. For each $r\in (0,\infty)$, define $g^r:S\to\mathbb{C}$ by $g^r(\eta)=g(r,\eta)$ for $\eta\in S$ and, for each $\eta\in S$, define $g_\eta:(0,\infty)\to\mathbb{C}$ by $g_\eta(r)=g(r,\eta)$ for $r\in (0,\infty)$. 
\begin{enumerate}
\item For $\lambda_P$-almost every $r$, $g^r$ is $\Sigma_{P,E}$-measurable and, for $\sigma_{P,E}$-almost every $\eta$, $g_\eta$ is $\mathcal{L}$-measurable.
\item\label{item:Fubini1} If $g\geq 0$, then:
\begin{enumerate}
\item For $\lambda_P$-almost every $r$, 
\begin{equation*}
H(r)=\int_S g^r(\eta)\,\sigma_{P,E}(d\eta)
\end{equation*}
exists as a non-negative extended real number. 
\item For $\sigma_{P,E}$-almost every $\eta$,
\begin{equation*}
G(\eta)=\int_0^\infty g_\eta(r)r^{\mu_P-1}\,dr
\end{equation*}
exists as a non-negative extended real number. 
\item We have
\begin{equation}\label{eq:Fubini1}
\int_0^\infty H(r)r^{\mu_P-1}dr=\int_{(0,\infty)\times S}g\,d(\lambda_P\times\sigma_{P,E})=\int_S G(\eta)\,\sigma_{P,E}(d\eta)
\end{equation}
and, in particular,
\begin{equation}\label{eq:Fubini2}
\int_0^\infty\left(\int_S g(r,\eta)\,\sigma_{P,E}(d\eta)\right)r^{\mu_P-1}\,dr=\int_S\left(\int_0^\infty g(r,\eta)r^{\mu_P-1}\,dr\right)\,\sigma_{P,E}(d\eta).
\end{equation}
\end{enumerate}
\item\label{item:Fubini2} If $g$ is complex valued and
\begin{equation*}
\int_S\left(\int_0^\infty |g(r,\eta)|r^{\mu_P-1}\,dr\right)\,\sigma_{P,E}(d\eta)<\infty\hspace{.2cm}\mbox{or}\hspace{.2cm}\int_0^\infty\left(\int_S|g(r,\eta)|\,\sigma_{P,E}(d\eta)\right)r^{\mu_P-1}\,dr<\infty,
\end{equation*}
then $g\in L^1((0,\infty)\times S,(\mathcal{L}\times\Sigma_{P,E})',\lambda_P\times\sigma_{P,E})$.
\item If $g\in L^1((0,\infty)\times S,(\mathcal{L}\times\Sigma_{P,E})',\lambda_P\times\sigma_{P,E})$, then $g^r\in L^1(S,\Sigma_{P,E},\sigma_{P,E})$ for $\lambda_P$-almost every $r$, $g_\eta\in L^1((0,\infty),\mathcal{L},\lambda_P)$ for $\sigma_{P,E}$-almost every $\eta$, and Equations \eqref{eq:Fubini1} and \eqref{eq:Fubini2} hold.
\end{enumerate}
\end{theorem}
\end{framed}
\noindent Our primary goal in this subsection is to prove the theorem below, which is a slightly more special statement of the second half of Theorem \ref{thm:BestIntegrationFormula}. 

\begin{framed}
\begin{theorem}\label{thm:MainIntegrationFormula}
Let $((0,\infty)\times S,(\mathcal{L}\times\Sigma_{P,E})',\lambda_P\times\sigma_{P,E})$ be as above.
\begin{enumerate}
\item\label{item:MainIntegrationFormula1} The map $\psi_E: (0,\infty)\times S\to\mathbb{R}^d\setminus\{0\}$, defined by \eqref{eq:Homeomorphism}, is a point isomorphism of the measure spaces $((0,\infty)\times S,(\mathcal{L}\times\Sigma_{P,E})',\lambda_P\times\sigma_{P,E})$ and $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d,m)$. That is
\begin{equation*}
\mathcal{M}_d=\{A\subseteq \mathbb{R}^d\setminus\{0\}:\psi_E^{-1}(A)\in(\mathcal{L}\times\Sigma_{P,E})'\}
\end{equation*}
and, for each $A\in\mathcal{M}_d$,
\begin{equation*}
m(A)=(\lambda_P\times\sigma_{P,E})(\psi_E^{-1}(A)).
\end{equation*}
\item\label{item:MainintegrationFormula2} If $f:\mathbb{R}^d\to\mathbb{C}$ is Lebesgue measurable, then $f\circ \psi_E$ is $(\mathcal{L}\times\Sigma_{P,E})'$-measurable and the following statements hold:
\begin{enumerate}
\item If $f\geq 0$, then
\begin{eqnarray}\label{eq:MainIntegrationFormula}
\int_{\mathbb{R}^d}f(x)\,dx&=&\int_0^\infty\left(\int_S f(r^E\eta)\,\sigma_{P,E}(d\eta)\right)r^{\mu_P-1}\,dr\nonumber\\
&=&\int_S\left(\int_0^\infty f(r^E\eta)r^{\mu_P-1}\,dr\right)\,\sigma_{P,E}(d\eta).
\end{eqnarray}
\item When $f$ is complex-valued, we have 
\begin{equation*}f\in L^1(\mathbb{R}^d)\hspace{.5cm}\mbox{if and only if}\hspace{0.5cm}f\circ\psi_E\in L^1((0,\infty)\times S,(\mathcal{L}\times \Sigma_{P,E})',\lambda_P\times\sigma_{P,E})
\end{equation*}
and, in this case, \eqref{eq:MainIntegrationFormula} holds.
\end{enumerate}
\end{enumerate}
\end{theorem}
\end{framed}



\noindent Properties \ref{item:MainIntegrationFormula1} and \ref{item:MainintegrationFormula2} in Theorem \ref{thm:MainIntegrationFormula} differ only from Properties \ref{property:BestPointIsomorphism} and \ref{property:BestIntegrationFormula} in Theorem \ref{thm:BestIntegrationFormula} only in the apparent dependence on our choice of $E\in\Exp(P)$. We shall see in Subsection \ref{subsec:IndependentofE} and Proposition \ref{prop:Endependence} therein that $\Sigma_{P,E_1}=\Sigma_{P,E_2}$ and $\sigma_{P,E_1}=\sigma_{P,E_2}$ for all $E_1,E_2\in\Exp(P)$ and so the dependence is indeed superficial. With this result, we shall obtain Properties \ref{property:BestPointIsomorphism} and \ref{property:BestIntegrationFormula} of Theorem \ref{thm:BestIntegrationFormula} immediately from Theorem \ref{thm:MainIntegrationFormula}.\\

\noindent To prove Theorem \ref{thm:MainIntegrationFormula}, we shall first treat several lemmas. These lemmas isolate and generalize several important ideas used in standard proofs of \eqref{eq:StandardPolarIntegrationFormula} (See, e.g., \cite{folland_real_2013} and \cite{stein_real_2009}). Lemma \ref{lemma:Scaling} establishes the scaling property of $\{ r^E\}$ on the Lebesgue measures and measurability of sets in $\mathbb{R}^d$. Lemma \ref{lem:SpecialRectangle} relates the Lebesgue measure of sets of the form $\psi_E(I\times F)$, where $I\subseteq (0,\infty)$ is sufficiently nice and $F\in \Sigma_{P,E}$, to the product measure $\lambda_P \times \sigma_{P,E}$. 

\begin{framed}
\begin{lemma}\label{lemma:Scaling}
Let $A\subseteq\mathbb{R}^d$ and $r>0$.  $A$ is Lebesgue measurable if and only if $r^E A=\{x=r^E a:a\in A\}$ is Lebesgue measurable and, in this case,
\begin{equation*}
m(r^E A)=r^{\mu_P}m(A).
\end{equation*}
\end{lemma}
\end{framed}


\begin{proof}
Because $x\mapsto r^E x$ is a linear isomorphism, $r^E A$ is Lebesgue measurable if and only if $A$ is Lebesgue measurable. Observe that $x\in r^E A$ if and only if $r^{-E}x\in A$ and therefore
\begin{equation*}
m(r^E A)=\int_{\mathbb{R}^d}\chi_{r^E A}(x)\,dx=\int_{\mathbb{R}^d}\chi_{A}(r^{-E}x)\,dx
\end{equation*}
where $\chi_{r^EA}$ and $\chi_{A}$ respectively denote the indicator functions of the sets $r^EA$ and $A$. Now, by making the linear change of variables $x\mapsto r^E x$, we have
\begin{equation*}
m(r^E A)=\int_{\mathbb{R}^d}\chi_A(x)|\det(r^E)|\,dx=r^{\mu_P}m(A),
\end{equation*}
because $\det(r^E)=r^{\tr E}=r^{\mu_P}>0$ by virtue of Proposition \ref{prop:ContinuousGroupProperties} and Corollary \ref{cor:TraceisInvariant}.
\end{proof}



\begin{framed}
\begin{lemma}\label{lem:SpecialRectangle}
Let $F\in\Sigma_{P,E}$. If $I\subseteq (0,\infty)$ is open, closed, $G_\delta$, or $F_\sigma$, then $\psi_E(I\times F)\in\mathcal{M}_d$ and
\begin{equation}\label{eq:SpecialRectangle}
m(\psi_E(I\times F))=(\lambda_P\times\sigma_{P,E})(I\times F)=\lambda_P(I)\sigma_{P,E}(F).
\end{equation}
\end{lemma}
\end{framed}
\begin{proof}
To simplify notation, we shall write $\lambda=\lambda_P$ and $\sigma=\sigma_{P,E}$ throughout the proof. We fix $F\in\Sigma_{P,E}$ and consider several cases for $I$.

\begin{subproof}[Case 1:]\textit{$I=(0,b)$ for $0<b\leq \infty$.} When $b$ is finite, observe that
\begin{equation*}
\psi_E(I\times F)=\{r^E\eta:0<r<b,\eta\in F\}=b^E\{r^E\eta:0<r<1,\eta \in F\}=b^E\widetilde{F_E}.
\end{equation*}
By virtue of Lemma \ref{lemma:Scaling}, it follows that $\psi_E(I\times F)\in\mathcal{M}_d$ and
\begin{eqnarray*}
(\lambda\times\sigma)(I\times F)&=&\lambda(I)\sigma(F)\\
&=&\left(\int_0^b r^{\mu_P-1}\,dr\right)\left(\mu_P\cdot m(\widetilde{F_E})\right)\\
&=&b^{\mu_P}m(\widetilde{F_E})\\
&=&m(b^{E}\widetilde{F_E})\\
&=&m(\psi_E(I\times F)).
\end{eqnarray*}
When $b=\infty$ i.e., $I=(0,\infty)$, we observe that
\begin{equation*}
I=\bigcup_{n=1}^\infty (0,n)=\bigcup_{n=1}^\infty I_n
\end{equation*}
where the open intervals $I_n=(0,n)$ are nested and increasing. In view of the result above (for finite $b=n$), we have
\begin{equation*}\psi_E(I\times F)=\psi_E\left(\bigcup_{n=1}^\infty (I_n\times F)\right)=\bigcup_{n=1}^\infty\psi_E(I_n\times F)\in\mathcal{M}_d.
\end{equation*}
Given that $\psi_E$ is a bijection, $\{\psi_E(I_n\times F)\}$ is necessarily a nested increasing sequence and so, by the continuity of the measures $\lambda\times\sigma$ and $m$,
\begin{equation*}
(\lambda\times\sigma)(I\times F)=\lim_{n\to\infty}(\lambda\times\sigma)(I_n\times F)=\lim_{n\to\infty}m(\psi_E(I_n\times F))= m(\psi_E(I\times F)). 
\end{equation*}
\end{subproof}

\begin{subproof}[Case 2:]\textit{$I=(0,a]$ for $0<a<\infty$.} We have
\begin{equation*}
I=(0,a]=\bigcap_{n=1}^\infty (0,a+1/n)=\bigcap_{n=1}^\infty I_n
\end{equation*}
where the open intervals $I_n=(0,a+1/n)$ are nested and decreasing. By reasoning analogous to that given in Case 1, we have
\begin{equation*}
\psi_E(I\times F)=\bigcap_{n=1}^\infty \psi_E(I_n\times F)\in \mathcal{M}_d
\end{equation*}
and
\begin{equation*}
(\lambda\times\sigma)(I\times F)=\lim_{n\to\infty}(\lambda\times\sigma)(I_n\times F)=\lim_{n\to\infty}m(\psi_E(I_n\times F))=m(\psi_E(I\times F)).
\end{equation*}
In particular, $m(\psi_E(I\times F))=\lambda((0,a])\sigma(F)=a^{\mu_P}\sigma(F)/\mu_P<\infty.$
\end{subproof}
\begin{subproof}[Case 3:]\textit{$I=(a,b)$ for $0<a<b\leq \infty$.} In this case, $I=(0,b)\setminus (0,a]$ and so, in view of Cases 1 and 2, $\psi_E(I\times F)=\psi_E((0,b)\times F)\setminus \psi_E((0,a]\times F)\in\mathcal{M}_d$ and
\begin{eqnarray*}
(\lambda\times\sigma)(I\times F)&=&(\lambda\times\sigma)( (0,b)\times F)-(\lambda\times\sigma)((0,a]\times F)\\
&=&m(\psi_E((0,b)\times F))-m(\psi_E((0,a]\times F))\\
&=&m(\psi_E(I\times F))
\end{eqnarray*}
where we have used the fact that $(\lambda\times\sigma)((0,a]\times F)=m(\psi_E((0,a]\times F))<\infty$.
\end{subproof}
\begin{subproof}[Case 4:]\textit{$I\subseteq (0,\infty)$ is open.} In this case, it is known that $I$ can be expressed as a countable union of disjoint open intervals $\{I_n\}$ and, by virtue of Cases 1 and 3, we have
\begin{equation*}
\psi_E(I\times F)=\bigcup_{n=1}^\infty\psi_E(I_n\times F)\in\mathcal{M}_d,
\end{equation*}
where this union is disjoint, and
\begin{eqnarray*}
\lefteqn{\hspace{-1cm}m(\psi_E(I\times F))=\sum_n m(\psi_E(I_n\times F))=\sum_n (\lambda\times\sigma)(I_n\times F)}\\
&&\hspace{2cm}=\sum_n \lambda(I_n)\sigma(F)=\left(\sum_n \lambda(I_n)\right)\sigma(F)=\lambda(I)\sigma(F)=(\lambda\times\sigma)(I\times F).
\end{eqnarray*}
\end{subproof}
\begin{subproof}[Case 5:]\textit{$I\subseteq (0,\infty)$ is closed.} In this case, we have $I=(0,\infty)\setminus O$ where $O$ is open and so
\begin{equation*}
\psi_E(I\times F)=\psi_E(F\times ((0,\infty)\setminus O))=\psi_E( (0,\infty)\times F)\setminus \psi_E(O\times F)\in\mathcal{M}_d.
\end{equation*}
At this point, we'd like to use the property that 
\begin{equation*}
m(\psi_E((0,\infty)\times F)\setminus \psi_E( O\times F))=m(\psi_E((0,\infty)\times F))-m(\psi_E(O\times F)),
\end{equation*} but this only holds when $m(\psi_E(O\times F))$ is finite. We must therefore proceed differently. For each natural number $n$, define $O_n=O\cap(0,n)$ and $I_n=(0,n)\setminus O_n$. It is straightforward to show that $\{I_n\}$ and $\{\psi_E(I_n\times F)\}$ are nested and increasing with
\begin{equation*}
I=\bigcup_{n=1}^\infty I_n\hspace{1cm}\mbox{and}\hspace{1cm}\psi_E(I\times F)=\bigcup_{n=1}^\infty \psi_E(I_n\times F). 
\end{equation*}
The results of Cases 1 and 4 guarantee that, for each $n$,
\begin{equation*}
m(\psi_E(O_n\times F))=(\lambda\times\sigma)(O_n\times F)\leq (\lambda\times\sigma)((0,n)\times F)<n^{\mu_P}m(\widetilde{F_E})<\infty
\end{equation*}
and therefore
\begin{eqnarray*}
m(\psi_E(I_n\times F))
&=&m(\psi_E((0,n)\times F))-m(\psi_E(O_n\times F))\\
&=&(\lambda\times\sigma)((0,n)\times F)-(\lambda\times\sigma)(O_n\times F)\\
&=&(\lambda\times\sigma)(I_n\times F).
\end{eqnarray*}
Then, by virtue of the continuity of measure,
\begin{equation*}
m(\psi_E(I\times F))=\lim_{n\to\infty}m(\psi_E(I_n\times F))=\lim_{n\to\infty}(\lambda\times\sigma)(I_n\times F)=(\lambda\times\sigma)(I\times F). 
\end{equation*}
\end{subproof}
\begin{subproof}[Case 6]\textit{$I\subseteq (0,\infty)$ is $G_\delta$ or $F_\sigma$.} Depending on whether $I$ is $G_\delta$ or $F_\sigma$,  express $I$ as an intersection of nested decreasing open sets or a union of nested increasing closed sets. In both cases, by virtually the same argument given in the previous cases, we find that $\psi_E(I\times F)\in \mathcal{M}_d$,
\begin{equation*}
m(\psi_E(I\times F))=(\lambda\times\sigma)(I\times F).
\end{equation*}
\end{subproof}
\end{proof}

\noindent The following lemma generalizes the result of Lemma \ref{lem:SpecialRectangle} (which only deals with cases of ``special rectangles'') so that the previous statement holds for any set $L \in \mathcal{L}$, the $\sigma$-algebra of Lebesgue measurable subsets of $(0,\infty)$. The result allows us to express the product measure of sufficiently nice sets $L\times F$ in terms of the Lebesgue measure of $\psi_E(L\times F)$, with which we can translate integration over $\mathbb{R}^d$ to integration over $(0,\infty)\times S$ as intended. The proof makes use of $F_\sigma$ and $G_\delta$ sets and properties of complete measure spaces.
\begin{framed}
\begin{lemma}\label{lem:AllMeasurableRectangles} For any $L\in\mathcal{L}$ and $F\in \Sigma_{P,E}$, $\psi_E(L\times F)\in\mathcal{M}_d$ and 
\begin{equation*}
m(\psi_E(L\times F))=(\lambda_P\times\sigma_{P,E})(L\times F).
\end{equation*}
\end{lemma}
\end{framed}
\begin{proof}
Fix $L\in\mathcal{L}$ and $F\in\Sigma_{P,E}$. It is easy to see that $\lambda_P$ and the Lebesgue measure $dr$ on $(0,\infty)$ are mutually absolutely continuous. It follows that $((0,\infty), \mathcal{L},\lambda_P)$ is a complete measure space and, further, that there exists an $F_\sigma$ set $L_\sigma\subseteq (0,\infty)$ and a $G_\delta$ set $L_\delta\subseteq (0,\infty)$ for which $L_\sigma\subseteq L\subseteq L_\delta$ and $\lambda_P(L_\delta\setminus L_\sigma)=0$. Note that, necessarily, $\lambda_P(L)=\lambda_P(L_\sigma)=\lambda_P(L_\delta)$. We have
\begin{equation}\label{eq:AllMeasurableRectangles1}
\psi_E(L\times F)=\psi_E( L_\sigma\times F)\cup\psi_E((L\setminus L_\sigma)\times F)
\end{equation}
where, by virtue of the preceding lemma, $\psi_E(L_\sigma\times F)\in \mathcal{M}_d$ and
\begin{equation}\label{eq:AllMeasurableRectangles2}
m(\psi_E(L_{\sigma}\times F))=(\lambda_P\times\sigma_{P,E})( L_\sigma\times F)=\lambda_P(L_\sigma)\sigma_{P,E}(F)=\lambda_P(L)\sigma_{P,E}(F)=(\lambda_P\times\sigma_{P,E})(L\times F).
\end{equation}
Observe that
\begin{equation*}
\psi_E((L\setminus L_\sigma)\times F)\subseteq \psi_E((L_{\delta}\setminus L_\sigma)\times F)
\end{equation*}
where, because $L_\delta\setminus L_\sigma$ is an $G_{\delta}$ set, the latter set is a member of $\mathcal{M}_d$ and
\begin{equation*}
m(\psi_E((L_\delta\setminus L_\sigma)\times F))=(\lambda_P\times\sigma_{P,E})((L_\delta\setminus L_\sigma)\times F)=\lambda_P(L_\delta\setminus L_\sigma)\sigma_{P,E}(F)=0
\end{equation*}
by virtue of the preceding lemma. Using the fact that $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d,m)$ is complete, we conclude that $\psi_E((L\setminus L_\sigma)\times F)\in \mathcal{M}_d$ and $m(\psi_E((L\setminus L_\sigma)\times F))=0$. It now follows from \eqref{eq:AllMeasurableRectangles1} and \eqref{eq:AllMeasurableRectangles2} that $\psi_E(L\times F)\in\mathcal{M}_d$ and
\begin{equation*}
m(\psi_E(L\times F))=m(\psi_E(L_\sigma\times F))+m(\psi_E((L\setminus L_\sigma)\times F))=(\lambda_P\times\sigma_{P,E})(L\times F),
\end{equation*}
as desired.
\end{proof}

\noindent The following two lemmas provide another key ingredient to proving Theorem \ref{thm:MainIntegrationFormula}. Lemma \ref{lem:S_Dense} is a standard result in real analysis which states that a compact subset of any metric space contains a countably dense set. This results is then used in Lemma \ref{lem:OpenRectangle} to show that every open set in $\mathbb{R}^d\setminus \{ 0\}$ can be written as a countable union of sets of the form $\psi_E(\mathcal{U})$ where $\mathcal{U}$ is an open rectangle in $(0,\infty)\times S$. In our proof of Theorem \ref{thm:MainIntegrationFormula}, we will use this result as justification for the fact that $\psi_E(\mathcal{L}\times \Sigma_{P,E})$ contains every open subset of $\mathbb{R}^d\setminus \{0 \}$. 
\begin{framed}
\begin{lemma}\label{lem:S_Dense}
Let $S$ be a compact subset of a metric space. Then $S$ contains a countably dense set.
\end{lemma}
\end{framed}
\begin{proof}
For each $n\in\mathbb{N}$, consider the open cover
\begin{equation*}
\{B_{1/n}(x)\cap S, x\in S\}
\end{equation*}
of $S$. Since $S$ is compact, there exists a finite subcover. Let $x_{j,n}$, $j=1,2,\dots N_n$ denote the center of each of the balls, then, we have that $S$ is covered by $\{B_{1/n}(x_{j,n})\cap S,j=1,2,\dots, N_n\}$. Thus, for each $n\in \mathbb{N}$, we have a finite set $\{x_{j,n}\}$ of centers. The countable union of these finite sets, $\bigcup^\infty_{n=1} \{ x_{j,n}\}$, is countable. It is also dense because for every point $x\in S$ and $\epsilon >0$, there is always some $n$ such that $\vert x_{j,n} - x\vert < 1/n < \epsilon$.  
\end{proof}
\begin{framed}
\begin{lemma}\label{lem:OpenRectangle}
Every open subset $U\subseteq \mathbb{R}^d\setminus\{0\}$ can be written as a countable union of open sets of the form $\psi_E(\mathcal{U})$ where $\mathcal{U}=I\times\mathcal{O}$ is an open rectangle in $(0,\infty)\times S$.
\end{lemma}
\end{framed}


\begin{proof}
Let $\{r_k\}_{k=1}^\infty$ and $\{\eta_j\}_{j=1}^\infty$ be countably dense subsets of $(0,\infty)$ and $S$, respectively.  For each triple of natural numbers $j,l,n\in\mathbb{N}_+$, consider the open set
\begin{equation*}
\mathcal{U}_{j,l,n}=\{ \vert r - r_j \vert < 1/n \}\times \mathcal{O}_{l,n}\subseteq (0,\infty)\times S
\end{equation*}
where
\begin{equation*}
\mathcal{O}_{l,n}=\{\eta\in S: |\eta-\eta_l|<1/n\}.
\end{equation*}
Let $U\subseteq \mathbb{R}^d\setminus \{0\}$ be open. We will show that
\begin{equation}\label{eq:OpenRectangle}
U=\bigcup_{\substack{j,l,n\\ \psi_E(\mathcal{U}_{j,l,n})\subseteq U}}\psi_E(\mathcal{U}_{j,l,n}),
\end{equation}
where, in view of Proposition \ref{prop:PsiHomeomorphism}, each $\psi_E(\mathcal{U}_{j,l,n})$ is open. It is clear that any element of the union on the right hand side of \eqref{eq:OpenRectangle} belongs to some $\psi_E(\mathcal{U}_{j,l,n}) \subseteq U$ and so the union is a subset of $U$. To prove \eqref{eq:OpenRectangle}, it therefore suffices to prove that, for each $x\in U$, there exists a triple $j,l,n$ with
\begin{equation*}
x\in\psi_E(\mathcal{U}_{j,l,n})\subseteq U.
\end{equation*}
To this end, fix $x\in U$ and let $\delta>0$ be such that $\mathbb{B}_\delta(x)\subseteq U$. Consider $(r_x,\eta_x)=\psi_E^{-1}(x)\in (0,\infty)\times S$ and set $M=\|r_x^E\|>0$ and $C=\|E\|>0$. Observe that 
\begin{equation*}
\|I-\alpha^E\|=\left\|\sum_{k=1}^\infty \frac{(\ln \alpha)^k}{k!} E^k\right\|\leq \sum_{k=1}^\infty \frac{|\ln \alpha|^k}{k!} \|E\|^k=e^{(C|\ln \alpha|)}-1
\end{equation*}
for all $\alpha>0$. Since $\alpha\mapsto e^{(C|\ln \alpha|)}-1$ is continuous and $0$ at $\alpha=1$, we can choose $\delta'>0$ for which
\begin{equation*}
\|I-\alpha ^E\|< \frac{\delta}{2M (  |\eta_x|+2)}
\end{equation*}
whenever $|\alpha-1|<\delta'$. Fix an integer $n>\max \left\{1/\delta'r_x, 4M/\delta \right\}$ and, using the density of the collections $\{r_j\}$ and $\{\eta_l\}$, let $r_j$ and $ \eta_l$ be such that $\abs{r_j - r_x } < 1/n$ and $\abs{\eta_l - \eta_x} < 1/n$. It follows that the corresponding open set $\mathcal{U}_{j,l,n}$ contains $\psi_E^{-1}(x)$, or, equivalently, $x\in \psi_E(\mathcal{U}_{j,l,n})$. Thus, it remains to show that $\psi_E(\mathcal{U}_{j,l,n}) \subseteq \mathbb{B}_\delta(x)$. To this end, let $y=\psi_E(r_y,\eta_y)\in\psi_E(\mathcal{U}_{j,l,n})$ and observe that
\begin{eqnarray*}
| x - y | &\leq& \vert \psi_E(r_x,\eta_x,) - \psi_E(r_x,\eta_y) \vert 
    + \vert \psi_E(r_x,\eta_y) - \psi_E(r_y,\eta_y) \vert\\
    &=&  \vert r_x^E (\eta_x - \eta_y) \vert + \vert (r_x^E - r_y^E) \eta_y \vert\\
    &\leq& M\vert \eta_x - \eta_y \vert + \|{r_x^E - r_y^E}\|  \vert \eta_y \vert.
\end{eqnarray*}
Since both $(\eta_x,r_x),(\eta_y,r_y) \in \mathcal{U}_{j,l,n}$, we have
\begin{equation*}
    \vert \eta_x - \eta_y \vert \leq \vert \eta_x - \eta_j \vert + \vert \eta_j - \eta_y \vert < \frac{2}{n}
\hspace{1cm}\mbox{and}\hspace{1cm}
    \vert \eta_y \vert \leq \vert \eta_y - \eta_x \vert + \vert \eta_x \vert < \vert \eta_x \vert + \frac{2}{n}.
\end{equation*}
Also, since $|r_x-r_y|<1/n$, it follows that $r_y=\alpha r_x$ where $|1-\alpha|<1/nr_x < \delta'$ by our choice of $n$. Consequently,
\begin{eqnarray*}
    \vert x - y \vert 
    &< & \frac{2}{n} M+ \left( \vert \eta_x \vert + \frac{2}{n} \right) \|{r_x^E -  r_x^E \alpha^E}\|   \\ 
    &<& \frac{2}{n}M + \left( \vert \eta_x \vert + 2 \right)M\| I - \alpha^E\| \\
    &<&  \frac{2}{n}M +  \frac{\delta M \left( \vert \eta_x \vert + 2\right) }{2M (| \eta_x | + 2)}  \\
    &<& \frac{\delta}{2} + \frac{\delta}{2}=\delta 
\end{eqnarray*}
and so we have established \eqref{eq:OpenRectangle}. Finally, upon noting that $\{\mathcal{U}_{j,l,n}\}_{(j,l,n)\in\mathbb{N}_+^3}$ is a countable collection of open rectangles, the union in \eqref{eq:OpenRectangle} is necessarily countable and we are done with the proof.
\end{proof}

\noindent In our final lemma preceding the proof of Theorem \ref{thm:MainIntegrationFormula}, we treat a general measure-theoretic statement which gives sufficient conditions concerning two measure spaces to ensure that their completions are isomorphic. This lemma is used in the proof of Theorem \ref{thm:MainIntegrationFormula} to show that the (complete) measure spaces $((0,\infty),(\mathcal{L}\times \Sigma_{P,E})',\lambda_P\times \sigma_{P,E})$ and $(\mathbb{R}^d\setminus \{ 0\},\mathcal{M}_d,m)$ are isomorphic with point isomorphism $\psi_E$. Here, $((0,\infty),(\mathcal{L}\times \Sigma_{P,E})',\lambda_P\times \sigma_{P,E})$ is the completion of $((0,\infty),\mathcal{L}\times \Sigma_{P,E},\lambda_P\times \sigma_{P,E})$, and $(\mathbb{R}^d\setminus \{ 0\},\mathcal{M}_d,m)$ is the completion of $(\mathbb{R}^d\setminus \{ 0\},\mathcal{B}(\mathbb{R}^d\setminus\{ 0 \}),m)$. 

\begin{framed}
\begin{lemma}\label{lem:PushforwardLemma}
Let $(X_1,\Sigma_1,\nu_1)$ and $(X_2,\Sigma_2,\nu_2)$ be measure spaces, let $\varphi:X_1\to X_2$ be a bijection and denote by $(X_i,\Sigma_i',\nu_i')$ the completion of the measure space $(X_i,\Sigma_i,\nu_i)$ for $i=1,2$. Assume that the following two properties are satisfied:
\begin{enumerate}
\item\label{property:PushforwardLemma1} For each $A_1\in\Sigma_1$, $\varphi(A_1)\in\Sigma_2'$ and $\nu_2'(\varphi(A_1))=\nu_1(A_1).$
\item\label{property:PushforwardLemma2} For each $A_2\in\Sigma_2$, $\varphi^{-1}(A_2)\in \Sigma_1'$ and $\nu_1'(\varphi^{-1}(A_2))=\nu_2(A_2)$.
\end{enumerate}
Then the measure spaces $(X_1,\Sigma_1',\nu_1')$ and $(X_2,\Sigma_2',\nu_2')$ are isomorphic with point isomorphism $\varphi$. Specifically,
\begin{equation}\label{eq:PushforwardLemma1}
\Sigma_2'=\{A_2\subseteq X_2: \varphi^{-1}(A_2)\in\Sigma_1'\}
\end{equation}
and
\begin{equation}\label{eq:PushforwardLemma2}
\nu_2'(A_2)=\nu_1'(\varphi^{-1}(A_2))
\end{equation}
for all $A_2\in\Sigma_2'$.
\end{lemma}
\end{framed}
\begin{proof}
Let us first assume that $A_2\in\Sigma_2'$. By definition, $A_2=G_2\cup H_2$ where $G_2\in\Sigma_2$ and $H_2\subseteq G_{2,0}\in \Sigma_2$ with $\nu_2'(A_2)=\nu_2(G_2)$ and $\nu_2'(H_2)=\nu_2(G_{2,0})=0$. Consequently, $\varphi^{-1}(A_2)=\varphi^{-1}(G_2)\cup\varphi^{-1}(H_2)$ and $\varphi^{-1}(H_2)\subseteq \varphi^{-1}(G_{2,0})$. In view of Property \ref{property:PushforwardLemma2}, $\varphi^{-1}(G_2),\varphi^{-1}(G_{2,0})\in \Sigma_1'$ and we have
\begin{equation*}
\nu_1'(\varphi^{-1}(G_2))=\nu_2(G_2)=\nu_2'(A_2)\hspace{1cm}\mbox{and}\hspace{1cm}\nu_1'(\varphi^{-1}(G_{2,0}))=\nu_2(G_{2,0})=0.
\end{equation*}
In view of the fact that $(X_1',\Sigma_1',\nu_1')$ is complete, $\varphi^{-1}(H_2)\in\Sigma_1'$ and $\nu_1'(\varphi^{-1}(H_2))=0$. Consequently, we obtain $\varphi^{-1}(A_2)=\varphi^{-1}(G_2)\cup\varphi^{-1}(H_2)\in\Sigma_1'$ and
\begin{equation*}
\nu_2'(A_2)=\nu_1'(\varphi^{-1}(G_2))\leq\nu_1'(\varphi^{-1}(A_2))\leq\nu_1'(\varphi^{-1}(G_2))+\nu_1'(\varphi^{-1}(H_2))=\nu_2(G_2)+0=\nu_2'(A_2).
\end{equation*}
From this we obtain that $\Sigma_2'\subseteq \{A_2\subseteq X_2:\varphi^{-1}(A_2)\in\Sigma_1'\}$ and, for each $A_2\in\Sigma_2'$, $\nu_2'(A_2)=\nu_1'(\varphi^{-1}(A_2))$. It remains to prove that
\begin{equation*}
\{A_2\subseteq X_2:\varphi^{-1}(A_2)\in\Sigma_1'\}\subseteq \Sigma_2'.
\end{equation*}
To this end, let $A_2$ be a subset of $X_2$ for which $\varphi^{-1}(A_2)\in\Sigma_1'$. By the definition of $\Sigma_1'$, we have $\varphi^{-1}(A_2)=G_1\cup H_1$ where $G_1\in\Sigma_1$, $H_1\subseteq G_{1,0}\in\Sigma_1$ and $\nu_1'(H_1)=\nu_1(G_{1,0})=0$. In view of Property \ref{property:PushforwardLemma1}, $\varphi(G_1)\in\Sigma_2'$, $\varphi(H_1)\subseteq\varphi(G_{1,0})\in\Sigma_2'$ and $\nu_2'(\varphi(G_{1,0}))=\nu_1(G_{1,0})=0$. Because $(X_2',\Sigma_2',\nu_2')$ is complete, we have $\varphi(H_1)\in\Sigma_2'$ and so
\begin{equation*}
A_1=\varphi(\varphi^{-1}(A_2))=\varphi(G_1)\cup\varphi(H_1)\in \Sigma_2',
\end{equation*}
as desired.
\end{proof}

\noindent We are finally in a position to prove Theorem \ref{thm:MainIntegrationFormula}. Our approach can be described as follows. We first argue that $\mathcal{L}\times \Sigma_{P,E}$ is contained in the monotone class $\mathcal{C}$ comprised of the sets $G\subseteq (0,\infty)\times S$ for which $\psi_E(G) \in \mathcal{M}_d$ and $m(\psi_E(G)) = (\lambda_P \times \sigma_{P,E})(G)$ via the monotone class lemma. This allows us to show that every set $G$ in $\mathcal{L}\times \Sigma_{P,E}$ satisfies the two properties above, and that the $\sigma$-algebra of Borel subsets of $\mathbb{R}^d\setminus\{ 0\}$ is contained in $\psi_E(\mathcal{L}\times \Sigma_{P,E})$. Property \ref{item:MainIntegrationFormula1} follows from recognizing that the $\sigma$-algebras and measure spaces in the hypothesis of Theorem \ref{thm:MainIntegrationFormula} are completions of those in preceding arguments. To prove Property \ref{item:MainintegrationFormula2}, we let a measureable function $f: \mathbb{R}^d \to \mathbb{C}$ be given and use Property \ref{item:MainintegrationFormula2}, the monotone convergence theorem (in case that $f\geq 0$), and Fubini's theorem.   
 

\begin{proof}[Proof of Theorem \ref{thm:MainIntegrationFormula}]
Denote by $\mathcal{C}$ the collection of sets $G\subseteq (0,\infty)\times S$ for which $\psi_E(G)\in \mathcal{M}_d$ and $m(\psi_E(G))=(\lambda_P\times\sigma_{P,E})(G).$ By virtue of Lemma \ref{lem:AllMeasurableRectangles}, it follows that $\mathcal{C}$ contains all elementary sets, i.e., finite unions of disjoint measurable rectangles. Using the continuity of measure (applied to the measures $m$ and $\lambda_P\times\sigma_{P,E}$) and the fact that $\psi_E$ is a bijection, it is straightforward to verify that $\mathcal{C}$ is a monotone class. By the monotone class lemma (Theorem 8.3 of \cite{rudin_real_1987}), it immediately follows that $\mathcal{L}\times\Sigma_{P,E}\subseteq\mathcal{C}$. In other words, for each $G\in\mathcal{L}\times\Sigma_{P,E}$,
\begin{equation}\label{eq:Good1}
\psi_E(G)\in\mathcal{M}_d\hspace{1cm}\mbox{and}\hspace{1cm}m(\psi_E(G))=(\lambda_P\times\sigma_{P,E})(G).
\end{equation}
We claim that, for each Borel subset $A$ of $\mathbb{R}^d\setminus\{0\}$, $\psi_E^{-1}(A)\subseteq \mathcal{L}\times\Sigma_{P,E}$. To this end, we write
\begin{equation*}
\psi_E(\mathcal{L}\times\Sigma_{P,E})=\{\psi_E(G):G\in\mathcal{L}\times\Sigma_{P,E}\}
\end{equation*}
for the $\sigma$-algebra on $\mathbb{R}^d\setminus\{0\}$ induced by $\psi_E$. In view of Lemma \ref{lem:OpenRectangle}, $\psi_E(\mathcal{L}\times\Sigma_{P,E})$ contains every open subset of $\mathbb{R}^d\setminus\{0\}$ and therefore
\begin{equation*}
\mathcal{B}(\mathbb{R}^d\setminus\{0\})\subseteq\psi_E(\mathcal{L}\times\Sigma_{P,E}).
\end{equation*}
where $\mathcal{B}(\mathbb{R}^d\setminus\{0\})$ denotes the $\sigma$-algebra of Borel subsets of $\mathbb{R}^d\setminus\{0\}$ thus proving our claim. 

Together, the results of the two preceding paragraphs show that, for each $A\in\mathcal{B}(\mathbb{R}^d\setminus\{0\})$, $\psi_E^{-1}(A)\subseteq \mathcal{L}\times\Sigma_{P,E}$ and $m(A)=(\lambda_P\times\sigma_{P,E})(\psi_E^{-1}(A))$. Upon noting that $\mathcal{L}\times\Sigma_{P,E}\subseteq (\mathcal{L}\times\Sigma_{P,E})'$, we immediately obtain the following statement: For each $A\in\mathcal{B}(\mathbb{R}^d\setminus\{0\})$,
\begin{equation}\label{eq:Good2}
\psi_E^{-1}(A)\in (\mathcal{L}\times\Sigma_{P,E})'\hspace{1cm}\mbox{and}\hspace{1cm}m(A)=(\lambda_P\times\sigma_{P,E})(\psi_E^{-1}(A)).
\end{equation}
In comparing \eqref{eq:Good1} and \eqref{eq:Good2} with Properties \ref{property:PushforwardLemma1} and \ref{property:PushforwardLemma2} of Lemma \ref{lem:PushforwardLemma} and, upon noting that $((0,\infty)\times S,(\mathcal{L}\times\Sigma_{P,E})',\lambda_P\times\sigma_{P,E})$ is the completion of $((0,\infty)\times S,\mathcal{L}\times\Sigma_{P,E},\lambda_P\times\sigma_{P,E})$ and $(\mathbb{R}^d\setminus\{0\},\mathcal{M}_d,m)$ is the completion of $(\mathbb{R}^d\setminus\{0\},\mathcal{B}(\mathbb{R}^d\setminus\{0\}),m)$, Property \ref{item:MainIntegrationFormula1} of Theorem \ref{thm:MainIntegrationFormula} follows immediately from Lemma \ref{lem:PushforwardLemma}.

It remains to prove Property \ref{item:MainintegrationFormula2}. To this end, let $f:\mathbb{R}^d\to\mathbb{C}$ be Lebesgue measurable. Because $\mathcal{M}_d=\{A\subseteq \mathbb{R}^d\setminus\{0\}:\psi_E^{-1}(A)\in(\mathcal{L}\times\Sigma_{P,E})'\}$, it follows that $f\circ\psi_E$ is $(\mathcal{L}\times\Sigma_{P,E})'$-measurable. In the case that $f\geq 0$, we may approximate $f$ monotonically by simple functions and, by invoking Property \ref{item:MainIntegrationFormula1} and the monotone convergence theorem, we find that
\begin{equation}\label{eq:ChangeofMeasure}
\int_{\mathbb{R}^d}f(x)\,dx=\int_{\mathbb{R}^d\setminus \{0\}}f(x)\,dx=\int_{(0,\infty)\times S}f\circ \psi_E\, d(\lambda_P\times\sigma_{P,E}).
\end{equation}
From this, \eqref{eq:MainIntegrationFormula} follows from Fubini's theorem (see, e.g., Part (a) of Theorem 8.8 and Theorem 8.12 of \cite{rudin_real_1987}). Finally, by applying the above result to $|f|\geq 0$, we obtain $f\in L^1(\mathbb{R}^d)$ if and only if $f\circ \psi_E\in L^1((0,\infty)\times S,(\mathcal{L}\times\Sigma_{P,E})',\lambda_P\times\sigma_{P,E})$. In this case, by applying \eqref{eq:ChangeofMeasure} to $\Re(f)_+,\Re(f)_-,\Im(f)_+$ and $\Im(f)_-$, we find that \eqref{eq:ChangeofMeasure} holds for our integrable $f$ and, by virtue Fubini's theorem (see, e.g., Part (b) of Theorem 8.8 and Theorem 8.12 of \cite{rudin_real_1987}), the desired result follows.
\end{proof}

\noindent Our next result, Proposition \ref{prop:Regular}, guarantees that, in particular, $\sigma_{P,E}$ is a Radon measure. 

\begin{framed}
\begin{proposition}\label{prop:Regular}
The following statements are true:
\begin{enumerate}
    \item\label{item:Complete} $(S,\Sigma_{P,E},\sigma_{P,E})$ is the completion of the measure space $(S,\mathcal{B}(S),\sigma_{P,E})$. In particular, the $(S,\Sigma_{P,E},\sigma_{P,E})$ is complete and every $F\in \Sigma_{P,E}$ is of the form $F=G\cup H$ where $G$ is a Borel set and $H$ is a subset of a Borel set $Z$ with $\sigma_{P,E}(Z)=0$.
\item\label{item:Regular} For each $F\in\Sigma_{P,E}$,
\begin{equation}\label{eq:OuterRegular}
\sigma_{P,E}(F)=\inf\{\sigma_{P,E}(\mathcal{O}):F\subseteq\mathcal{O}\subseteq S\mbox{ and $\mathcal{O}$ is open}\}
\end{equation}
and
\begin{equation}
\sigma_{P,E}(F)=\sup\{\sigma_{P,E}(K):K\subseteq F\subseteq S\mbox{ and $K$ is compact}\}.
\end{equation}
\end{enumerate} 
\end{proposition}
\end{framed}


\begin{remark}
This proposition can be seen as an application of Proposition \ref{prop:BorelContainment} and Theorem 2.18 of \cite{rudin_real_1987}. The proof we give here is distinct and, we believe, nicely illustrates the utility of \eqref{eq:MainIntegrationFormula} of Theorem \ref{thm:MainIntegrationFormula}.
\end{remark}


\begin{proof}
Throughout the proof, we shall write $\sigma=\sigma_{P,E}$, $\Sigma=\Sigma_{P,E}$ and, for each $F\subseteq S$, $\widetilde{F}=\widetilde{F_E}$. We remark that, by standard arguments using $G_\delta$ and $F_\sigma$ sets, Item \ref{item:Complete} follows immediately from Item \ref{item:Regular}. Also, given that $S$ is compact and $\sigma$ is finite, it suffices to prove \eqref{eq:OuterRegular}, i.e., it suffices to prove the statement: For each $F\in \Sigma$ and $\epsilon>0$, there is an open subset $\mathcal{O}$ of $S$ containing $F$ for which 
\begin{equation*}
\sigma(\mathcal{O}\setminus F)<\epsilon.
\end{equation*}
To this end, let $F\in \Sigma$ and $\epsilon>0$. Given that $\widetilde{F}\in\mathcal{M}_d$ and $m$ is outer regular, there exists an open set $U\subseteq \mathbb{R}^d\setminus\{0\}$ for which $\widetilde{F}\subseteq U$ and $m(U\setminus\widetilde{F})<\epsilon/(2\mu_P)$. Since $\widetilde{F}$ is a subset of the open set $B\setminus\{0\}$, we may assume without loss of generality that $U\subseteq B\setminus\{0\}$ and so $m(\widetilde{F})\leq m(U)<\infty$ and
\begin{equation}\label{eq:LebesgueOuter}
m(U\setminus \widetilde{F})=m(U)-m(\widetilde{F})<\epsilon/(2\mu_P).
\end{equation}
For each $0<r<1$, consider the open set
\begin{equation*}
\mathcal{O}_r=S\cap\left( r^{-E}U\right)
\end{equation*}
in $S$. Observe that, for each $x\in F$, $r^E x\in \widetilde{F}\subseteq U$ and therefore $x\in \mathcal{O}_r$. Hence, for each $0<r<1$, $\mathcal{O}_r$ is an open subset of $S$ containing $F$. 

We claim that there is at least one $r_0\in (0,1)$ for which 
\begin{equation}\label{eq:GoodIneq}
m(\widetilde{\mathcal{O}_{r_0}})< m(U)+\epsilon/(2\mu_P).
\end{equation}
To prove the claim, we shall assume, to reach a contradiction, that 
\begin{equation*}
m(\widetilde{\mathcal{O}_{r}})\geq m(U)+\epsilon/(2\mu_P)
\end{equation*}
for all $0<r<1$. By virtue of \eqref{eq:MainIntegrationFormula} of Theorem \ref{thm:MainIntegrationFormula},
\begin{equation*}
m(U)=\int_{0}^\infty\left(\int_S \chi_{U}(r^E\eta)\,\sigma(d\eta)\right)r^{\mu_P-1}\,dr.
\end{equation*}
Upon noting that $U\subseteq B\setminus\{0\}$, it is easy to see that
\begin{equation*}
U=\bigcup_{0<s<1}s^E\mathcal{O}_s
\hspace{1cm}\mbox{and}\hspace{1cm}
r^E\eta\in \bigcup_{0<s<1}s^E\mathcal{O}_s
\end{equation*}
if and only if $0<r<1$ and $\eta\in \mathcal{O}_r$. Consequently,
\begin{equation*}
m(U)=\int_0^1\left(\int_S\chi_{\mathcal{O}_r}(\eta)\,\sigma(d\eta)\right)\,r^{\mu_P-1}\,dr=\int_0^1\sigma(\mathcal{O}_r)r^{\mu_P-1}\,dr=\int_0^1 \mu_P\cdot m(\widetilde{\mathcal{O}_r})\,r^{\mu_P-1}\,dr.
\end{equation*}
Upon making use of our supposition, we have
\begin{equation*}
\int_0^1\mu_P\cdot m(\widetilde{\mathcal{O}_r})r^{\mu_P-1}\,dr\geq \int_0^1\mu_P\cdot (m(U)+\epsilon/(2\mu_P))r^{\mu_P-1}\,dr=m(U)+\epsilon/(2\mu_P)
\end{equation*}
and so
\begin{equation*}
m(U)\geq m(U)+\epsilon/(2\mu_P),
\end{equation*}
which is impossible. Thus, the stated claim is true.

Given any such $r_0$ for which \eqref{eq:GoodIneq} holds, set $\mathcal{O}=\mathcal{O}_{r_0}$. As previously noted, $\mathcal{O}$ is an open subset of $S$ which contains $F$. In view of \eqref{eq:LebesgueOuter} and \eqref{eq:GoodIneq}, we have
\begin{equation*}
m(\widetilde{\mathcal{O}})-m(\widetilde{F})<m(U)-m(\widetilde{F})+\epsilon/(2\mu_P)<\epsilon/(2\mu_P)+\epsilon/(2\mu_P)=\epsilon/\mu_P
\end{equation*}
and therefore
\begin{equation*}
\sigma(\mathcal{O}\setminus F)=\sigma(\mathcal{O})-\sigma(F)=\mu_P(m(\widetilde{\mathcal{O}})-m(\widetilde{F}))<\epsilon,
\end{equation*}
as desired.
\end{proof}




\subsection{The construction is independent of $E\in \Exp{P}$}\label{subsec:IndependentofE}

\noindent In this subsection, we show that the measure $\sigma_{P,E}$ is independent of the choice of $E\in\Exp(P)$ and complete the proof of Theorem \ref{thm:BestIntegrationFormula}. We let $E_1,E_2\in\Exp(P)$ and consider the measure spaces $(S,\Sigma_{P,E_1},\sigma_{P,E_1})$ and $(S,\Sigma_{P,E_2},\sigma_{P,E_2})$ produced via the construction in Subsection \ref{subsec:ConstructionofSigma}. 

\begin{framed}
\begin{proposition}\label{prop:Endependence}
$\Sigma_{P,E_1}=\Sigma_{P,E_2}$ and $\sigma_{P,E_1}=\sigma_{P,E_2}$.
\end{proposition}
\end{framed}
\begin{proof}
Throughout the proof, we will write $\Sigma_i=\Sigma_{P,E_i}$ and $\sigma_i=\sigma_{P,E_i}$ for $i=1,2$. In view of the Proposition \ref{prop:Regular}, it suffices to show that 
\begin{equation*}
\sigma_1(F)=\sigma_2(F)
\end{equation*}
for all $F\in \mathcal{B}(S)\subseteq \Sigma_{1}\cap\Sigma_{2}$. To this end, we let $F\in\mathcal{B}(S)$ be arbitrary but fixed. 

Given $n\in\mathbb{N}_+$, using the regularity of the measures $\sigma_1$ and $\sigma_2$, select open sets $\mathcal{O}_{n,1},\mathcal{O}_{n,2}$ and compact sets $K_{n,1},K_{n,2}$ for which
\begin{equation*}
K_{n,j}\subseteq F\subseteq \mathcal{O}_{n,j}\hspace{1cm}\mbox{and}\hspace{1cm}\sigma_j(\mathcal{O}_{n,j}\setminus K_{n,j})<1/n
\end{equation*}
for $j=1,2$. Observe that $K_n=K_{n,1}\cup K_{n,2}$ is a compact set, $\mathcal{O}_n=\mathcal{O}_{n,1}\cap\mathcal{O}_{n,2}$ is an open set, and $K_n\subseteq F\subseteq \mathcal{O}_n$. Furthermore, 
\begin{equation*}
\sigma_j(\mathcal{O}_n\setminus K_n)\leq \sigma_j(\mathcal{O}_{n,j}\setminus K_{n,j})<1/n
\end{equation*}
for $j=1,2$. Given that $\mathcal{O}_n$ is open in $S$, $\mathcal{O}_n=S\cup U_n$ where $U_n$ is an open subset of $\mathbb{R}^d$ and, because that $S$ is compact, $K_n=K_n\cap S$ is a compact subset of $\mathbb{R}^d$. By virtue of Urysohn's lemma, let $\phi_n:\mathbb{R}^d\to [0,1]$ be a continuous function which is compactly supported in $U_n$ and for which $\phi_n(x)=1$ for all $x\in K_n$. Using this sequence of functions $\{\phi_n\}$, we establish the following useful lemma.

\begin{lemma}\label{lem:IndepProof}
For $j=1,2$ and $n\in\mathbb{N}$, define $g_{n,j}:(0,\infty)\to\mathbb{R}$ by
\begin{equation*}
g_{n,j}(r)=\int_S\phi_n(r^{E_j}\eta)\,\sigma_j(d\eta).
\end{equation*}
for $r>0$. Then $g_{n,j}$ is continuous for each $n\in\mathbb{N}$ and $j=1,2$ and
\begin{equation*}
    \sigma_j(F)=\lim_{n\to\infty}g_{n,j}(1)
\end{equation*}
for $j=1,2$.
\end{lemma}
\begin{subproof}
First, we note that, for each $r\in (0,\infty)$, the above integral makes sense because $\eta\mapsto \phi_n(r^{E_j}\eta)$ is Borel measurable (because it's continuous on $S$) and non-negative. Let $\epsilon>0$ and $r_0\in (0,\infty)$ be arbitrary but fixed. It is clear that the function $(0,\infty)\times S\ni (r,\eta)\mapsto \phi_n(r^{E_j}\eta)$ is continuous on its domain and therefore, in view of the compactness of $S$, we can find a $\delta>0$ for which
\begin{equation*}
|\phi_n(r^{E_j}\eta)-\phi_n(r_0^{E_j}\eta)|\leq\frac{\epsilon}{2\sigma_j(S)}\hspace{1cm}\mbox{whenever}\hspace{1cm}|r-r_0|<\delta
\end{equation*}
for all $\eta\in S$. The triangle inequality guarantees that
\begin{equation*}
|g_{n,j}(r)-g_{n,j}(r_0)|\leq \int_S|\phi_n(r^{E_j}\eta)-\phi_n(r_0^{E_j}\eta)|\,\sigma_j(d \eta)\leq\epsilon/2<\epsilon
\end{equation*}
whenever $|r-r_0|<\delta$. Thus, $g_{n,j}$ is continuous.

We observe that
\begin{equation*}
g_{n,j}(1)=\int_{S}\phi_n(\eta)\,\sigma_j(d\eta)
\end{equation*}
because $1^{E_j}=I$. By construction, we have $\chi_{K_n}(\eta)\leq\phi_{n}(\eta)\leq \chi_{\mathcal{O}_n}(\eta)$ for all $\eta\in S$ and $n\in\mathbb{N}_+$ and therefore
\begin{equation*}
\sigma_j(K_n)\leq g_{n,j}(1)\leq \sigma_j(\mathcal{O}_n)
\end{equation*}
by the monotonicity of the integral. Since
\begin{equation*}
\sigma_j(F)=\lim_{n\to\infty}\sigma_j(K_n)=\lim_{n\to\infty}\sigma_j(\mathcal{O}_n)
\end{equation*}
in view of our choice of $\mathcal{O}_n$ and $K_n$, the remaining result follows immediately from the preceding inequality (and the squeeze theorem).
\end{subproof}

\noindent Let us now complete the proof of Proposition \ref{prop:Endependence}. Given any $0<s<1< t$ and $n\in\mathbb{N}$, consider the function $f=f_{n,s,t}:\mathbb{R}^d\to [0,1]$ given by
\begin{equation*}
f(x)=\phi_n(x)\chi_{[s,t]}(P(x))
\end{equation*}
for $x\in\mathbb{R}^d$. It is clear that $f$ is Lebesgue measurable on $\mathbb{R}^d$ and non-negative. By virtue of Theorem \ref{thm:MainIntegrationFormula} (applied to the two measures $\sigma_1$ and $\sigma_2$), we have
\begin{equation}\label{eq:SameMeasure1}
\int_0^\infty \int_Sf(r^{E_1}\eta)\,\sigma_1(d\eta)r^{\mu_P-1}\,dr=\int_{\mathbb{R}^d}f(x)\,dx=\int_0^\infty \int_Sf(r^{E_2}\eta)\,\sigma_2(d\eta)r^{\mu_P-1}\,dr
\end{equation}
Upon noting that
\begin{equation*}
f(r^{E_j}\eta)=\phi_n(r^{E_j}\eta)\chi_{[s,t]}\left((P(r^{E_j}\eta)\right)=\phi_n(r^{E_j}\eta)\chi_{[s,t]}(rP(\eta))=\chi_{[s,t]}(r)\phi_n(r^{E_j}\eta)
\end{equation*}
for $r\in (0,\infty)$, $\eta\in S$, and $j=1,2$, we have
\begin{equation*}
\int_0^\infty\int_S f(r^{E_j}\eta)\,\sigma_j(d\eta)r^{\mu_P-1}\,dr=\int_{[s,t]}\int_S\phi_n(r^{E_j}\eta)\,\sigma_j(d\eta) r^{\mu_P-1}\,dr=\int_{[s,t]}g_{n,j}(r)r^{\mu_P-1}\,dr
\end{equation*}
for $j=1,2$. By virtue of the Lemma \ref{lem:IndepProof}, $r\mapsto g_{n,j}(r)r^{\mu_P-1}$ is continuous and necessarily bounded on $[s,t]$ and so the final integral above can be interpreted as a Riemann integral. In this interpretation, we have
\begin{equation}\label{eq:SameMeasure2}
\int_s^tg_{n,j}(r)r^{\mu_P-1}\,dr=\int_0^\infty \int_S f(r^{E_j}\eta)\,\sigma_j(d\eta)r^{\mu_P-1}\,dr
\end{equation}
for $j=1,2$ and $0<s<1<t$. In view of \eqref{eq:SameMeasure1} and \eqref{eq:SameMeasure2}, we conclude that
\begin{equation*}
\int_s^t g_{n,1}(r)r^{\mu_P-1}\,dr=\int_s^t g_{n,2}(r)r^{\mu_P-1}\,dr
\end{equation*}
for all $0<s<1<t$. In view of continuity of the integrands, an application of the fundamental theorem of calculus now guarantees that $g_{n,1}(1)=g_{n,2}(1)$ for each $n\in\mathbb{N}$. Therefore
\begin{equation*}
\sigma_1(F)=\lim_{n\to\infty}g_{n,1}(1)=\lim_{n\to\infty}g_{n,2}(1)=\sigma_2(F)
\end{equation*}
by virtue of Lemma \ref{lem:IndepProof}.
\end{proof}

\noindent In view of Proposition \ref{prop:Endependence}, we will denote by $\Sigma_P$ and $\sigma_P$ the unique $\sigma$-algebra and measure on $S$ which, respectively, satisfy
\begin{equation*}
    \Sigma_P=\Sigma_{P,E}\hspace{1cm}\mbox{and}\hspace{1cm}\sigma_P=\sigma_{P,E}
\end{equation*}
for all $E\in\Exp(P)$. We will henceforth assume this notation. 


\begin{framed}
\begin{proposition}\label{prop:SymInvariance}
For any $O\in\Sym(P)$ and $F\in\Sigma_P$,  $OF\in\Sigma_P$ and
\begin{equation*}
\sigma_P(O F)=\sigma_P(F).
\end{equation*} 
That is, the measure $\sigma_P$ is invariant under the action by $\Sym(P)$.
\end{proposition}
\end{framed}


\begin{proof}
Let $O\in\Sym(P)$, $F\in\Sigma_P$ and, for $E\in \Exp(P)$, define $E'=O^* EO$. In view of Proposition \ref{prop:ExpP}, we note that $E'\in \Exp(P)$. Observe that
\begin{equation}\label{eq:TildeConjugation}
    \widetilde{(OF)_E}=\bigcup_{0<r<1}r^E (OF)=\bigcup_{0<r<1}O\left(O^* r^E O F\right)=O\left(\bigcup_{0<r<1} r^{E'}F\right)=O \widetilde{F_{E'}}
\end{equation}
thanks to Proposition \ref{prop:ContinuousGroupProperties}.
In view of Proposition \ref{prop:Endependence}, we have $O\widetilde{F_{E'}}\in \mathcal{M}_d$ because $F\in \Sigma_P=\Sigma_{P,E'}$ and $O$ is linear. Using \eqref{eq:TildeConjugation}, we find that $\widetilde{(OF)_E}\in\mathcal{M}_d$ and therefore  $OF\in\Sigma_{P,E}=\Sigma_P$ by virtue of Proposition \ref{prop:Endependence}. In view of the fact that $O$ is orthogonal,
\begin{equation*}
\sigma_{P,E}(OF)=\mu_P\cdot m\left(\widetilde{(OF)_E}\right)=\mu_P\cdot m\left(O \widetilde{F_{E'}}\right)=\mu_P\cdot m\left(\widetilde{F}_{E'}\right)=\sigma_{P,E'}(F)
\end{equation*}
and therefore, a final appeal to Proposition \ref{prop:Endependence} guarantees that
\begin{equation*}
    \sigma_P(OF)=\sigma_{P,E}(OF)=\sigma_{P,E'}(F)=\sigma_P(F),
\end{equation*}
as desired.
\end{proof}



\noindent This is the final result required to completely prove Theorem \ref{thm:BestIntegrationFormula}:



\begin{proof}[Proof of Theorem \ref{thm:BestIntegrationFormula}]
Together, the results of Propositions \ref{prop:Regular}, \ref{prop:Endependence} and \ref{prop:SymInvariance}, guarantee that $\sigma_P$ is a Radon measure satisfying Properties \ref{property:Completion} and \ref{property:Invariance}. Property \ref{property:DefiningConditionofsigma} follows directly from Proposition \ref{prop:Endependence} and the definition of $\sigma_P$ in terms of $\sigma_{P,E}$ for any $E\in\Exp(P)$. Similarly, Properties \ref{property:BestPointIsomorphism} and \ref{property:BestIntegrationFormula} follow from Theorem \ref{thm:MainIntegrationFormula} by virtue of Proposition \ref{prop:Endependence}. 
\end{proof}








%%% MANIFOLD STUFF %%%%%%

\section{Using a smooth structure on $S$ to compute $\sigma$}\label{sec:smooth_manifold}


\noindent In this section, we consider the special case in which a positive-homogeneous function $P$ on $\mathbb{R}^d$ is smooth\footnote{Many of the results in this section remain valid (with appropriate modification) under the weaker assumption that $P\in C^k(\mathbb{R}^d)$ for $k=1,2,\dots$. In this setting, $S$ is easily seen to be a $C^k$ manifold. Because working in the smooth category is sufficient for our purposes, we shall not pursue the greater level of generality but invite the reader to do so.}\footnote{{To avoid trivialities, we assume that $d>1$ throughout.}}.
Under this additional assumption, we show in Proposition \ref{prop:InnerProdIsOne} that $\grad P$ is everywhere non-vanishing on $S$ and so $S$ is a smooth compact embedded hypersurface in $\mathbb{R}^d$. For a detailed treatment of smooth manifold theory, the author encourages the reader to refer to \cite{lee_introduction_2003}. For an elementary application of theory to be presented here, the reader may refer to Section \ref{sec:estimating_SigmaHat}.\\

\noindent We first set up some notation: For a smooth manifold $M$, we denote by $\mathcal{A}(M)$ its unique maximal atlas. Also on $M$, the collection of smooth vector fields is denoted by $\mathfrak{X}(M)$ and, for each $k=1,2,\dots$, the set of (smooth) differential $k$-forms on $M$ will be denoted by $\Omega^k(M)$.  In this section, we integrate non-smooth differential forms and, for the generality needed here, we shall refer the reader to \cite{naber_topology_2011} for background (Another perspective is given in \cite{amann_analysis_2009}). To this end, let us denote the Lebesgue $\sigma$-algebra of measurable sets on $M$ by $\mathcal{L}(M)$. We note that $F\in\mathcal{L}(M)$ if and only if, \begin{equation*}
    \varphi(F\cap \mathcal{U})\in\mathcal{M}_d
\end{equation*}
for every chart $(\varphi,\mathcal{U})\in\mathcal{A}(M)$. An $n$-form $\omega$ on $M$, with $n=\dim(M)$, is said to be (Lebesgue) measurable, if in each coordinate system $(\varphi,\mathcal{U})$, the local representation
\begin{equation*}
    \omega=h_{\varphi}(x)dx^1\wedge dx^2\wedge \cdots\wedge dx^n
\end{equation*}
in the coordinates $\varphi=(x^1,x^2,\dots,x^n)$ has $h_{\varphi}(x)$ a Lebesgue measurable function on $U=\varphi(\mathcal{U})\subseteq\mathbb{R}^n$. The collection of measurable $n$-forms on $M$ is denoted by $\mathcal{L}(\Lambda^d(M))$ and, naturally, $\Omega^{d}(M)\subseteq \mathcal{L}(\Lambda^d(M))$. As standard, we shall use Einstein's summation convention.\\



\noindent We view $\mathbb{R}^d$ as smooth oriented Riemannian manifold with its standard Euclidean metric $\overline{g}$, oriented smooth atlas $\mathcal{A}_+(\mathbb{R}^d)$, and Riemannian volume form $ d\Vol_{\mathbb{R}^d}$. Given any $E\in\Exp(P)$, consider $\mathcal{E}_E\in \mathfrak{X}(\mathbb{R}^d)$ defined, at each $x\in\mathbb{R}^d$, by
\begin{equation*}
    (\mathcal{E}_E)_x(f)=\frac{d}{dt}f(x+t(Ex))\big\vert_{t=0}\hspace{1cm}
\end{equation*}
for $f\in C^\infty(\mathbb{R}^d)$. In the standard (global) chart with coordinates $x=(x^1,x^2,\dots,x^d)$, $(\mathcal{E}_E)_{x}\in T_{x}(\mathbb{R}^d)$ is given by
\begin{equation*}
    (\mathcal{E}_E)_{x}=(Ex)^{\alpha}\partial_{x^\alpha}=E^\alpha_\beta x^{\beta}\partial_{x^\alpha}
\end{equation*}
where $(E_\alpha^\beta)$ is the standard matrix representation for $E$ and  $\partial_{x^{\alpha}}=\partial/\partial x^\alpha$. By an abuse of notation, we shall write $\grad P$ to denote both the function
\begin{equation*}
\mathbb{R}^d\ni x\mapsto \grad P(x)=\left(\frac{\partial P}{\partial x^1},\frac{\partial P}{\partial x^2},\dots,\frac{\partial P}{\partial x^d}\right)\in\mathbb{R}^d,
\end{equation*}
where $\frac{\partial P}{\partial x^{\alpha}}=\frac{\partial P}{\partial x^{\alpha}}\vert_{x}$ for $\alpha=1,2\dots,d$, and its canonical identification $\grad P\in \mathfrak{X}(\mathbb{R}^d)$ given by \begin{equation*}
    \grad P_x=\overline{g}^{\alpha\beta}\frac{\partial P}{\partial x^{\alpha}}\partial_{x^{\beta}}=\delta^{\alpha\beta}\frac{\partial P}{\partial x^{\alpha}}\partial_{x^{\beta}}=\sum_{\alpha=1}^d\frac{\partial P}{\partial x^{\alpha}}\partial_{x^\alpha}
\end{equation*}
in standard Euclidean coordinates $x=(x^\alpha)$. Of course, for each $x\in\mathbb{R}^d$, the Riemannian norm $|\grad P_x |_{\overline{g}}$ of $\grad P_x \in T_x (\mathbb{R}^d)$ coincides with the Euclidean norm $| \grad P(x) |$ of $ \grad P(x) \in \mathbb{R}^d$. These equivalent quantities (functions) will be henceforth denoted by $|\grad P|$.

\begin{framed}
\begin{proposition}\label{prop:InnerProdIsOne}
For each $\eta\in S$, 
\begin{equation*}
    \overline{g}(\grad P,\mathcal{E})_{\eta}=\grad P(\eta)\cdot (E\eta)=1.
\end{equation*}
In particular, $\grad P \neq 0$ on $S$ and so $S$ is a compact embedded hypersurface in $\mathbb{R}^d$.
\end{proposition}
\end{framed}
\begin{proof}
Given that $E\in\Exp(P)$ and $P\in C^\infty(\mathbb{R}^d)$, we differentiate the identity $rP(x)=P(r^Ex)$ to find that
\begin{equation*}
    P(x)=\frac{d}{dr}P(r^Ex)=\grad P(r^Ex)\cdot\left(\left(r^{E-I}E\right)x\right)
\end{equation*}
for $r>0$ and $x\in\mathbb{R}^d$. In particular, when $r=1$ and $x=\eta\in S$, we have
\begin{equation*}
    1=\grad P(\eta)\cdot \left(E\eta\right)=\frac{\partial P}{\partial x^\alpha}(E\eta)^\alpha=\overline{g}_{\alpha \beta}\left(\grad P_\eta\right)^{\alpha}(\mathcal{E}_\eta)^\beta=\overline{g}(\grad P,\mathcal{E})_\eta.
\end{equation*}
Thus, our (necessarily) compact level set $S$ is a smooth embedded hypersurface of $\mathbb{R}^d$ in view of the regular level set theorem.
\end{proof}
\noindent We shall denote by $\iota:  S \hookrightarrow \mathbb{R}^d$ the canonical inclusion map and set $d'=d-1$. As an embedded submanifold of $\mathbb{R}^d$, $S$ is a Riemannian submanifold of $\mathbb{R}^d$ with metric $g^S$ given by
\begin{equation*}
    g^S(X,Y)=\overline{g}(\iota_*(X),\iota_*(Y))
\end{equation*}
for $X,Y\in\mathfrak{X}(S)$; here, for each $\eta\in S$,  $\iota_*:T_\eta(S)\to T_\eta(\mathbb{R}^d)$ is the pushforward of $\iota$.  In view of the preceding proposition, $N:=\grad P/|\grad P|\in \mathfrak{X}(\mathbb{R}^d)$ is a smooth unit normal vector field along $S$ and it determines an orientation on the Riemannian manifold $S$. Equipped with this orientation, $(S,g^S)$ is an oriented Riemannian manifold and we shall denote by $d\Vol_S$ the Riemannian volume form and by $\mathcal{A}_+(S)$ its corresponding (maximal) oriented atlas. By virtue of Proposition 15.21 of \cite{lee_introduction_2003}, $d\Vol_S=(N\iprod d\Vol_{\mathbb{R}^d})\vert_S$, i.e.,
\begin{eqnarray*}
    d\Vol_S(X_1,X_2,\dots,X_{d'})&=&d\Vol_{\mathbb{R}^d}(N,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'}))\\
    &=&\frac{1}{|\grad P|}d\Vol_{\mathbb{R}^d}(\grad P,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'}))
\end{eqnarray*}
for any collection $\{X_1,X_2,\dots,X_{d'}\}\in \mathfrak{X}(S)$. Beyond $d\Vol_S\in \Omega^{d'}(S)$, we consider the following smooth $d'$-form(s): Given $E\in \Exp(P)$, define $d\sigma_{P,E}\in\Omega^{d'}(S)$ by
\begin{equation*}
    d\sigma_{P,E}(X_1,X_2,\dots,X_{d'})=d\Vol_{\mathbb{R}^d}(\mathcal{E}_E,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'}))
\end{equation*}
for $X_1,X_2,\dots,X_{d'}\in\mathfrak{X}(S)$. We have
\begin{framed}
\begin{proposition}\label{prop:FormRiemannRelation}
For any $E\in\Exp(P)$,
\begin{equation*}
    d\sigma_{P,E}=\frac{1}{|\grad P|}d\Vol_S.
\end{equation*}
In particular, $d\sigma_{P,E}$ is positively oriented and is independent of $E\in\Exp(P)$.
\end{proposition}
\end{framed}
\noindent Before proving the proposition, we first treat a lemma of a purely linear algebraic nature. 

\begin{framed}
\begin{lemma}\label{lem:determinants}
Let $v_1,v_2,\dots,v_{d'}$ be linearly independent vectors in $\mathbb{R}^d$ and suppose that $w\in\mathbb{R}^d \setminus\{0\}$ is such that $w\perp v_i$ for all $i$. Then, for any $z\in\mathbb{R}^d$ for which $z\cdot w=1$,
\begin{equation*}
\det(z, v_1,v_2,\dots,v_{d'})=\frac{1}{|w|}\det(n,v_1,v_2,\dots,v_{d'})=\frac{1}{|w|^2}\det(w,v_1,v_2,\dots,v_{d'}).
\end{equation*}
where $n:=w/|w|$.
\end{lemma}
\end{framed}


\begin{proof}
Given $z\in\mathbb{R}^d$ such that $z\cdot w=1$, it follows that 
\begin{equation*}
z=\frac{1}{|w|}n+a_1v_1+a_2v_2+\cdots a_{d'}v_{d'}.
\end{equation*}
By the multilinearity of the determinant map, we have
\begin{eqnarray*}
\det(z,v_1,v_2,\dots,v_{d'}) &=&\det\lp \frac{1}{|w|}n+a_1v_2+a_2v_2+\cdots a_{d'} v_{d'},v_1,v_2,\dots,v_{d'}\rp\\
    &=&\frac{1}{|w|}\det(n,v_1,v_2,\dots,v_{d'})+\det(a_1v_1+\cdots+a_{d'} v_{d'}, v_1,v_2,\dots,v_{d'})\\
&=&\frac{1}{|w|}\det(n, v_1,v_2,\dots,v_{d'})+0
\end{eqnarray*}
where we have used the fact that the columns of the matrix $(a_1v_1+\cdots+a_{d'} v_{d'}, v_1,v_2,\dots,v_{d'})$ are linearly dependent to conclude that the final determinant is zero.
\end{proof}
\begin{proof}[Proof of Proposition \ref{prop:FormRiemannRelation}]
We fix $E\in\Exp(P)$ and note that the assertion at hand is a local one. Thus, it suffices to verify that, for any $\eta\in S$ and $X_1,X_2,\dots,X_{d'}\in T_\eta(S)$, 
\begin{equation*}
    d\sigma_{P,E}(X_1,X_2,\dots,X_{d'})=\frac{1}{|\grad P_{\eta}|}d\Vol_{\mathbb{R}^d}(N_\eta,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'})).
\end{equation*}
Fix $\eta\in S$ and let $(\mathcal{O},\varphi)$ be a coordinate chart centered at $\eta$ with local coordinates $u=(u^{\alpha})$. As usual, denote by $x=(x^{\alpha})$ the Euclidean coordinates on $\mathbb{R}^d$.  For each $i=1,2,\dots,{d'}$, \begin{equation*}
X_i=X_i^\alpha \partial_{u^{\alpha}}\hspace{1cm}\mbox{and}\hspace{1cm}\iota_*(X_i)=v_i^\beta\partial_{x^{\beta}}
\end{equation*}
where
\begin{equation*}
v_i^\beta =X_i^\alpha\frac{\partial x^\beta}{\partial u^\alpha}.
\end{equation*}
For each $i=1,2,\dots,d'$, we set $v_i=(v_i^1,v_i^2,\dots,v_i^{d'})\in\mathbb{R}^d$. Also, let $w=\grad P(\eta)\in\mathbb{R}^d$ with $|w|=|\grad P(\eta)|=|\grad P_\eta|$, set $n=w/|w|\in\mathbb{R}^d$ and note that
\begin{equation*}
    N_\eta=\frac{1}{|\grad P_\eta|}\sum_{k=1}^d\frac{\partial P}{\partial x^{k}}\partial_{x^k}=n^{\mu}\partial_{x^\mu}.
\end{equation*}Given that $\grad P$ is normal to $S$, we have
\begin{equation*}
    v_i\cdot w=\overline{g}_{\mu,\nu}v_i^\mu w^\nu= \overline{g}(\iota_*(X_i),\grad P)_\eta=0
\end{equation*}
and therefore $w\perp v_i$ for each $i=1,2,\dots,{d'}$. Upon recalling that $(\mathcal{E}_E)_\eta=(E\eta)^\alpha\partial_{x^{\alpha}}$, set $z=((E\eta)^1,(E\eta)^2,\dots,(E\eta)^d)\in\mathbb{R}^d$ and observe that $z\cdot w=1$ by virtue of Proposition \ref{prop:InnerProdIsOne}. An appeal to the lemma guarantees that
\begin{eqnarray*}
d\sigma_{P,E}(X_1,X_2,\dots,X_{d'})&=&d\Vol_{\mathbb{R}^d}(\mathcal{E}_E,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'}))\\
&=&\det(z,v_1,v_2,\dots,v_{d'})\\
&=&\frac{1}{|w|}\det(n,v_1,v_2,\dots,v_{d'})\\
&=&\frac{1}{|\grad P_\eta|}d\Vol_{\mathbb{R}^d}(N_\eta,\iota_*(X_1),\iota_*(X_2),\dots,\iota_*(X_{d'}))\\
&=&\frac{1}{|\grad P|}d\Vol_S(X_1,X_2,\dots,X_{d'}).
\end{eqnarray*}
\end{proof}
\noindent By virtue of the preceding proposition, we shall denote by $d\sigma_P$ the unique smooth $d'$-form on $S$ which satisfies
\begin{equation}\label{eq:sigmaForm}
    d\sigma_P=d\sigma_{P,E}=\frac{1}{|\grad P|}d\Vol_S
\end{equation}
for all $E\in\Exp(P)$. In this notation, we have this section's central result.



\begin{framed}
\begin{theorem}\label{thm:RiemannLebesgue}
Let $P$ be a smooth positive-homogeneous function and let $S=\{\eta\in\mathbb{R}^d:P(\eta)=1\}$. Then $S$ is a compact smooth embedded hypersurface of $\mathbb{R}^d$. Viewing $\mathbb{R}^d$ as an oriented Riemannian manifold with its usual orientation and metric $\overline{g}$, $N=\grad P/|\grad P|$ is a smooth unit normal vector field along $S$. As a submanifold of $\mathbb{R}^d$, $S$ is a oriented Riemannian manifold of dimension $d'=d-1$ with its induced Riemannian metric $g^S$, volume form $d\Vol_S\in\Omega^{d'}(S)$ and orientation determined by $N$. The $\sigma$-algebras $\Sigma_P$ and $\mathcal{L}(S)$ on $S$ coincide and the smooth $d'$-form $d\sigma_P\in\Omega^{d'}(S)$, defined by \eqref{eq:sigmaForm}, coincides with the measure $\sigma_P$ in the sense that
\begin{equation}\label{eq:FormsAndMeasures}
\int_S g(\eta)\,\sigma_P(d\eta)=\int_S g\,d\sigma_P
\end{equation}
for all $g\in L^1(S,\Sigma_P,\sigma_P)$; here, the left hand side represents the Lebesgue integral of $g$ with respect to $\sigma_P$ and the right hand side is the integral of the measurable $d'$-form $g\, d\sigma_P$. Furthermore, the measure $\sigma_P$ and the canonical Riemannian volume measure $\Vol_S$ on $S$ are mutually absolutely continuous.
\end{theorem} 
\end{framed}

\noindent The following two lemmas will take us to the proof of this theorem. The first lemma lets us relate the smooth $d'$-form $d\sigma_{P,E} = d\sigma_P$ to the Jacobian induced by some parameterization $\varphi^{-1}$ via the Riemannian volume form $d\Vol_{\mathbb{R}^d}$ and $d\Vol_S$.

\begin{framed}
\begin{lemma}\label{lem:JacobianRelation}
Let $(\mathcal{U},\varphi)\in \mathcal{A}(S)$ and $E\in\Exp(P)$. Set $U=\varphi(\mathcal{U})\subseteq\mathbb{R}^{d'}$, $V=(0,1)\times U$ and define $\rho_{E,\varphi}:V\to \mathbb{R}^d$ and $h_{E,\varphi}:U\to \mathbb{R}$, respectively, by
\begin{equation*}
    \rho_{E,\varphi}(y)=\psi_E(r,\varphi^{-1})=r^E\varphi^{-1}(u)
\end{equation*}
for $y=(r,u)\in V$ and
\begin{equation*}
    h_{E,\varphi}(u)=\det\left.\left(E\varphi^{-1}(u)\right\vert D_u\varphi^{-1}(u)\right)
\end{equation*}
for $u\in U$; here, the vertical bar separates the first column of the (necessarily) $d\times d$ matrix from the rightmost $d\times d'$ submatrix and $D_u$ denotes the Jacobian in the coordinates $u=(u^1,u^2,\dots,u^{d'})\in U$. Then, $\rho_{E,\varphi}$ is a diffeomorphism onto its image $\rho_{E,\varphi}(V)=\widetilde{\mathcal{U}_E}$ and its Jacobian matrix $D\rho_{E,\varphi}$ has
\begin{equation}\label{eq:JacobianRelation1}
    \det(D\rho_{E,\varphi}(y))=r^{\mu_P-1}h_{E,\varphi}(u)
\end{equation}
for all $y=(r,u)\in V$. Furthermore, $h_{E,\varphi}$ is everywhere non-zero, smooth and
%\begin{equation}\label{eq:JacobianRelation2}
%    h_{E,\varphi}(u)=(d\sigma_P)_{\varphi^{-1}(u)}(\partial_{u^1},\partial_{u^2},\dots,\partial_{u^{d'}})
%\end{equation}
\begin{equation}\label{eq:JacobianRelation2}
    d\sigma_P=h_{E,\varphi}(u)\,du^1\wedge du^2\wedge\cdots\wedge du^{d'}
\end{equation}
in the coordinates $u=(u^1,u^2,\dots,u^{d'})\in U$. 
\end{lemma}
\end{framed}
\begin{proof}
The map $\rho_{E,\varphi}$ is smooth because $\varphi$ is smooth. By virtually the same argument made in the proof of Proposition \ref{prop:PsiHomeomorphism}, which here uses the fact that $P\in C^\infty(\mathbb{R}^d)$, we conclude that $\rho_{E,\varphi}$ is a diffeomorphism onto 
\begin{equation*}\rho_{E,\varphi}(V)=\bigcup_{0<r<1}r^E\mathcal{U}=\widetilde{\mathcal{U}_E}
\end{equation*}
with inverse $\rho_{E,\varphi}^{-1}(x)=(P(x),\varphi((P(x))^{-E}x))$. For $y=(r,u)\in V$, observe that
\begin{eqnarray*}
D\rho_{E,\varphi}(y)&=&\left.\left(\frac{d}{dr}(r^E\varphi^{-1}(u)) \right\vert D_u\left[r^E\varphi^{-1}(u)\right]\right)\\
&=&\left.\left(r^{E-I}E\varphi^{-1}(u)\right\vert r^E D_u\varphi^{-1}(u)\right)\\
&=&r^E\left.\left(\frac{1}{r}E\varphi^{-1}(u)\right\vert D_u\varphi^{-1}(u)\right).
\end{eqnarray*}
Using properties of the determinant, we have
\begin{eqnarray*}
    \det(D\rho_E(y))&=&\det(r^E)\det\left.\left(\frac{1}{r}E\varphi^{-1}(u)\right\vert D_u\varphi^{-1}(u)\right)\\
    &=&r^{\tr E}r^{-1}\det\left.\left(E\varphi^{-1}(u)\right\vert D_u\varphi^{-1}(u)\right)\\
    &=&r^{\mu_P-1}h_{E,\varphi}(u)
\end{eqnarray*}
for all $y=(r,u)\in V$ thus proving \eqref{eq:JacobianRelation1}. It is clear that $h_{E,\varphi}$ is smooth and, by virtue of the fact that $\rho_{E,\varphi}:(0,1)\times U\to \widetilde{\mathcal{U}_E}$ is a diffeomorphism, \eqref{eq:JacobianRelation1} guarantees that $h_{E,\varphi}$ is everywhere non-vanishing. Finally, 
in view of Proposition \ref{prop:FormRiemannRelation} (and \eqref{eq:sigmaForm}), we find that
\begin{eqnarray*}
    h_{E,\varphi}(u)&=&
    \det\left.\left(E\varphi^{-1}(u)\right\vert D_u\varphi^{-1}(u)\right)\\ \nonumber
    &=&
    (d\Vol_{\mathbb{R}^d})_{\varphi^{-1}(u)}(\mathcal{E}_E,\iota_*(\partial_{u^1}),\iota_*(\partial_{u^2}),\dots,\iota_*(\partial_{u^{d'}}))\\ \nonumber
    &=&\left(d\sigma_P\right)_{\varphi^{-1}(u)}(\partial_{u^1},\partial_{u^2},\dots,\partial_{u^{d'}})\\
\end{eqnarray*}
for $u\in U$ and so \eqref{eq:JacobianRelation2} is satisfied. \footnote{For more details on conventional notation in smooth manifold theory, the reader may reference \cite{lee_introduction_2003}.}
\end{proof}


\begin{framed}
\begin{lemma}\label{lem:LocalIntegralFormula}
Let $g\in L^1(S,\Sigma_P,\sigma_P)$ be supported on the domain of some chart on $S$. Then, for any $(\mathcal{U},\varphi)\in\mathcal{A}^+(S)$ such that  $\supp(g)\subseteq\mathcal{U}$, the pushforward $(\varphi^{-1})^*(g)=g\circ\varphi^{-1}$ is Lebesgue measurable on $U=\varphi(\mathcal{U})\subseteq\mathbb{R}^{d'}$ and 
\begin{equation*}
\int_S g(\eta)\sigma_P(d\eta)=\int_{U}(\varphi^{-1})^*(g\, d\sigma_P).
\end{equation*}
\end{lemma}
\end{framed}
\begin{proof}
Let $(\mathcal{U},\varphi)$ be a chart on $S$ for which $\supp(g)\subseteq \mathcal{U}$ and assume the notation of Lemma \ref{lem:JacobianRelation}. Given $E\in\Exp(P)$, observe that
\begin{equation*}
    f(x)=\mu_P\, \chi_{(0,1)}(P(x))g(P(x)^{-E}x),
\end{equation*}
defined for $x\in\mathbb{R}^d\setminus\{0\}$, is supported on $\widetilde{\mathcal{U}_E}=\rho_{E,\varphi}(V)$. An appeal to Corollary \ref{cor:IntegrateOnS} guarantees that $f$ is absolutely integrable on $\rho_{E,\varphi}(V)$ and
\begin{equation}\label{eq:LocalIntegralFormula1}
\int_S g(\eta)\,\sigma_P(d\eta)=\int_{\rho_{E,\varphi}(V)}f(x)\,dx.
\end{equation}
Given that $\rho_{E,\varphi}$ is a diffeomorphism, an appeal to Theorem 15.11 of \cite{apostol_mathematical_1974} guarantees that
\begin{equation}\label{eq:LocalIntegralFormula2}
\int_{\rho_{E,\varphi}(V)}f(x)\,dx=\int_V f(\rho_{E,\varphi}(y))|\det(D\rho_{E,\varphi}(y))|\,dy;
\end{equation}
in particular, $V\ni y\mapsto f(\rho_{E,\varphi}(y))|\det(D\rho_{E,\varphi}(y))$ is Lebesgue measurable on $\mathbb{R}^{d}$. Let us now view the Lebesgue measure $dy$ on $\mathbb{R}^d$ as the completion of the product measure $dr\times du$ on the product space $\mathbb{R}\times\mathbb{R}^{d'}$. By virtue of Lemma \ref{lem:JacobianRelation}, we have
\begin{eqnarray}\label{eq:LocalIntegralFormula3}\nonumber
    f(\rho_{E,\varphi}(y))|\det(D\rho_{E,\varphi}(y))|
    &=& f(r^E\varphi^{-1}(u))\,r^{\mu_{P}-1}|h_{E,\varphi}(u)|\\ \nonumber
    &=& \mu_P\,\chi_{(0,1)}(r)g(\varphi^{-1}(u))\, r^{\mu_P-1}|h_{E,\varphi}(u)|\\ 
    &=& \mu_P\,r^{\mu_P-1}g(\varphi^{-1}(u))|h_{E,\varphi}(u)|
\end{eqnarray}
for $y=(r,u)\in V$. By virtue of Fubini's theorem, $dr$-almost every $r\in (0,1)$, the $r$-section 
\begin{equation*}
    U\ni u\mapsto \mu_P r^{\mu_P-1}g(\varphi^{-1}(u))|h_{E,\varphi}(u)|
\end{equation*}
is Lebesgue measurable and,  upon recalling that $h_{E,\varphi}$ is smooth and everywhere nonzero, we conclude that $(\varphi^{-1})^*(g)=g\circ\varphi^{-1}$ is Lebesgue measurable on $U$. In view of \eqref{eq:LocalIntegralFormula3}, Fubini's theorem also guarantees that
\begin{eqnarray}\label{eq:LocalIntegralFormula4}\nonumber
    \int_V f(\rho_{E,\varphi}(y))|\det(D\rho_{E,\varphi}(y))|\,dy
    &=&\int_{(0,1)}\int_U \mu_P\, r^{\mu_P-1}g(\varphi^{-1}(u))|h_{E,\varphi}(u)|\,du\,dr\\\nonumber
    &=&\int_0^1\mu_P\, r^{\mu_P-1}\left(\int_U g(\varphi^{-1}(u))|h_{E,\varphi}(u)|\,du\right)\,dr\\
    &=&\int_U g(\varphi^{-1}(u))|h_{E,\varphi}(u)|\,du
\end{eqnarray}
By combining \eqref{eq:LocalIntegralFormula1}, \eqref{eq:LocalIntegralFormula2} and \eqref{eq:LocalIntegralFormula4}, we have shown that $(\varphi^{-1})^*g=g\circ\varphi^{-1}$ is Lebesgue measurable on $U=\varphi(\mathcal{U})$ and
\begin{equation*}
    \int_S g(\eta)\sigma_P(d\eta)=\int_U g(\varphi^{-1}(u))|h_{E,\varphi}(u)|\,du.
\end{equation*}
Finally, if $(\mathcal{U},\varphi)\in\mathcal{A}_+(S)$, an appeal to Proposition \ref{prop:FormRiemannRelation} and \eqref{eq:JacobianRelation2} of Lemma \ref{lem:JacobianRelation} guarantees that
\begin{equation*}
    |h_{E,\varphi}(u)|=h_{E,\varphi}(u)=(d\sigma_P)_{\varphi^{-1}(u)}(\partial_{u^1},\partial_{u^2},\dots,\partial_{u^{d'}})>0
\end{equation*}
for all $u=(u^1,u^2,\dots,u^{d'})\in U$ and thus
\begin{eqnarray*}
        \int_S g(\eta)\sigma_P(d\eta)&=&\int_U g(\varphi^{-1}(u))h_{E,\varphi}(u)\,du\\
        &=&\int_U g(\varphi^{-1}(u))\,h_{E,\varphi}(u)\,du^1\wedge du^2\wedge\cdots \wedge du^{d'}\\
        &=&\int_U (\varphi^{-1})^*(g\cdot d\sigma_P),
\end{eqnarray*}
as desired. 
\end{proof}



\begin{remark}\label{rmk:LocalIntegralFormula}
In studying the proof of Lemma \ref{lem:LocalIntegralFormula}, we deduce a slightly more general statement: Given any chart $(\mathcal{U},\varphi)\in\mathcal{A}(S)$ and $g\in L^1(S,\Sigma_P,\sigma_P)$ for which $\supp(g)\in\mathcal{U}$, $(\varphi^{-1})^*g$ is Lebesgue measurable on $U=\varphi(\mathcal{U})$ and 
\begin{equation*}
    \int_S g(\eta)\sigma_P(d\eta)=\begin{cases}
    \displaystyle\int_U(\varphi^{-1})^*(g\,d\sigma_P) &\mbox{ if }(\mathcal{U},\varphi)\in\mathcal{A}_+(S)\\
    &\\
    -\displaystyle\int_U(\varphi^{-1})^*(g\,d\sigma_P)&\mbox{ if }(\mathcal{U},\varphi)\in\mathcal{A}_-(S)\coloneqq\mathcal{A}(S)\setminus\mathcal{A}_+(S).
    \end{cases}
\end{equation*}
\end{remark}
\begin{proof}[Proof of Theorem \ref{thm:RiemannLebesgue}]
In view of Proposition \ref{prop:InnerProdIsOne} and the discussion following its proof, it remains to prove the assertions in the last two sentences in the statement of the theorem. Given any $F\in \Sigma_P$ and chart $(\mathcal{U},\varphi)\subseteq \mathcal{A}(S)$, we have $\chi_{\varphi(F\cap \mathcal{U})}=(\varphi^{-1})^*\left(\chi_{F\cap\mathcal{U}}\right)$ is Lebesgue measurable on $U=\varphi(\mathcal{U})$ and so it follows (Exercise 4.6.2 of \cite{naber_topology_2011}) that $F\in\mathcal{L}(S)$. Consequently, $\mathcal{B}(S)\subseteq\Sigma_P\subseteq\mathcal{L}(S)$.

Let $g\in L^1(S,\Sigma_P,\sigma_P)$, which is necessarily Lebesgue measurable on $S$ in view of the results of the previous paragraph. Now, let  $\{(\mathcal{U}_j,\varphi_j)\}\subseteq\mathcal{A}_+(S)$ be a countable atlas on $S$ and let $\{\kappa_j\}$ be a smooth partition of unity subordinate to the cover $\{\mathcal{U}_j\}$. For each $j\in\mathbb{N}$, observe that $\kappa_j g\in L^1(S,\Sigma_P,\sigma_P)$ and has $\supp(\kappa_j g)\subseteq \mathcal{U}_j$. By virtue of Lemma \ref{lem:LocalIntegralFormula}, we have $(\varphi_j^{-1})^*(\kappa_j g\,d\sigma_P)$ is integrable on $U_j=\varphi(\mathcal{U}_j)$ and
\begin{equation}\label{eq:LebesgueRiemann1}
\int_S \kappa_j(\eta)g(\eta)\sigma_P(d\eta)=\int_{U_j}(\varphi_j^{-1})^*(\kappa_j g\,d\sigma_P)
\end{equation}
for each $j\in\mathbb{N}$. With the help of Proposition \ref{prop:FormRiemannRelation}, it is easy to see that $g\,d\sigma_P$ and $\kappa_j g\,d\sigma_P$ (for $j\in\mathbb{N}$) are Lebesgue measurable $d'$-forms on $S$. In view of (4.4.6) of \cite{naber_topology_2011}, \eqref{eq:LebesgueRiemann1} ensures that, for each $j\in\mathbb{N}$, $\kappa_j g\,d\sigma_P$ is integrable (in the sense of forms) on $S$ and
\begin{equation*}
\int_S \kappa_j(\eta)g(\eta)\sigma_P(d\eta)=\int_S \kappa_j g\,d\sigma_P.
\end{equation*}
By the monotone convergence theorem, it follows that
\begin{equation*}
\sum_{j=1}^\infty\left| \int_S \kappa_j g\,d\sigma_P\right|=\sum_{j=1}^\infty \left|\int_S \kappa_j(\eta)g(\eta)\sigma(d\eta)\right|\leq \sum_{j=1}^\infty\int_S \kappa_j(\eta)|g(\eta)|\sigma_P(d\eta)=\|g\|_{L^1(S,\Sigma_P,\sigma_P)}<\infty.
\end{equation*}
Therefore, in view of the construction on p. 242 of \cite{naber_topology_2011}, we conclude that the $d'$-form $g\,d\sigma_P$ is integrable and
\begin{equation*}
\int_S g(\eta)\sigma_P(d\eta)=\sum_{j=1}^\infty \int_S \kappa_j(\eta)g(\eta)\sigma_P(d\eta)=\sum_{j=1}^\infty \int_{S} \kappa_j g\,d\sigma_P=\int_S g\,d\sigma_P
\end{equation*}
by virtue of the dominated convergence theorem; this is \eqref{eq:FormsAndMeasures}.

Finally, given that $\abs{\grad P}$ is continuous and non-vanishing on the compact set $S$,
\begin{equation*}
    C_1 := \inf_S\frac{1}{|\grad P|}\quad\mbox{and}\quad C_2 := \sup_{S}\frac{1}{\abs{\grad P }}
\end{equation*}
are both positive real numbers. For each $F\in \Sigma_P\subseteq\mathcal{L}(S)$, \eqref{eq:FormsAndMeasures} guarantees that
\begin{equation*}
    \sigma_P(F)=\int_S\chi_F(\eta)\sigma_P(d\eta)=\int_S \chi_F\,d\sigma_P
\end{equation*}
By virtue of Proposition \ref{prop:FormRiemannRelation}, it follows that
\begin{equation*}
C_1\Vol_S(F)=C_1\int_S \chi_F\,d\Vol_S\leq \int_S \frac{\chi_F}{|\grad P|}d\Vol_S=\int_S \chi_F\,d\sigma_P=\sigma_P(F)
\end{equation*}
and
\begin{equation*}
    \sigma_P(F)=\int_S\chi_F d\sigma_P=\int_S\frac{\chi_F}{|\grad P|}\,d\Vol_S\leq C_2\int_S\chi_F\,d\Vol_S=C_2\Vol_S(F)
\end{equation*}
where we have used the definition of the Riemannian volume measure on $S$, c.f., \cite{amann_analysis_2009}. In short, there are positive constants $C_1$ and $C_2$ for which
\begin{equation}\label{eq:FormsAndMeasures2}
    C_1\Vol_S(F)\leq\sigma_P(F)\leq C_2\Vol_S(F)
\end{equation}
for all $F\in\Sigma_P$. In particular, \eqref{eq:FormsAndMeasures} holds for all $F\in\mathcal{B}(S)$ and so it follows that the completions of the $\sigma$-algebra $\mathcal{B}(S)$ with respect to $\sigma_P$ and $\Vol_S$ coincide. We know, however, that $\Vol_S$, which is defined on $\mathcal{L}(S)$, is a Radon measure (Proposition 1.5 \cite[Chapter XII]{amann_analysis_2009}) and, by virtue of Proposition \ref{prop:Regular}, it follows that $\Sigma_P=\mathcal{L}(S)$ and \eqref{eq:FormsAndMeasures2} holds for all $F$ in this common $\sigma$-algebra. Thus $\sigma_P$ and $\Vol_S$ are mutually absolutely continuous and the theorem is proved.
\end{proof}

\noindent We immediately obtain the following corollary which allows us to compute the Lebesgue integral with respect to $\sigma_P$ in coordinates.

\begin{framed}
\begin{corollary}\label{cor:IntegralFormula}
Let $g\in L^1(S,\mathcal{L}(S),\sigma_P)$. Then, given any  countable (or finite) atlas $\{(\mathcal{U}_j,\varphi_j)\}\subseteq\mathcal{A}_+(S)$,  smooth partition of unity $\{\kappa_j\}$ subordinate to $\{\mathcal{U}_j\}$, and $E\in\Exp(P)$,
\begin{equation*}
\int_S g(\eta)\sigma_P(d\eta)=\sum_{j}\int_S \kappa_jg\,d\sigma_P=\sum_j\int_{U_j}\kappa_j(\varphi^{-1}(u))g(\varphi^{-1}(u))h_{E,\varphi_j}(u)\,du
\end{equation*}
where, for each $j$, $U_j=\varphi_j(\mathcal{U}_j)\subseteq\mathbb{R}^{d'}$ and
\begin{equation*}
    h_{E,\varphi_j}(u)=\det(E\varphi^{-1}(u)\vert D_u\varphi^{-1})
\end{equation*}
for $u=(u^1,u^2,\dots,u^{d'})\in U_j$. 
\end{corollary}
\end{framed}















%%%%%%%%%%%%%%%% Van der Corput  %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Van der Corput Lemmas and Estimating Oscillatory Integrals}\label{chap:VanDerCorput}
\chaptermark{VdC Lemmas \& Oscillatory Integrals}


In this chapter, we are interested in some technical results related to estimating one-dimensional oscillatory integrals of the form 
\begin{equation}\label{eq:Osc_Int}
    \int^b_a e^{i \Phi(x)}\psi(x)\,dx,
\end{equation}
where $\Phi, \psi$ are functions which satisfy certain hypotheses. In particular, $\Phi$ is a real-valued function. Here, $\Phi(x)$ is often referred to as the {\textbf{phase}} function, while $\psi(x)$ the \textbf{amplitude}. Integrals of this form often appear in Fourier analysis and are treated extensively in this context (see Chapter 8 of \cite{SteinFunctionalAnalysis}, for example). In Section \ref{sec:Estimate_OscInt}, we present a number of propositions and lemmas and prove a version of the Van der Corput lemma (Lemma \ref{lem:VdC}), which is a key ingredient for obtaining our sup-norm estimate of convolution powers. The main approach we take to prove our preliminary results is fairly standard; however, we also take a more general approach by considering sub-level set estimates inspired by \cite{phd_thesis}, which then gives the Van der Corput lemma as a special case. In Section \ref{sec:estimating_SigmaHat}, we apply our result to obtain decay estimates for the Fourier transform of the surface measure $\sigma_P$ associated with a positive homogeneous polynomial $P$ along the coordinate axes. These estimates are a partial improvement of the results in \cite{greenblatt_fourier_2021}.















%\section{Van der Corput Lemmas}\label{sec:VanDerCorput}

\section{Estimating Oscillatory Integrals \& the Van der Corput lemma}\label{sec:Estimate_OscInt}


\noindent The following result helps us isolate the influences of the amplitude $\psi$ and the phase $\Phi$ on the decay of \eqref{eq:Osc_Int}; its proof makes use of integration by parts.


\begin{framed}
\begin{lemma}\label{lem:setup_VdC}
Let $h\in L^1([a,b])$ and $g\in C^1([a,b])$ be complex-valued. Then for any $M$ such that
\begin{equation*}
    \abs{\int^x_a h(u)\,du} \leq M
\end{equation*}
for all $x\in [a,b]$ we have
\begin{equation*}
    \abs{\int^b_a g(u)h(u)\,du} \leq M \lp \norm{g'}_1 + \norm{g}_\infty \rp.
\end{equation*}
\end{lemma}
\end{framed}
\begin{proof}
Since $h\in L^1([a,b])$, the function 
\begin{equation*}
    f(x) = \int^x_a h(u)\,du
\end{equation*}
is absolutely continuous and $f'(x) = h(x)$ almost everywhere. Further, because $\abs{f(x)} \leq M$ for all $x\in [a,b]$, we have, by integration by parts,
\begin{equation*}
    \int^b_a g(u)h(u)\,du = g(u)f(u)\big\vert^b_a - \int^b_a g'(u)f(u)\,du.
\end{equation*}
It follows that
\begin{eqnarray*}
    \abs{\int^b_a g(u)h(u)\,du} 
    \leq \abs{f(b)g(b)} + 0 + \int^b_a \abs{f(u)} \abs{g'(u)}\,du \leq M\lp \norm{g}_\infty + \norm{g'}_1 \rp. 
\end{eqnarray*}
\end{proof}


\begin{remark}
The assumption that $g$ is once continuously differentiable can be weakened slightly to ask that $g$ belongs to the Sobolev space $W^{1\,1}([a,b])$. For the essential details, we refer the reader to \cite{leoni2017first} and specifically Theorem 7.16.
\end{remark}








\begin{framed}
\begin{proposition}\label{prop:NoCriticalPoint}
Let $\Phi\in C^2([a,b])$ be a real-valued function for which $\Phi'$ is monotonic and $\abs{\Phi'(x)} \geq \delta > 0$ for all $x\in [a,b]$, then 
\begin{equation*}
    \left|\int_a^b e^{i\Phi(x)}\,dx\right|\leq \frac{4}{\delta}.
\end{equation*}
\end{proposition}
\end{framed}
\begin{proof}
Observe that
\begin{eqnarray*}
    \int_{a}^b e^{i \Phi(x)}\,dx  
    &=& \int_{a}^b   \f{1}{i \Phi'(x)}\lp \f{d}{dx}e^{i \Phi}\rp   \,dx \\
    &=& \f{1}{i \Phi'(x)}e^{i \Phi(x)}\bigg\vert_{a}^b 
    - \int_{a}^b  e^{i \Phi(x)} \f{d}{dx}\lp \f{1}{i \Phi'(x)} \rp \,dx 
\end{eqnarray*}
where we have integrated by parts and used the fact that $\Phi'$ never vanishes. Consequently,
\begin{equation*}
    \left|\int_a^b e^{i\Phi(x)}\,dx\right|\leq \left|\frac{1}{\Phi'(b)}-\frac{1}{\Phi'(a)}\right|+\int_a^b\left|\frac{d}{dx}\left(\frac{1}{\Phi'(x)}\right)\right|\,dx.
\end{equation*}
Since $\Phi'$ is monotonic, the absolute value in the second term of the right hand side can be brought outside of the integral. Subsequently, we apply fundamental theorem of calculus to this term to obtain the first assertion by taking
\begin{equation*}
 C=\left|\frac{1}{\Phi'(b)}-\frac{1}{\Phi'(a)}\right|+\int_a^b\left|\frac{d}{dx}\left(\frac{1}{\Phi'(x)}\right)\right|\,dx=2\left|\frac{1}{\Phi'(b)}-\frac{1}{\Phi'(a)}\right|\leq\frac{4}{\delta}.
\end{equation*}
\end{proof}











\noindent We note that the function $\Phi$ in the preceding proposition has no critical points on $[a,b]$. In what follows, we will extend the result of Proposition \ref{prop:NoCriticalPoint} by obtaining an estimate for 
\begin{equation*}
    \abs{\int^b_a e^{i \Phi(x)}\,dx}
\end{equation*}
where $\Phi$ is a real-valued function on $[a,b]$ such that for some $k\geq 2$ and $\delta > 0$ we have $\Phi \in C^k([a,b])$ and $\abs{\Phi^{(k)}(x)} \geq \delta$ for all $x\in [a,b]$. To this end, we require the help from the forthcoming results (Proposition \ref{prop:SublevelSetEstimate} and Lemma \ref{lem:CriticalPoints}) to count and bound the (Lebesgue) measures of sub-level sets of $\Phi$, which have the form
\begin{equation*}
    E_\al = \{ t\in [a,b] : \abs{\Phi(t)} \leq \al\}
\end{equation*}
for each $\al > 0$. Proposition \ref{prop:SublevelSetEstimate} is inspired by Proposition 1.2 of \cite{phd_thesis}. The proof of Proposition \ref{prop:SublevelSetEstimate} is fairly involved and makes use of the Lagrange interpolation polynomials, while the proof of Lemma \ref{lem:CriticalPoints} is a straightforward induction argument on the number of critical points of $f$. 

\begin{framed}
\begin{proposition}\label{prop:SublevelSetEstimate} 
For an integer $k\geq 1$, suppose that $\Phi\in C^k([a,b])$ is real-valued and, for some $\delta>0$, $\abs{\Phi^{(k)}(t)} \geq \delta$ for all $t \in [a,b]$. Then, for each $\alpha>0$, the sub-level set $E_\al := \{ t \in[a,b] : \abs{\Phi(t)} \leq \al \}$ has
\begin{equation*}
    m(E_\al) \leq 2 k \lp \f{\al}{\delta} \rp^{1/k},
\end{equation*}
where $m$ denotes the Lebesgue measure on $\mathbb{R}$.
\end{proposition}
\end{framed}




\begin{proof}
Since $\Phi$ is continuous, there is an integer $N$ for which $E_\al = \cup^N_{i=1}E_i$ where $E_i$ for $i=1,2,\dots,N$ are disjoint compact intervals for which
\begin{equation*}
    \max{E_1} \leq \min{E_2} \leq \max{E_2} \leq \dots \leq \max{E_{N-1}}  \leq \min{E_N}.
\end{equation*}
Slide each $E_i$ along $\R$ such that $\max{E_i} = \min{E_{i+1}}$ for $i=1,2,\dots k-1$ to create a single closed interval $I$ with $m(I) = m(E_\al)$. Pick $k+1$ equally spaced points $x'_0,x_1',\dots,x_k'$ in $I$ and move the intervals $E_i$ back to their original positions. The selected points are now $x_0,x_1,\dots,x_k$ and satisfy
\begin{equation}\label{eq:Spacing}
    \abs{x_j - x_l} \geq m(E_\al)\f{\abs{j-l}}{k}, \mbox{ for } j,l = 0,1,\dots,k 
\end{equation}
Let us now consider the Lagrange interpolation polynomial
\begin{equation*}
    h(x)=\sum_{j=0}^k\Phi(x_j)p_j(x)
\end{equation*}
where
\begin{equation*}
    p_j(x)=\prod_{\substack{l=0\\l\neq j}}^k\frac{(x-x_j)}{(x_l-x_j)}
\end{equation*}
for $j=0,1,\dots,k$. As designed, each $p_j$ is a $k$th-order polynomial and $h$ interpolates $\Phi$ at the points $x_0,x_1,\dots,x_k$. In particular, $F(x):=h(x)-\Phi(x)$ vanishes at $x_0,x_1,\dots,x_k$ and is necessarily $k$-times continuously differentiable on $[a,b]$. It follows that there are $k$ points $y_1<y_2<\dots < y_k$ such that $x_0 < y_1 < x_1 < y_2 < x_2 < \dots < y_k < x_k$ and
\begin{equation*}
    F'(y_1) = F'(y_2) = \dots = F'(y_k) = 0.
\end{equation*}
Upon repeating this argument an additional $k-1$ times, we find that $F^{(k)}(\xi) = 0$ at some $\xi\in (a,b)$ and here,
\begin{equation*}
    \Phi^{(k)}(\xi) = h^{(k)}(\xi) = \sum_{j=0}^k \Phi(x_j)p_j^{(k)}(\xi).
\end{equation*}
By virtue of \eqref{eq:Spacing}, for each $j=0,1,2,\dots k$,
\begin{equation*}
|p_j^{(k)}(\xi)|
=
k!\prod_{\substack{l=0\\ l\neq j}}^k\frac{1}{|x_l-x_j|}\leq k!\left(\frac{k^k}{m(E_\alpha)^k}\prod_{\substack{l=0\\l\neq j}}^k\frac{1}{|j-l|}\right)=\frac{ k^k}{m(E_\alpha)^k}\frac{k!}{j!(k-j)!}=\frac{k^k}{m(E_\alpha)^k} {k\choose j}.
\end{equation*}
Because $\delta\leq \abs{\Phi^{(k)}(\xi)}$ and $|\Phi(x_j)|\leq \alpha$ for each $j=0,1,2,\dots,k$, it follows that
\begin{equation*}
\delta\leq \left|\sum_{j=0}^k \Phi(x_j)p_j^{(k)}(\xi)\right|\leq \sum_{j=0}^k\alpha|p_j^{(k)}(\xi)|\leq \frac{\alpha k^k}{m(E_\alpha)^k}\sum_{j=0}^k{k\choose j}=\frac{\alpha (2k)^k}{m(E_\alpha)^k}
\end{equation*}
where we have made use of the binomial theorem. Consequently,
\begin{equation*}
    m(E_\alpha)\leq 2k\left(\frac{\alpha}{\delta}\right)^{1/k}.
\end{equation*}
\end{proof}

\begin{framed}
\begin{lemma}\label{lem:CriticalPoints} Given an integer $k \geq 1$, suppose that $f \in C^k([a,b])$ is a real-valued function for which $\abs{f^{(k)}(t)} > 0$ for all $t\in [a,b]$. Then $[a,b]$ has a minimal cover of compact subintervals $I_1,I_2,\dots,I_l$ with $l\leq k$ and for which the restriction of $f$ to each subinterval is strictly monotonic.
\end{lemma}
\end{framed}

\begin{proof}
We will prove this lemma by induction on $k$. When $k=1$, the hypothesis ensures that $f$ is strictly monotonic on $[a,b]$, as asserted. We now suppose that, for $k\geq 1$, $f\in C^{(k+1)}([a,b])$ and $f^{(k)}(t)>0$ for all $t\in [a,b]$; the case in which $f^{(k)}(t)<0$ is similar. Our inductive hypothesis guarantees a minimal cover $I_1,I_2,\dots,I_l$ of $[a,b]$ where $l\leq k$ and each $I_j$ is a compact interval on which $f'$ is strictly monotonic. Given that a strictly monotonic function can intersect $0$ at most once on its domain, $f$ must have, at most, $l$ critical points in the interval $(a,b)$, one for each interval $I_1,I_2,\dots,I_l$. If there are no critical points, then $f$ is necessarily strictly monotonic on $[a,b]$ and the desired result holds. Otherwise, denote by $x_1,x_2,\dots,x_m$ the critical points of $f$ where, necessarily, $m\leq l\leq k$, and we have arranged these points so that $a<x_1<x_2<\cdots<x_m<b$. In this case, $f$ is strictly monotonic on the $m+1$ compact intervals $[a,x_1],[x_1,x_2],\dots,[x_{m-1},x_m],[x_m,b]$. Of course, $m+1\leq l+1\leq k+1$ and so the assertion holds for $k+1$.
\end{proof}

\noindent Now we are ready to prove the following extension of Proposition \ref{prop:NoCriticalPoint} to deal with cases where $\Phi(x)$ has critical points. From here, Lemma \ref{lem:setup_VdC} gives us an estimate for more general oscillatory integrals where $\Phi(x)$ is not necessarily the constantly 1 functions. A special case of this (where $k=2$) is a version of the Van der Corput lemma which we will state as Lemma \ref{lem:VdC} and prove.


\begin{framed}
\begin{proposition}\label{prop:NoPsi}
Let $\Phi$ be a real-valued function on $[a,b]$ and suppose that, for some $k\geq 2$, $\Phi\in C^k([a,b])$ and $\abs{\Phi^{(k)}(x)} \geq \delta$ for all $x\in [a,b]$ where $\delta>0$. Then
\begin{equation*}
    \abs{\int_a^b e^{i \Phi(x)} \,dx} \leq \f{2k\cdot (2(k-1))^{\f{1}{k}}}{\delta^{\f{1}{k}}}.
\end{equation*}
\end{proposition}
\end{framed}

\begin{proof}
Define, for $\alpha>0$,
\begin{equation*}
    I(\alpha)=\int_{\{x\in[a,b]:|\Phi'(x)|\geq \alpha\}}e^{i\Phi(x)}\,dx
\end{equation*}
and observe that
\begin{eqnarray*}
    \abs{\int_a^b e^{i \Phi(x)} \,dx}
    &\leq&  \abs{\int_{\{x\in[a,b]:|\Phi'(x)|\geq \alpha\}}e^{i\Phi(x)}\,dx}
    + 
    \abs{\int_{\{ x\in [a,b]: \abs{\Phi'(x)} < \al \}}e^{i \Phi(x)} \,dx } \\
    &\leq& \abs{I(\alpha)}  + m(E_\al)\\
    &\leq& \abs{I(\alpha)} + 2(k-1)\lp\f{\al}{\delta}\rp^{\f{1}{k-1}}
\end{eqnarray*}
for all $\alpha>0$ by virtue of Proposition \ref{prop:SublevelSetEstimate}. 

Let's estimate $I(\al)$. In view of Lemma \ref{lem:CriticalPoints}, there is a minimal cover of $[a,b]$ containing at most $(k-1)$ compact intervals on which $\Phi'$ is strictly monotonic. For any $\alpha>0$, by removing the set $E_\alpha$ from $[a,b]$, we obtain at most $2(k-1)$ compact intervals $I_1,I_2,\dots,I_l$ covering $\{ x\in [a,b] : \abs{\Phi'} \geq\alpha \}=[a,b]\setminus E_\alpha$ and on each of which $\Phi'$ is strictly monotonic. Applying Proposition \ref{prop:NoCriticalPoint} to each such interval and using the triangle inequality we find 
\begin{equation*}
    \abs{I(\alpha)} \leq l\f{2}{\alpha} \leq 2(k-1)\frac{2}{\alpha}= \f{4(k-1)}{\alpha}
\end{equation*}
which holds for all $\alpha>0$. Consequently,
\begin{equation*}
    \abs{\int_a^be^{i\Phi(x)}\,dx}\leq \frac{4(k-1)}{ \alpha}+2(k-1)\left(\frac{\alpha}{\delta}\right)^{1/(k-1)}=2(k-1)\left(\frac{2}{\alpha}+\left(\frac{\alpha}{\delta}\right)^{1/(k-1)}\right)
\end{equation*}
for all $\alpha>0$ and therefore
\begin{equation*}
    \abs{\int_a^b e^{i\Phi(x)}\,dx}\leq 2(k-1)\inf_{\alpha>0}\left(\frac{2}{\alpha}+\left(\frac{\alpha}{\delta}\right)^{1/(k-1)}\right).
\end{equation*}
It is easily shown that this infimum is attained at
\begin{equation*}
    \al_0 = \delta^{\f{1}{k}} [2(k-1)]^{\f{k-1}{k}}
\end{equation*}
and so it follows that,
\begin{equation*}
    \abs{\int_a^b e^{i \Phi(x)} \,dx} \leq 2(k-1)\left( \f{2}{ \alpha_0} +\left(  \f{\al_0}{\delta}\right)^{\f{1}{k-1}}   \right)=\f{2k\cdot (2(k-1))^{\f{1}{k}}}{(\delta)^{\f{1}{k}}},
\end{equation*}
as desired. It follows that for any choice of $\al > 0$,
\begin{equation*}
    \abs{\int_a^b e^{i \Phi(x)} \,dx}  \leq \f{4(k-1)}{\alpha} + 2(k-1)\lp\f{\al}{\delta}\rp^{\f{1}{k-1}} = 2(k-1)\lb \f{2}{ \alpha} +\lp  \f{\al}{\delta}\rp^{\f{1}{k-1}}   \rb =: f(\alpha),
\end{equation*}
Now, 
\begin{equation*}
    f'(\alpha) = \frac{2 }{\alpha ^2  }\left[
     \alpha^{\f{k}{k-1}} \delta^{\f{-1}{k-1}}
    -2(k-1)\right] =  0 \iff \al = \delta^{\f{1}{k}} \lb 2(k-1) \rb^{\f{k-1}{k}} .
\end{equation*}
With this choice of $\al$, we have that $f(\al)$ attains a minimum:
\begin{eqnarray*}
    f''(\al) 
    &=&  \frac{2 (k-1)
   }{\alpha ^3} \left[4-\frac{ k-2}{(
   k-1)^2} \alpha^{\f{k}{k-1}} \delta^{\frac{-1}{k-1}} \right]\\
   &=& \frac{2 (k-1)
   }{\alpha ^3} \left[4-\frac{ k-2}{(
   k-1)^2}  2(k-1) \delta^{\f{1}{k-1}} \delta^{\frac{-1}{k-1}} \right]\\
   &=& \frac{4 (k-1)
   }{\alpha ^3} \left(2-\frac{ k-2}{
   k-1}  \right)\\
   &\geq& 0
\end{eqnarray*}
and that
\begin{eqnarray*}
    \abs{\int_a^b e^{i \Phi(x)} \,dx}  
    &\leq& 2(k-1)\lb \f{2}{ \alpha} +\lp  \f{\al}{\delta}\rp^{\f{1}{k-1}}   \rb\\
    &=&  2(k-1)\lb 2\delta^{\f{-1}{k}}\lb 2(k-1) \rb^{\f{1-k}{k}} +  \lc \delta^{\f{1}{k}-1} \lb 2(k-1) \rb^{\f{k-1}{k}} \rc^{\f{1}{k-1}}\rb \\
    &=& 2\lb \f{2(k-1)}{\delta} \rb^{\f{1}{k}} + 2(k-1)\lb \f{2(k-1)}{\delta}\rb^{\f{1}{k}} \\
    &=& \f{2k\cdot [2(k-1)]^{\f{1}{k}}}{\delta^{\f{1}{k}}}
\end{eqnarray*}
as desired. 
\end{proof}

\noindent Finally, the following lemma is a version of the Van der Corput lemma which we will use to obtain sup-norm estimates for convolution powers in the next chapter.

\begin{framed}
\begin{lemma}\label{lem:VdC}
Let $g\in C^1([a,b])$ be complex-valued and let $\Phi\in C^2([a,b])$ be real-valued such that $\Phi''(x) \neq 0$ for all $x\in [a,b]$. Then
\begin{equation*}
    \abs{\int^b_a g(u) e^{i\Phi(u)}\,du} \leq \min \lc \f{4}{\delta}, \f{8}{\sqrt{\rho}}  \rc \lp \norm{g'}_1 + \norm{g}_\infty \rp,
\end{equation*}
where $\delta = \inf_{x\in [a,b]} \abs{\Phi'(x)}$ and $\rho = \inf_{x\in [a,b]} \abs{\Phi''(x)}$. 
\end{lemma}
\end{framed}
\begin{proof}
Since $\Phi''$ never changes sign on $[a,b]$, $\Phi'$ must be monotonic on $[a,b]$. As a result, we can combine Proposition \ref{prop:NoCriticalPoint} and Proposition \ref{prop:NoPsi} (with $k=2$) to find
\begin{equation*}
    \abs{\int^x_a e^{i\Phi(u)}\,du} \leq \min \lc \f{4}{\delta}, \f{8}{\sqrt{\rho}} \rc
\end{equation*}
for any $x\in [a,b]$. Setting $h(u) = e^{i\Phi(u)}$ we note that the functions $g$ and $h$ are those in Lemma \ref{lem:setup_VdC}, from which the desired result follows immediately. 
\end{proof}





% \begin{framed}
% \begin{corollary}\label{cor:psi}
% Let $\Phi$ be a real-valued function on $[a,b]$ and suppose that, for some $k\geq 2$, $\Phi\in C^k([a,b])$ and $\abs{\Phi^{(k)}(x)} \geq \delta$ for all $x\in [a,b]$ where $\delta>0$. Also, let $\psi\in C^1([a,b])$ and set
% \begin{equation*}
% C(k,\psi)=2k\cdot(2(k-1))^{1/k}\left(|\psi(b)|+\int_a^b|\psi'(x)|\,dx\right).
% \end{equation*}
% Then
% \begin{equation*}
%     \abs{\int_a^b e^{i \Phi(x)} \psi(x) \,dx} \leq \frac{C(k,\psi)}{\delta^{1/k}}.
% \end{equation*}
% \end{corollary}
% \end{framed}
% \begin{proof}
% We prove this corollary by integration by parts. Define
% \begin{equation*}
%     F(x) = \int_a^x e^{i \Phi(x)}\,dx.
% \end{equation*}
% for $a\leq x\leq b$. An appeal to Proposition \ref{prop:NoPsi} (on the intervals $[a,x]$), we obtain the estimate
% \begin{equation*}
%     \abs{F(x)} \leq \f{C_k}{\delta^{\f{1}{k}}}
% \end{equation*}
% for all $x\in [a,b]$ where $C_k=2k\cdot(2(k-1))^{1/k}$. It follows that 
% \begin{eqnarray*}
%      \abs{\int_a^b e^{i \Phi(x)} \psi(x) \,dx} 
%      &=& \abs{\int_a^b F'(x)\psi(x)\,dx}  \\
%      &=& \abs{ F(x)\psi(x)\bigg\vert_{a}^b - \int_a^b F(x)\psi'(x)\,dx   } \\
%      &\leq& \abs{F(b)}\abs{ \psi(b)} + \int_a^b \abs{\psi'(x)}\abs{ F(x)}\, dx  \\
%      &\leq& \f{C_k}{\delta^{1/k}}\abs{\psi(b)} + \f{C_k}{\delta^{1/k}} \int_a^b \abs{\psi'(x)}\,dx\\
%      &\leq& \frac{C(k,\psi)}{\delta^{1/k}},
% \end{eqnarray*}
% as desired.
% \end{proof}

% \begin{framed}
% \begin{corollary}\label{cor:minK}
% Let $\psi\in C^1([a,b])$ and $\Phi\in C^{\infty}([a,b])$. Suppose that $\Phi$ has a single critical point at $c\in (a,b)$ where $\Phi^{(j)}(c)\neq 0$ for some $j\geq 2$ and set
% \begin{equation*}
%     k=\min\{j:\Phi^{(j)}(c)\neq 0\}.
% \end{equation*}
% Then there exists a positive constant $C$ for which
% \begin{equation*}
%     \left|\int_a^b e^{i\Phi(x)}\psi(x)\,dx\right|\leq C.
% \end{equation*}
% \end{corollary}
% \end{framed}
% \begin{proof}
% Given that $\Phi^{(k)}$ is continuous and non-zero at $c\in (a,b)$, there exist $a<c_1<c<c_2<b$ for which $|\Phi^{(k)}(x)|\geq |\Phi^{(k)}(c)|/2$ for all $c_1\leq x\leq c_2$. Further, our hypothesis guarantees that $\Phi'(x)\neq 0$ for all $x\in[a,c_1]$ and $x\in[c_2,b]$. An appeal to Proposition \ref{prop:NoCriticalPoint} gives constants $C_1$ and $C_2$ for which
% \begin{equation*}
%     \left|\int_a^{c_1}e^{i\Phi(x)}\psi(x)\,dx\right|\leq C_1
%     \hspace{1cm}\mbox{ and }\hspace{1cm}\left|\int_{c_2}^b e^{i\Phi(x)}\psi(x)\,dx\right|\leq C_2
% \end{equation*}
% Also, an appeal to the preceding corollary gives a constant $C_0$ for which
% \begin{equation*}
%     \left|\int_{c_1}^{c_2}e^{i\Phi(x)}\psi(x)\,dx\right|\leq \frac{2^{1/k}C_0}{|\Phi^{(k)}(c)|^{1/k}}.
% \end{equation*}
% Consequently,
% \begin{equation*}
%     \left|\int_a^b e^{i\Phi(x)}\psi(x)\,dx\right|\leq C_1+\frac{2^{1/k}C_0}{|\Phi^{(k)}(c)|^{1/k}}+C_2\leq C,
% \end{equation*}
% as desired.
% \end{proof}















% \subsection{Multi-parameter theory}
% In this subsubsection we wish to extend the preceding results to a multi-variable theory. To do this, we let $\Phi(u)$ absorb $\lambda$, which is now a tuple of numbers. We will eventually be interested in $\Phi(u,\vec{\lambda})$ of the form
% \begin{equation*}
%     \Phi(u,\vec{\lambda}) = \lambda_1 f(u_2,\dots,u_d) + \lambda_2 u_2 + \dots \lambda_d u_d,
% \end{equation*}
% but for now we will just treat a general $\Phi(u,\vec{\lambda})$ where $u$ is a single variable of integration. In particular, we would like to modify Proposition \ref{prop:NoCriticalPoint} and Proposition \ref{prop:SublevelSetEstimate}.
% \begin{framed}
% \begin{proposition}\label{prop:LambdaNoCriticalPoint} 
% Let $\mathcal{O}\subseteq\mathbb{R}^d$ and, given real numbers $a<b$, suppose that $\Phi=\Phi(u,\lambda)$ is a real-valued function on $[a,b]\times\mathcal{O}$ which is twice continuously differentiable in the variable $u\in [a,b]$ for each $\lambda\in\mathcal{O}$. Suppose that, for each $\lambda\in\mathcal{O}$,
% \begin{equation*}
%     \delta(\lambda):=\inf_{u\in[a,b]}\left|\frac{\partial \Phi}{\partial u}(u,\lambda)\right|>0.
% \end{equation*}
% If, for $\lambda\in\mathcal{O}$, $u\mapsto \partial_u \Phi (u,\lambda)$ is monotonic, then
% \begin{equation*}
%     \left|\int_a^b e^{i\Phi(u,\lambda)}\,du\right|\leq \frac{4}{\delta(\lambda)}.
% \end{equation*}
% \end{proposition}
% \end{framed}

% \begin{proof}
% \begin{eqnarray*}
%     \int_{a}^b e^{i \Phi(u,\lambda)}\,du  
%     &=& \int_{a}^b   \f{1}{i \p_u\Phi(u, \lambda)}\lp \p_u e^{i \Phi(u,\lambda)}\rp   \,du \\
%     &=& \f{1}{i \p_u \Phi(u,\lambda)}e^{i \Phi(u,\lambda)}\bigg\vert_{a}^b 
%     - \int_{a}^b  e^{i \Phi(u,\lambda)} \f{d}{du}\lp \f{1}{i \p_u \Phi(u,\lambda)} \rp \,du 
% \end{eqnarray*}
% where we have integrated by parts and used the fact that $\Phi'$ never vanishes. Consequently,
% \begin{equation*}
%     \left|\int_a^b e^{i\Phi(u,\lambda)}\,du \right|\leq \left|\frac{1}{\p_u \Phi(b,\lambda)}-\frac{1}{\p_u \Phi(a,\lambda)}\right|+\int_a^b\left|\frac{d}{du}\left(\frac{1}{\p_u \Phi(u,\lambda)}\right)\right|\,dx
% \end{equation*}
% and so,
% \begin{eqnarray*}
%     \left|\int_a^b e^{i\Phi(u,\lambda)}\,du \right|
%     &=&\left|\frac{1}{\p_u \Phi(b,\lambda)}-\frac{1}{\p_u \Phi(a,\lambda)}\right|+\int_a^b\left|\frac{d}{du}\left(\frac{1}{\p_u \Phi(u,\lambda)}\right)\right|\,du \\
%     &=& 2\left|\frac{1}{\p_u \Phi(b,\lambda)}-\frac{1}{\p_u \Phi(a,\lambda)}\right|, \quad \mbox{by monotonicity of $\p_u \Phi(u,\lambda)$ and FTC} \\
%     &\leq& \f{4}{\delta(\lambda)}.
% \end{eqnarray*}
% \end{proof}


% \textcolor{red}{
% \begin{framed}
% \begin{corollary}\label{cor:DeltaLambda}
% Let $\Phi$ and $\delta(\lambda)$ be given by the preceding proposition. Then
% \begin{equation*}
%     \left|\int_a^b e^{i\Phi(u,\lambda)} \psi(u)\,du \right| \leq \f{4}{\delta(\lambda)}\lb \abs{\psi(b)} + \int_a^b \abs{\psi'(u)}\,du \rb.
% \end{equation*}
% \end{corollary}
% \end{framed}
% % \begin{proof}
% % We prove this corollary by integration by parts. Define
% % \begin{equation*}
% %     F(x) = \int_a^x e^{i \Phi(u,\lambda)}\,du.
% % \end{equation*}
% % for $a\leq x\leq b$. An appeal to the preceding proposition (on the intervals $[a,x]$), we obtain the estimate
% % \begin{equation*}
% %     \abs{F(x)} \leq \f{4}{\delta(\lambda)}
% % \end{equation*}
% % for all $x\in [a,b]$. It follows that 
% % \begin{eqnarray*}
% %      \abs{\int_a^b e^{i \Phi(u,\lambda)} \psi(u) \,du} 
% %      &=& \abs{\int_a^b F'(u)\psi(u)\,du}  \\
% %      &=& \abs{ F(u)\psi(u)\bigg\vert_{a}^b - \int_a^b F(u)\psi'(u)\,du   } \\
% %      &\leq& \abs{F(b)}\abs{ \psi(b)} + \int_a^b \abs{\psi'(u)}\abs{ F(u)}\, du  \\
% %      &\leq& \f{4}{\delta(\lambda)}\abs{\psi(b)} + \f{4}{\delta(\lambda)} \int_a^b \abs{\psi'(u)}\,du\\
% %      &\leq& \f{4}{\delta(\lambda)}\lb \abs{\psi(b)} + \int_a^b \abs{\psi'(u)}\,du \rb 
% % \end{eqnarray*}
% % for all $\lambda$, as desired.
% % \end{proof}
% }

% \begin{framed}
% \begin{proposition}\label{prop:EAlpha}
% Let $\mathcal{O}\subseteq\mathbb{R}^d$ and, given real numbers $a<b$, suppose that $\Phi=\Phi(u,\lambda)$ is a real-valued function on $[a,b]\times\mathcal{O}$ which is twice continuously differentiable in the variable $u\in [a,b]$ for each $\lambda\in\mathcal{O}$. For each $\lambda\in\mathcal{O}$ and $\alpha>0$, set
% \begin{equation*}
%     E_{\alpha}(\lambda)=\{u\in[a,b]:|\partial_u \Phi(u,\lambda)|\leq\alpha\}.
% \end{equation*}
% If, for $\lambda\in\mathcal{O}$, $u\mapsto \partial_u\Phi(u,\lambda)$ is monotonic, then
% \begin{equation*}
% \left|\int_a^b e^{i\Phi(u,\lambda)}\,du\right| \leq \frac{8}{\alpha}+m(E_\alpha(\lambda))
% \end{equation*}
% for all $\alpha>0$.
% \end{proposition}
% \end{framed}

% \begin{proof}
% Define, for $\alpha>0$,
% \begin{equation*}
%     I(\alpha, \lambda)=\int_{\{u\in[a,b]:|\p_u \Phi(u,\lambda)|> \alpha\}}e^{i\Phi(u,\lambda)}\,du
% \end{equation*}
% and observe that
% \begin{eqnarray*}
%     \abs{\int_a^b e^{i\Phi(u,\lambda)} \,du}
%     &\leq&  \abs{\int_{\{u\in[a,b]:|\p_u\Phi(u,\lambda)|> \alpha\}}e^{i\Phi(u,\lambda)}\,du}
%     + 
%     \abs{\int_{\{ u \in [a,b]: \abs{\p_u\Phi(u,\lambda)} \leq \al \}}e^{i\Phi(u,\lambda)} \,du } \\
%     &\leq& \abs{I(\alpha,\lambda)}  + m(E_\al).
% \end{eqnarray*}

% Let's estimate $I(\al,\lambda)$. For any $\alpha>0$, by removing the set $E_\alpha$ from $[a,b]$, we obtain at most $2$ compact intervals $I_1,I_2$ covering $\{ u\in [a,b] : \abs{\p_u \Phi(u,\lambda)} \geq\alpha \}=[a,b]\setminus E_\alpha$ and on each of which $\p_u\Phi(u,\lambda)$ is strictly monotonic in $u$. Applying a similar argument as that in Proposition \ref{prop:LambdaNoCriticalPoint} with $\al$ in place of $\delta(\lambda)$ to each such interval and using the triangle inequality we find 
% \begin{equation*}
%     \abs{I(\alpha,\lambda)} \leq  2\cdot \f{4}{\al} = \f{8}{\al},
% \end{equation*}
% which holds for all $\alpha>0$. Consequently, we have
% \begin{equation*}
% \left|\int_a^b e^{i\Phi(u,\lambda)}\,du\right| \leq \frac{8}{\alpha}+m(E_\alpha(\lambda))
% \end{equation*}
% as desired.
% \end{proof}




% \begin{framed}
% \begin{corollary}\label{cor:LambdaPsiPhi}
% Let the hypothesis of the preceding proposition be satisfied and $\psi \in C^1([a,b])$. Then for every $\al > 0$, there exists a constant $C$ for which
% \begin{equation*}
% \left|\int_a^b e^{i\Phi(u,\lambda)}\psi(u) \,du\right| \leq  C\lb \frac{8}{\alpha}+m(E_\alpha(\lambda))\rb .
% \end{equation*}
% \end{corollary}
% \end{framed}


% \begin{proof}
% We prove this corollary by integration by parts. Define
% \begin{equation*}
%     F(x) = \int_a^x e^{i \Phi(u,\lambda)}\,du.
% \end{equation*}
% for $a\leq x\leq b$. We simply following a similar argument that appears in the proof of Corollary \ref{cor:DeltaLambda} to obtain the desired result.
% \end{proof}


% Estimating the decay of the oscillatory integrals above in an arbitrary direction is in general much more difficult and requires more advanced techniques beyond the scope of this thesis.









\section{An application}\label{sec:estimating_SigmaHat}


An important application of the facts regarding oscillatory integrals in the preceding section is in the study of averaging operators and the decay of the Fourier transform of surface-carried measures. Here, we will follow the beginning of Chapter 8 of \cite{SteinFunctionalAnalysis} to give some motivational context. \\

\noindent In $\mathbb{R}^d$, the averaging operator $A$ that gives for each function $f$ its average over the unit hypersphere centered at $x$ is defined by
\begin{equation*}
    \mathcal{A}(f) = \f{1}{\sigma(\mathbb{S}_d)}\int_{\mathbb{S}_{d-1}} f(x-y)\,\Theta(dy)
\end{equation*}
where $\Theta$ is the induced measure on the unit hypersphere $\mathbb{S}_{d-1}$. $\mathcal{A}$ smooths $f$ in several senses, the simplest one is given by Proposition 1.1 of \cite{SteinFunctionalAnalysis}, which states that the mapping $f\to \mathcal{A}(f)$ from $L^2(\mathbb{R}^d)$ to the Sobolev space $L_k^2(\mathbb{R}^d)$ with $k=(d-1)/2$ is bounded.\footnote{For definitions of these mathematical objects, the reader may refer to Chapter 1 of \cite{SteinFunctionalAnalysis}.}  The proof of this statement relies on a crucial fact, which is that the Fourier transform of the canonical spherical measure $\Theta$, denoted by $\widehat{\Theta}$, can be written as
\begin{equation*}
    \widehat{\Theta}(\xi) = 2\pi \abs{\xi}^{-d/2+1}J_{d/2}(2\pi \abs{\xi}),
\end{equation*}
from which and the known asymptotic behavior of the Bessel functions $J_m$ of order $m$ one finds 
\begin{equation}\label{eq:estimate_stein}
    \abs{\widehat{\Theta}(\xi)} \leq O(\abs{\xi}^{-(d-1)/2})
\end{equation}
as $\abs{\xi} \to\infty$. We thus see that the knowledge of how the Fourier transform of the spherical measure decays allows us to learn something about the averaging operator $\mathcal{A}$. The natural next step is to generalize the estimate in \eqref{eq:estimate_stein}. Chapter 8.3 of \cite{SteinFunctionalAnalysis} provides an excellent summary of results relating the curvature of hypersurfaces and the associated decay estimates. While this is interesting in its own right, for the remainder of this section, we shall turn our attention to directly obtaining decay estimates of the Fourier transform of a measure $\sigma$ associated with a positive homogeneous polynomial $P$ along the coordinate axes, using only the facts about oscillatory integrals provided in the preceding section. We will then compare our results to \cite{greenblatt_fourier_2021}, which studies various mathematical objects derived from estimates on Fourier transforms of hypersurface measures, and demonstrate that when restricted to only finding decay estimates along the coordinate axes, our result is slightly more optimal. \\


\noindent To start, let us consider the polynomial $P$ of the form 
\begin{equation*}
    P(x_1,x_2) = x_1^2 + x_2^4.
\end{equation*}


\noindent An appeal to Corollary \ref{cor:IntegralFormula} gives us an expression for the Fourier transform of the measure $\widehat{\sigma_P}(\xi) = \widehat{\sigma_P}(\xi_1,\xi_2)$:
\begin{equation*}
    2\pi \widehat{\sigma_P}(\xi) = \int_S e^{-i \xi \cdot \eta }\sigma_P (d\eta)
\end{equation*}
where of course
\begin{equation*}
    S = \{ \eta \in \R^d : P(\eta) = 1 \}.
\end{equation*}


\noindent From Theorem 1.1 of \cite{greenblatt_fourier_2021}, we have that for any $\xi \in \R^d$ with sufficiently large $\abs{\xi}$, there is a constant $C$ for which
\begin{equation}\label{eq:greenblatt}
    \abs{\widehat{\sigma_P}(\xi)} \leq \f{C}{\abs{\xi}^{1/4}}.
\end{equation}
With this result in mind, we shall restrict ourselves to only the coordinate axes, i.e., we now study how $\abs{\widehat{\sigma_P}(\xi_1,0)}$ and $\abs{\widehat{\sigma_P}(0,\xi_2)}$ decay. Given $S$, we consider a finite atlas of charts $\{ (U_\al, \varphi^{-1}_\al) \}$ with $\al = 1,2,3,4$ given by 
\begin{empheq}[left=\empheqlbrace]{align*}
    \varphi_1 &: (-a,a) \to S \quad \varphi_1(u) = (\sqrt{1-u^4},u) \\
    \varphi_2 &: (-a,a) \to S \quad \varphi_2(u) = -\varphi_1(u) \\
    \varphi_3 &: (-b,\,b) \to S \quad \varphi_3(u) = (u, -(1-u^2)^{1/4}) \\
    \varphi_4 &: (-b,\,b) \to S \quad \varphi_4(u) = -\varphi_3(u).
\end{empheq}
where $0 < a < 1$ and $({1-a^2})^{1/4}=b$. Further, set $S_\al=\varphi_\al((-a,a))$ for $\al = 1,2$ and $S_\al=\varphi_\al((-b,b))$ for $\al  = 3,4$. Figure \ref{fig:S} shows the parameterization associated with this atlas. \\

\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.6]{S.eps}
    \caption{$S$}
    \label{fig:S}
\end{figure}





\noindent Note that the atlas $\{ (U_\al, \varphi^{-1}_\al) \}$ is defined so that it is positively oriented. We find the $P$-adapted surface area scaling factor to be 
\begin{equation*}
    h_{E,\varphi_1}(u) = h_{E,\varphi_2}(u) = {\det \begin{pmatrix} 
    \f{1}{2}\sqrt{1-u^4} &  -\f{2u^3}{\sqrt{1-u^4}} \\
    \f{1}{4}u & 1
    \end{pmatrix}} = \f{1}{2\sqrt{1-u^4}}
\end{equation*}
for $u\in(-a,a)$ and
\begin{equation*}
    h_{E,\varphi_3}(u) = h_{E,\varphi_4}(u) = {\det\begin{pmatrix}
    \f{1}{2}u&  1  \\
    -\f{1}{4}(1-u^2)^{1/4}  & \f{u}{2(1-u^2)^{3/4}}
    \end{pmatrix}} = \f{1}{4(1 - u^2)^{3/4}}
\end{equation*}
for $u\in(-b,b)$. We want to break this integral up into a sum over the $S_\al$'s. To this end, putting $A = (-a,a), B = (-b,b)$, we let a partition of unity $\{\rho_\al\}_\al$ where $\al=1,2,3,4$ subordinate to the cover $\{ \varphi_1(A), \varphi_2(A), \varphi_3(B), \varphi_4(B)\}$ associated with the atlas above. With this, we have
\begin{eqnarray*}
    2\pi \widehat{\sigma_P}(\xi) 
    &=& \int_S e^{-i \xi \cdot \eta }\sigma_P (d\eta) \\
    &=& \sum^{4}_{\al = 1} \int_{S} \rho_\al e^{-i \xi \cdot \eta} \sigma_P(d\eta)\\
    &=& \sum^{4}_{\al = 1} \int_{S_\al} e^{-i \xi \cdot \eta} \sigma_P(d\eta)\\
    &=& \int_{-a}^a  e^{-i \xi \cdot \varphi_1(u)} h_{E,\varphi_1}(u)\,du  + \int_{-a}^a  e^{-i \xi \cdot \varphi_2(u)} h_{E,\varphi_2}(u)\,du \\
    &\quad& + \int_{-b}^b e^{-i \xi \cdot \varphi_3(u)} h_{E,\varphi_3}(u)\,du + \int_{-b}^b e^{-i \xi \cdot \varphi_4(u)} h_{E,\varphi_4}(u)\,du.
\end{eqnarray*}


\subsection{Decay along the $\xi_2$-axis}

When $\xi = (0,\xi_2)$ with $\xi_2 \neq 0$ we have:
\begin{eqnarray*}
    2\pi \widehat{\sigma_P}(\xi) 
    &=& \int_{-a}^a  e^{-i \xi_2 u} \f{1}{2\sqrt{1-u^4}}\,du  + \int_{-a}^a  e^{+i \xi_2 u} \f{1}{2\sqrt{1-u^4}}\,du \\
    &\quad& + \int_{-b}^b e^{+i \xi_2 (1-u^2)^{1/4}} \f{1}{4(1 - u^2)^{3/4}} \,du + \int_{-b}^b e^{-i \xi_2 (1-u^2)^{1/4}} \f{1}{4(1 - u^2)^{3/4}}\,du \\
    &\coloneqq& I_1(\xi_2) + I_2(\xi_2) + I_3(\xi_2) + I_4(\xi_2).
\end{eqnarray*}
For each of $I_1$ and $I_2$, the phase function is real-valued, twice-differentiable and has monotonic first derivative whose absolute value is greater than or equal to $\abs{\xi_2} > 0$ on $(-a,a)$. Moreover, the amplitude function is once-differentiable on $(-a,a)$. Thus, we can appeal to Lemma \ref{lem:setup_VdC} and Proposition \ref{prop:NoCriticalPoint} to find a positive constant $C$ for which
\begin{equation*}
    \abs{I_1(\xi_2)} \leq \f{C}{\abs{\xi_2}} \quad \mbox{and} \quad \abs{I_2(\xi_2)} \leq \f{C}{\abs{\xi_2}}.
\end{equation*}
To estimate $\abs{I_3(\xi_2)}$ and $\abs{I_4(\xi_2)}$, we first let $\Phi(u) = (1-u^2)^{1/4}$. We have that $\Phi'(u) = 0$ if and only if $u=0$, and that the smallest integer $k$ for which $\Phi^{(k)}(u) \neq 0$ for all $u\in [-a,a]$ is $k=2$. Another appeal to Lemma \ref{lem:VdC} yields
\begin{equation*}
    \abs{I_3(\xi_2)} \leq \f{C}{\abs{\xi_2}^{1/2}} \quad \mbox{and} \quad \abs{I_4(\xi_2)} \leq \f{C}{\abs{\xi_2}^{1/2}}.
\end{equation*}
It follows that there is a positive constant $C$ for which
\begin{equation*}
    \abs{\widehat{\sigma_P}(\xi) }=\abs{\widehat{\sigma_P}(0,\xi_2) } \leq \f{C}{\abs{\xi_2}^{1/2}}.
\end{equation*}
for all $\xi=(0,\xi_2)$ where $\xi_2\in\mathbb{R}\setminus \{ 0 \}$. In the case that $\xi_2 = 0$, we can evaluate the integrals, and no estimates are needed. We see that this estimate is sharper than in estimate in \eqref{eq:greenblatt}.




\subsection{Decay along the $\xi_1$-axis}

When $\xi = (\xi_1,0)$ we have
\begin{eqnarray*}
    2\pi \widehat{\sigma_P}(\xi) 
    &=& \int_{-a}^a  e^{-i \xi_1 \sqrt{1-u^4}} \f{1}{2\sqrt{1-u^4}}\,du  + \int_{-a}^a  e^{+i \xi_1 \sqrt{1-u^4}} \f{1}{2\sqrt{1-u^4}}\,du \\
    &\quad& + \int_{-b}^b e^{-i \xi_1 u}  \f{1}{4(1 - u^2)^{3/4}} \,du + \int_{-b}^b e^{+i \xi_1 u} \f{1}{4(1 - u^2)^{3/4}}\,du \\
    &\coloneqq& I_1(\xi_1) + I_2(\xi_1) + I_3(\xi_1) + I_4(\xi_1).
\end{eqnarray*}
In view of Lemma \ref{lem:VdC}, we have
\begin{equation*}
    \abs{I_3(\xi_1)} \leq \f{C}{\abs{\xi_1}} \quad \mbox{and} \quad \abs{I_4(\xi_1)} \leq \f{C}{\abs{\xi_1}}.
\end{equation*}
for some positive constant $C$. To estimate $\abs{I_1(\xi_2)}$ and $\abs{I_2(\xi_2)}$, we first let $\Phi(u) = \sqrt{1-u^4}$. We have that $\Phi'(u) = 0$ if and only if $u=0$, and that the smallest integer $k$ for which $\Phi^{(k)}(u) \neq 0$ for all $u\in [-b,b]$ is $k=4$. Another appeal to Lemma \ref{lem:VdC} yields
\begin{equation*}
    \abs{I_1(\xi_1)} \leq \f{C}{\abs{\xi_1}^{1/4}} \quad \mbox{and} \quad \abs{I_2(\xi_1)} \leq \f{C}{\abs{\xi_1}^{1/4}}.
\end{equation*}
It follows that there is a positive constant $C$ for which
\begin{equation*}
    \abs{\widehat{\sigma_P}(\xi)}= \abs{\widehat{\sigma_P}(\xi_1,0) } \leq \f{C}{\abs{\xi_1}^{1/4}}.
\end{equation*}
for all $\xi=(\xi_1,0)$ where $\xi_1\in\mathbb{R}$. This estimate is consistent with \eqref{eq:greenblatt}.




















%%%%%%%%%%%%%%%% Estimating convolution powers  %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Application: Estimating convolution powers of complex-valued functions on $\mathbb{Z}^d$}
\label{chap:Estimate-ConvPwr}
\chaptermark{Applications in convolution powers}




In this chapter, we utilize our generalized polar-coordinate integration formula and the Van der Corput lemmas from the preceding chapter to obtain sup-norm-type estimates for convolution powers of ``sufficient nice'' complex-valued functions $\phi$ defined on the $d$-dimensional integer lattice. Section \ref{sec:ConvolutionPowers} covers the necessary theory and includes the main theorem (Theorem \ref{thm:ConvolutionPowerEstimate}). Section \ref{sec:Examples} shows how this theory is applied through some examples. This chapter is essentially as it appears in Section 3 of \cite{bui2021generalized}.\\





\section{An application: Estimates for convolution powers}\label{sec:ConvolutionPowers}

This section can be summarized as follows. We first give some historical context related to the studying convolution powers and define the class of aforementioned ``sufficiently nice'' functions, denoted by $\mathcal{S}_d$, whose convolution power estimates we wish to obtain. This class of functions is a subclass of $\ell^1(\mathbb{Z}^d)$ which contains all ``absolutely summable'' $\phi$'s (We will define this in the next paragraph) and is a discrete analogue of the Schwartz class. Since our approach relies heavily on the relationship between the Fourier transform and the convolution, we define both operations for all functions in $\ell^1(\mathbb{Z}^d)$ and thus for all of $\mathcal{S}_d$.  From here, we can define the Taylor expansions $\Gamma_{\xi_0}$ of the Fourier transform of $\phi$, denoted by $\widehat{\phi}$, around the points $\xi_0$ where $\widehat{\phi}$ is maximized. As we will see, the leading polynomials in $\Gamma_{\xi_0}$ are related to the positive homogeneous functions in Chapter \ref{chap:pos-hom-fns} and its subtypes (subhomogeneous and strongly subhomogeneous of order $k$) and give rise to a homogeneous order $\mu_{\xi_0}$ depending on the ``type'' of $\xi_0$. We then show that the smallest homogeneous order over all admissible $\xi_0$'s dictates the power-law decay of the sup-norm of the convolution powers $\phi^{(n)}$.\\






\noindent We denote by $\ell^1(\mathbb{Z}^d)$ the set of absolutely summable functions, i.e., $\phi:\mathbb{Z}^d\to\mathbb{C}$ for which
\begin{equation*}
\|\phi\|_1:=\sum_{x\in\mathbb{Z}^d}\abs{\phi(x)}<\infty.
\end{equation*}
Given $\psi,\phi\in \ell^1(\mathbb{Z}^d)$, the convolution product $\psi\ast\phi\in\ell^1(\mathbb{Z}^d)$ is defined by
\begin{equation*}
\left(\psi\ast\phi\right)(x)=\sum_{y\in\mathbb{Z}^d}\psi(x-y)\phi(y)
\end{equation*}
for $x\in\mathbb{Z}^d$. For a given $\phi\in\ell^1(\mathbb{Z}^d)$, we are interested in the asymptotic behavior of its convolution powers $\phi^{(n)}\in\ell^1(\mathbb{Z}^d)$ defined iteratively by $\phi^{(n)}=\phi^{(n-1)}\ast\phi$ for $n\geq 1$ where $\phi^{(0)}=\phi$. \\


\noindent There are known theories for special cases of $\phi$. When $\phi$ is non-negative (and satisfies mild summability conditions), the asymptotic behavior of $\phi^{(n)}$ is well understood and is the subject of the local (central) limit theorem. For accounts of this history and its connection to probability and random walk theory, the reader may refer to \cite{lawler_random_2010} and \cite{spitzer_principles_1964} (see also Section 7.6 of \cite{randles_convolution_2017}). When $\phi$ is generally complex-valued (or simply a real-valued function taking on both positive and negative values), its convolution powers can exhibit exotic behaviors not seen in the probabilistic setting. For example, Figure \ref{fig:Interesting_Example} shows the real part and the modulus of $\phi^{(n)}$ for $n = 400$ and $n = 1500$ where $\phi: \mathbb{Z}^d \to \mathbb{C}$ is given by 
\begin{equation*}
    \phi(x,y) =
    \frac{1}{192}
    \begin{cases}
    144 - 64i &(x,y) = (0,0)\\
    16 + 16i &(x,y) = (\pm 1, 0)\mbox{ or }(0,\pm 1)\\
    -4        &(x,y) = (\pm 2,0)\mbox{ or }(0,\pm 2)\\
    i   &(x,y) = \pm(1,1)\\
    -i   &(x,y) = \pm(1,-1)\\
    0& \text{otherwise}.
    \end{cases}
\end{equation*}


\begin{figure}[!htb]
    \centering
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[scale=0.52]{Real_400.eps}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[scale=0.52]{Real_1500.eps}
    \end{subfigure}
    \vspace{1cm}
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[scale=0.52]{Abs_400.eps}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \includegraphics[scale=0.52]{Abs_1500.eps}
    \end{subfigure}
    \caption{The real part and modulus of $\phi^{(n)}$ for $n = 400$ and $n = 1500$.}
    \label{fig:Interesting_Example}
\end{figure}




\noindent The problem of describing these behaviors dates back to Erastus L. De Forest in his study of data smoothing in the nineteenth century and was further pursued by Isaac J. Schoenberg and Thomas N. E.  Greville. In the 1960's, spurred by advancements in scientific computing, the study was reinvigorated by its application to numerical solutions to partial differential equations. \cite{diaconis_convolution_2014} provides a full account of this history and references to the literature. Regarding recent developments, mostly in the context of one spatial dimension, we encourage the reader to see the articles \cite{diaconis_convolution_2014,randles_convolution_2015, coulombel2020generalized, randles_convolution_2017}. Concerning global space-time estimates, \cite{diaconis_convolution_2014} establishes Gaussian and sub-Gaussian estimates for the convolution powers of finitely-supported complex-valued functions on $\mathbb{Z}$ whose Fourier transform (characteristic function) satisfies certain hypotheses and the article \cite{coulombel2020generalized} focuses on Gaussian estimates and extends results of \cite{diaconis_convolution_2014} and \cite{randles_convolution_2017}. The articles \cite{diaconis_convolution_2014} and \cite{randles_convolution_2015} treat local limit theorems and sup norm estimates for the convolution powers of complex-valued functions on $\mathbb{Z}$; the latter provides a complete description of local limit theorems and sup norm estimates for the class of finitely-supported complex-valued functions on $\mathbb{Z}$, essentially resolving \textit{De Forest's problem}. In the general context of $\mathbb{Z}^d$, \cite{randles_convolution_2017} treats local limit theorems, global space-time estimates and sup norm estimates for the convolution powers of complex-valued functions whose Fourier transform satisfies certain assumption discussed below.  \\

\noindent In this section, we focus on sup-norm-type estimates for convolution powers of complex-valued functions on $\mathbb{Z}^d$. Our main result, Theorem \ref{thm:ConvolutionPowerEstimate}, partially extends results of \cite{randles_convolution_2015} and \cite{randles_convolution_2017}, and its proof makes use of Theorem \ref{thm:BestIntegrationFormula} and the Van der Corput lemma. A forthcoming article will present a theory of local limit theorems for complex-valued functions on $\mathbb{Z}^d$ satisfying the hypotheses of Theorem \ref{thm:ConvolutionPowerEstimate}. The Fourier transform is essential to our analysis and is defined as follows: Given $\phi\in\ell^1(\mathbb{Z}^d)$, the Fourier transform of $\phi$ is the function $\widehat{\phi}:\mathbb{R}^d\to\mathbb{C}$ defined by
\begin{equation*}
    \widehat{\phi}(\xi)=\sum_{x\in\mathbb{Z}^d}\phi(x)e^{ix\cdot\xi}
\end{equation*}
for $\xi\in\mathbb{R}^d$. As in \cite{randles_convolution_2017}, we shall focus on the subspace $\mathcal{S}_d$ of $\ell^1(\mathbb{Z}^d)$ consisting of those $\phi:\mathbb{Z}^d\to\mathbb{C}$ for which
\begin{equation*}
    \|x^\beta \phi(x)\|_1=\sum_{x\in\mathbb{Z}^d}\abs{x^\beta\phi(x)}=\sum_{x\in\mathbb{Z}^d}\abs{(x^1)^{\beta_1}(x^2)^{\beta_2}\cdots(x^d)^{\beta_d}\phi(x^1,x^2,\dots,x^d)}<\infty
\end{equation*}
for each multi-index $\beta=(\beta_1,\beta_2,\dots,\beta_d)\in\mathbb{N}^d$. $\mathcal{S_d}$ is a discrete analogue of the Schwartz class of functions and contains all finitely supported complex-valued functions on $\mathbb{Z}^d$.  It is easy to see that $\widehat{\phi}\in C^\infty(\mathbb{R}^d)$ whenever $\phi\in \mathcal{S}_d$. As discussed in \cite{thomee_stability_1965,diaconis_convolution_2014,randles_convolution_2015,randles_convolution_2017}, the asymptotic behavior of the iterative convolution powers $\phi^{(n)}$ of $\phi\in\mathcal{S}_d$ is characterized by the local behavior of $\widehat{\phi}$ near points at which $\widehat{\phi}$ is maximized in absolute value. For simplicity of our analysis, we shall focus on those $\phi\in\mathcal{S}_d$ which have been suitably normalized so that $\sup_{\xi}|\widehat{\phi}(\xi)|=1$ and, in this case, we define
\begin{equation*}
    \Omega(\phi)=\left\{\xi\in \mathbb{T}^d:\abs{\widehat{\phi}(\xi)}=1\right\}
\end{equation*}
where $\mathbb{T}^d=(-\pi,\pi]^d$. For each $\xi_0\in \Omega(\phi)$, consider $\Gamma_{\xi_0}:\mathcal{U}\to\mathbb{C}$ defined by
\begin{equation*}\Gamma_{\xi_0}(\xi)=\log\left(\frac{\widehat{\phi}(\xi+\xi_0)}{\widehat{\phi}(\xi_0)}\right)
\end{equation*}
for $\xi\in \mathcal{U}$ where $\mathcal{U}\subseteq\mathbb{R}^d$ is a convex open neighborhood of $0$ which is small enough to ensure that $z\mapsto\log(z)$, the principal branch of the logarithm, is defined and continuous on $\{\widehat{\phi}(\xi+\xi_0)/\widehat{\phi}(\xi_0):\xi\in\mathcal{U}\}$. Because $\widehat{\phi}$ is smooth, $\Gamma_{\xi_0}\in C^{\infty}(\mathcal{U})$ and so we can use Taylor's theorem to approximate $\Gamma_{\xi_0}$ near $0$. More precisely, we can write
\begin{equation}\label{eq:GammaExpansion}
    \Gamma_{\xi_0}(\xi)=i\alpha_{\xi_0}\cdot\xi -i\left(Q_{\xi_0}(\xi)+\widetilde{Q}_{\xi_0}(\xi)\right)-\left(R_{\xi_0}(\xi)+\widetilde{R}_{\xi_0}(\xi)\right)
\end{equation}
where $\alpha_{\xi_0}\in\mathbb{R}^d$, $Q_{\xi_0}$ and $R_{\xi_0}$ are real-valued polynomials which vanish at $0$ and contain no linear terms, and $\widetilde{Q}_{\xi_0}$ and $\widetilde{R}_{\xi_0}$ are real-valued smooth functions on $\mathcal{U}$ which vanish at $0$. The fact that this expansion contains no real linear part is seen necessary because $\xi_0$ is a local maximum for $|\widehat{\phi}|$. The vector $\alpha_{\xi_0}\in\mathbb{R}^d$ is said to be the \textbf{drift}\footnote{In the case that $\phi$ defines a probability measure and a $\mathbb{Z}^d$-valued random vector $X$ has this measure as its distribution, then $\alpha_{\xi_0}$ is $X$'s mean. For a precise statement and details, see Proposition 7.4 of \cite{randles_convolution_2017}.} associated to $\xi_0$. Motivated by Thom\'{e}e \cite{thomee_stability_1965}, we introduce the following definition for the ``types'' of $\xi_0$.


\begin{framed}
\begin{definition}\label{def:Types}
Let $\phi\in\mathcal{S}_d$ with $\sup_{\xi}|\widehat{\phi}(\xi)|=1$ and, given $\xi_0\in\Omega(\phi)$, consider the expansion \eqref{eq:GammaExpansion} above.
\begin{enumerate}
    \item We say that $\xi_0$ is of \textbf{positive homogeneous type} for $\widehat{\phi}$ if $R_{\xi_0}$ is positive homogeneous and, there exists $E\in \Exp(R_{\xi_0})$ for which $Q_{\xi_0}$ is homogeneous with respect to $E$ and both $\widetilde{R}_{\xi_0}$ and $\widetilde{Q}_{\xi_0}$ are subhomogeneous with respect to $E$. In this case, we will write  $\mu_{\xi_0}=\mu_{R_{\xi_0}}$.
\item We say that $\xi_0$ is of \textbf{imaginary homogeneous type} for $\widehat{\phi}$ if $|Q_{\xi_0}|$ and $R_{\xi_0}$ are both positive homogeneous and, there exists $E\in\Exp(|Q_{\xi_0}|)$ and $k>1$ for which $R_{\xi_0}$ is homogeneous with respect to $E/k$, $\widetilde{Q}_{\xi_0}$ is strongly subhomogeneous with respect to $E$ of order $2$, and $\widetilde{R}_{\xi_0}$ is strongly subhomogeneous with respect to $E/k$ of order $1$. In this case, we write $\mu_{\xi_0}=\mu_{|Q_{\xi_0}|}$.
\end{enumerate}
In either case, $\mu_{\xi_0}$ is said to be the homogeneous order associated to $\xi_0$.
\end{definition}
\end{framed}

% \noindent In his study of approximation schemes to solutions of parabolic partial differential equations, V. Thom\'{e}e introduced the notions of points of type $\gamma$ and $\beta$, arising in local approximations of the Fourier transforms of (schemes) $\phi:\mathbb{Z}\to\mathbb{C}$, to dichotomize the stability of approximation schemes in the $\ell^\infty$ norm\cite{thomee_stability_1965}. Thom\'{e}e's definition provided a key insight which led to the complete description of the asymptotic behavior of convolution powers of finitely supported functions on $\mathbb{Z}$ given in \cite{randles_convolution_2015}. The points of positive homogeneous type and imaginary homogeneous type in the definition above parallel (and generalize) Thom\'{e}e's points of type $\gamma$ and $\beta$ (and points of type 1 and type 2 of \cite{randles_convolution_2015}), respectively.\\

\noindent In Definition 1.3 of \cite{randles_convolution_2017}, a point $\xi_0\in\Omega(\phi)$ is said to be of positive homogeneous type for $\widehat{\phi}$ provided that the expansion for $\Gamma_{\xi_0}$ is of the form
\begin{equation}\label{eq:GammaInTermsofP}
    \Gamma_{\xi_0}(\xi)=i\alpha_{\xi_0}\cdot\xi-P_{\xi_0}(\xi)-\widetilde{P}_{\xi_0}(\xi)
\end{equation}
for $\xi\in\mathcal{U}$ where $P_{\xi_0}$ is a positive homogeneous polynomial in the sense of Example \ref{exp:Polynomial} and $\widetilde{P}_{\xi_0}(\xi)=o(R_{\xi_0}(\xi))$ as $\xi\to 0$ where $R_{\xi_0}=\Re P_{\xi_0}$. To put this into context with our definition above, let's write $P_{\xi_0}(\xi)=R_{\xi_0}(\xi)+iQ_{\xi_0}(\xi)$ and $\widetilde{P}_{\xi_0}(\xi)=\widetilde{R}_{\xi_0}(\xi)+i\widetilde{Q}_{\xi_0}(\xi)$ in which case \eqref{eq:GammaExpansion} coincides with \eqref{eq:GammaInTermsofP}. If $\xi_0$ is of positive homogeneous type for $\widehat{\phi}$ in the sense of the definition above, it follows that $P_{\xi_0}$ is a complex-valued polynomial which is homogeneous with respect to $E$ (and so $\Exp(P_{\xi_0})$ contains $E\in\End(\mathbb{R}^d)$ for which $\{r^E\}$ is contracting) and $R_{\xi_0}=\Re P_{\xi_0}$ is positive definite. In view of Remark \ref{rmk:PositiveHomogeneousPolynomialsVSFunctions}, this is consistent with (and perhaps generalizes) the assumption in which $P_{\xi_0}$ is a positive homogeneous polynomial. Further, the assumption that $\widetilde{Q}_{\xi_0}$ and $\widetilde{R}_{\xi_0}$ are subhomogeneous with respect to $E$ guarantees that $\widetilde{P}_{\xi_0}(\xi)=o(R_{\xi_0}(\xi))$ as $\xi\to 0$ by virtue of Proposition \ref{prop:Subhomequivtolittleoh}. With these two observations, we see that our definition, which is stated in terms of subhomogeneity, is consistent with that of \cite{randles_convolution_2017}. \\


\noindent The essential difference between the cases in Definition \ref{def:Types} 
concerns the nature of the dominant (low order) term in the expansion. When $\xi_0$ is of positive homogeneous type for $\widehat{\phi}$, the dominant term $P_{\xi_0}$ contains the real-valued positive definite polynomial $R_{\xi_0}$. In this case, local limit theorems for $\phi^{(n)}(x)$ contains attractors/approximants of the form
\begin{equation*}
    H^n_{P_{\xi_0}}(x)=\frac{1}{(2\pi)^d}\int_{\mathbb{R}^d}e^{-nP_{\xi_0}(\xi)-ix\cdot\xi}\,d\xi
\end{equation*}
which can be seen, for example, in Theorem 1.5 of \cite{randles_convolution_2017}. These are necessarily Schwartz functions and appear as fundamental solutions to the higher-order partial differential equations discussed in \cite{randles_positive-homogeneous_2017}. On the other hand, when $\xi_0$ is of imaginary homogeneous type for $\widehat{\phi}$, the dominant term in the expansion is the purely imaginary polynomial $iQ_{\xi_0}(\xi)$ and its existence (without a real counterpart) profoundly affects the asymptotic behavior of $\phi^{(n)}(x)$ (e.g., see \cite{randles_convolution_2015}). In fact, as will be shown in a forthcoming article, local limit theorems for $\phi^{(n)}(x)$ will contain approximants/attractors which are (formally) given by the oscillatory integral
\begin{equation*}
    H_{iQ_{\xi_0}}^{n}(x)=\frac{1}{(2\pi)^d}\int_{\mathbb{R}^d}e^{-inQ_{\xi_0}(\xi)-ix\cdot \xi}\,d\xi
\end{equation*}
whose convergence is a delicate matter.\\






\noindent Our theorem will be stated under the assumption that, for $\phi\in\mathcal{S}_d$ with $\sup_\xi|\widehat{\phi}(\xi)|=1$, each $\xi_0\in\Omega(\phi)$ is either of positive homogeneous type or of imaginary homogeneous type for $\widehat{\phi}$. In both cases, the positive definiteness of $R_{\xi_0}$ guarantees that each $\xi_0\in\Omega(\phi)$ is an isolated point of $\mathbb{T}^d$. Consequently, if each $\xi_0\in\Omega(\phi)$ is of positive homogeneous or imaginary homogeneous type for $\widehat{\phi}$, the set $\Omega(\phi)$ is finite and we set
\begin{equation*}
    \mu_{\phi}=\min_{\xi\in\Omega(\phi)}\mu_{\xi}.
\end{equation*}


\begin{framed}
\begin{theorem}\label{thm:ConvolutionPowerEstimate}
Let $\phi\in\mathcal{S}_d$ be such that $\sup |\widehat{\phi}|=1$ and suppose that each $\xi_0\in\Omega(\phi)$ is of positive homogeneous or imaginary homogeneous type for $\widehat{\phi}$. If $\alpha_{\xi_0}=0$ and $\mu_{\xi_0}<1$ for each $\xi_0\in\Omega(\phi)$ which is of imaginary homogeneous type for $\widehat{\phi}$, then, for any compact set $K$, there is a constant $C_K>0$ for which
\begin{equation*}
    \left|\phi^{(n)}(x)\right|\leq\frac{C_K}{n^{\mu_\phi}}
\end{equation*}
for all $x\in K$ and $n\in\mathbb{N}_+$.
\end{theorem}
\end{framed}


\noindent This partially extends the analogous one-dimensional results of \cite{randles_convolution_2015} into the $d$-dimensional setting. Specifically, Theorem 3.6 of \cite{randles_convolution_2015} guarantees that, for each $\phi:\mathbb{Z}\to\mathbb{C}$ for which $\sup_{\xi\in\mathbb{T}}|\widehat{\phi}(\xi)|=1$ and whose support is finite and contains more than one point, there is a constant $C$ and a positive integer $m$ for which
\begin{equation*}
    \abs{\phi^{(n)}(x)}\leq Cn^{-1/m}
\end{equation*}
for all $x\in\mathbb{Z}$ and $n\in\mathbb{N}_+$. Under these hypotheses concerning $\phi$'s support, it follows from a basic result of complex analysis that every point $\xi$ of $\Omega(\phi)$ is necessarily\footnote{This is Proposition 2.2 of \cite{randles_convolution_2015}. It is easy to see that the assertion fails when $d>1$.} of positive homogeneous type or imaginary homogeneous type for $\widehat{\phi}$ with $\mu_{\xi}\leq 1/2<1$. In this way, we see that Theorem \ref{thm:ConvolutionPowerEstimate} partially extends Theorem 3.6 of \cite{randles_convolution_2015} in the sense that it guarantees a spatially uniform estimate over compact sets and is stated under the additional hypotheses that the drift is zero for each point of imaginary homogeneous type for $\widehat{\phi}$. Though we expect that this is not the final result on the matter, the more limited scope of Theorem \ref{thm:ConvolutionPowerEstimate} is not surprising in light of the natural complexity of $\mathbb{R}^d$ (and $\mathbb{Z}^d$).\\

\noindent Concerning the existing theory in $\mathbb{Z}^d$, Theorem \ref{thm:ConvolutionPowerEstimate} is stated under weaker hypotheses than is the analogous result in \cite{randles_convolution_2017}. Specifically, Theorem 1.4 of \cite{randles_convolution_2017} is stated under the assumption that, given $\phi\in\mathcal{S}_d$ with $\sup_{\xi}|\widehat{\phi}(\xi)|=1$, every point $\xi_0\in\Omega(\phi)$ is of positive homogeneous type for $\widehat{\phi}$ and, in this case, the theorem gives positive constants $C$ and $C'$, for which
\begin{equation}\label{eq:SupNormResultforPosHom}
    C'n^{-\mu_\phi}\leq \abs{\phi^{(n)}(x)}\leq C n^{-\mu_\phi}
\end{equation}
for all $x\in\mathbb{Z}^d$ and $n\in\mathbb{N}$. Though we have not stated it this way, our proof of Theorem \ref{thm:ConvolutionPowerEstimate} (see Lemma \ref{lem:EstPosHom}), guarantees the upper estimate in \eqref{eq:SupNormResultforPosHom} (with $K=\mathbb{Z}^d$) in the case that there are no points $\xi_0\in\Omega(\phi)$ of imaginary homogeneous type for $\widehat{\phi}$. It is the presence of points $\xi_0\in\Omega(\phi)$ of imaginary homogeneous type that make the analysis significantly more difficult (even in one dimension) and lead to the slightly weaker conclusion. It is our belief that a uniform estimate of the type \eqref{eq:SupNormResultforPosHom} is valid when all points are either of positive homogeneous or imaginary homogeneous type for $\widehat\phi$ (perhaps still with some restriction on homogeneous order) but a resolution of such a conjecture will require further analysis and a thorough study of local limits. In Section \ref{sec:Examples}, we give several examples illustrating the conclusion of Theorem \ref{thm:ConvolutionPowerEstimate}, none of which satisfy the hypotheses of Theorem 1.4 of \cite{randles_convolution_2017}.\\



\noindent Our proof of Theorem \ref{thm:ConvolutionPowerEstimate} will make use of the Fourier inversion formula
\begin{equation}\label{eq:FourierInversionConvolutionPower}
\phi^{(n)}(x)=\frac{1}{(2\pi)^d}\int_{\mathbb{T}_\phi^d}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi
\end{equation}
which is valid for all $n\in\mathbb{N}_+$ and $x\in\mathbb{R}^d$; here $\mathbb{T}_\phi^d=\mathbb{T}^d+\xi_\phi\subseteq\mathbb{R}^d$
is a representation of the $d$-dimensional torus chosen so that $\Omega(\phi)\subseteq \Interior(\mathbb{T}_{\phi}^d)$; this can always be arranged, i.e., some $\xi_\phi\in\mathbb{R}^d$ can be selected, because $\Omega(\phi)$ is a finite set (see Remark 3 of \cite{randles_convolution_2017}). As discussed in \cite{randles_convolution_2017}, the asymptotic behavior of $\phi^{(n)}$ is characterized by the contributions to the above integral produced by integration over neighborhoods of points $\xi_0\in\Omega(\phi).$ Specifically, we shall study integrals of the form
\begin{equation}\label{eq:LocalizedFourierInversionConvolutionPower}
\frac{1}{(2\pi)^d}\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi
\end{equation}
where $\mathcal{O}_{\xi_0}$ is some (small and to be determined) neighborhood of $\xi_0\in\Omega(\phi)$. When $\xi_0$ is of positive homogeneous type for $\widehat{\phi}$, such integrals are very well behaved (the integrand is dominated uniformly by $e^{-nR_{\xi_0}(\xi)/2}$, a member of the Schwartz class). When $\xi_0$ is of imaginary homogeneous type, such integrals are oscillatory in nature and therefore much more difficult to handle. Our first lemma below handles the ``easy" case in which $\xi_0$ is of positive homogeneous type for $\widehat{\phi}$. This lemma appears, essentially, as Lemma 4.3 of \cite{randles_convolution_2017}. For illustrative purposes, we have decided to present a distinct proof here which makes use of the polar coordinate integration formula in Theorem \ref{thm:BestIntegrationFormula}. 

\begin{framed}
\begin{lemma}\label{lem:EstPosHom}
Let $\xi_0\in\Omega(\phi)$ be of positive homogeneous type for $\widehat{\phi}$ with homogeneous order $\mu_{\xi_0}$. Then, there exists an open neighborhood $\mathcal{O}_{\xi_0}\subseteq\Interior(\mathbb{T}^d_\phi)$ of $\xi_0$, which can be taken as small as desired, and a constant $C=C_{\xi_0}$ for which
\begin{equation*}
    \left|\frac{1}{(2\pi)^d}\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi\right|\leq 
    C_{\xi_0} n^{-\mu_{\xi_0}}
\end{equation*}
for all $n\in\mathbb{N}_+$ and $x\in\mathbb{R}^d$.
\end{lemma}
\end{framed}

\begin{proof}
For simplicity, we write $R=R_{\xi_0}$, $\widetilde{R}=\widetilde{R}_{\xi_0}$ and $\mu=\mu_{\xi_0}$. Given that $\xi_0$ is of positive homogeneous type for $\widehat{\phi}$, there is an open neighborhood $\mathcal{U}$ of $0$ for which
\begin{equation*}
    \left|\widehat{\phi}(\xi+\xi_0)\right|=\left|\widehat{\phi}(\xi_0)e^{\Gamma_{\xi_0}(\xi)}\right|=e^{-\left(R(\xi)+\widetilde{R}(\xi)\right)}
\end{equation*}
for $\xi\in \mathcal{U}$. Using the fact that $\widetilde{R}(\xi)=o(R(\xi))$ as $\xi\to 0$ in view of Proposition \ref{prop:Subhomequivtolittleoh}, we can further restrict $\mathcal{U}$ so that
\begin{equation*}
    \left|\widehat{\phi}(\xi+\xi_0)\right|\leq e^{-R(\xi)/2}
\end{equation*}
for all $\xi\in\mathcal{U}$. Take $E\in\Exp(R)$ and let $\sigma_R$ be the surface measure on  $S=\{\eta\in\mathbb{R}^d:R(\eta)=1\}$ guaranteed by Theorem \ref{thm:BestIntegrationFormula}. We fix an open neighborhood $\mathcal{O}_{\xi_0}$ of $\xi_0$ which is as small as desired and has the property that
\begin{equation*}
    \mathcal{O}:=\mathcal{O}_{\xi_0}-\xi_0\subseteq\mathcal{U}.
\end{equation*}
With this, we observe that
\begin{equation}\label{eq:WlogCenterAtZero}
\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi=\int_{\mathcal{O}}\widehat{\phi}^n(\xi+\xi_0)e^{-ix\cdot(\xi+\xi_0)}\,d\xi
\end{equation}
and therefore
\begin{eqnarray*}
    \left|\frac{1}{(2\pi)^d}\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi\right|&\leq& \frac{1}{(2\pi)^d}\int_{\mathcal{O}}\left|\widehat{\phi}^n(\xi+\xi_0)e^{-i x\cdot(\xi+\xi_0)}\right|\,d\xi\\
    &\leq& \frac{1}{(2\pi)^d}\int_{\mathcal{U}}e^{-nR(\xi)/2}\,d\xi\\
    &\leq&\frac{1}{(2\pi)^d}\int_{\mathbb{R}^d} e^{-(n/2)R(\xi)}\,d\xi
\end{eqnarray*}
for all $x\in\mathbb{R}^d$ and $n\in\mathbb{N}_+$. By virtue of Theorem \ref{thm:BestIntegrationFormula}, we have
\begin{equation*}
\int_{\mathbb{R}^d}e^{-(n/2)R(\xi)}\,d\xi=\int_S \int_0^\infty e^{-(n/2)r}r^{\mu-1}\,dr\,\sigma_R(d\eta)=\int_S \frac{2^\mu\Gamma(\mu)}{n^{\mu}}\,\sigma_R(d\eta)=2^\mu\Gamma(\mu)\sigma_R(S)n^{-\mu}
\end{equation*}
where $\Gamma$ denotes the Gamma function. Consequently,
\begin{equation*}
    \left|\frac{1}{(2\pi)^d}\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi\right|\leq C n^{-\mu}
\end{equation*}
for all $x\in\mathbb{R}^d$ and $n\in\mathbb{N}_+$ where $C=2^\mu \Gamma(\mu)\sigma_R(S)/(2\pi)^d.$
\end{proof}
\noindent We shall now focus on the case in which $\xi_0\in\Omega(\phi)$ is of imaginary homogeneous type for $\widehat{\phi}$. As discussed above,  \eqref{eq:LocalizedFourierInversionConvolutionPower} is oscillatory in nature; this is due to the fact that the ``principal" behavior of $\Gamma_{\xi_0}(\xi)$, for small $\xi$, is characterized by the purely imaginary polynomial $iQ_{\xi_0}$. Our main estimate is presented in Lemma \ref{lem:EstImagHom} and its proof makes use of \eqref{eq:BestIntegrationFormula} and a version of the Van der Corput lemma stated as Lemma \ref{lem:VdC}.


% following version of the Van der Corput lemma.


% \begin{framed}
% \begin{proposition}\label{prop:VanderCorput}
% Let $g\in C^1([a,b])$ be complex-valued and $f\in C^2([a,b])$ be real-valued and such that $f''(x)\neq 0$ for all $x\in [a,b]$. Then
% \begin{equation*}
% \abs{\int_a^b e^{if(x)}g(x)\,dx}\leq \min\left\{\frac{4}{\lambda_1},\frac{8}{\sqrt{\lambda_2}}\right\}\left(\|g\|_{L^\infty[a,b]}+\|g'\|_{L^1[a,b]}\right).
% \end{equation*}
% where $\lambda_1=\inf_{x\in[a,b]}\abs{f'(x)}$ and $\lambda_2=\inf_{x\in [a,b]}\abs{f''(x)}$.
% \end{proposition}
% \end{framed}


\noindent Before estimating \eqref{eq:LocalizedFourierInversionConvolutionPower} in the case that $\xi_0$ is of imaginary homogeneous type using the result of Lemma \ref{lem:VdC}, we first treat two preliminary lemmas. The first lemma (Lemma \ref{lem:PhaseDerivativeEstimate}) deals with the first and second derivative of the phase function that will appear in Eq. \eqref{eq:LocalizedFourierInversionConvolutionPower} following the use of the polar-coordinate integration formula. The second lemma (Lemma \ref{lem:AmplitudeSobolevEstimates}) deals with the $L^1$ and $L^\infty$ norm of the amplitude function. 


\begin{framed}
\begin{lemma}\label{lem:PhaseDerivativeEstimate}
Let $Q:\mathbb{R}^d\to\mathbb{R}$ be a continuous function for which $\abs{Q}$ is positive homogeneous with $\mu:=\mu_{\abs{Q}}<1$. Given a compact subset $S$ of $\mathbb{R}^d$ for which $0\notin S$, set
\begin{equation*}
    \rho=\inf_{\eta\in S}|Q(\eta)|/3>0.
\end{equation*}
For an open neighborhood $\mathcal{O}$ of $0$ in $\mathbb{R}^d$, suppose that $\widetilde{Q}:\mathcal{O}\to\mathbb{R}$ is a twice continuously differentiable function which is strongly subhomogeneous with respect to $E$ of order $2$, set $F=E/\mu$, and define
\begin{eqnarray*}
f_{n,\eta,x}(\theta)&=&-nQ(\theta^F\eta)-n\widetilde{Q}(\theta^F\eta)-x\cdot \theta^F\eta\\
&=&-n\theta^{1/\mu}Q(\eta)-n\widetilde{Q}(\theta^{F}\eta)-x\cdot \theta^{F}\eta
\end{eqnarray*}
for $n\in\mathbb{N}_+$, $\eta\in S$, $x\in\mathbb{R}^d$ and $\theta>0$ sufficiently small so that $\theta^F\eta\in\mathcal{O}$. Then, given any compact set $K$, there is a $\delta>0$ for which $\partial_\theta^2 f_{n,x,\eta}(\theta)\neq 0$ and
\begin{equation*}
    |\partial_\theta f_{n,x,\eta}(\theta)|\geq \frac{\rho}{\mu} n^{\mu}
\end{equation*}
for all $n\in\mathbb{N}_+$, $\eta\in S$,  $x\in K$, and $\theta>0$ for which $n^{-\mu}\leq \theta\leq \delta^\mu$.
\end{lemma}
\end{framed}


\begin{proof}
Let $E$ and $S$ be as in the statement of the lemma and write $f=f_{n,\eta,x}$. Because ${\theta^F}$ is contracting, let $\delta_1>0$ be such that
\begin{equation}\label{eq:PhaseDerivativeEstimate1}
    \abs{x\cdot \theta^F F \eta}\leq \frac{\rho}{\mu}\hspace{.5cm}\mbox{and}\hspace{.5cm}\abs{x\cdot \theta^F (F-I)Fx}\leq \frac{\rho}{\mu}\left(\frac{1}{\mu}-1\right)
\end{equation}
for all $0<\theta<\delta_1^\mu$, $x\in K$ and $\eta\in S$. By virtue of Proposition \ref{prop:2StronglySubhomogeneous}, there exists $\delta_2>0$ such that
\begin{equation}\label{eq:PhaseDerivativeEstimate2}
    \abs{\theta\partial_\theta \widetilde{Q}(\theta^F\eta)}\leq\frac{\rho}{\mu}\theta^{1/\mu}
\hspace{0.5cm}\mbox{and}\hspace{0.5cm}
    \abs{\theta^2\partial_{\theta}^2\widetilde{Q}(\theta^F\eta)}\leq\frac{\rho}{\mu}\left(\frac{1}{\mu}-1\right)\theta^{1/\mu}
\end{equation}
for all $0<\theta<\delta_2^{\mu}$ and $\eta\in S$. Set $\delta=\min\{\delta_1,\delta_2\}$. By virtue \eqref{eq:PhaseDerivativeEstimate1} and \eqref{eq:PhaseDerivativeEstimate2}, we have
\begin{eqnarray*}
    \abs{\theta^2\partial_{\theta}^2 f(\theta)}&=&\theta^2\abs{n\partial_\theta^2\left( \theta^{1/\mu}Q(\eta)+\widetilde{Q}(\theta^F\eta)\right)+\partial_\theta^2\left(x\cdot \theta^F\eta\right)}\\
    &=&\abs{\frac{n}{\mu}\left(\frac{1}{\mu}-1\right)\theta^{1/\mu}Q(\eta)+n\theta^2\partial_\theta^2\widetilde{Q}(\theta^F\eta)+\left(x\cdot \theta^F(F-I)F\eta\right)}\\
    &\geq& \frac{n}{\mu}\left(\frac{1}{\mu}-1\right)\theta^{1/\mu}\abs{Q(\eta)}-n\abs{\theta^2\partial_\theta^2\widetilde{Q}(\theta^F\eta)}-\abs{x\cdot\theta^F(F-I)F\eta}\\
    &\geq&\frac{3\rho n}{\mu}\left(\frac{1}{\mu}-1\right)\theta^{1/\mu}-\frac{\rho n}{\mu}\left(\frac{1}{\mu}-1\right)\theta^{1/\mu}-\frac{\rho}{\mu}\left(\frac{1}{\mu}-1\right)\\
    &\geq &\frac{\rho}{\mu}\left(\frac{1}{\mu}-1\right)\left(2n\theta^{1/\mu}-1\right)
\end{eqnarray*}
for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $0<\theta<\delta^\mu$. Given that $\theta\mapsto \theta^{1/\mu}$ is increasing, it follows that
\begin{equation*}
    \abs{\theta^2\partial_\theta^2 f(\theta)}\geq \frac{\rho}{\mu}\left(\frac{1}{\mu}-1\right)(2n\theta^{1/\mu}-1)\geq \frac{\rho}{\mu}\left(\frac{1}{\mu}-1\right)(2n (n^{-\mu})^{1/\mu}-1)=\frac{\rho}{\mu}\left(\frac{1}{\mu}-1\right)>0
\end{equation*}
and, in particular, $\partial_\theta^2 f(\theta)\neq 0$ for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $\theta>0$ for which $n^{-\mu}\leq\theta\leq\delta^{\mu}$. By another appeal to \eqref{eq:PhaseDerivativeEstimate1} and \eqref{eq:PhaseDerivativeEstimate2}, we find
\begin{eqnarray*}
    \abs{\partial_\theta f(\theta)} &=& \abs{n\partial_\theta \left(\theta^{1/\mu}Q(\eta)+\widetilde{Q}(\theta^F\eta)\right)+\partial_\theta\left(x\cdot \theta^F \eta\right)}\\
    &=&\abs{\frac{n}{\mu}\theta^{1/\mu-1}Q(\eta)+n\partial_\theta\widetilde{Q}(\theta^F\eta)+\theta^{-1}\left(x\cdot\theta^F F\eta\right)}\\
    &\geq &\frac{3\rho n}{\mu}\theta^{1/\mu-1}-n\theta^{-1}\abs{\theta\partial_\theta \widetilde{Q}(\theta^F\eta)}-\theta^{-1}\abs{x\cdot\theta^F F\eta}\\
    &\geq& \frac{3\rho n}{\mu}\theta^{1/\mu-1}-\frac{\rho n}{\mu}\theta^{1/\mu-1}-\frac{\rho}{\mu}\theta^{-1}\\
    &\geq &\frac{\rho}{\mu}\left(2n\theta^{1/\mu-1}-\theta^{-1}\right)
\end{eqnarray*}
for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $0<\theta<\delta^{\mu}$. Given our supposition that $\mu<1$, $\theta\mapsto\left( 2n\theta^{1/\mu-1}-\theta^{-1}\right)$ is increasing for $\theta>0$ and therefore
\begin{equation*}
 \abs{\partial_\theta f(\theta)}\geq\frac{\rho}{\mu}\left(2n\theta^{1/\mu-1}-\theta^{-1}\right)\geq \frac{\rho}{\mu}\left(2n(n^{-\mu})^{1/\mu-1}-(n^{-\mu})^{-1}\right)=\frac{\rho}{\mu}n^{\mu}
\end{equation*}
for all for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $\theta>0$ for which $n^{-\mu}\leq\theta\leq\delta^{\mu}$, as we asserted.
\end{proof}

% \begin{comment}\begin{proof}
% Let $E$ and $S$ be as in the statement of the lemma. For $n\in\mathbb{N}_+$, $\eta\in S$ and $x\in \mathbb{R}^d$, define
% \begin{eqnarray*}
% \Phi_{n,\eta,x}(r)&=&nQ(r^E\eta)+n\widetilde{Q}(r^E\eta)+x\cdot r^E\eta\\
% &=&nrQ(\eta)+n\widetilde{Q}(r^E\eta)+x\cdot r^E\eta
% \end{eqnarray*}
% for all $r>0$ sufficiently small so that $r^E\eta\in \mathcal{O}$.  We observe that, for $n\in\mathbb{N}_+$, $\eta\in S$ and $x\in\mathbb{R}^d$, 
% \begin{equation*}
% f_{n,\eta,x}(\theta)=-\Phi_{n,\eta,x}\left(\theta^{1/\mu}\right)
% \end{equation*}
% whenever $\theta^F\eta=(\theta^{1/\mu})^E\eta\in \mathcal{O}$. Let's suppose that, given a compact set $K$, there exists $0<\delta\leq 1$ for which
% \begin{equation}\label{eq:PhaseDerivativeEstimate2}
% \abs{\partial_r \Phi_{n,\eta,x}(r)}\geq\rho n
% \end{equation}
% for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $r>0$ for which $1/n\leq r\leq \delta$. Then, for this $\delta>0$, we have
% \begin{equation*}
%     \abs{\p_\theta f_{n,\eta,x} (\theta)} = 
%      \abs{  \p_{\theta^{1/\mu}} \Phi_{n,\eta,x}\left(\theta^{1/\mu}\right)}
%      \abs{ \f{\p \theta^{1/\mu}}{\p \theta}} 
%      \geq 
%     \rho n\f{\theta^{1/\mu - 1}  }{\mu}  \geq \f{\rho}{\mu}n^{\min\{\mu,1 \}}
% \end{equation*}
% for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $n^{-\mu}\leq \theta\leq \delta^{-\mu}$, which is our desired assertion. Thus, it suffices to prove \eqref{eq:PhaseDerivativeEstimate2}.


% To this end, we fix a compact set $K\subseteq\mathbb{R}^d$. Given that $r^E$ is contracting and $S$ and $K$ are compact, there is $\delta_1>0$ for which $|x\cdot r^E E\eta|\leq \rho$ for all $x\in K$, $\eta\in S$ and $0<r<\delta_1$. Also, because $\widetilde{Q}$ is strongly subhomogeneous with respect to $E$, we may find $\delta_2>0$ for which
% \begin{equation*}
%     |\partial_r\widetilde{Q}(r^E\eta)|\leq \rho
% \end{equation*}
% for all $0<r<\delta_2$ and $\eta\in S$. We set $\delta=\min\{\delta_1,\delta_2,1\}$ and observe that, for any $x\in K$, $\eta\in S$ and $0<r<\delta$, we have
% \begin{eqnarray*}
% \left|\partial_r
% \left(x\cdot r^E\eta
% +n\widetilde{Q}
% (r^E\eta)\right)
% \right|
% &\leq &
% \left|\partial_r\left(x\cdot r^E\eta\right)\right|+n\left|
% \partial_r\widetilde{Q}(r^E\eta)
% \right|\\
% &\leq&\frac{1}{r}|x\cdot r^E E\eta)|+n\rho\\
% &\leq& n|x\cdot r^E E\eta)|+n\rho\\
% &<&2n\rho.
% \end{eqnarray*}
% Therefore,
% \begin{eqnarray*}
% \abs{\partial_r\Phi_{n,\eta,x}(r)}&=&\abs{nQ(\eta)- \left(-\partial_r\left(x\cdot r^E\eta+n\widetilde{Q}(r^E\eta)\right)\right)}\\
% &\geq& n|Q(\eta)|-\left|\partial_r
% \left(x\cdot r^E\eta
% +n\widetilde{Q}
% (r^E\eta)\right)
% \right|\\
% &\geq& 3n\rho-2n\rho\\
% &\geq &n\rho
% \end{eqnarray*}
% for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $r>0$ for which $1/n\leq r\leq \delta$, as asserted.
% \end{proof}
% \end{comment}


\begin{framed}
\begin{lemma}\label{lem:AmplitudeSobolevEstimates}
Let $R$ be a positive homogeneous function with $G\in\Exp(R)$, $\widetilde{R}:\mathcal{O}\to\mathbb{R}$ be once continuously differentiable on a neighborhood $\mathcal{O}$ of $0$ which has $\widetilde{R}(0)=0$ and is strongly subhomogeneous with respect to $G$ of order $1$, and let $k$ and $\mu$ be positive real numbers. Set $F=(k/\mu) G$ and, for each $\eta\in S=\{\eta:R(\eta)=1\}$ and $n\in\mathbb{N}_+$, set
\begin{equation*}
    g_{n,\eta}(\theta)=e^{-n\left(R\left(\theta^F\eta\right)+\widetilde{R}\left(\theta^F\eta\right)\right)}
\end{equation*}
for $\theta>0$ which is sufficiently small so that $\theta^F\eta\in\mathcal{O}$. Then, for each $\beta>1$, there is $\delta>0$ for which 
\begin{equation*}
    \|g_{n,\eta}\|_{L^\infty[\theta_1,\theta_2]}\leq 1
\end{equation*}
and
\begin{equation*}
    \|\partial_\theta g_{n,\eta}\|_{L^1[\theta_1,\theta_2]}\leq \beta
\end{equation*}
uniformly for $\eta\in S$, $n\in\mathbb{N}$ and $0<\theta_1\leq\theta_2\leq \delta^{\mu}$.
\end{lemma}
\end{framed}
\begin{proof}
By virtue of the strong subhomogeneity of $\widetilde{R}$, Proposition \ref{prop:supersub_implies_sub}, and the fact that $r^G$ is a contracting group, we may choose $\delta>0$ for which 
\begin{equation}\label{eq:AmplitudeSobolevEstimates1}
    R(r^G\eta)+\widetilde{R}\left(r^G\eta\right)=r+\widetilde{R}\left(r^G\eta\right)\geq (1-\epsilon)r>0
\end{equation}
and
\begin{equation}\label{eq:AmplitudeSobolevEstimates2}
    \abs{\partial_r\left(R(r^G\eta)+\widetilde{R}(r^G\eta)\right)}\leq 1+\epsilon
\end{equation}
for all $0<r<\delta^k$ and $\eta\in S$ where
\begin{equation*}
    \epsilon=\frac{\beta-1}{\beta+1}\in(0,1).
\end{equation*}
In view of \eqref{eq:AmplitudeSobolevEstimates1}, for any $0<\theta_1\leq\theta_2<\delta^{\mu}$, $\eta\in S$ and $n\in\mathbb{N}_+$,
\begin{equation*}
\|g_{n,\eta}\|_{L^\infty[\theta_1,\theta_2]}\leq\sup_{0<\theta\leq\delta^{\mu}}\abs{g_{n,\eta}(\theta)}=\sup_{0<r\leq\delta^k}\abs{g_{n,\eta}(r^{\mu/k})}\leq \sup_{0<r\leq \delta^k}e^{-nr(1-\epsilon)}= 1
\end{equation*}
where we have used the fact that $(r^{\mu/k})^F=r^{(\mu/k)F}=r^G$ for $r>0$. By virtue of \eqref{eq:AmplitudeSobolevEstimates1} and \eqref{eq:AmplitudeSobolevEstimates2}, we find that
\begin{eqnarray*}
\|\partial_{\theta}g_{n,\eta}\|_{L^1[\theta_1,\theta_2]}
&=&\int_{\theta_1}^{\theta_2}\abs{\p_\theta g_{n,\eta}(\theta)}\,d\theta\\
&=&\int_{\theta_1^{k/\mu}}^{\theta_2^{k/\mu}}\abs{\p_r \lp g_{n,\eta}(r^{\mu/k})\rp}\,dr\\
&=&\int_{\theta_1^{k/\mu}}^{\theta_2^{k/\mu}}\abs{\p_r \left(e^{-n\left(R(r^G\eta)+\widetilde{R}(r^G\eta)\right)}\right) }\,dr\\
&=&\int_{\theta_1^{k/\mu}}^{\theta_2^{k/\mu}}n\abs{\partial_r\left(R(r^G\eta)+\widetilde{R}(r^G\eta)\right)}\abs{e^{-nR(r^G\eta)+\widetilde{R}(r^G\eta)}}\,dr\\
&\leq&\int_{\theta_1^{k/\mu}}^{\theta_2^{k/\mu}}n(1+\epsilon)e^{-n(1-\epsilon)r}\,dr\\
&\leq &\frac{1+\epsilon}{1-\epsilon}\int_0^\infty e^{-r}\,dr=\beta
\end{eqnarray*}
for all $n\in\mathbb{N}_+$, $\eta\in S$ and $0<\theta_1\leq\theta_2\leq\delta^{\mu}$, as desired.
\end{proof}



\begin{framed}
\begin{lemma}\label{lem:EstImagHom}
Suppose that $\xi_0$ is of imaginary homogeneous type for $\widehat{\phi}$ with associated drift $\alpha_{\xi_0}$ and homogeneous order $\mu_{\xi_0}$. If $\alpha_{\xi_0}=0$ and $\mu_{\xi_0}<1$, then, for each compact set $K$, there is an open neighborhood $\mathcal{O}_{\xi_0}\subseteq\Interior(\mathbb{T}_\phi^d)$ of $\xi_0$, which can be taken as small as desired, and a constant $C_{\xi_0}$ for which
\begin{equation*}
    \abs{\f{1}{(2\pi)^d}\int_{\mathcal{O}_{\xi_0}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi}\leq C_{\xi_0}n^{-\mu_{\xi_0}}
\end{equation*}
for all $x\in K$ and $n\in\mathbb{N}_+$.
\end{lemma}
\end{framed}
\begin{proof}
For simplicity of notation, we will write $Q=Q_{\xi_0}$, $\widetilde{Q}=\widetilde{Q}_{\xi_0}$, $R=R_{\xi_0}$, $\widetilde{R}=\widetilde{R}_{\xi_0}$ and $\mu=\mu_{\xi_0}$. We fix a compact set $K\subseteq\mathbb{R}^d$ and let $E$ and $k$ as given in Definition \ref{def:Types}. In studying the proof of Lemma \ref{lem:EstPosHom} and \eqref{eq:WlogCenterAtZero}, in particular, it is evident that we may assume $\xi_0=0$ and $\widehat{\phi}(0)=1$ without loss of generality. Given that $G:=E/k\in\Exp(R)$, set
\begin{equation*}
    F=(k/\mu)G=E/\mu.
\end{equation*} Using the positive homogeneous structure of $R$, let $\sigma_R$ be the measure on $S=\{\eta\in \mathbb{R}^d:R(\eta)=1\}$ as guaranteed by Theorem \ref{thm:BestIntegrationFormula}. By setting
\begin{equation*}
    \rho=\inf_{\eta\in S}|Q(\eta)|/3,
\end{equation*}
an appeal to Lemma \ref{lem:PhaseDerivativeEstimate} guarantees a $\delta_1>0$ for which 
\begin{equation}\label{eq:EstImagHom1}
    \abs{\partial_{\theta}f_{n,\eta,x}(\theta)}\geq \frac{\rho}{\mu}n^{\mu}\hspace{1cm}\mbox{and}\hspace{1cm}\partial_\theta^2 f_{n,\eta,x}(\theta)\neq 0
\end{equation} for all $n\in\mathbb{N}_+$, $\eta\in S$, $x\in K$ and $\theta>0$ for which $n^{-\mu}\leq \theta\leq \delta_1^\mu$. An appeal to Lemma \ref{lem:AmplitudeSobolevEstimates} guarantees $\delta_2>0$ for which
\begin{equation}\label{eq:EstImagHom2}
    \|g_{n,\eta}\|_{L^\infty[\theta_1,\theta_2]}
    +
    \|\p_\theta g_{n,\eta} \|_{ L^1[\theta_1,\theta_2]}
    \leq 3
\end{equation}
for all $n\in\mathbb{N}_+$, $\eta\in S$ and $0<\theta_1\leq\theta_2\leq\delta_2^{\mu}$. We set $\mathcal{O}=\{\eta\in\mathbb{R}^d:R(\eta)<\delta^k\}$
where $0<\delta\leq \min\{\delta_1,\delta_2\}$ is as small as desired; this is necessarily an open neighborhood of $0$. We have
\begin{eqnarray*}
    \int_{\mathcal{O}}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi
    &=&
    \int_S\int_0^{\delta^{k}}\widehat{\phi}^n(r^G\eta)e^{-ix\cdot r^G\eta}r^{\mu/k-1}\,dr \sigma_R(d\eta)\\
    &=&
    \frac{k}{\mu}\int_S \int_0^{\delta^{\mu}} \widehat{\phi}^n(\theta^{F} \eta) e^{-i x\cdot\theta^F \eta}  \,d\theta \,\sigma_R(d\eta)\\
    &=&
    \frac{k}{\mu}\int_S I_{n,x}(\eta)\,\sigma_R(d\eta)
\end{eqnarray*}
where we have made the change of variables $\theta=r^{\mu/ k}$ and set
\begin{eqnarray*}
    I_{n,x}(\eta)&=&\int_0^{\delta^{\mu}}\widehat{\phi}^n(\theta^F\eta)e^{-ix\cdot\theta^F\eta}\,d\theta.
\end{eqnarray*}
For each $n\in\mathbb{N}_+$, $\eta\in S$, and $x\in\mathbb{R}^d$, we have
\begin{eqnarray*}
\abs{I_{n,x}(\eta)}
&\leq & 
\abs{\int_{n^{-\mu}}^{\delta^{\mu}}\widehat{\phi}^n(\theta^F\eta)e^{-ix\cdot\theta^F\eta}\,d\theta} +\int_{0}^{n^{-\mu}}\abs{\widehat{\phi}^n(\theta^F\eta)}\,d\theta\\
&\leq& \abs{\int_{n^{-\mu}}^{\delta^\mu} e^{-i\left(nQ\left(\theta^F\eta\right)+n\widetilde{Q}\left(\theta^F\eta\right)+x\cdot\theta^F\eta\right)}e^{-n\left(R\left(\theta^F\eta\right)+\widetilde{R}\left(\theta^F\eta\right)\right)}\,d\theta}+n^{-\mu}\\
& &\hspace{1cm}=\abs{\int_{n^{-\mu}}^{\delta^\mu} e^{i f_{n,\eta,x}(\theta) } g_{n,\eta}(\theta)\,d\theta} 
+ n^{-\mu}.
\end{eqnarray*}
In view of \eqref{eq:EstImagHom1} and \eqref{eq:EstImagHom2}, an appeal to Lemma \ref{lem:VdC} guarantees that, for any $n\in\mathbb{N}_+$, $\eta\in S$ and $x\in K$,
\begin{eqnarray*}
 \hspace{-1cm}\abs{\int_{n^{-\mu}}^{\delta^\mu}e^{if_{n,\eta,x}(\theta)}g_{n,\eta}(\theta)\,d\theta}
    &\leq& 
    4
    \frac{ 
    \|g_{n,\eta}\|_{L^\infty[n^{-\mu},\delta^{\mu}]}
    +
    \|\partial_{\theta}g_{n,\eta}\|_{L^1[n^{-\mu},\delta^{\mu}]}
    }{
    \inf_{n^{-\mu}\leq\theta\leq \delta^{\delta}}|\partial_{\theta}f_{n,x,\eta}(\theta)|
    }\\
    &\leq& 4\frac{3}{(\rho/\mu) n^{\mu}}=\frac{12\mu}{\rho}n^{-\mu}
\end{eqnarray*}
and so
\begin{equation*}
    \abs{I_{n,x}(\eta)}\leq \left(\frac{12\mu}{\rho}\right)n^{-\mu}+n^{-\mu}\leq \left(\frac{12\mu}{\rho}+1\right)n^{-\mu}.
\end{equation*}
Thus, for all $n\in\mathbb{N}_+$ and $x\in K$,
\begin{eqnarray*}
\abs{\f{1}{(2\pi)^d}\int_{\mathcal{O}}\widehat{\phi}^n(\xi)e^{-i\xi\cdot x}\,d\xi}
&=&\frac{1}{(2\pi)^d}\f{k}{\mu}\abs{\int_S I_{n,x}(\eta)\,\sigma_R(d\eta)} \\
&\leq& \frac{1}{(2\pi)^d}\f{k}{\mu}\int_S \abs{I_{n,x}(\eta)}\,\sigma_R(d\eta)\\
&\leq& Cn^{-\mu}
\end{eqnarray*}
where
\begin{equation*}
    C=\f{1}{(2\pi)^d} \f{k}{\mu} \left(\frac{12\mu}{\rho}+1\right)\sigma_R(S).
\end{equation*}
\end{proof}




\begin{proof}[Proof of Theorem \ref{thm:ConvolutionPowerEstimate}]
Let $K\subseteq\mathbb{R}^d$ be a compact set. As we discussed in the paragraph preceding the theorem, the set $\Omega(\phi)$ is finite and so we may write
\begin{equation*}
    \Omega(\phi)=\{\xi_1,\xi_2,\dots,\xi_N,\xi_{N+1},\xi_{N+2},\dots,\xi_M\}
\end{equation*}
where our labeling assumes that the points $\xi_1,\xi_2,\dots,\xi_N$ are of imaginary homogeneous type for $\widehat{\phi}$ and the points $\xi_{N+1},\xi_{N+2},\dots,\xi_M$ are of positive homogeneous type for $\widehat{\phi}$. In view of the theorem's hypotheses, for each $j=1,2,\dots,N$, the point $\xi_j$, which is of imaginary homogeneous type for $\widehat{\phi}$, has drift $\alpha_{\xi_j}=0$ and homogeneous order $\mu_j:=\mu_{\xi_j}<1$. Thus, for each $j=1,2,\dots,N$, an appeal to Lemma \ref{lem:EstImagHom} guarantees an open neighborhood $\mathcal{O}_j=\mathcal{O}_{\xi_j}\subseteq\Interior(\mathbb{T}_\phi^d)$ of $\xi_j$ and a constant $C_j=C_{\xi_j}$ for which
\begin{equation}\label{eq:ConvolutionPowerEstimate1}
    \abs{\frac{1}{(2\pi)^d}\int_{\mathcal{O}_j}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi}\leq C_j n^{-\mu_j}
\end{equation}
for all $n\in\mathbb{N}_+$ and $x\in K$. For each $j=N+1,N+2,\dots M$, an appeal to Lemma \ref{lem:EstPosHom} guarantees an open neighborhood $\mathcal{O}_j=\mathcal{O}_{\xi_j}\subseteq\Interior(\mathbb{T}_\phi^d)$ of $\xi_j$ and a constant $C_j=C_{\xi_j}$ for which 
\begin{equation}\label{eq:ConvolutionPowerEstimate2}
        \abs{\frac{1}{(2\pi)^d}\int_{\mathcal{O}_j}\widehat{\phi}^n(\xi)e^{-ix\cdot\xi}\,d\xi}\leq C_jn^{-\mu_j}
\end{equation}
for all $n\in\mathbb{N}_+$ and $x\in\mathbb{R}^d$ where $\mu_j:=\mu_{\xi_j}$ is the homogeneous order associated to $\xi_j$. As guaranteed by the lemmas, let us take this collection of open sets $\mathcal{O}_1,\mathcal{O}_2,\dots,\mathcal{O}_M\subseteq\mathbb{T}_{\phi}^d$ to be mutually disjoint and define
\begin{equation}
    \mathcal{G}=\mathbb{T}_{\phi}^d\setminus\left(\bigcup_{j=1}^M \mathcal{O}_j\right).
\end{equation}
Given that $\mathcal{G}$ is a closed set which contains no elements of $\Omega(\phi)$,
\begin{equation*}
s:=\sup_{\xi\in\mathcal{G}}\abs{\widehat{\phi}(\xi)}<1.
\end{equation*}
By virtue of \eqref{eq:FourierInversionConvolutionPower}, \eqref{eq:ConvolutionPowerEstimate1}, \eqref{eq:ConvolutionPowerEstimate2}, and the disjointness of the collection $\mathcal{O}_1,\mathcal{O}_2,\dots,\mathcal{O}_M$, we have
\begin{eqnarray}\label{eq:ConvolutionPowerEstimate3}\nonumber
    \abs{\phi^{(n)}(x)}
    &=&\abs{\lb \sum_{j=1}^M\frac{1}{(2\pi)^d}\int_{\mathcal{O}_j}\widehat{\phi}^n(\xi)e^{-x\cdot\xi}\,d\xi \rb
    +\frac{1}{(2\pi)^d}\int_{\mathcal{G}}\widehat{\phi}^n(\xi)e^{-x\cdot\xi}\,d\xi}\\\nonumber
    &\leq&\sum_{j=1}^M\abs{\frac{1}{(2\pi)^d}\int_{\mathcal{O}_j}\widehat{\phi}^n(\xi)e^{-x\cdot\xi}\,d\xi}+\abs{\frac{1}{(2\pi)^d}\int_{\mathcal{G}}\widehat{\phi}^n(\xi)e^{-x\cdot\xi}\,d\xi}\\
    &\leq&\sum_{j=1}^M C_jn^{-\mu_j}+s^n
\end{eqnarray}
for all $n\in\mathbb{N}_+$ and $x\in K$. Upon noting that $\mu_\phi=\min\{\mu_1,\mu_2,\dots,\mu_M\}$, we have
\begin{equation*}
    n^{-\mu_j}=O(n^{-\mu_\phi})
\end{equation*}
as $n\to\infty$ for each $j=1,2,\dots M$. Also, because $s<1$, $s^n=o(n^{-\mu_\phi})$ as $n\to \infty$. With these two observations, the theorem follows immediately from \eqref{eq:ConvolutionPowerEstimate3}.
\end{proof}



\section{Examples}\label{sec:Examples}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In this section, we give a number of examples illustrating the results of Theorem \ref{thm:ConvolutionPowerEstimate}, all of which are beyond the scope of validity of the results of \cite{randles_convolution_2017}. First, we treat a useful proposition which gives sufficient conditions for a point $\xi_0\in\Omega(\phi)$ to be of positive homogeneous or imaginary homogeneous type for $\hat{\phi}$ in terms of the Taylor expansion for $\Gamma_{\xi_0}$.


\begin{framed}
\begin{proposition}\label{prop:ExpandGamma}
Let $\phi\in\mathcal{S}_d$ with $\sup_{\xi}|\widehat{\phi}(\xi)|=1$ and let $\xi_0\in\Omega(\phi)$. Suppose that there exists $\mathbf{m}\in \mathbb{N}^d_+$ and some $k \geq 1$ such that the Taylor expansion of $\Gamma_{\xi_0} : \mathcal{U}\to\mathbb{C}$ centered at $0$ is a series of the form
\begin{eqnarray}\label{eq:SemiEllipticImaginaryExpansion}\nonumber
    \Gamma_{\xi_0}(\xi) 
    &=& i\al_{\xi_0} \cdot \xi - i \left( \sum_{\abs{\be : 2\mathbf{m}} \geq 1} A_\be \xi^\be\right) - \sum_{\abs{\be : 2\mathbf{m}} \geq k} B_\be \xi^\be \\ \nonumber
    &=& i\al_{\xi_0} \cdot \xi - i \lp \sum_{\abs{\be : 2\mathbf{m}} = 1} A_\be \xi^\be + \sum_{\abs{\be : 2\mathbf{m}} > 1} A_\be \xi^\be\rp 
    - \lp \sum_{\abs{\be : 2\mathbf{m}} = k} B_\be \xi^\be + \sum_{\abs{\be : 2\mathbf{m}} > k} B_\be \xi^\be \rp \\
    &=&  i\al_{\xi_0} \cdot \xi - i\lp Q_{\xi_0}(\xi) + \widetilde{Q}_{\xi_0}(\xi)\rp - \lp R_{\xi_0}(\xi) + \widetilde{R}_{\xi_0}(\xi) \rp,
\end{eqnarray}
where $\al_{\xi_0} \in \mathbb{R}^d$;   $Q_{\xi_0}$ and $R_{\xi_0}$ are real-valued polynomials for which $R_{\xi_0}$ is positive definite; and  $\widetilde{Q}_{\xi_0},$ and $\widetilde{R}_{\xi_0}$ are real multivariate power series which are absolutely and uniformly convergent on $\mathcal{U}$. If $k=1$, then $\xi_0$ is of positive homogeneous type for $\widehat{\phi}$. If $k>1$ and $|Q_{\xi_0}|$ is positive definite, then $\xi_0$ is of imaginary homogeneous type for $\hat{\phi}$. In either case, $\xi_0$ has drift $\alpha_{\xi_0}$ and homogeneous order
\begin{equation*}
    \mu_{\xi_0}=\abs{\mathbf{1}:2\mathbf{m}}=\sum_{j=1}^d\frac{1}{2m_j}.
\end{equation*}
\end{proposition}
\end{framed}

\noindent Before proving the proposition, we shall first take care of the following useful lemma.

\begin{framed}
\begin{lemma}
Given an open neighborhood $\mathcal{U}$ of $0$ in $\mathbb{R}^d$, suppose that $Q:\mathcal{U}\to\mathbb{C}$ is real-analytic on $\mathcal{U}$ with absolutely and uniformly convergent series expansion
\begin{equation*}
    Q(\xi)=\sum_{|\beta:\mathbf{n}|>1}A_\beta\xi^\beta
\end{equation*}
for some $\mathbf{n}\in\mathbb{N}_+^d$. Consider $E\in\End(\mathbb{R}^d)$ with standard representation $\diag(1/n_1,1/n_2,\dots,1/n_d)$. Then, for each $k\in\mathbb{N}_+$, $Q$ is strongly subhomogeneous with respect to $E$ of order $k$. 
\end{lemma}
\end{framed}
\begin{proof}
It suffices to show that, for each, $j\in\mathbb{N}_+$, $\epsilon>0$ and compact set $K\subseteq\mathbb{R}^d$, there is a $\delta>0$ for which
\begin{equation*}
    \abs{r^j\partial_r^jQ(r^E\eta)}\leq \epsilon r
\end{equation*}
for all $0<r<\delta$ and $\eta\in K$. To this end, we fix $j$, $\epsilon$, and $K$ as above and write $Q=Q_1+Q_2$ where
\begin{equation*}
Q_1(\xi)=\sum_{1+\rho\leq |\beta:\mathbf{n}|\leq 2j+2}A_\beta\xi^\beta
\hspace{0.5cm}\mbox{and}\hspace{0.5cm}
    Q_2(\xi)=\sum_{|\beta:\mathbf{n}|> 2j+2}A_{\beta}\xi^\beta
\end{equation*}
where $\rho:=\min\{|\beta:\mathbf{n}|:A_\beta\neq 0\}-1>0$.
For each $q\geq 1$ and $l\in \mathbb{N}_+$, define
\begin{equation*}
    \mathcal{P}(q,l)=q(q-1)(q-2)\cdots (q-(l-1)).
\end{equation*}
In this notation, we observe that 
\begin{equation*}
    \partial_r^j(r^E\xi)^\beta=\partial_r^j\left(r^{|\beta:\mathbf{n}|}\xi^\beta\right)=\mathcal{P}(|\beta:\mathbf{n}|,j)r^{|\beta:\mathbf{n}|-j}\xi^\beta
\end{equation*}
for $\xi\in\mathbb{R}^d$, $r>0$ and $\beta\in\mathbb{N}^d$.
Because $Q_1$ is a polynomial and $K$ is compact, we have
\begin{equation*}
    M_1:=\sup_{\eta\in K}\lp\sum_{1+\rho\leq |\beta:\mathbf{n}|\leq 2j+2}\abs{A_\beta \mathcal{P}(|\beta:\mathbf{n}|,j)\eta^\beta}\rp<\infty.
\end{equation*}
Given that $Q$ is absolutely and uniformly convergent on $\mathcal{U}$, let $\mathcal{O}\subseteq \overline{\mathcal{O}}\subseteq\mathcal{U}$ be an open neighborhood of $0$ for which
\begin{equation*}
    M_2:=\sup_{\xi\in \mathcal{O}}\lp \sum_{|\beta:\mathbf{n}|>2j+2}\abs{A_\beta\xi^\beta}\rp<\infty.
\end{equation*}
We now specify $\delta$. First, given that $\{r^E\}$ and $\{r^{E/4}\}$ are contracting and the set $K$ is compact, we may find a $0<\delta_1\leq 1$ for which $r^E\eta$ and $r^{E/4}\eta$ belong to $\mathcal{O}$ whenever $0<r<\delta_1$ and $\eta\in K$. Also, there exists $\delta_2>0$ for which
\begin{equation}\label{eq:PermuationEst}
    \abs{\mathcal{P}(q,j)}r^{q/4}\leq 1
\end{equation}
for all $q>j$ and $0<r\leq \delta_2$; it is sufficient to take $\delta_2=e^{-4j}$.  Finally, given that $\rho>0$, let $\delta_3>0$ be such that
\begin{equation*}
    M_1 r^\rho+M_2r<\epsilon
\end{equation*}
for all $0<r<\delta_3$. Set $\delta=\min\{\delta_1,\delta_2,\delta_3\}$ and observe that
for all $\eta\in K$ and $0<r<\delta$, we have
\begin{eqnarray*}
    \abs{r^j\partial_r^jQ_1(r^E\eta)}&=&r^j\abs{\sum_{1+\rho\leq|\beta:\mathbf{n}|\leq 2j+2}A_\beta \partial_r^j\lp r^E\eta\rp^{\beta}}\\
    &\leq&r^j\sum_{1+\rho\leq|\beta:\mathbf{n}|\leq 2j+2}\abs{A_\beta\mathcal{P}(|\beta:\mathbf{n}|,j)r^{|\beta:\mathbf{n}|-j}\eta^\beta}\\
    &\leq&r^{1+\rho}\sum_{1+\rho\leq |\beta:\mathbf{n}|\leq 2j+2}\abs{A_\beta \mathcal{P}(|\beta:\mathbf{n}|,j)\eta^\beta}\\
&\leq&r  M_1r^\rho.
\end{eqnarray*}
By virtue of \eqref{eq:PermuationEst}, for each $q=|\beta:\mathbf{n}|>2j+2$, we have
\begin{eqnarray*}
    \abs{\partial_r^j\lp A_\beta(r^E\eta)^\beta\rp}&=&\abs{A_\beta}\abs{\mathcal{P}(|\beta:\mathbf{n}|,j)}r^{|\beta:\mathbf{n}|-j}\abs{\eta^\beta}\\
    &=&r^{|\beta:\mathbf{n}|/2-j}\abs{A_\beta}\abs{\mathcal{P}(|\beta:\mathbf{n}|,j)r^{|\beta:\mathbf{n}|/4}}\abs{(r^{E/4}\eta)^\beta}\\
    &\leq& r\abs{A_\beta(r^{E/4}\eta)^\beta}
\end{eqnarray*}
for all $0<r<\delta\leq\delta_2$ and $\eta\in K$. It follows that
\begin{eqnarray*}
    \abs{\partial_r^jQ_2(r^E\eta)}&=&\abs{\sum_{|\beta:\mathbf{n}|> 2j+2}\partial_r^j\lp A_\beta(r^E\eta)^\beta\rp}\\
    &\leq & \sum_{|\beta:\mathbf{n}|>2j+2}\abs{\partial_r^j\lp A_\beta(r^E\eta)^\beta\rp}\\
    &\leq&\sum_{|\beta:\mathbf{n}|>2j+2}r\abs{A_\beta(r^{E/4}\eta)^\beta}\\
    &\leq &rM_2
\end{eqnarray*}
for all $0<r<\delta$ and $\eta\in K$. Therefore, for each $0<r<\delta$ and $\eta\in K$, we have
\begin{eqnarray*}
    \abs{r^j\partial_r^jQ(r^E\eta)}&\leq&\abs{r^j\partial_r^jQ_1(r^E\eta)}+\abs{r^j\partial_r^jQ_2(r^E\eta)}\\
    &\leq& rr^\rho M_1+r^{j+1}M_2\\
    &\leq& r(M_1r^\rho+M_2r)\\
    &<&r \epsilon.
\end{eqnarray*}
\end{proof}

\begin{proof}[Proof of Proposition \ref{prop:ExpandGamma}.]
It is easy to see that $E\in \Exp(Q_{\xi_0})\cap\Exp(\abs{Q_{\xi_0}})$ and $E/k\in\Exp(R_{\xi_0})$ for $E\in\End(\mathbb{R}^d)$ with standard matrix representation 
\begin{equation*}
\diag((2m_1)^{-1}, (2m_2)^{-1},\dots, (2m_d)^{-1}).
\end{equation*}
If $k=1$, $R_{\xi_0}$ is positive homogeneous with $E\in\Exp(R_{\xi_0})\cap\Exp(Q_{\xi_0})$. By virtue of the preceding lemma (with $\mathbf{n}=2\mathbf{m}$), $\widetilde{Q}_{\xi_0}$ and $\widetilde{R}_{\xi_0}$ are strongly subhomogeneous with respect to $E$ of order $1$ and so, in view of Proposition \ref{prop:supersub_implies_sub}, both are subhomogeneous with respect to $E$. In this case, we may conclude that $\xi_0$ is of positive homogeneous type for $\widehat{\phi}$ with drift $\alpha_{\xi_0}$ and homogeneous order
\begin{equation*}
    \mu_{\xi_0}=\tr E=|\mathbf{1}:2\mathbf{m}|=\sum_{j=1}^d\frac{1}{2m_j}.
\end{equation*}
If $k>1$, our supposition guarantees that $\abs{Q_{\xi_0}}$ is positive homogeneous with respect to $E$ and $R_{\xi_0}$ is positive homogeneous with respect to $E/k$. By virtue of the preceding lemma, $\widetilde{Q}_{\xi_0}$ is strongly subhomogeneous with respect to $E$ of order $2$ and $\widetilde{R}_{\xi_0}$ is strongly subhomogeneous with respect to $E/k$ of order $1$. Consequently, $\xi_0$ is of imaginary homogeneous type for $\widehat{\phi}$ with drift $\alpha_{\xi_0}$ and homogeneous order $\mu_{\xi_0}=\tr E$ as in the previous case.
\end{proof}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




% \begin{comment}%% EXAMPLE 5
% \begin{example}\normalfont
% Consider the function $\phi : \mathbb{Z}^2 \to \mathbb{C}$ defined by 
% \begin{equation*}
%     \phi(x,y) =
%     \frac{1}{192}
%     \begin{cases}
%     144 - 64i &(x,y) = (0,0)\\
%     16 + 16i &(x,y) = (\pm 1, 0)\mbox{ or }(0,\pm 1)\\
%     -4        &(x,y) = (\pm 2,0)\mbox{ or }(0,\pm 2)\\
%     i   &(x,y) = \pm(1,1)\\
%     -i   &(x,y) = \pm(1,-1)\\
%     0& \text{otherwise}.
%     \end{cases}
% \end{equation*}
% It is easily verified that $\sup_{\xi}|\widehat{\phi}|=1$ and $\Omega(\phi) = \{\xi_0 \}$ where $\xi_0=(0,0)$. Since $\phi$ is finitely supported, $\Gamma_{0}=\Gamma_{\xi_0}$ is $\mathbb{C}^2$ analytic on its domain and so its Taylor series converges absolutely and uniformly on an open neighborhood $\mathcal{U}\subseteq \mathbb{R}^2$ of $0$. By a straightforward computation, we find
% \begin{eqnarray*}
% \Gamma_{0}(\xi)
% &=& 
% -i\lp \frac{\tau^2}{12} +\frac{\tau\zeta}{48} + \frac{\zeta^2}{12}   \rp
% -i \sum_{|\beta:(2,2)|\geq 2}A_\beta \xi^\beta\\
% && 
% \hspace{1.3cm}-\lp \frac{5\tau^4}{288} -\f{\tau^3\zeta}{576} -\frac{11\tau^2\zeta^2}{1536}-\frac{\tau\zeta^3}{576} + \frac{5\zeta^4}{288}  \rp 
% - \sum_{|\beta:(2,2)|\geq 6}B_\beta \xi^\beta\\
% &=&-i\lp Q_{0}(\xi)+\widetilde{Q}_{0}(\xi)\rp-\lp R_0(\xi)+\widetilde{R}_0(\xi)\rp
% \end{eqnarray*}
% where
% \begin{equation*}
% Q_{0}(\xi)=\sum_{|\beta:(2,2)|=1}A_\beta \xi^\beta=\frac{\tau^2}{12} +\frac{\tau\zeta}{48} + \frac{\zeta^2}{12},
% \end{equation*}
% \begin{equation*}
% R_{0}(\xi)=\sum_{|\beta:(2,2)|=2}B_\beta\xi^\beta
% = \frac{5\tau^4}{288} -\f{\tau^3\zeta}{576} -\frac{11\tau^2\zeta^2}{1536}-\frac{\tau\zeta^3}{576} + \frac{5\zeta^4}{288}, 
% \end{equation*}
% \begin{equation*}
% \widetilde{Q}_{0}(\xi)= \sum_{|\beta:(2,2)|\geq 2}A_\beta \xi^\beta= - \frac{\tau^4}{144}  - \frac{\zeta^4}{144} - \frac{\tau\zeta^3}{288} + \cdots, 
% %\frac{31 \tau^2\zeta^4}{27648} + \cdots,
% %- \frac{\tau^3\zeta}{288} + \frac{95\tau^3\zeta^3}{331776} + \dots,
% \end{equation*}
% and
% \begin{eqnarray*}
% \widetilde{R}_{0}(\xi)=\sum_{|\beta:(2,2)|\geq 3}B_\beta \xi^\beta =
% -\f{5(\tau^6+\zeta^6)}{1728} + \f{(\tau^5\zeta+\tau\zeta^5)}{2304} + \frac{(\tau^4\zeta^2+\tau^2\zeta^4)}{1536} +   \frac{\tau^3\zeta^3}{1728} + \cdots, 
% %+ \f{\tau\zeta^5}{2304} - \f{5\zeta^6}{1728} + \cdots,
% \end{eqnarray*}
% for $\xi=(\tau,\zeta)\in\mathcal{U}$. Observe that this expansion is of the form \eqref{eq:SemiEllipticImaginaryExpansion} with $\alpha_0=(0,0)$, $\mathbf{m}=(1,1)$, and $k=2$. It is readily verified that $|Q_0|=Q_0$ and $R_0$ are positive definite and, by virtue of Proposition \ref{prop:ExpandGamma}, we conclude that $\xi_0=0$ is of imaginary homogeneous type for $\widehat\phi$ with drift $\alpha_0=0$ and homogeneous order
% \begin{equation*}
%     \mu_{\phi}=\mu_0=|\mathbf{1}:2\mathbf{m}|=\frac{1}{2}+\frac{1}{2}=1.
% \end{equation*}
% By an appeal to Theorem \ref{thm:ConvolutionPowerEstimate} we obtain, to each compact set $K\subseteq\mathbb{R}^2$, a positive constant $C$ for which
% \begin{equation}\label{eq:SecondOrderExampleDecay}
%     |\phi^{(n)}(x,y)|\leq \frac{C}{n^{\mu_\phi}}=\frac{C}{n}
% \end{equation}
% for all $n\in\mathbb{N}_+$ and $(x,y)\in K$. We note that this asymptotic behavior agrees with that of an aperiodic and irreducible random walk on $\mathbb{Z}^2$ whose distribution decays on the order of $n^{-d/2}=n^{-1}$ (see, e.g., Theorem 7.5 of \cite{randles_convolution_2017}). To illustrate this result, we consider the compact set $K = [-300, 300] \times [-300, 300]$ and define $f(n)=f_{\phi,K}(n)=\max_{(x,y)\in K}\abs{\phi^{(n)}(x,y)}$. Figure \ref{fig:Conv_Pwr_0} illustrates the power-law decay of $f(n)$ relative to that of $n^{-\mu_\phi}$ as predicted by \eqref{eq:SecondOrderExampleDecay} in accordance with Theorem \ref{thm:ConvolutionPowerEstimate}.\\


% \begin{figure}[!htb]
%     \begin{subfigure}{0.49\textwidth}
%     \centering
%     \includegraphics[scale=0.58]{Fig5a.eps}
%     \caption{$\log_2 f(n)$ and $\log_2 2n^{-1}$ versus $\log_2 n$}
%     \end{subfigure}
%     \begin{subfigure}{0.49\textwidth}
%     \centering
%     \includegraphics[scale=0.58]{Fig5b.eps}
%     \caption{$f(n)$ and $2n^{-1}$ versus $n$}
%     \end{subfigure}
%     \caption{Behavior of $f(n)=f_{\phi,K}(n)=\max_{(x,y)\in K}\abs{\phi^{(n)}(x,y)}$}
%     \label{fig:Conv_Pwr_0}
% \end{figure}


% \noindent Though the large-$n$ asymptotic behavior of $\max_{(x,y)\in K}\abs{\phi^{(n)}(x,y)}$, as discussed above, agrees with that of the probabilistic setting, the local (spatial) asymptotic behavior of $\phi^{(n)}$ is vastly different from that seen in the study of random walks wherein convolution powers are approximated by Gaussian densities. This local behavior is illustrated in Figure \ref{fig:Conv_Pwr_00}; specifically, Figures \ref{fig:Conv_Pwr_00a} and \ref{fig:Conv_Pwr_00b} illustrate the real part of $\phi^{(n)}$ for $n = 100, 1000$, respectively. A forthcoming article will treat local limit theorems which describe these illustrations. 

% \begin{figure}[!htb]
%     \begin{subfigure}{0.49\textwidth}
%     \centering
%     \includegraphics[scale=0.58]{Fig6a.eps}
%     \caption{$n = 100$.}
%     \label{fig:Conv_Pwr_00a}
%     \end{subfigure}
%     \begin{subfigure}{0.49\textwidth}
%     \centering
%     \includegraphics[scale=0.58]{Fig6b.eps}
%     \caption{$n = 1000$.}
%     \label{fig:Conv_Pwr_00b}
%     \end{subfigure}
%     \caption{$\Re\phi^{(n)}(x,y)$ for $n=100$ and $1000$}
%     \label{fig:Conv_Pwr_00}
% \end{figure}
% \end{example}
% \end{comment}


%%%%%% NEW EXAMPLE TO REPLACE the E = diag(1/2, 1/2) example:
%%%%%% EXAMPLE 6: E = diag(1/4,1/4)




\begin{example}\normalfont


Consider the function $\phi : \mathbb{Z}^2 \to \mathbb{C}$ defined by 
\begin{equation*}
    \phi(x,y) =
    \frac{1}{512}
    \begin{cases}
    372 - 96i &(x,y) = (0,0)\\
    56+32i &(x,y) = (\pm 1, 0)\mbox{ or }(0,\pm 1)\\
    -28-8i        &(x,y) = (\pm 2,0)\mbox{ or }(0,\pm 2)\\
    8       &(x,y) = (\pm 3,0)\mbox{ or }(0,\pm 3)\\
    -1        &(x,y) = (\pm 4,0)\mbox{ or }(0,\pm 4)\\
    0& \text{otherwise}.
    \end{cases}
\end{equation*}
It is easily verified that $\sup_{\xi}|\widehat{\phi}|=1$ and $\Omega(\phi) = \{\xi_0 \}$ where $\xi_0=(0,0)$. Since $\phi$ is finitely supported, $\Gamma_{0}=\Gamma_{\xi_0}$ is $\mathbb{C}^2$ analytic on its domain and so its Taylor series converges absolutely and uniformly on an open neighborhood $\mathcal{U}\subseteq \mathbb{R}^2$ of $0$. By a straightforward computation, we find 
\begin{eqnarray*}
\Gamma_{0}(\xi)
&=& 
-i\lp \frac{\tau^4}{64} + \frac{\zeta^4}{64}   \rp
-i \sum_{|\beta:(4,4)|\geq 2}A_\beta \xi^\beta\\
&& 
\hspace{1.3cm}
-\lp \f{15\tau^8}{8192} - \f{\tau^4\zeta^4}{4096} + \f{15\zeta^8}{8192}   \rp 
- \sum_{|\beta:(4,4)|\geq 6}B_\beta \xi^\beta\\
&=&-i\lp Q_{0}(\xi)+\widetilde{Q}_{0}(\xi)\rp-\lp R_0(\xi)+\widetilde{R}_0(\xi)\rp
\end{eqnarray*}
where
\begin{equation*}
Q_{0}(\xi)=\sum_{|\beta:(4,4)|=1}A_\beta \xi^\beta=\frac{\tau^4}{64} + \frac{\zeta^4}{64} ,
\end{equation*}
\begin{equation*}
R_{0}(\xi)=\sum_{|\beta:(4,4)|=2}B_\beta\xi^\beta
=  \f{15\tau^8}{8192} - \f{\tau^4\zeta^4}{4096} + \f{15\zeta^8}{8192}  , 
\end{equation*}
\begin{equation*}
\widetilde{Q}_{0}(\xi)= \sum_{|\beta:(4,4)| \geq 3/2}A_\beta \xi^\beta= 
-\f{\tau^6+\zeta^6}{384}  + \f{\tau^8 + \zeta^8}{5120}+  \f{7(\tau^4\zeta^8+\tau^8\zeta^4)}{262144} +
\cdots, 
\end{equation*}
and
\begin{eqnarray*}
\widetilde{R}_{0}(\xi)=\sum_{|\beta:(4,4)|\geq 5/2}B_\beta \xi^\beta 
=\f{(\tau^4\zeta^6 + \tau^6\zeta^4)}{24576} - \f{\tau^6\zeta^6}{147456} - \f{(\tau^4\zeta^8 + \tau^8\zeta^4)}{327680}
\cdots, 
\end{eqnarray*}
for $\xi=(\tau,\zeta)\in\mathcal{U}$. Observe that this expansion is of the form \eqref{eq:SemiEllipticImaginaryExpansion} with $\alpha_0=(0,0)$, $\mathbf{m}=(2,2)$, and $k=2$. It is readily verified that $|Q_0|=Q_0$ and $R_0$ are positive definite and, by virtue of Proposition \ref{prop:ExpandGamma}, we conclude that $\xi_0=0$ is of imaginary homogeneous type for $\widehat\phi$ with drift $\alpha_0=0$ and homogeneous order
\begin{equation*}
    \mu_{\phi}=\mu_0=|\mathbf{1}:2\mathbf{m}|=\frac{1}{4}+\frac{1}{4}=\f{1}{2}.
\end{equation*}
By an appeal to Theorem \ref{thm:ConvolutionPowerEstimate} we obtain, to each compact set $K\subseteq\mathbb{R}^2$, a positive constant $C$ for which
\begin{equation}\label{eq:SecondOrderExampleDecay}
    |\phi^{(n)}(x,y)|\leq \frac{C}{n^{\mu_\phi}}=\frac{C}{n^{1/2}}
\end{equation}
for all $n\in\mathbb{N}_+$ and $(x,y)\in K$. To illustrate this result, we consider the compact set $K = [-700, 700] \times [-700, 700]$ and define $f(n)=f_{\phi,K}(n)=\max_{(x,y)\in K}\abs{\phi^{(n)}(x,y)}$. Figure \ref{fig:Conv_Pwr_0_new} illustrates this result by capturing the decay of $f(n)=f_{\phi,K}(n)=\max_{(x,y)\in K}\abs{\phi^{(n)}(x,y)}$ relative to that of $n^{-\mu_\phi}$. Also, Figure \ref{fig:Conv_Pwr_00_new} illustrates the graph of $\Re \phi^{(n)}(x,y)$ for $(x,y)\in K$ and $n=200$ and $n=1000$.


\begin{figure}[!htb]
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig5a.eps}
    \caption{$\log_2 f(n)$ and $\log_2 n^{-1/2}$ versus $\log_2 n$}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig5b.eps}
    \caption{$f(n)$ and $n^{-1/2}$ versus $n$}
    \end{subfigure}
    \caption{Behavior of $f(n)=f_{\phi,K}(n)=\max_{(x,y)\in K}\abs{\phi^{(n)}(x,y)}$}
    \label{fig:Conv_Pwr_0_new}
\end{figure}


\begin{figure}[!htb]
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig6a.eps}
    \caption{$n = 100$.}
    \label{fig:Conv_Pwr_00a}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig6b.eps}
    \caption{$n = 1000$.}
    \label{fig:Conv_Pwr_00b}
    \end{subfigure}
    \caption{$\Re\phi^{(n)}(x,y)$ for $n=200$ and $1000$}
    \label{fig:Conv_Pwr_00_new}
\end{figure}
\end{example}






%%% EXAMPLE 7
\begin{example}\normalfont
Consider the function $\phi : \mathbb{Z}^2 \to \mathbb{C}$ defined by 
\begin{equation*}
    \phi(x,y) = 
    \f{1}{768}\times
    \begin{cases}
    602 - 112i &(x,y) = (0,0)\\
    56 + 32i   &(x,y) = (0,\pm 1)\mbox{ or }(-1,0)\\
    72 + 32i   &(x,y) = (1,0)\\
    -28 - 8i   &(x,y) = (0,\pm 2)\\
    -16        &(x,y) = (\pm 2,0)\\
    56         &(x,y) = (0,\pm 3)\\
    -1         &(x,y) = (0,\pm 4)\\
    4          &(x,y) = (-1,\pm 1)\\
    -4         &(x,y) = (1,\pm 1)\\
    0          &\text{otherwise}.
    \end{cases}
\end{equation*}
As with the preceding examples, it is easy to see that $\sup_{\xi}|\widehat{\phi}(\xi)|=1$, $\Omega(\phi)=\{\xi_0\}=\{(0,0)\}$ and $\Gamma_{0}=\Gamma_{\xi_0}$ has the absolutely and uniformly convergent Taylor expansion
\begin{equation*}
    \Gamma_{0}(\xi)=-i\left(Q_0(\xi)+\widetilde{Q}_0(\xi)\right)-\left(R_0(\xi)+\widetilde{R}_0(\xi)\right)
\end{equation*}
where
\begin{equation*}
    Q_0(\xi)=\sum_{|\beta:(2,4)|=1}A_\beta \xi^\beta=\frac{\tau^2}{24}-\frac{\tau\zeta^2}{96} +\frac{ \zeta^4}{96},
\end{equation*}
\begin{equation*}
    R_0(\xi)=\sum_{|\beta:(2,4)|=2}B_\beta \xi^\beta=\frac{23\tau^4}{1152}  + \frac{\tau^3\zeta^2}{2304}  - \frac{\tau^2\zeta^4}{2048} + \f{\tau\zeta^6}{9216}+ \frac{23\zeta^8}{18432},
\end{equation*}
\begin{equation*}
    \widetilde{Q}_0(\xi)=\sum_{|\beta:(2,4)|\geq 3/2}A_\beta \xi^\beta=- \frac{\tau^4}{288}+\frac{\tau\zeta^4}{1152} +\frac{\tau^3\zeta^2}{576}  -\frac{\tau^3\zeta^4}{6912} %+ \frac{43\tau^4\zeta^4}{221184} 
    + \cdots,
\end{equation*}
and
\begin{equation*}
    \widetilde{R}_0(\xi)=\sum_{|\beta:(2,4)|\geq 5/2}B_\beta \xi^\beta
    =  - \frac{\tau^3\zeta^4}{27648} + \frac{\tau^4\zeta^4}{18432} +  \frac{\tau^4\zeta^4}{18432} + \cdots
\end{equation*}
for $\xi=(\tau,\zeta)\in\mathcal{U}$ where $\mathcal{U}\subseteq\mathbb{R}^2$ is a neighborhood of $0$. In this case, the above expansion is of the form \eqref{eq:SemiEllipticImaginaryExpansion} with $\alpha_0=(0,0)$, $\mathbf{m}=(1,2)$ and $k=2$. Here, as with the previous examples, it is readily verified that $|Q_0|=Q_0$ and $R_0$ are positive definite and so an appeal to Proposition \ref{prop:ExpandGamma} guarantees that $\xi_0=(0,0)$ is of imaginary homogeneous type for $\widehat{\phi}$ with drift $\alpha_0=(0,0)$ and homogeneous order
\begin{equation*}
    \mu_\phi=\mu_0=|\mathbf{1}:2\mathbf{m}|=
    \frac{1}{2}+\frac{1}{4}=\frac{3}{4}.
\end{equation*}
By an appeal to Theorem \ref{thm:ConvolutionPowerEstimate}, we obtain, to each compact set $K$, a positive constant $C$ for which
\begin{equation}\label{eq:SecondOrderExampleDecay2}
    \abs{\phi^{(n)}(x,y)}\leq\frac{C}{n^{\mu_\phi}}=\frac{C}{n^{3/4}}
\end{equation}
for all $n\in\mathbb{N}$ and $(x,y)\in K$. Figure \ref{fig:Conv_Pwr_2} illustrates this result by capturing the decay of $f(n)=f_{\phi,K}(n)=\max_{(x,y)\in K}\abs{\phi^{(n)}(x,y)}$ where %$K=[-50,50]\times [-50,50]$
$K=[-300,300]\times [-300,300]$ relative to that of $n^{-\mu_\phi}$. Also, Figure \ref{fig:Conv_Pwr_20} illustrates the graph of $\Re \phi^{(n)}(x,y)$ for $(x,y)\in K$ and $n=300$ and $n=600$.


\begin{figure}[!htb]
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig7a.eps}
    \caption{$\log_2 f(n)$ and  $\log_2 2n^{-3/4}$ versus $\log_2 n$.}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig7b.eps}
    \caption{$f(n)$ and $2n^{-3/4}$ versus $n$}
    \end{subfigure}
    \caption{Behavior of $f(n)=f_{\phi,K}(n)=\max_{(x,y)\in K}\abs{\phi^{(n)}(x,y)}$.}
    \label{fig:Conv_Pwr_2}
\end{figure}

\begin{figure}[!htb]
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig8a.eps}
    \caption{$n=300$.}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig8b.eps}
    \caption{$n = 600$.}
    \label{fig:Conv_Pwr_2b}
    \end{subfigure}
    \caption{$\Re{\phi^{(n)}}$ for $n = 300$ and $n=600$}
    \label{fig:Conv_Pwr_20}
\end{figure}
\end{example}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%% INTERESTING EXAMPLE %%%%%%%%

\begin{example}\normalfont
This example illustrates a complex-valued function $\phi$ on $\mathbb{Z}^2$ whose Fourier transform is maximized in absolute value at two distinct points in $\mathbb{T}^2$, one of which is a point of imaginary homogeneous type for $\widehat{\phi}$ with homogeneous order $2/3$ and the other is a point of positive homogeneous type $\widehat{\phi}$ of homogeneous order $1$. We define $\phi: \mathbb{Z}^2 \to \mathbb{C}$ by $\phi=2^{-7}\phi_1-i2^{-11}\phi_2+2^{-21}\phi_3$ where
\begin{equation*}
    \phi_1(x,y)=\begin{cases}
    15 + 15i &(x,y) = (\pm 1,0)\\
    16 + 16i &(x,y) = (0, \pm 1)\\
     1 + 1i &(x,y) = (\pm 3,0)\\
    0 &\mbox{otherwise}
    \end{cases},
    \hspace{1cm}
    \phi_2(x,y) = 
    \begin{cases}
    682 &(x,y) = (0,0)\\
    152  &(x,y) = (\pm 2,0)\\
    -28  &(x,y) = (\pm 4,0)\\
    8 &(x,y) = (\pm 6, 0)\\
    -1 &(x,y) = (\pm 8, 0)\\
    60  &(x,y) = (0, \pm 2)\\
    -24 &(x,y) = (0,\pm 4)\\
    4 &(x,y) = (0,\pm 6)\\
    0 &\mbox{otherwise}
    \end{cases},
\end{equation*}
and
\begin{equation*}
    \phi_3(x,y) = 
    \begin{cases}
    1387004 &(x,y) = (0,0)\\
    -106722 &(x,y) = (\pm 2,0)\\
    3960 &(x,y) = (\pm 4,0)\\
    -1045 &(x,y) = (\pm 6, 0)\\
    138  &(x,y) = (\pm 8, 0)\\
    -9 &(x,y) = (\pm 10, 0)\\
    -131072 &(x,y) = (0, \pm 2)\\
    0 &\mbox{otherwise}
    \end{cases}
\end{equation*}
for $(x,y)\in\mathbb{Z}^2$. Though this example is slightly more complicated than the previous ones considered, it is straightforward to verify that $\sup_{\xi}|\widehat{\phi}(\xi)|=1$ and, in this case, the supremum is attained at two points in $\mathbb{T}^2$. Specifically, $\Omega(\phi)=\{\xi_1,\xi_2\}$ where $\xi_1=(0,0)$ and $\xi_2=(\pi,\pi)$. For $\xi_1$, $\Gamma_1=\Gamma_{\xi_1}$ has an absolutely and uniformly convergent Taylor series of the form
\begin{equation*}
    \Gamma_{1}(\xi)=-i\left(Q_{1}(\xi)-\widetilde{Q_1}(\xi)\right)-\left(R_1(\xi)+\widetilde{R_1}(\xi)\right)
\end{equation*}
for $\xi=(\tau,\zeta)\in\mathcal{U}_1$ where $\mathcal{U}_1\subseteq\mathbb{R}^2$ is an open neighborhood of $(0,0)$ and
\begin{equation*}
    Q_{1}(\xi)=\sum_{|\beta:(6,2)|=1}A_\beta \xi^\beta=\frac{\tau^6}{128}+\frac{\zeta^2}{8},
\end{equation*}
\begin{equation*}
    R_1(\xi)=\sum_{|\beta:(6,2)|=2}B_\beta\xi^\beta=\frac{111\tau^{12}}{32768}-\frac{\tau^6 \zeta^2}{1024}+\frac{3\zeta^4}{128},
\end{equation*}
\begin{equation*}
    \widetilde{Q_1}(\xi)=\sum_{|\beta:(6,2)|\geq 4/3}A_\beta \xi^\beta=-\f{65\tau^8}{512} -\f{\zeta^4}{96} + \frac{\tau^6\zeta^4}{8192} 
    +\cdots,
\end{equation*}
and
\begin{equation*}
    \widetilde{R_1}(\xi)=\sum_{|\beta:(6,2)|\geq 7/3}B_\beta\xi^\beta=\f{65\tau^8\zeta^2}{4096}  + \f{\tau^6 \zeta^4}{12288} + \cdots
\end{equation*}
for $\xi=(\tau,\zeta)\in\mathcal{U}_1$. It is straightforward to verify that $Q_1=\abs{Q_1}$ and $R_1$ are positive definite and so Proposition \ref{prop:ExpandGamma} guarantees that $\xi_1=(0,0)$ is of imaginary homogeneous type for $\widehat{\phi}$ with $\mathbf{m}_1=(3,1)$, $k_1=2$, drift $\alpha_{\xi_1}=(0,0)$ and homogeneous order
\begin{equation*}
    \mu_{\xi_1}=|\mathbf{1}:2\mathbf{m}_1|=\frac{1}{6}+\frac{1}{2}=\frac{2}{3}.
\end{equation*}
For $\xi_2 = (\pi,\pi)$, $\Gamma_2=\Gamma_{\xi_2}$ has an absolutely and uniformly convergent Taylor series of the form
\begin{equation*}
    \Gamma_2(\xi)=-i\left(Q_2(\xi)+\widetilde{Q_2}(\xi)\right)-\left(R_2(\xi)+\widetilde{R_2}(\xi)\right)
\end{equation*}
for $\xi=(\tau,\zeta)\in\mathcal{U}_2$ where $\mathcal{U}_2\subseteq\mathbb{R}^2$ is an open neighborhood of $(0,0)$ and 
\begin{equation*}
    Q_2(\xi)=\sum_{|\beta:(2,2)|=1}A_\beta \xi^\beta=-\left(\frac{3\tau^2}{8}+\frac{\zeta^2}{4}\right),
\end{equation*}
\begin{equation*}
    R_2(\xi)=\sum_{|\beta:(2,2)|=1}B_\beta\xi^\beta=\frac{\tau^2}{8}+\frac{3\zeta^2}{8},
\end{equation*}
\begin{equation*}
    \widetilde{Q_2}(\xi)=\sum_{|\beta:(2,2)|\geq 2}A_\beta\xi^\beta=\frac{\tau^4}{64}-\frac{9\tau^2\zeta^2}{64}+\frac{\zeta^4}{48}+\cdots,
\end{equation*}
and
\begin{equation*}
    \widetilde{R_2}(\xi)=\sum_{|\beta:(2,2)|\geq 2}B_\beta\xi^\beta=-\frac{\tau^4}{8}-\frac{3\tau^2\zeta^2}{64}-\frac{13\zeta^4}{384}+\cdots,
\end{equation*}
for $\xi=(\tau,\zeta)\in\mathcal{U}_2$. Thus, the expansion is of the form \eqref{eq:SemiEllipticImaginaryExpansion} with $\mathbf{m}_2=(1,1)$ and $k_2=1$. Since $R_2$ is clearly positive definite, Proposition \ref{prop:ExpandGamma} guarantees that $\xi_2=(\pi,\pi)$ is of positive homogeneous type for $\widehat{\phi}$ with drift $\alpha_{\xi_2}=(0,0)$ and homogeneous order
\begin{equation*}
    \mu_{\xi_2}=|\mathbf{1}:2\mathbf{m}_2|=\frac{1}{2}+\frac{1}{2}=1.
\end{equation*}
Upon noting that $\mu_{\phi}=\min\{\mu_{\xi_1},\mu_{\xi_2}\}=2/3$, an appeal to Theorem \ref{thm:ConvolutionPowerEstimate} guarantees, to each compact set $K$, a constant $C$ for which
\begin{equation}
    \abs{\phi^{(n)}(x,y)}\leq\frac{C}{n^{\mu_\phi}}=\frac{C}{n^{2/3}}
\end{equation}
for all $n\in\mathbb{N}$ and $(x,y)\in K$. Figure \ref{fig:Conv_Pwr_5} illustrates this result by capturing the decay of $f(n)=f_{\phi,K}(n)=\max_{(x,y)\in K}\abs{\phi^{(n)}(x,y)}$ where $K=[-500,500]\times [-500,500]$ relative to that of $n^{-\mu_\phi}$. Also, Figure \ref{fig:Conv_Pwr_50} illustrates the graph of $\Re \phi^{(n)}(x,y)$ for $(x,y)\in K$ and $n=200$ and $n=700$.


\begin{figure}[!htb]
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig9a.eps}
    \caption{$\log_2 f(n)$ and $\log_2 n^{-2/3}$ versus $\log_2 n$}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig9b.eps}
    \caption{$f(n)$ and $n^{-2/3}$ versus $n$}
    \end{subfigure}
    \caption{Behavior of $f(n)=f_{\phi,K}(n)=\max_{(x,y)\in K}\abs{\phi^{(n)}(x,y)}$.}
    \label{fig:Conv_Pwr_5}
\end{figure}


\begin{figure}[!htb]
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig10a.eps}
    \caption{$n = 200$.}
    \label{fig:Conv_Pwr_5a}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
    \centering
    \includegraphics[scale=0.58]{Fig10b.eps}
    \caption{$n = 700$.}
    \label{fig:Conv_Pwr_5b}
    \end{subfigure}
    \caption{$\Re{\phi^{(n)}}$ for $n = 200$ and $n=700$.}
    \label{fig:Conv_Pwr_50}
\end{figure}



\end{example}




%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%% Appendix  %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Appendix}\label{chap:Appendix}



\section{Continuous one-parameter subgroups of $\Gl(\mathbb{R}^d)$}\label{sec:OneParameterGroups}

\begin{proposition}[See Section 8 of \cite{randles_convolution_2017}]\label{prop:ContinuousGroupProperties}
Let $E,G\in\End(\mathbb{R}^d)$ and $A\in\Gl(\mathbb{R}^d)$. Also, let $E^*$ denote the adjoint of $E$. Then, for all $t,s>0$, the following statements hold:

\vspace{.3cm}
\begin{tabular}{lll}
$\bullet$ $1^E=I$ &  $\bullet$ $t^{E^*}=(t^E)^*$ & $\bullet$ $(t^E)^{-1}=t^{-E}$ 
\\
\vspace{.1cm}\\
$\bullet$ $At^EA^{-1}=t^{AEA^{-1}}$ &  $\bullet$ $\det\left(t^E\right)=t^{\tr E}$ & $\bullet$ $(st)^E=s^Et^E$\\
\vspace{.1cm}\\
$\bullet$ If $EG=GE$, then $t^Et^G=t^{E+G}$ &&
\end{tabular}
\end{proposition}

\begin{definition} A continuous one-parameter group $T_t=t^E$ is said to be \textit{contracting} if
\begin{equation*}
\lim_{t\to 0}\|T_t\|=0. 
\end{equation*}
\end{definition}

\begin{proposition}
Let $\{T_t\}$ be a continuous one-parameter group. Then $\{T_t\}$ is contracting if and only if
\begin{equation}\label{eq:ContractingSufficient}
\lim_{t\to 0}|T_tx|=0
\end{equation}
for all $x\in\mathbb{R}^d$.
\end{proposition}

\begin{proof}
It is clear that \eqref{eq:ContractingSufficient} is a necessary condition for $\{T_t\}$ to be contracting. We must therefore prove \eqref{eq:ContractingSufficient} also sufficient. To this end, we assume that the continuous one-parameter group $\{T_t\}$ satisfies \eqref{eq:ContractingSufficient}. By virtue of the continuity of $\{T_t\}$ and \eqref{eq:ContractingSufficient}, we have
\begin{equation*}
\sup_{0<t\leq 1}|T_t x|<\infty
 \end{equation*}
for each $x\in\mathbb{R}^d$. From the Banach-Steinhaus theorem, it follows that $\|T_t\|\leq C$ for all $0<t\leq 1$. Now, suppose that $\{T_t\}$ is not contracting. In this case, one can find a sequence $\{\eta_n\}\subseteq\mathbb{S}$ and a sequence $t_n\rightarrow 0$ for which $\lim_n|T_{t_n}\eta_n|>0$. But because the unit sphere is compact, $\{\eta_n\}$ has a convergence subsequence $\eta_{n_k}\rightarrow \eta$ with $|\eta|=1$ . Observe that, for all $n$,
 \begin{equation*}
 |T_{t_n}(\eta-\eta_n)|\leq C|\eta-\eta_n|
 \end{equation*}
 and so it follows that
 \begin{equation*}
 \lim_{k\rightarrow\infty}|T_{t_{n_k}}\eta|=\lim_{k\rightarrow\infty}|T_{t_{n_k}}\eta_{n_k}|>0,
 \end{equation*}
 a contradiction.
 \end{proof}




\begin{lemma}\label{lem:OperatorBoundsforContractingGroup}
Let $\{T_t\}\subseteq\GldR$ be a continuous one-parameter group and let $E\in\End(\mathbb{R}^d)$ be its generator, i.e., $T_t=t^E$ for all $t>0$.
If $\{T_t\}$ is contracting, then $E\in\Gl(\mathbb{R}^d)$ and there is a positive constant $C$ for which
\begin{equation*}
\|T_t\|\leq C+t^{\|E\|}
\end{equation*}
for all $t>0$.
\end{lemma}
\begin{proof}
If for some non-zero vector $\eta$, $E\eta=0$, then $t^E\eta=\eta$ for all $t>0$ and this would contradict our assumption that $\{T_t\}$ is contracting. Hence $E\in\Gl(\mathbb{R}^d)$ and, in particular, $\|E\|>0$. From the representation $T_t=t^E$, it follows immediately that $\|T_t\|\leq t^{\|E\|}$ for all $t\geq 1$ and so it remains to estimate $\|T_t\|$ for $t<1$. Given that $\{T_t\}$ is continuous and contracting, the map $t\mapsto \|T_t\|$ is continuous and approaches $0$ as $t\rightarrow 0$ and so it is necessarily bounded for $0<t\leq 1$.
\end{proof}


\begin{lemma}\label{lem:SpectralEstimateforContractingGroup}
Let $E\in\GldR$ be diagonalizable with strictly positive spectrum. Then $\{t^E\}$ is a continuous one-parameter contracting group. Moreover, there is a positive constant $C$ such that
\begin{equation*}
\|t^E\|\leq Ct^{\lambda_{\mbox{\tiny{max}}}}
\end{equation*}
for all $t\geq 1$ and
\begin{equation*}
\|t^E\|\leq Ct^{\lambda_{\mbox{\tiny{min}}}}
\end{equation*}
for all $0<t<1$, where $\lambda_{\mbox{\tiny{max}}}=\max(\Spec(E))$ and $\lambda_{\mbox{\tiny{min}}}=\min(\Spec(E))$.
\end{lemma}
\begin{proof}
Let $A\in\GldR$ be such that $A^{-1}EA=D=\diag(\lambda_1,\lambda_2,\dots,\lambda_d)$ where necessarily $\Spec(E)=\Spec(D)=\{\lambda_1,\lambda_2,\dots,\lambda_d\}\subseteq (0,\infty)$. It follows from the spectral mapping theorem that $\Spec(t^D)=\{t^{\lambda_1},t^{\lambda_2},\dots,t^{\lambda_d}\}$ for all $t>0$ and moreover, because $t^D$ is symmetric,
\begin{equation*}
\|t^D\|\leq \max(\{t^{\lambda_1},t^{\lambda_2},\dots,t^{\lambda_d}\})
=\begin{cases}
t^{\lambda_{\mbox{\tiny{max}}}} & \mbox{if }t\geq 1\\
t^{\lambda_{\mbox{\tiny{min}}}} & \mbox{if }t<1.
\end{cases}
\end{equation*}
By the property of $t^E$, we have
\begin{equation*}
\|t^E\|=\|At^DA^{-1}\|\leq \|A\|\|t^D\|\|A^{-1}\|\leq C\|t^D\|=C\times
\begin{cases}
t^{\lambda_{\mbox{\tiny{max}}}} & \mbox{if }t\geq 1\\
t^{\lambda_{\mbox{\tiny{min}}}} & \mbox{if }t<1
\end{cases}
\end{equation*}
for $t>0$ where $C=\|A\|\|A^{-1}\|$; in particular, $\{t^E\}$ is contracting because $\lambda_{\mbox{\tiny{min}}}>0$.
\end{proof}


\begin{proposition}\label{prop:ContractingLimits}
Let $\{T_t\}_{t>0}\subseteq\Gl(\mathbb{R}^d)$ be a continuous one-parameter contracting group.  Then, for all non-zero $x\in\mathbb{R}^d$,
\begin{equation*}
\lim_{t\rightarrow 0}|T_t x|=0\hspace{.5cm}\mbox{ and }\hspace{.5cm}\lim_{t\rightarrow\infty}|T_t x|=\infty.
\end{equation*}
\end{proposition}
\begin{proof}
The validity of the first limit is clear. Upon noting that $|x|=|T_{1/t}T_tx|\leq \|T_{1/t}\||T_t x|$ for all $t>0$, the second limit follows at once.
\end{proof}
\begin{proposition}\label{prop:ScaleFromSphere}
Let $\{T_t\}_{t>0}$ be a continuous one-parameter contracting group. There holds the following:
\begin{enumerate}[label=(\alph*), ref=(\alph*)]
\item\label{item:ScaleFromSphere_1} For each non-zero $x\in \mathbb{R}^d$, there exists $t>0$ and $\eta\in \mathbb{S}$ for which $T_t\eta=x$. Equivalently,
\begin{equation*}
\mathbb{R}^d\setminus\{0\}=\{T_t\eta:t>0\mbox{ and }\eta\in \mathbb{S}\}.
\end{equation*}
\item\label{item:ScaleFromSphere_2} For each sequence $\{x_n\}\subseteq\mathbb{R}^d$ such that $\lim_n|x_n|=\infty$, $x_n=T_{t_n}\eta_n$ for each $n$, where $\{\eta_n\}\subseteq \mathbb{S}$ and $t_n\rightarrow\infty$ as $n\rightarrow\infty$.
\item\label{item:ScaleFromSphere_3} For each sequence $\{x_n\}\subseteq\mathbb{R}^d$ such that $\lim_n|x_n|=0$, $x_n=T_{t_n}\eta_n$ for each $n$, where $\{\eta_n\}\subseteq \mathbb{S}$ and $t_n\rightarrow 0$ as $n\rightarrow\infty$.
\end{enumerate}
\end{proposition}
\begin{proof}
In view of Proposition \ref{prop:ContractingLimits}, the assertion \ref{item:ScaleFromSphere_1} is a straightforward application of the intermediate value theorem. For \ref{item:ScaleFromSphere_2}, suppose that $\{x_n\}\subseteq\mathbb{R}^d$ is such that $|x_n|\rightarrow \infty$ as $n\rightarrow\infty$. In view of \ref{item:ScaleFromSphere_1}, take $\{\eta_n\}\subseteq S$ and $\{t_n\}\subseteq (0,\infty)$ for which $x_n=T_{t_n}\eta_n$ for each $n$. In view of Lemma \ref{lem:OperatorBoundsforContractingGroup},
\begin{equation*}
\infty=\liminf_n |x_n|\leq\liminf_n \left(C+t_n^M\right)|\eta_n|\leq C+\liminf_nt_n^M,
\end{equation*}
where $C,M>0$ and therefore $t_n\rightarrow\infty$. If instead $\lim_n x_n=0$,
\begin{equation*}
\infty=\lim_{n\rightarrow\infty}\frac{|\eta_n|}{|x_n|}=\lim_{n\rightarrow\infty}\frac{|T_{1/t_n}x_n|}{|x_n|}\leq\limsup_n\|T_{1/t_n}\|\leq\limsup_n(C+(1/t_n)^M)
\end{equation*}
from which we see that $t_n\rightarrow 0$, thus proving \ref{item:ScaleFromSphere_3}.
\end{proof}

\begin{proposition}\label{prop:ContractingCapturesCompact}
Let $\{T_t\}$ be a continuous contracting one-parameter group. Then for any open neighborhood $\mathcal{O}\subseteq\mathbb{R}^d$ of the origin and any compact set $K\subseteq\mathbb{R}^d$, $K\subseteq T_t(\mathcal{O})$ for sufficiently large $t$.
\end{proposition}
\begin{proof}
Assume, to reach a contradiction, that there are sequences $\{x_n\}\subseteq K$ and $t_n\rightarrow\infty$ for which $x_n\notin T_{t_n}(\mathcal{O})$ for all $n$. Because $K$ is compact, $\{x_n\}$ has a subsequential limit and so by relabeling, let us take sequences $\{\zeta_k\}\subseteq K$ and $\{r_k\}\subseteq (0,\infty)$ for which $\zeta_k\rightarrow \zeta$, $r_k\rightarrow\infty$ and $\zeta_k\notin T_{r_k}(\mathcal{O})$ for all $k$. Setting $s_k=1/r_k$ and using the fact that $\{T_t\}$ is a one-parameter group, we have $T_{s_k}\zeta_k\notin\mathcal{O}$ for all $k$ and so $\liminf_{k}|T_{s_k}\zeta_k|>0$, where $s_k\rightarrow 0$. This is however impossible because $\{T_t\}$ is contracting and so
\begin{equation*}
\lim_{k\rightarrow\infty}|T_{s_k}\zeta_k|\leq\lim_{k\rightarrow \infty}|T_{s_k}(\zeta_k-\zeta)|+\lim_{k\rightarrow\infty}|T_{s_k}\zeta|\leq C\lim_{k\rightarrow\infty}|\zeta_k-\zeta|+0=0
\end{equation*}
in view of Lemma \ref{lem:OperatorBoundsforContractingGroup}.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\section{Some basic measure theory}\label{sec:measure_theory}

% \textcolor{red}{There is a lot of stuff in this section not used (and really minimally relevant to the topic) and I think it would be better to remove it. I would remove from here:}
% \begin{theorem}
% Every open subset $\mathcal{O}$ of $\mathbb{R}$ can be written uniquely as a countable union of disjoint open intervals. Every open subset $\mathcal{O}$ of $\mathbb{R}^d$, $d\geq 1$, can be written as a countable union of almost disjoint closed cubes. 
% \end{theorem}
% \begin{definition}[Exterior measure]
% If $E \subseteq \mathbb{R}^d$, then the exterior measure of $E$ is 
% \begin{equation*}
%     m_*(E) = \inf \sum^\infty_{n=1}\abs{Q_j} \in [0,\infty]
% \end{equation*}
% where the infimum is taken over all countable coverings $E\subseteq \bigcup^\infty_{j=1} Q_j$ by closed cubes.
% \end{definition}
% \begin{proposition}
% (Monotonicity) If $E_1 \subset E_2$ then $m_*(E_1)\leq m_*(E_2)$.
% \end{proposition}
% \begin{proposition}
% (Countable Sub-additivity) If $E = \bigcup^\infty_{j=1} E_j$ then $m_*(E) \leq \sum^\infty_{j=1} m_*(E_j)$.
% \end{proposition}
% \begin{proposition}
% If $E \subseteq \mathbb{R}^d$, $m_*(E) \leq \inf m_*(\mathcal{O})$ where the infimum is taken over all open $\mathcal{O} \supseteq E$. 
% \end{proposition}
% \begin{proposition}
% If $E = E_1 \cup E_2$ and $d(E_1, E_2) > 0$ then $m_*(E) = m_*(E_1) + m_*(E_2)$.
% \end{proposition}
% \begin{proposition}
% If $E$ is a countable union of almost disjoint cubes $E = \cup^\infty_{i=1}Q_i$ then $m_*(E) = \sum^\infty_{i=1}\abs{Q_i}$.
% \end{proposition}
% \begin{definition}[Lebesgue measurable]
%     A subset $E$ of $\R^d$ is Lebesgue measurable if for any $\epsilon > 0$ there exists an open set $\mathcal{O}$ containing $E$ such that 
%     \begin{equation*}
%         m_*(\mathcal{O}\setminus E) \leq \epsilon,
%     \end{equation*}
%     in which case, the Lebesgue measure of $E$ is given by
%     \begin{equation*}
%         m(E) = m_*(E).
%     \end{equation*}
% \end{definition}
% \begin{proposition}
% Every open set in $\R^d$ is measurable. 
% \end{proposition}
% \begin{proposition}
% If $m_*(E) = 0$ then $E$ is measurable. In particular, if $F\subseteq E$ with $m_*(E)=  0$ then $F$ is measurable. 
% \end{proposition}
% \begin{proposition}
% A countable union of measurable sets is measurable. 
% \end{proposition}
% \begin{proposition}
% Closed sets are measurable. 
% \end{proposition}
% \begin{proposition}
% The complement of a measurable set is measurable.
% \end{proposition}
% \begin{proposition}
% A countable intersection of measurable sets is measurable.
% \end{proposition}
% \begin{theorem}
% If $E_1, E_2, \dots$ are disjoint measurable sets, and $E = \bigcup^\infty_{i=1}E_i$ then 
% \begin{equation*}
%     m(E) = \sum^\infty_{i=1}m(E_i)
% \end{equation*}
% \end{theorem}
% \begin{corollary}
% Suppose $E_1,, E_2, \dots$ are measurable subsets of $\mathbb{R}^d$, 
% \begin{itemize}
%     \item If $E_k \uparrow E$ then $m(E) = \lim_{n\to \infty}m(E_n)$.
%     \item If $E_k \downarrow E$ and $m(E_k) < \infty$ for some $k$ then $m(E) = \lim_{n\to \infty} m(E_n)$.
% \end{itemize}
% \end{corollary}
% \begin{theorem}
% If  $E$ is a measurable subset of $\R^d$ then for every $\epsilon > 0$, 
% \begin{itemize}
%     \item There exists an open set $\mathcal{O}$ with $E \subseteq \mathcal{O}$ and $m(\mathcal{O}\setminus E) \leq \epsilon$.
%     \item There exists a closed set $F$ with $F \subseteq E$ and $m(E\setminus F) \leq \epsilon$.
%     \item If $m(E)$ is finite, there exists a compact set $K$ with $K \subseteq E$ and $m(E\setminus K) \leq \epsilon$.
%     \item If $m(E)$ is finite, then there exists a finite union $F = \bigcup^N_{i=1}Q_i$ of closed cubes such that $m(E\Delta F) \leq \epsilon$, where the notation $E\Delta F$ stands for the symmetric difference between the sets $E$ and $F$:
%     \begin{equation*}
%         E \Delta F = (E\setminus F) \cup (F \setminus E).
%     \end{equation*}
% \end{itemize}
% \end{theorem}
% \begin{corollary}
% A subset $E$ of $\R^d$ is measurable 
% \begin{itemize}
%     \item if and only if $E$ differs from a $G_\delta$ set by a set of measure zero. Here a $G_\delta$ set is a countable intersection of open sets,
%     \item if and only if $E$ differs from a $F_\sigma$ by a set of measure zero. Here an $F_\sigma$ set is a countable union of closed sets.
% \end{itemize}
% \end{corollary}
% \begin{definition}[Algebra in a set]
% Let $X$ be a set. An algebra in $X$ is a non-empty collection of subsets of $X$ that is closed under complements, finite unions, and finite intersections. 
% \end{definition}
% \textcolor{red}{To here.}
\begin{definition}[$\sigma$-algebra]
Consider a set $X$ an its power set $\mathcal{P}(X)$. A set $\mathcal{A} \subseteq \mathcal{P}(X)$ is a $\sigma$-algebra if 
\begin{itemize}
    \item $\varnothing, X \in \mathcal{A} $
    \item $A\in \mathcal{A} \implies A^c = X\setminus A \in \mathcal{A}$.
    \item $A_j \in \mathcal{A}, i\in \mathbb{N} \implies \bigcup^\infty_{i=1} A_j \in \mathcal{A}$.
\end{itemize}
Any set $A\in \mathcal{A}$ is called an $\mathcal{A}$-measurable set. 
\end{definition}
\begin{remark}
If $\mathcal{A}_i$ is a $\sigma$-algebra on $X$, then for $i \in I$ where $I$ is any index set, then $\bigcap_{i\in I} \mathcal{A}_i$ is also a $\sigma$-algebra on $X$. This is important especially when we want to construct some $\sigma$-algebra that has all the properties of other $\sigma$-algebras.
\end{remark}
\begin{proposition}
For $\mathcal{M} \subset \mathcal{P}(X)$, there is a smallest $\sigma$-algebra that contains $\mathcal{M}$:
\begin{equation*}
    \sigma(M) \coloneqq  \bigcap_{\mathcal{A}\supseteq \mathcal{M}} \mathcal{A}, \quad \mathcal{A} \text{ is a $\sigma$-algebra}
\end{equation*}
called the $\sigma$-algebra generated by $\mathcal{M}$. 
\end{proposition}
\begin{definition}[Borel $\sigma$-algebra]
Let $X$ be a topological space (or a metric space, or a subset of $\mathbb{R}^n$), so that we have ``open sets.'' The Borel $\sigma$-algebra $\mathcal{B}(X)$ is the smallest $\sigma$-algebra generated by the open sets.
\end{definition}


\begin{definition}[Monotone class]
A monotone class on a space $X$ is a subset $\mathcal{C}\subset \mathcal{P}(X)$ that is closed under increasing unions and countable decreasing intersections. That is, if $E_j \in \mathcal{C}$ and $E_1 \subset E_2 \subset \dots$ then $\bigcup E_j \in \mathcal{C}$, and likewise for intersections.
\end{definition}
\begin{remark}
Every $\sigma$-algebra is a monotone class.
\end{remark}
\begin{remark}
The intersection of any family of monotone classes is a monotone class.
\end{remark}
\begin{definition}[Monotone class generated by a subset of $\mathcal{P}(X)$]
For any $\mathcal{E} \subset \mathcal{P}(X)$, there is a unique smallest monotone class containing $\mathcal{E}$, called the monotone class \textbf{generated by $\mathcal{E}$}. 
\end{definition}
% \begin{definition}[$\sigma$-algebra generated by a family of subsets]
% Let $F$ be an arbitrary family of subsets of $X$. Then there exists a unique smallest $\sigma$-algebra which contains every set in $F$. It is, in fact, the intersection of all $\sigma$-algebras containing $F$. This $\sigma$-algebra is denoted $\sigma(F)$ and is called the $\sigma$-algebra generated by $F$.
% \end{definition}
\begin{lemma}[Monotone Class Lemma]
If $\mathcal{A}$ is an algebra of subsets of $X$, then the monotone class $\mathcal{C}$ generated by $\mathcal{A}$ coincides with the $\sigma$-algebra $\mathcal{M}$ generated by $\mathcal{A}$. 
\end{lemma}



\begin{definition}[Measure(able) space]
Consider a set $X$ and a $\sigma$-algebra $\mathcal{A}$ on $X$. $(X, \mathcal{A})$ is a measurable space. The map $\mu : \mathcal{A} \to [0,\infty] = [0,\infty) \cup \{ \infty\}$ is called a measure if it satisfies:
\begin{itemize}
    \item $\mu(\varnothing) = 0$
    \item $\sigma$-additivity
    \begin{equation*}
        \mu \lp \bigcup^\infty_{i=1} A_i \rp = \sum^\infty_{i=1} \mu(A_i)
    \end{equation*}
    whenever $A_i \cap A_j = \varnothing$ for $i \neq j$ and $A_i \in \mathcal{A}$ for all $i$. 
\end{itemize}
Once the measure $\mu$ is defined on the measurable space $(X,\mathcal{A})$, the triple $(X,\mathcal{A},\mu)$ is called a measure space.  
\end{definition}
\begin{definition}[Complete measure space]
A measure space $(X,\Sigma, \mu)$ is a complete measure space if and only if for any null set (set of measure zero) $N\in \Sigma$, if $S\subseteq N$ then $S\in \Sigma$.
\end{definition}

\begin{definition}[$\sigma$-finite measure]
Let $(X,\mathcal{A}, \mu)$ be a measure space. The measure $\mu$ is called a $\sigma$-finite measure if it satisfies one of the following equivalent criteria:
\begin{itemize}
    \item The set $X$ can be covered with at most countably many measurable sets with finite measure, i.e., there are sets $A_1,\dots, \in \mathcal{A}$ with $\mu(A_n)< \infty$ for all $n$ such that $\bigcup_{n\in \mathbb{N}} A_n = X$.
    \item The set $X$ can be covered with at most countable many measurable disjoint sets with finite measure, i.e., there are sets $B_1,\dots, \in \mathcal{A}$ with $\mu(B_n) < \infty$ for all $n$ and $B_i \cap B_j = \varnothing$ for $i\neq j$ that satisfy $\bigcup_{n\in \mathbb{N}} B_n = X$.
    \item The set $X$ can be covered with a monotone sequence of measurable sets with finite measure, i.e., there are sets $C_1,\dots, \in \mathcal{A}$ with $C_1 \subseteq C_2 \subseteq \dots$ and $\mu(C_n) < \infty$ for all $n$ that satisfy $\bigcup_{n\in \mathbb{N}} C_n = X$.
    \item There exists a strictly positive measurable function $f$ whose integral is finite, i.e., $f(x) > 0$ for all $x\in X$ and $\int_X f\,d\mu < \infty$. 
\end{itemize}
If $\mu$ is a $\sigma$-finite measure, the measure space $(X,\mathcal{A},\mu)$ is called a $\sigma$-finite measure space. 
\end{definition}





\begin{definition}[Borel measure]
Let $X$ be a topological space and $\mathcal{B}(X)$ be its Borel $\sigma$-algebra. A measure $\mu$ on $X$ is called a Borel measure if it is defined on a $\sigma$-algebra which contains $\mathcal{B}(X)$.
\end{definition}

\begin{definition}[Outer, inner regular \& Regular]
Let $\mu$ be a Borel measure on $X$ and $B$ a Borel subset of $X$. $\mu$ is called outer regular on $B$ if
\begin{equation*}
    \mu(B) = \inf \{ \mu(U) : U \supset B, U \text{ open} \}
\end{equation*}
and inner regular if
\begin{equation*}
    \mu(B) = \sup \{ \mu(K) : K \subset B, K \text{ compact} \}.
\end{equation*}
If $\mu$ is outer and inner regular on all Borel sets, $\mu$ is called regular.
\end{definition}

\begin{definition}[Radon measure]
A Radon measure on $X$ is a Borel measure which is finite on compact sets, outer regular on all on all Borel sets, and inner regular on all open sets. Radon measures are also inner regular on all of their $\sigma$-finite sets.
\end{definition}











% \textcolor{red}{Do you ever use premeasure?}
% \begin{definition}[Premeasure]
% Let $\mathcal{A}$ be an algebra in $X$. A premeasure on an algebra $\mathcal{A}$ is a function $\mu_0 : \mathcal{A} \to [0,\infty]$ that satisfies 
% \begin{itemize}
%     \item $\mu_0(\varnothing) = 0.$
%     \item If $E_1,\dots$ is a countable collection of disjoint sets in $\mathcal{A}$ with $\bigcup^\infty_{n=1}E_n \in \mathcal{A}$ then 
%     \begin{equation*}
%         \mu_0 \lp \bigcup^\infty_{k=1} E_k \rp = \sum^\infty_{k=1} \mu_0 (E_k)
%     \end{equation*}
% \end{itemize}
% In particular, $\mu_0$ is finitely additive on $\mathcal{A}$. 
% \end{definition}


\begin{theorem}[Product measure]\label{thm:ProdMeasure}
Let $(X,\mathcal{M},\mu)$ and $(Y,\mathcal{N},\nu)$ be measure spaces, then we have the product $\sigma$-algebra $\mathcal{M}\otimes \mathcal{N}$ on $X\times Y$. If $\mu,\nu$ are $\sigma$-finite, then $\mu\times \nu$ is also $\sigma$-finite. In this case, $\mu\times \nu$ is a unique measure on $\mathcal{M}\otimes \mathcal{N}$ such that 
\begin{equation*}
    \mu \times \nu (A\times B) = \mu(A) \nu(B)
\end{equation*}
for all rectangles $A\times B$ where $A\in \mathcal{M}$ and $B\in \mathcal{N}$. 
\end{theorem}
\begin{definition}[Slices]
Let $(X,\mathcal{M},\mu),(Y,\mathcal{N},\nu)$ be measure spaces. If $E \subset X\times Y$, for $x\in X, y\in Y$ we define the $x$-section $E_x$ and $y$-section $E^y$ of $E$ by
\begin{equation*}
    E_x = \{y\in Y : (x,y)\in E \} \subseteq Y, \quad
    E^y = \{ x\in X: (x,y)\in E \} \subseteq X
\end{equation*}
Also, if $f$ is a function on $X\times Y$ we define the $x$-section $f_x$ and $y$-section $f^y$ of $f$ by 
\begin{equation*}
    f_x(y) = f^y(x) = f(x,y).
\end{equation*}
\end{definition}
\begin{proposition}[Measurable slice proposition]
$\,$
\begin{itemize}
    \item If $E \in \mathcal{M}\otimes \mathcal{N}$, then $E_x \in \mathcal{N}$ for all $x\in X$ and $E^y \in \mathcal{M}$ for all $y\in Y$. 
    
    \item If $f$ is $\mathcal{M}\otimes \mathcal{N}$-measurable, then $f_x$ is $\mathcal{N}$-measurable for all $x\in X$ and $f^y$ is $\mathcal{M}$-measurable for all $y\in Y$
\end{itemize}
\end{proposition}

\begin{theorem}[Fubini-Tonelli's Theorem for finite measure spaces]\label{thm:Fubini-Tonelli-OG}
Suppose that $(X,\mathcal{M},\mu)$ and $(Y,\mathcal{N},\nu)$ are $\sigma$-finite measure spaces
\begin{itemize}
    \item (Tonelli's) If $f \in L^+(X\times Y)$ then the functions $g(x) =\int f_x\,d\nu$ and $h(y) = \int f^y \,d\mu$ are in $L^+(X), L^+(Y)$, respectively, and
    \begin{equation*}
        \int f \,d(\mu\times \nu) = \int \lb \int f(x,y)\,d\nu(y) \rb d\mu(x) = \int \lb \int f(x,y)\,d\mu(x) \rb \,d\nu(y).
    \end{equation*}
    
    \item (Fubini's) If $f \in L^1(\mu\times \nu)$ then $f_x \in L^1(\nu)$ for a.e. $x\in X$,  $f^y \in L^1(\mu)$ for a.e. $y\in Y$, the a.e.-defined functions $g(x) = \int f_x\,d\nu$ and $h(y) = \int f^y\,d\mu$ are in $L^1(\mu),L^1(\nu)$ respectively, and   
    \begin{equation*}
        \int f \,d(\mu\times \nu) = \int \lb \int f(x,y)\,d\nu(y) \rb d\mu(x) = \int \lb \int f(x,y)\,d\mu(x) \rb \,d\nu(y).
    \end{equation*}
\end{itemize}
\end{theorem}

\begin{theorem}[Fubini's Theorem for Complete Measures]
Suppose that $(X,\mathcal{M},\mu)$ and $(Y,\mathcal{N},\nu)$ are $\sigma$-finite and complete measure spaces, and let $(X\times Y, L, \lambda)$ be the completion of $(X\times Y, \mathcal{M}\otimes \mathcal{N}, \mu\times \nu)$. If $f$ is $L$-measurable and either (a) $f\geq 0$ or (b) $f\in L^1(\lambda)$, then $f_x,f^y$ are also integrable for a.e. $x,y$. Moreover, $x\mapsto \int f_x\,d\nu, y\mapsto \int f^y\,d\mu$ are measurable, and in case (b) also integrable, and
\begin{equation*}
    \int f\,d\lambda = \iint f(x,y)\,d\mu(x)d\nu(y) = \iint f(x,y)\,d\nu(y)d\mu(x) .
\end{equation*}
\end{theorem}

\begin{theorem}[Monotone Convergence Theorem]
Let a measure space $(X,\mathcal{A},\mu)$ and measurable functions $f_n,f: X\to [0,\infty)$ be given for all $n\in \mathbb{N}$ with
\begin{itemize}
    \item $f_1\leq f_2 \leq f_3 \leq \dots $ $\mu$-a.e.
    \item $\lim_{n\to \infty}f_n(x) = f(x)$ $\mu$-a.e. 
\end{itemize}
then 
\begin{equation*}
    \lim_{n\to \infty} \int_X f_n \,d\mu = \int \lim_{n\to \infty} f_n \,d\mu = \int_X f\,d\mu.
\end{equation*}
\end{theorem}


\begin{corollary}
Suppose $(g_n)_{n\in \mathbb{N}}$ with $g_n : X \to [0,\infty]$ measurable for all $n$ be given. Then  $\sum^\infty_{i=1}g_n : X \to [0, \infty]$ is measurable. By the MCT
\begin{equation*}
    \int_X \sum^\infty_{i=1} g_n \,d\mu = \sum^\infty_{i=1} \int_X g_n \,d\mu.
\end{equation*}
\end{corollary}


\begin{corollary}
Let $(X_j,\Sigma_j,\mu_j)$ for $j=1,2$ be measure spaces which are isomorphic in the sense that there is a bijection $\varphi:X_1\to X_2$ for which
\begin{equation*}
\Sigma_2=\{A\in X_2:\varphi^{-1}(A)\in\Sigma_1\}
\end{equation*}
and, for each $A\in\Sigma_2$,
\begin{equation*}
\mu_2(A)=\mu_1(\varphi^{-1}(A)).
\end{equation*}
Let $f:X_2\to\mathbb{C}$. Then $f$ is $\Sigma_2$-measurable if and only if $f\circ \varphi:X_1\to\mathbb{C}$ is $\Sigma_1$ measurable. Further, if $f\geq 0$,
\begin{equation*}
\int_{X_2}f\,d\mu_2=\int_{X_1}f\circ \varphi\,d\mu_1.
\end{equation*}
If $f$ is generally complex-valued, then $f\in L^1(\mu_1)$ if and only if $f\circ \psi\in L^1(\mu_2)$ and in this case we also have
\begin{equation*}
\int_{X_2}f\,d\mu_2=\int_{X_1}f\circ \varphi\,d\mu_1.
\end{equation*}
\end{corollary}

\begin{theorem}[Lebesgue's Dominated Convergence Theorem]
Let a measure space $(X,\mathcal{A},\mu)$ be given. Consider the set of all Lebesgue-integrable functions:
\begin{equation*}
    L^1(\mu) \coloneqq \left\{ f: X \to \mathbb{R} \text{ measureable}\vert \, \int_X \abs{f}^1\,d\mu < \infty \right\}.
\end{equation*}
For $f\in L^{1}(\mu)$, write $f = f^+ - f^-$ with $f^+,f^- \geq 0$ and define
\begin{equation*}
    \int_X f\,d\mu \coloneqq \int_X f^+ \,d\mu - \int_X f^- \,d\mu.
\end{equation*}
Consider $f_n : X \to \mathbb{R}$ a sequence of measurable functions and $f : X \to \mathbb{R}$ with $\lim_{n\to \infty} f_n(x) = f(x)$ for $x\in X$, $\mu$-a.e. where $\abs{f_n} \leq g$ with $g\in L^1(\mu)$ for all $n$. Then $f_1, \dots, \in L^{1}(\mu)$, $f\in L^{1}(\mu)$ and 
\begin{equation*}
    \lim_{n\to \infty} \int_X f_n\,d\mu = \int_X f\,d\mu.
\end{equation*}
\end{theorem}


% \section{Additional notational details for Section 3.2}
% \label{app:Smooth_Manifold}
% Let's write $\partial_{u^1},\partial_{u^2},\dots,\partial_{u^{d'}}$ for the frame on $S$, i.e., each is a vector field on $S$, and $\frac{\partial}{\partial u^1},\frac{\partial}{\partial u^2},\dots,\frac{\partial}{\partial u^{d'}}$ for the frame on $U\in\mathbb{R}^d$. These are connected via the following relation (which actually defines the former): For any $h\in C^\infty(S)$, 
% \begin{equation*}
%     \partial_{u^\mu}(h)(\eta)=\frac{\partial}{\partial u^{\mu}}\left(h\circ\varphi^{-1}\right)(u)
% \end{equation*}
% where $u=\varphi(\eta)$. In other words,
% \begin{equation*}
%     \partial_{u^\mu}=\varphi^{-1}_*\frac{\partial}{\partial u^\mu}.
% \end{equation*}
% Now, by definition of the pullback $(\varphi^{-1})^*\,d\sigma_P$ is a $d'$-form on the $d'$-dimensional manifold $U$ and every such form is given by $f(u)du^1\wedge du^2\wedge\cdots\wedge du^{d'}$ for some smooth function $f$, i.e., there is a smooth function $f:\mathbb{R}^d\to\mathbb{R}$ for which
% \begin{equation*}
%     (\varphi^{-1})^*d\sigma_P=f(u) du^1\wedge du^2\wedge\cdots\wedge du^{d'}.
% \end{equation*}
% % Then, by definition, 
% % \begin{equation*}
% %     \int_U (\varphi^{-1})^*d(g\cdot d\sigma_P)=\int_U g(\varphi^{-1}(u))f(u)\,du^1,du^2,\dots,du^{d'}
% % \end{equation*}
% % (we've erased the wedges to integrate). Thus, we really just need to know $f$. We have
% To find $f$, we proceed as follow:
% \begin{eqnarray*}
%     f(u)&=&f(u)\left(du^1\wedge du^2\wedge\cdots\wedge du^{d'}\right)\left(\frac{\partial}{\partial u^1},\frac{\partial}{\partial u^2},\dots,\frac{\partial}{\partial u^{d'}}\right)\\
%     &=&\left((\varphi^{-1})^*\,d\sigma_P\right)\left(\frac{\partial}{\partial u^1},\frac{\partial}{\partial u^2},\dots,\frac{\partial}{\partial u^{d'}}\right)\\
%     &=&d\sigma_P\left(\varphi^{-1}_*\left(\frac{\partial}{\partial u^1}\right),\varphi^{-1}_*\left(\frac{\partial}{\partial u^2}\right),\dots,\varphi^{-1}_*\left(\frac{\partial}{\partial u^{d'}}\right)\right)\\
%     &=&d\sigma_P(\partial_{u^1},\partial_{u^2},\dots,\partial_{u^{d'}})\\
%     &=&h_{E,\varphi}(u).
% \end{eqnarray*}
% % Therefore
% % \begin{equation*}
% %     \int_U (\varphi^{-1})^*(g\cdot d\sigma_P)=\int_U g(\varphi^{-1}(u))h_{E,\varphi}(u)\,du.
% % \end{equation*}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%% Bibliography %%%%%%%%%%%%%%%%%%%%

\bibliographystyle{abbrv}
\bibliography{GPIF}





% \begin{thebibliography}{99}

% % \bibitem{absil2009optimization}
% % Absil, P-A and Mahony, Robert and Sepulchre, Rodolphe.
% % \newblock{\em Optimization algorithms on matrix manifolds}.
% % \newblock{\em Princeton University Press, 2009}





% \bibitem{Amann2009}
% H. Amann and J. Escher
% \newblock {\em {Analysis III} }
% \newblock {Birkh\"{a}user Basel, 2009}

% \bibitem{Apostol1974} 
% T.M. Apostol
% \newblock {\em {Mathematical Analysis} 2nd Edition}
% \newblock {Addison-Wesley, 1974}

% \bibitem{Baker1997} 
% John A. Baker
% \newblock {\em {Integration over spheres and the divergence theorem for balls.}}
% \newblock {\textit{The American Mathematical Monthly}, 104(1):36-47, 1997.}

% \bibitem{Browder1996} 
% A. Browder
% \newblock {\em {Mathematical Analysis: An Introduction} \newblock {Springer-Verlag, New York, Berlin, 1996}}

% \bibitem{Bogachev2007}
% V. I. Bogachev.
% \newblock {\em {Measure Theory} Vol. 1}.
% \newblock Springer-Verlag, 2007.

% \bibitem{Braun1993}
% M. Braun
% \newblock {\em {Differential Equations and Their Applications} Fourth Ed.}
% \newblock Springer-Verlag, 1993.

% \bibitem{Engel2005}
% Klaus-Jochen Engel and Rainer Nagel
% \newblock {\em {A Short Course on Operator Semigroups}}.
% \newblock Springer-Verlag, 2005

% \bibitem{Engel2000}
% K.-J. Engle and R. Nagel
% \newblock {\em {One-Parameter Semigroups for Linear Evolution Equations}}, {\em Graduate Texts in Mathematics., Vol. 194,}
% \newblock Springer-Verlag, 2000. 

% \bibitem{Folland1984}
% Gerald Folland.
% \newblock {\em {Real Analysis: Modern Techniques and Their Applications}}, {\em Pure \& Applied Mathematics}.
% \newblock Wiley-Interscience, 1984

% \bibitem{Folland2001}
% Gerald Folland.
% \newblock {\em{How to Integrate a Polynomial over a Sphere.}}
% \newblock {\em{The American Mathematical Monthly.} 108(5):446-448, 2001} 


% \bibitem{Hormander1983}
% Lars H{\"{o}}rmander.
% \newblock {\em {The Analysis of Linear Partial Differential Operators II}}.
% \newblock Springer-Verlag Berlin Heidelberg, Berlin, 1983.

% \bibitem{lee2013smooth}
% Lee, John M.
% \newblock{{\em Introduction to Smooth Manifolds,} Second Ed.}
% \newblock{\em Springer, 2013}


% \bibitem{Naber2011}
% Naber, Gregory L.
% \newblock{{\em Topology, Geometry
% and Gauge fields,} Second Ed.}
% \newblock{\em Springer, 2011}

% \bibitem{Randles2015}
% Evan Randles and Laurent Saloff-Coste.
% \newblock {\em {``On the Convolution Powers of Complex Functions on $\mathbb{Z}$''}}.
% \newblock {\em J. Fourier Anal. Appl.}, 21(4):754--798, 2015.

% \bibitem{Randles2017}
% Evan Randles and Laurent Saloff-Coste. 
% \newblock {\em {``Convolution powers of complex functions on $\mathbb{Z}^d$."}
% \newblock Revista Matem\'{a}tica Iberoamericana, vol. 33, no. 3, 2017, pp. 1045-1121.}

% \bibitem{Randles2017a}
% Evan Randles and Laurent Saloff-Coste.
% \newblock {\em {``Positive-homogeneous operators, heat kernel estimates and the Legendre-Fenchel transform.''}
% \newblock Stochastic Analysis and Related Topics: A Festschrift in Honor of Rodrigo Ba\~{n}uelos. Progress in Probability, Book 72 (2017).}


% \bibitem{Rudin1987}
% Walter Rudin.
% \newblock {\em {Real and Complex Analysis}}, {\em McGraw-Hill Series in Higher Mathematics}.
% \newblock WCB/McGraw-Hill, 1987.

% \bibitem{Stein2005}
% Elias Stein and Rami Shakarchi.
% \newblock {\em {Real Analysis} Measure Theorem, Integration, \& Hilbert Spaces}, {\em Princeton Lectures in Analysis III}.
% \newblock Princeton University Press, 2005.

% \bibitem{SteinHarmonicAnalysis}
% Elias Stein and Rami Shakarchi.
% \newblock {\em Harmonic Analysis: Real-Variable Methods, Orthogonality, and Oscillatory Integrals}, 1st Edition.
% \newblock Princeton University Press, 1993.

% \bibitem{SteinFunctionalAnalysis}
% Elias Stein and Rami Shakarchi.
% \newblock {\em Functional Analysis: Introduction to Further Topics in Analysis}.
% \newblock Princeton University Press, 2011.

% \bibitem{Thomee1965}
% Vidar Thom{\'{e}}e.
% \newblock {Stability of difference schemes in the maximum-norm}.
% \newblock {\em J. Differ. Equ.}, 1(3):273--292, jul 1965.

% \bibitem{YoshidaFunctionalAnalysis}
% Yoshida, K\^{o}saku.
% \newblock {\em Functional Analysis}, 6th Edition.
% \newblock Springer-Verlag, 1980.

% \end{thebibliography}



\end{document}