\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{physics}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage[shortlabels]{enumitem}
\hypersetup{
	colorlinks,
	linkcolor={black!50!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black}
}
\usepackage{newpxtext,newpxmath}
\usepackage[left=1.25in,right=1.25in,top=1.5in,bottom=1.5in]{geometry}

\newcommand{\f}[2]{\frac{#1}{#2}}


%\newcommand{\fig}[1]{figure #1}
%\newcommand{\explain}{appendix?}
%\newcommand{\rat}{\mathbb{Q}}
%
%\newcommand{\mathbb{R}}{\mathbb{R}}
%\newcommand{\nat}{\mathbb{N}}
%\newcommand{\inte}{\mathbb{Z}}
%\newcommand{\M}{{\cal{M}}}
%\newcommand{\sss}{{\cal{S}}}
%\newcommand{\rrr}{{\cal{R}}}
%\newcommand{\uu}{2pt}
%\newcommand{\vv}{\vec{v}}
%\newcommand{\comp}{\mathbb{C}}
%\newcommand{\field}{\mathbb{F}}
%\newcommand{\f}[1]{ \hspace{.1in} (#1) }
%\newcommand{\set}[2]{\mbox{$\left\{ \left. #1 \hspace{3pt}
%\right| #2 \hspace{3pt} \right\}$}}
%\newcommand{\integral}[2]{\int_{#1}^{#2}}
%\newcommand{\ba}{\hookrightarrow}
%\newcommand{\ep}{\varepsilon}
%\newcommand{\limit}{\operatornamewithlimits{limit}}
%\newcommand{\ddd}{.1in}
%\newcommand{\ccc}{2in}
%\newcommand{\aaa}{1.5in}
%\newcommand{\B}{{\cal B}}
%\newcommand{\C}{{\cal C}}
%\newcommand{\D}{{\cal D}}
%\newcommand{\FF}{{\cal F}}


%\usepackage{epstopdf}
%\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `basename #1 .tif`.png}
%\usepackage{graphics}
%\usepackage{array}
%\def\set#1#2{\left\{\left.\;#1\;\right| #2 \; \right\}}
%\def\Sum{\sum}
%\def\me{.05in}















\begin{document}
\begin{center}
{\Large\bf  MA338 (S'20): Final Exam}\\
$\,$\\
{\Large  Huan Q. Bui}
\end{center}





\noindent \textbf{1. Differentiation}
\begin{enumerate}[(a)]
	\item Assume that 
	\begin{align*}
	f(x) = \begin{cases}
	\frac{g(x)}{x}, \quad x\neq 0\\
	0, \quad x=0
	\end{cases}
	\end{align*}
	and assume that $g(0) = 0$ and $g''(0) = 17$. With no further assumptions, find $f'(0)$, justify everything.
	
	\noindent \textit{\underline{Solution}:} The answer is $\boxed{f'(0) = 17/2}$. The key is using L'H\^{o}pital's rule twice. By definition, 
	\begin{align*}
	f'(0) = \lim_{x\to 0} \frac{f(x) - f(0)}{x-0} = \lim_{x\to 0}\frac{f(x)}{x} = \lim_{x\to 0}\frac{g(x)}{x^2}. 
	\end{align*}  
	Since $g''(0)$ exists, $g'(x)$ must be differentiable at $0$. It follows that $g(x)$ must be continuous at $0$. Now, $g(0)=0$, so $\lim_{x\to 0} g(x) = g(0) = 0$ by continuity. It is also clear that $\lim_{x\to 0} x^2 = 0$. L'H\^{o}pital's rule says that 
	\begin{align*}
	\lim_{x\to 0}\f{g(x)}{x^2} = \lim_{x\to 0}\f{g'(x)}{2x}, 
	\end{align*} 
	provided the limit on the right hand side exists. The evaluate the limit on the right hand side, we apply L'\^{o}pital's rule again: Clearly $\lim_{x\to 0}2x = 0$. It remains to show $\lim_{x\to 0}g'(x) = g'(0) =0$. The first equality follows from the fact that $g'(x)$ is differentiable (hence continuous) at $x=0$. We want to justify the second equality. By definition,
	\begin{align*}
	g'(0) = \lim_{x\to 0}\f{g(x)  -g(0)}{x-0} = \lim_{x\to 0}\f{g(x)}{x} = f(0) = 0.
	\end{align*} 
	So, because $\lim_{x\to 0}g'(x) = 0$ and $\lim_{x\to 0}2x =0$, L'H\^{o}pital's rule says 
	\begin{align*}
	\lim_{x\to 0}\f{g'(x)}{2x} = \lim_{x\to 0}\f{g''(x)}{2} = \f{17}{2}.
	\end{align*}
	Thus, 
	\begin{align*}
	f'(0) = \f{17}{2}.
	\end{align*}
	\hfill $\square$
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\item Assuming only that $f'(0) > 0$ and $f'$ continuous at $0$, prove that there exists an interval containing $0$ on which $f$ is increasing. (This $f$ is in no way related to the previous $f$ in part (a).)
	
	
	
	\noindent \textit{\underline{Proof}:} Since $f'$ is continuous at $0$ and $f'(0) > 0$ there exists a neighborhood $(-\delta,\delta) \subset \mathbb{R}$ on which $f' > 0$. This makes sense, because by definition, for $\epsilon = {f'(0)}/2 > 0$, there exists $\delta >0$ such that whenever $\abs{y-x} < \delta$, $\abs{f'(y) - f'(x)} < \epsilon = {f'(0)}/2 < f'(0)$. The triangle inequality says that $f'(t) > 0$ for all $t\in (-\delta, \delta)$. With this, take $x,y\in (-\delta,\delta)$ such that $x < 0 < y$.
	
	The mean value theorem says that there exists $t \in [x,y]$ such that 
	\begin{align*}
	\f{f(y) - f(x)}{y-x} = f'(t) > 0, \mbox{ since } t\in [x,y] \subset (-\delta,\delta).
	\end{align*}
	Rearranging gives $f(y) - f(x) > (y-x)f'(t)$ for any $x,y\in (-\delta,\delta)$ such that $y>0>x$. We have demonstrated that it is possible to find an interval containing $0$ on which $f$ is increasing.\hfill $\square$
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\item Show that there exists a continuous function $f$ with $f'(0) > 0$, but $f$ is not increasing on any interval containing $0$.
	
	
	\noindent \textit{\underline{Proof}:} Intuitively, we want to construct a function $f$ such that even though $f'(0) >0$, it ``wiggles'' so much that $f$ is never strictly increasing on any interval around zero, no matter how small. This idea suggests picking an $f$ that oscillates faster near zero. To this end, consider $f: \mathbb{R} \to \mathbb{R}$ given by
	\begin{align*}
	f(x) = \begin{cases}
	x + 2x^2\sin\f{1}{x},\quad x \neq 0\\
	0,\quad x=0
	\end{cases}
	\end{align*}
	\begin{figure}[!htb]
		\centering
		\includegraphics[scale=0.35]{f}
	\end{figure}
	
	We first show that $f$ is continuous. When $x\neq 0$, $f$ is clearly continuous. So we only focus on showing $f$ is continuous at $0$. Let $\epsilon > 0$ be given, then
	\begin{align*}
	\abs{f(x) - f(0)} = \abs{f(x)} \leq \abs{x} + \abs{2x^2 \sin\f{1}{x}} \leq \abs{x} + 2\abs{x^2}. 
	\end{align*}
	Choose $\delta = \min\{1, \epsilon/3\}$. Then whenever $\abs{x-0} < \delta$, we have
	\begin{align*}
	\abs{f(x) - f(0)} \leq \abs{x} + 2\abs{x^2} = \abs{x}(2\abs{x} + 1) < \f{\epsilon}{3}\cdot 3 < \epsilon.
	\end{align*}
	This shows $f$ is continuous. Next, we want to show $f'(0) > 0$. To this end, we just evaluate $f'(0)$. By definition,
	\begin{align*}
	f'(0) = \lim_{x\to 0} \f{f(x) - f(0)}{x-0} = \lim_{x\to 0 }\f{f(x)}{x} = \lim_{x\to 0} \left( 1 + 2x\sin\f{1}{x}\right)= 1 > 0
	\end{align*}
	since $x\sin(1/x) \to 0$ as $x\to 0$. Finally, we will show that $f$ is not increasing on any interval containing 0. Assume (to get a contradiction) that $f$ is increasing on some interval containing 0. Because $f'$ is continuous and positive at 0, there exists an interval containing 0 on which $f'>0$ (we proved this in the last item). Now, look at $f$ again. For $x\neq 0$, 
	\begin{align*}
	f'(x) = 1-2\cos\f{1}{x} + 4x\sin\f{1}{x}.
	\end{align*}
	Let an interval containing $0$ be given. It is possible to find a sufficiently small $t$ in this interval such that $\cos(1/t) = 1$ and $\abs{4t} < 1/2$ (This is possible because $1/t$ will be sufficiently large in magnitude and $\cos$ is periodic.) It follows that
	\begin{align*}
	\abs{f'(t) + 1} = \abs{1-2 + 4t\sin\f{1}{t} + 1} = \abs{4t\sin\f{1}{t}} \leq \abs{4t} < 1/2,  
	\end{align*} 
	which implies $-3/2 < f(t) < -1/2$. Clearly, $f(t) < 0$, which contradicts the fact that there exists an interval containing 0 on which $f'(t) > 0$ for all $t$ on that interval.  \hfill $\square$
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\item Assume that $\abs{f(x) - f(y)} \leq (x-y)^2$ for all $x,y\in \mathbb{R}$. Prove that $f$ is a constant function. 
	
	
	
	\noindent \textit{\underline{Proof}:} Let $\delta > 0$ be given. Pick $x,y \in \mathbb{R}$ such that $0 < x-y< \delta$. Because $\abs{f(x) - f(y)} \leq (x-y)^2$ for all $x,y\in \mathbb{R}$, we have
	\begin{align*}
	0 \leq \f{\abs{f(x) - f(y)}}{x-y} = \abs{\f{f(x) - f(y)}{x-y}} \leq x-y < \delta.
	\end{align*}
	Since this holds for any $\delta > 0$, $f'(x) = 0$ for all $x\in\mathbb{R}$ (because $f'(x)$ is the limit of the difference quotient as $y\to x$). This means $f$ is constant, by Theorem 5.11(b), Baby Rudin. \hfill $\square$
\end{enumerate}






\newpage



\noindent \textbf{2. Series}

\begin{enumerate}[(a)]
	\item Prove that if $\sum^\infty_{n=1}a_n$ is absolutely convergent then 
	\begin{align*}
	\abs{\sum^\infty_{n=1}a_n} \leq \sum^\infty_{n=1}\abs{a_n}.
	\end{align*} 
	
	
	
	\noindent \textit{\underline{Proof}:} Since $\sum^\infty_{n=1}a_n$ converges absolutely, $\sum^\infty_{n=1}a_n$ converges (Theorem 3.45). Let $C = \sum^\infty_{n=1}a_n$. Consider the sequence $\{\abs{s_N}\}$ where each $s_N = {\lim^{N}_{n=1}a_n}$.  Clearly, 
	\begin{align*}
	\abs{\abs{s_N} - \abs{C}} \leq \abs{ s_N - C} \to 0, \mbox{ as } N\to \infty.
	\end{align*}
	Thus, $\lim_{N\to \infty}\abs{s_N} = \abs{C}$. Now, for each $N$, we also have the triangle inequality:
	\begin{align*}
	\abs{s_N} = \abs{\sum^N_{n=1}a_n} \leq \sum^N_{n=1}\abs{a_n}.
	\end{align*}
	Taking $N\to \infty$ on both sides we have
	\begin{align*}
	\lim_{N\to \infty}\abs{s_N} = \abs{C} =  \abs{\sum^\infty_{n=1}a_n} \leq \lim_{N\to \infty} \sum^N_{n=1}\abs{a_n} = \sum^\infty_{n=1}\abs{a_n}.
	\end{align*}
 	\hfill $\square$
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	\item Show that if $\sum^\infty_{n=1}a_n$ is absolutely convergent and $b_n$ is a subsequence of $a_n$, then $\sum^\infty_{n=1}b_n$ is absolutely convergent. Given an example that shows this statement is false if $\sum^\infty_{n=1}a_n$ is assumed to be only conditionally convergent. 
	
	
	
	\noindent \textit{\underline{Proof}:} The absolute convergence of $\sum^\infty_{n=1}a_n$ implies the convergence of $\sum^\infty_{n=1}\abs{a_n}$. Since $b_n$ is a subsequence of $a_n$, we must have that
	\begin{align*}
	\sum^\infty_{n=1}\abs{b_n} \leq \sum^\infty_{n=1}\abs{a_n} < \infty, 
	\end{align*} 
	where the first inequality follows because we are summing only nonnegative terms. Therefore, $\sum^\infty_{n=1}b_n$ is absolutely convergent. 
	
	
	When $\sum^\infty_{n=1}a_n$ is assumed to be only conditionally convergent, that is $\sum^\infty_{n=1}\abs{a_n}$ is divergent, then the statement is false. Consider the conditionally convergent series $\sum^\infty_{n=1}(-1)^{n+1}/n$:
	\begin{align*}
	\sum^\infty_{n=1}(-1)^{n+1}/n = 1 - \f{1}{2} + \f{1}{3} - \f{1}{4} + \dots
	\end{align*}
	We know that $\sum^\infty_{n=1}1/n$ is divergent (harmonic series). Call $a_n = (-1)^{n+1}/n$. Clearly, $\abs{a_1}\geq \abs{a_2} \geq \dots$; the sequence $\{a_n\}$ is alternating; and $\lim_{n\to \infty} a_n = 0$. Theorem 3.43 (alternating series test) tells us that $\sum^\infty_{n=1}(-1)^{n+1}/n$ is convergent. Hence, $\sum^\infty_{n=1}(-1)^{n+1}/n$ is conditionally convergent. 
	
	Consider the subsequence $\{b_n\}$ of $\{a_n\}$ consisting only of the terms of $a_n$ where $n$ is odd:
	\begin{align*}
	\sum^\infty_{n=1}b_n = 1 + \f{1}{3} + \f{1}{5} + \f{1}{7} + \dots
	\end{align*}
	We want to show that the series $\sum^\infty_{n=1}b_{n}$ is NOT absolutely convergent. We notice that
	\begin{align*}
	\sum^\infty_{n=1}\abs{b_n} = \sum^\infty_{n=1}b_n = 1 + \f{1}{3} + \f{1}{5} + \f{1}{7} + \dots = \sum^\infty_{n=1}\f{1}{2n-1}
	\end{align*}
	So this comes down to determining the convergence of $\sum^\infty_{n=1} b_n$. It turns out that $\sum^\infty_{n=1}b_n > \infty$ because it fails the integral test:
	\begin{align*}
	\int_1^\infty \f{1}{2n-1}\,dn = \lim_{k\to \infty}\int^k_1 \f{1}{2n-1}\,dn = \f{1}{2}\ln (1+2k) \to \infty
	\end{align*}
	as $k\to \infty$. Thus, $\sum^\infty_{n=1}b_n$ is NOT absolutely convergent. Therefore, the statement is false when $\sum^\infty_{n=1}a_n$ is only conditionally convergent. \hfill $\square$ 	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	 
	\item Assume $a_n$ is a decreasing sequence of positive numbers, and that $\sum^\infty_{n=1}a_n$ converges. Prove that $\lim_{n\to \infty}na_n = 0$.
	
	\noindent \textit{\underline{Proof}:} The key here is to put an upper bound on $na_n$ and show that bound goes to zero as $n\to \infty$. Consider the partial sum $S_n = \sum^{n}_{i=1}a_i$. We have
	\begin{align}
	S_{2n} - S_n &= \sum_{i={n+1}}^{2n} = a_{2n} + a_{2n-1} + \dots + a_{n+1}\\
	&\geq a_{2n} + a_{2n} + \dots + a_{2n}\\
	&= na_{2n}.
	\end{align}
	where we have used the condition that $a_n$ is a decreasing sequence of positive numbers to get the inequality. Now, $\sum^\infty_{n=1}a_n$ is convergent, so the sequence of partial sums is convergent, hence Cauchy. It follows that for any $\epsilon > 0$, there exists $N \in \mathbb{N}$ such that whenever $n \geq N$, 
	\begin{align*}
	\abs{na_{2n}} \leq \abs{S_{2n} - S_n} = \abs{\sum_{i={n+1}}^{2n}} < \epsilon.
	\end{align*}
	Thus $\lim_{n\to\infty} na_{2n} = 0$ and so $\lim_{n\to \infty}2na_{2n} = 0$. Further,
	\begin{align*}
	(2n+1)a_{2n+1} \leq (2n+1)a_{2n} = \left(1 + \f{1}{2n}\right)(2na_n) \leq 2\cdot 2na_{2n} = 4na_{2n},
	\end{align*}
	which also goes to 0 as $n\to \infty$. So, because both $na_{n} \to 0$ as $n\to \infty$ for all $n$ (odd or even), $\lim_{n\to \infty} na_n = 0$. \hfill$\square$
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	 
	\item Prove that every positive rational number can be written as a finite sum of \textit{distinct} numbers of the form $1/k$ with $k\in \mathbb{N}$.
	
	
	
	\noindent \textit{\underline{Proof}:} We will first show this is true for all rationals $r$ such that $0 \leq r=p/q < 1$ where $p,q$ are positive integers with no common factor. If $r=0$ or $p=1$ then the statement is true. Assume (an inductive hypothesis) that the statement holds for all rationals $r$ above but with $p<P$. Consider the rational number $P/q < 1$. We can always find the least positive integer $m$ such that $1/m \leq P/q$. Because $P/q < 1$ and $m$ is an integer, we have 
	\begin{align*}
	\f{1}{m} \leq \f{P}{q} < \f{1}{m-1} \implies mP - P < q \leq mP \implies 0 \leq mP-q < P.
	\end{align*}  
	Let the residual $R = P/q - 1/m = (mP-q)/qm$. Because $mP -q < P$, $R$ can be written as a finite sum of distinct $1/k$'s, $k\in \mathbb{N}$. We also have that 
	\begin{align*}
	R < \f{1}{m-1} - \f{1}{m} = = \f{1}{m(m-1)} \leq \f{1}{m}.
	\end{align*} 
	So, $1/m$ cannot appear in the finite sum for $R$. This means $r = P/q = R + 1/m$ can be written as a finite sum of distinct $1/k$'s. By induction, all rationals less than 1 can be written as a finite sum of distinct $1/k$'s, $k\in \mathbb{N}$. 
	
	We now want to extend this to all rationals greater than or equal to 1. We now use the fact that $\sum^\infty_{n=1}1/n = \infty$. Let $S_n = \sum^n_{i=1}1/i$, which is rational. Let a rational $r \geq 1$ be given. There exists $n\in \mathbb{N}$ such that 
	\begin{align*}
	S_{n} \leq r < S_{n+1}.
	\end{align*}
	Now let us write $r = (r - S_n) + S_n$, which is a sum of two rational numbers. By the choice of $n$,
	\begin{align*}
	r - S_n < S_{n+1} - S_n = \f{1}{n+1} < 1,
	\end{align*} 
	which means $r - S_n$ can be written as a finite sum of distinct $1/k$'s, $k\in \mathbb{N}$. Further, none of the summands in the sum for $r - S_n$ is can be greater than $1/(n+1)$, which means no summand in the sum for $r-S_n$ can be a summand of $S_n$, which is a finite sum of distinct $1/k$'s, $k\in \mathbb{N}$. Therefore, $r$ can be written as a finite sum of distinct numbers of the form $1/k$ with $k \in \mathbb{N}$. \hfill $\square$
	
 	
	 
\end{enumerate}




\newpage









\noindent \textbf{3. Hilbert Space}

\begin{enumerate}[(a)]
	\item Let $V$ denote the set of continuous functions that map $[0,1]$ into the complex numbers $\mathbb{C}$. With $f\in V$, each complex number $f(x)$ can be written in terms of its real and imaginary parts
	\begin{align*}
	f(x) = \Re{f(x)} + i\Im{f(x)}.
	\end{align*}
	The real valued functions $\Re{f}$ and $\Im{f}$ are called the real part of $f$ and the imaginary part of $f$, respectively. We define the integral of a complex valued function by 
	\begin{align*}
	\int^1_0 f(x)\,dx \equiv \int^1_0 \Re{f(x)}\,dx + i\int^1_0\Im{f(x)}\,dx.
	\end{align*}
	Show that the assignment 
	\begin{align*}
	\langle f,g \rangle \equiv \int^1_0 f(x)\overline{g(x)}\,dx
	\end{align*}
	satisfies the axioms of a complex inner product (find the axioms in a book or on the internet).
	
	
	
	
	
	
	
	
	\noindent \textit{\underline{Proof}:} Let $f,g,h\in V$ and $c\in \mathbb{C}$ be given.
	\begin{itemize}
		\item $\boxed{\langle f,g \rangle = \overline{\langle g,f\rangle}}$. We have that
		\begin{align*}
		\langle f,g \rangle \equiv \int^1_0 f(x)\overline{g(x)}\,dx
		\end{align*}
		and
		\begin{align*}
		g(x)\overline{f(x)} &= \left[\Re{g(x)} + i\Im{g(x)}\right]\left[\Re{f(x)} - i\Im{f(x)}\right]\\
		&= \left[\Re{f(x)}\Re{g(x)} + \Im{f(x)}\Im{g(x)}\right] \\
		&\qquad + i\left[\Im{g(x)}\Re{f(x)} - \Re{g(x)}\Im{f(x)}\right],
		\end{align*}
		\begin{align*}
		f(x)\overline{g(x)} &= \left[\Re{f(x)} + i\Im{f(x)}\right]\left[\Re{g(x)} - i\Im{g(x)}\right]\\
		&= \left[\Re{g(x)}\Re{f(x)} + \Im{g(x)}\Im{f(x)}\right] \\
		&\qquad + i\left[\Im{f(x)}\Re{g(x)} - \Re{f(x)}\Im{g(x)}\right].
		\end{align*}
		So, $\Re{g(x)\overline{f(x)}} = \Re{f(x)\overline{g(x)}}$ and $\Im{g(x)\overline{f(x)}} = -\Im{f(x)\overline{g(x)}}$
		\begin{align*}
		\overline{\langle g,f \rangle} &= \overline{\int^1_0 g(x)\overline{f(x)}\,dx}\\
		&= \overline{\int^1_0 \Re{g(x)\overline{f(x)}}\,dx + i\int^1_0 \Im{g(x)\overline{f(x)}}\,dx}\\
		&= \int^1_0 \Re{g(x)\overline{f(x)}}\,dx - i\int^1_0 \Im{g(x)\overline{f(x)}}\,dx\\
		&= \int^1_0 \Re{f(x)\overline{g(x)}}\,dx + i\int^1_0 \Im{f(x)\overline{g(x)}}\,dx\\
		&= \int^1_0 f(x)\overline{g(x)}\,dx \\
		&= \langle f,g\rangle.
		\end{align*}
		
		
		
		
		
		\item $\boxed{\langle f+g ,h \rangle  = \langle f,h \rangle + \langle g,h\rangle}$. We have that 
		\begin{align*}
		\Re{(f+g)h} = \Re{fh + gh} =\Re{fh} + \Re{gh}\\
		\Im{(f+g)h} = \Im{fh + gh} =\Im{fh} + \Im{gh}
		\end{align*}
		So,
		\begin{align*}
		\langle f+g,h\rangle &= \int^1_0 (f+g)\overline{h}\,dx \\
		&= \\
		&= \\
		&= 
		\end{align*}
		
		
		\item $\boxed{\langle f, g+h \rangle  = \langle f,g \rangle + \langle f,h\rangle}$
		
		
		\item $\boxed{\langle cf,g\rangle = c\langle f,g\rangle}$
		
		\item $\boxed{\langle f,cg\rangle = \overline{c}\langle f,g\rangle}$
		
		
		\item $\langle f,f\rangle$ is a nonnegative real number and $\langle f,f \rangle = 0$ if and only if $f=0$.
		
		
		
	\end{itemize}  
	
	
	
	
	
	
	
	
	
	\item Assume $V$ is a complex inner product space with inner product $\langle x,y \rangle$ and its associated metric
	\begin{align*}
	d(x,y) = \sqrt{\langle x-y,x-y \rangle}
	\end{align*}
	and let $\mathcal{H}$ denote the metric completion of $V$. Thus we may think of $V$ as a dense subset of the metric space $\mathcal{H}$. The purpose of the following exercises is to show how one may extend the vector space structure of $V$ to $\mathcal{H}$, and how to extend the inner product to $\mathcal{H}$, which shows that the metric completion of an inner product space is a Hilbert space. 
	
	
	\begin{itemize}
		\item Given $x,y\in \mathcal{H}$ and $\alpha,\beta \in \mathbb{C}$, we define $\alpha x + \beta y$ to be the limit of the sequence $\alpha x_i + \beta y_i$, where $x_i$ is any sequence in $V$ converging to $x$, $y_i$ is any sequence in $V$ converging to $y$. Show that this definition is well-defined. 
		
		
		\item Imitate the procedure above to show how to extend the inner product so that $\langle x,y\rangle$ is defined for all $x,y\in \mathcal{H}$. (Hint: extend one variable at a time.)
	\end{itemize}
\end{enumerate}



\newpage








\noindent \textbf{4. Isometries}

\begin{enumerate}[(a)]
	\item Assume that $f: \mathbb{R} \to \mathbb{R}$ satisfies $\abs{f(x) - f(y)} = \abs{x-y}$ for all $x,y\in \mathbb{R}$. Prove that 
	\begin{align*}
	f(x) = mx+b
	\end{align*}
	with $m=1$ or $m=-1$.
	
	\item Prove that there does not exist a function $f: \mathbb{R}^2 \to \mathbb{R}$ that satisfies $\abs{f(x) - f(y)} = \norm{x-y}$ for all $x,y\in \mathbb{R}^2$.
	
	
	\item Prove that if $f: \mathbb{R}^n \to \mathbb{R}^n$ satisfies $\norm{f(x) - f(y)} = \norm{x-y}$ for all $x,y\in \mathbb{R}^n$ then $f$ is onto.
	
	
	
	
	\item Let $\mathcal{H}$ denote an infinite dimensional (real or complex) Hilbert space. Given an example of a function $f: \mathcal{H} \to \mathcal{H}$ that satisfies 
	\begin{align*}
	\norm{f(x) - f(y)} = \norm{x-y}
	\end{align*} 
	for all $x,y\in \mathcal{H}$ but $f$ is \textit{not} onto. 
\end{enumerate}



\end{document}




