\documentclass[11pt]{article}
\usepackage{amsmath}
\usepackage{physics}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{hyperref}
\usepackage{amsfonts}
\usepackage{cancel}
\usepackage{xcolor}
\hypersetup{
	colorlinks,
	linkcolor={black!50!black},
	citecolor={blue!50!black},
	urlcolor={blue!80!black}
}
\usepackage{newpxtext,newpxmath}
\usepackage[left=1.25in,right=1.25in,top=0.9in,bottom=0.9in]{geometry}


%\newcommand{\fig}[1]{figure #1}
%\newcommand{\explain}{appendix?}
%\newcommand{\rat}{\mathbb{Q}}
%
%\newcommand{\mathbb{R}}{\mathbb{R}}
%\newcommand{\nat}{\mathbb{N}}
%\newcommand{\inte}{\mathbb{Z}}
%\newcommand{\M}{{\cal{M}}}
%\newcommand{\sss}{{\cal{S}}}
%\newcommand{\rrr}{{\cal{R}}}
%\newcommand{\uu}{2pt}
%\newcommand{\vv}{\vec{v}}
%\newcommand{\comp}{\mathbb{C}}
%\newcommand{\field}{\mathbb{F}}
%\newcommand{\f}[1]{ \hspace{.1in} (#1) }
%\newcommand{\set}[2]{\mbox{$\left\{ \left. #1 \hspace{3pt}
%\right| #2 \hspace{3pt} \right\}$}}
%\newcommand{\integral}[2]{\int_{#1}^{#2}}
%\newcommand{\ba}{\hookrightarrow}
%\newcommand{\ep}{\varepsilon}
%\newcommand{\limit}{\operatornamewithlimits{limit}}
%\newcommand{\ddd}{.1in}
%\newcommand{\ccc}{2in}
%\newcommand{\aaa}{1.5in}
%\newcommand{\B}{{\cal B}}
%\newcommand{\C}{{\cal C}}
%\newcommand{\D}{{\cal D}}
%\newcommand{\FF}{{\cal F}}


%\usepackage{epstopdf}
%\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `basename #1 .tif`.png}
%\usepackage{graphics}
%\usepackage{array}
%\def\set#1#2{\left\{\left.\;#1\;\right| #2 \; \right\}}
%\def\Sum{\sum}
%\def\me{.05in}















\begin{document}
\begin{center}
{\Large\bf  The Riemann-Stieltjes Integral:  6.1, 2, 3, 4, 5, 8, Baby Rudin}\\
$\,$\\
{\Large  Huan Q. Bui}
\end{center}




\noindent \textbf{6.1}
\noindent \textit{Proof:} $f$ is clearly bounded on $[a,b]$ and is discontinuous at exactly the point $x_0$, where $\alpha$ is continuous. Theorem 6.10 says these conditions imply $f \in \mathscr{R}(\alpha)$. So, for any partition $P$ of $[a,b]$, we have $\int^b_a f\,d\alpha = \sup L(P,f,\alpha) = \sup \sum^n_{i=1}\Delta \alpha_i \inf_{x\in [x_{i-1},x_i] }f $. Look at each interval, $[x_{i-1},x_i]$. If the interval has nonzero length then $\inf f$ on it is zero. If the interval is just the point $x_0$ then $\Delta \alpha_i$ is zero. So in any case, $\sup L(P,f,\alpha) = 0$, which means $\int f\, d\alpha = 0.$ \hfill $\square$\\


\noindent \textbf{6.2}
\noindent \textit{Proof:} We have $f\geq 0$ continuous on $[a,b]$ and $\int^b_a f\,dx = 0$. We first note that for $c,d \in [a,b]$ such that $c\leq d$, $\int^d_c f\,dx \geq 0$ because $f\geq 0$ for all $x \in [a,b]$. Now, suppose $f(x_0) > 0$ for some $x_0 \in [a,b]$. Let $\epsilon = f(x_0)/2 > 0$ be given. By continuity, there exists a small enough $\delta > 0$ such that $\abs{f(x) - f(x_0)} < \epsilon = f(x_0)/2 \implies f(x) > f(x_0)/2 $  for some $x$ in $(x_0 - \delta, x_0 + \delta)$. With this, we write
\begin{align*}
\int^b_a f\,dx = \int^{x_0 - \delta}_a f\,dx + \int^{x_0+\delta}_{x_0 - \delta}f\,dx + \int^b_{x_0+\delta}f\,dx \geq 0 + \delta f(x_0) + 0 > 0,
\end{align*}
which is a contradiction. So $f = 0$ on $[a,b]$. \hfill $\square$\\





\noindent \textbf{6.3}
\noindent \textit{Proof:} Define three functions $\beta_1, \beta_2, \beta_3$ as: $\beta_j(x) = 0$ if $x < 0$, $\beta_j (x) = 1$ if $x > 0$ for $j=1,2,3$; and $\beta_1(0) =0 , \beta_2(0) = 1, \beta_3(0) = 1/2$. $f$ is a bounded function on $[-1,1]$ .  
\begin{enumerate}
	\item We want to show $f \in \mathscr{R}(\beta_1) \iff \lim_{x\to 0+}f(x) \equiv f(0+) = f(0)$ and that then $\int f\,d \beta_1 = f(0)$. 
	\begin{enumerate}
		\item $(\rightarrow)$ Suppose $f \in \mathscr{R}(\beta_1)$. To prove the implication we want to look at what happens to $f$ as $x \to 0+$. Since $f \in \mathscr{R}(\beta_1)$ on $[-1,1]$, $f\in \mathscr{R}(\beta_1)$ on $[0,1]$ as well. Let $\epsilon > 0$ be given. Theorem 6.6. says that $f \in \mathscr{R}(\beta_1)$ on $[0,1] \iff \forall \epsilon > 0\exists$ a partition $P$ such that $U(P,f,\beta_1) - L(P,f,\beta_1) < \epsilon$. For any $x \in [0,\delta]$ where $0 < \delta < 1$, we have that 
		\begin{align*}
		L(P,f,\beta_1) \leq f(x) \leq U(P,f,\beta_1).
		\end{align*}
		Further, since $0 \in [0,1]$ 
		\begin{align*}
		L(P,f,\beta_1) \leq f(0) \leq U(P,f,\beta_1).
		\end{align*}
		So, $\abs{f(x) - f(0)} \leq U(P,f,\beta_1) - L(P,f,\beta_1) < \epsilon$. Since $\epsilon$ and $\delta$ can be made arbitrarily small, we have that $\lim_{x\to 0+}f(x) = f(0+) = f(0)$. 
		
		\item $(\leftarrow)$ Let $\epsilon > 0$ be given. Suppose $\lim_{x\to 0+}f(x) = f(0)$, then there exists $\delta > 0$ such that whenever $0 \leq x < \delta$, $\abs{f(x) - f(0)} < \epsilon$. Okay, fix any $y \in (0,\delta)$, set $M = \sup_{y\in (0,\delta)} f(y), m = \inf_{y\in (0,\delta)} f(y)$. Then clearly, for any $y \in (0,\delta)$, $M \geq f(y)$ and $m \leq f(y)$. This combines with $f(0+) = f(0)$ mean we can remove the absolute value sign and write $M - f(y) < \epsilon$ and $f(y) - m < \epsilon$. This imply 
		\begin{align*}
		M - m < 2\epsilon.
		\end{align*}
		Let a partition $P$ of $[-1,1]$ be given. Then we immediately have $U(P,f,\beta_1) = M$ and $L(P,f,\beta_1) = m$ (because $\beta_1(x) = 0$ for all $x<0$, which means there's no contribution from $d\beta_1$ from $x<0$). So, because the following holds for any arbitrary $P$ of $[-1,1]$
		\begin{align*}
		U(P,f,\beta_1) - L(P,f,\beta_1)  = M-n < 2\epsilon,
		\end{align*} 
		$f \in \mathscr{R}(\beta_1)$ on $[-1,1]$. So we're done. 
		
		\item Showing $\int f\,d\beta_1 = f(0)$ is easy. Since we have shown that for any partition $P$  of $[-1,1]$ and $\epsilon > 0$,  $U(P,f,\beta_1) - L(P,f,\beta_1) < \epsilon $. And because $L(P,f,\beta_1) \leq f(0)\cdot (\beta_1(x_j > 0) - \beta_1(0)) =f(0) \leq U(P,f,\beta_1)$, we must have that $f(0) = U(P,f,\beta_1) = L(P,f,\beta_1) = \int f\,d\beta_1$. 
	\end{enumerate}


	\item For $\beta_2$, the statement becomes $f \in \mathscr{R}(\beta_2) \iff f(0-) = f(0)$ and that then $\int f\,d\beta_2 = f(0)$. The proof is very similar to that in the previous item, except that we look at what happens when $x\to 0-$. The difference comes from the fact that $\beta_1(0) =0$ while $\beta_2(0) = 1$, that is the ``jump'' occurs at a different location. 
	
	
	\item We want to prove $f\in \mathscr{R}(\beta_3) \iff f$ is continuous at $0$, i.e., $f(0-) = f(0) = f(0+)$.  
	\begin{enumerate}
		\item $(\to)$ Suppose $f\in \mathscr{R}(\beta_3)$, then Theorem 6.6. says there is a partition $P$ such that $U(P,f,\beta_3) - L(P,f,\beta_3) < \epsilon$. Consider the numbers $\gamma < 0 < \rho$ in the partition $P$. For $u \in (\gamma, 0]$ and $v \in [0 ,\rho)$, we have that 
		\begin{align*}
		&L(P,f,\beta_3) \leq f(u)(\underbrace{\beta_3(0) - \beta_3(\gamma)}_{1/2}) + f(0)(\underbrace{\beta_3(\rho) - \beta_3(0)}_{1/2}) \leq U(P,f,\beta_3)\\
		&L(P,f,\beta_3) \leq f(v)(\underbrace{\beta_3(\rho) - \beta_3(0)}_{1/2}) + f(0)(\underbrace{\beta_3(0) - \beta_3(\gamma)}_{1/2}) \leq U(P,f,\beta_3).
		\end{align*} 
		In a similar fashion we also have 
		\begin{align*}
		L(P,f,\beta_3) \leq \frac{1}{2}f(0) + \frac{1}{2}f(0) = f(0) \leq U(P,f,\beta_3).
		\end{align*}
		Combining these we have
		\begin{align*}
		&\abs{f(u) - f(0)} \leq 2\abs{U(\dots) - L(\dots)} < \epsilon\\
		&\abs{f(v) - f(0)} \leq 2\abs{U(\dots) - L(\dots)} < \epsilon.
		\end{align*}
		So, $f(0-) = f(0) = f(0+)$. 
		
		\item $(\leftarrow)$ Suppose $f(0-) = f(0) = f(0+)$. Then we just have $f(0) = f(0-)$ and $f(0) = f(0+)$ (duh). But this allows us to repeat the proof in part (a) and (b) to get $f \in \mathscr(R)(\beta_3)$. 
		
	\end{enumerate}

	\item If $f$ is continuous at $0$ then (c) holds. Parts (a) and (b) hold automatically. So we're done. 
\end{enumerate}
\hfill $\square$\\



\noindent \textbf{6.4}
\noindent \textit{Proof:} Let $f(x) = 0$ for all irrational $x$, $f(x) = 1$ for all rational $x$. We want to show $f \notin \mathscr{R}$ on $[a,b]$ for any $a<b$. Well, let a partition $P$ be given. Both the rationals and irrationals are dense in $[a,b]$. So, for every little interval $[x_i,x_{i+1}]$, $\sup f = 1$. So, $U(P,f) = \sum^n_{i=1}\sup_{[x_i,x_{i+1}]} f(x)\Delta x_i = b-a$. Also, for every little interval $[x_i,x_{i+1}]$, $\inf f  =0$, so $L(P,f) = \sum^n_{i=1} \inf_{[x_i,x_{i+1}]} f(x) \Delta x_i = 0$. Obviously, $\underline{\int}f = \sup_P L = 0 < \inf_P U = b-a = \overline{\int}f$, so $f \notin \mathscr{R}$ on $[a,b]$. \hfill $\square$ \\


\noindent \textbf{6.5}
\noindent \textit{Proof:} Suppose $f$ is a bounded real function on $[a,b]$ and $f^2 \in \mathscr{R}$ on $[a,b]$. 
\begin{enumerate}
	\item $f\notin \mathscr{R}$, because we can't ``invert'' $f^2$ to get $f$ back. Consider the counter example: 
	\begin{align*}
	f(x) = \begin{cases}
	1, x \in [a,b] \cap \mathbb{Q}\\
	-1, x \in [a,b] \cap \mathbb{Q}^c
	\end{cases}
	\end{align*}
	Then $f^2 = 1 \in \mathscr{R}$. However, similar to last problem, we can show $L(P,f) = -1$ and $U(P,f) = 1$ for any partition $P$ of $[a,b]$. So, $f \notin \mathscr{R}$.  
	
	\item $f\in \mathscr{R}$ if $f^3 \in \mathscr{R}$. In this case we can ``invert'' $f^3$. Consider the continuous function $\phi$ on $[a,b]$ defined by $\phi(x) = x^{1/3}$. Since $f$ is bounded, Theorem 6.11., the function $h(x) = \phi(f^3(x)) = f(x) \in \mathscr{R}$ on $[a,b]$. 
\end{enumerate}
\hfill $\square$\\

\noindent \textbf{6.8}
\noindent \textit{Proof:} Suppose $f(x) \geq 0$ and that $f$ decreases monotonically on $[1,\infty)$. We want to show $\int^\infty_1 f\,dx$ converges $\iff$ $\sum^\infty_{n=1} f(n)$ converges.  
\begin{enumerate}
	\item $(\to)$ Suppose $\int^\infty_1f\,dx$ converges, that is, $\lim_{b\to \infty} \int_1^b f\,dx$ exists. We want to show $\sum^\infty_{n=1}f(n)$ converges, i.e., $\sum^{k}_{n=1}f(n)$ is bounded ($f$ is monotonic \& Theorem 3.14). Well, 
	\begin{align*}
	\sum^k_{n=1}f(n) = f(1) + \sum^k_{n=2}f(n)\leq f(1) + \int^k_{1}f(x)\,dx.
	\end{align*}   
	We note that $\lim_{k\to \infty} \int^k_{1} f\,dx$ exists, so $\sum^k_{n=1}f(n)$ is bounded for all $k$. And so, $\sum^\infty_{n=1} f(n)$ converges. 
	
	\item $(\leftarrow)$ We also have that 
	\begin{align*}
	\sum^k_{n=1}f(n) = f(1) + \sum^k_{n=2}f(n)\leq f(1) + \int^k_{1}f(x)\,dx \leq \sum^{k-1}_{n=1}f(n)
	\end{align*}
	which means if $\int^\infty_{1}f\,dx$ diverges, $\sum^\infty_{n=1}f(n)$ diverges as well. So, by contraposition, if $\sum^\infty_{n=1}f(n)$ converges, the integral $\int^\infty_1 f\,dx$ also converges. 
\end{enumerate}\hfill $\square$
  
\end{document}




